{"version":3,"sources":["../node_modules/array-flat-polyfill/index.mjs","../node_modules/clone/clone.js","../node_modules/vega-util/build/vega-util.module.js","../node_modules/vega-lite/src/util.ts","../node_modules/vega-lite/node_modules/fast-json-stable-stringify/index.js","../node_modules/vega-lite/src/channel.ts","../node_modules/vega-lite/src/axis.ts","../node_modules/vega-lite/src/legend.ts","../node_modules/vega-lite/src/log/message.ts","../node_modules/vega-lite/src/log/index.ts","../node_modules/vega-lite/src/type.ts","../node_modules/vega-lite/src/scale.ts","../src/util.ts","../node_modules/datalib/src/util.js","../src/property.ts","../node_modules/vega-lite/src/mark.ts","../src/wildcard.ts","../src/config.ts","../node_modules/vega-lite/src/aggregate.ts","../node_modules/vega-lite/src/bin.ts","../node_modules/vega-lite/src/channeldef.ts","../node_modules/vega-lite/src/datetime.ts","../node_modules/vega-lite/src/timeunit.ts","../node_modules/vega-lite/src/compile/scale/type.ts","../src/query/expandedtype.ts","../src/propindex.ts","../node_modules/vega-lite/src/encoding.ts","../node_modules/vega-lite/src/stack.ts","../src/query/spec.ts","../src/query/shorthand.ts","../src/query/encoding.ts","../node_modules/datalib/node_modules/d3-time/build/d3-time.js","../node_modules/datalib/src/time.js","../node_modules/datalib/src/bins/bins.js","../node_modules/datalib/src/import/type.js","../node_modules/datalib/src/generate.js","../node_modules/datalib/src/stats.js","../node_modules/d3-time/src/interval.js","../node_modules/d3-time/src/millisecond.js","../node_modules/d3-time/src/duration.js","../node_modules/d3-time/src/second.js","../node_modules/d3-time/src/minute.js","../node_modules/d3-time/src/hour.js","../node_modules/d3-time/src/day.js","../node_modules/d3-time/src/week.js","../node_modules/d3-time/src/month.js","../node_modules/d3-time/src/year.js","../node_modules/d3-time/src/utcMinute.js","../node_modules/d3-time/src/utcHour.js","../node_modules/d3-time/src/utcDay.js","../node_modules/d3-time/src/utcWeek.js","../node_modules/d3-time/src/utcMonth.js","../node_modules/d3-time/src/utcYear.js","../node_modules/vega-time/build/vega-time.module.js","../src/schema.ts","../src/constraint/base.ts","../src/constraint/field.ts","../src/constraint/value.ts","../src/constraint/encoding.ts","../src/constraint/spec.ts","../src/enumerator.ts","../src/query/groupby.ts","../src/nest.ts","../src/wildcardindex.ts","../src/model.ts","../src/query/normalize.ts","../src/result.ts","../src/ranking/effectiveness/type.ts","../src/ranking/effectiveness/base.ts","../src/ranking/effectiveness/typechannel.ts","../src/ranking/effectiveness/mark.ts","../src/ranking/effectiveness/index.ts","../src/ranking/effectiveness/axis.ts","../src/ranking/effectiveness/dimension.ts","../src/ranking/effectiveness/facet.ts","../src/ranking/effectiveness/sizechannel.ts","../src/ranking/aggregation.ts","../src/ranking/fieldorder.ts","../src/ranking/ranking.ts","../src/stylize.ts","../src/generate.ts","../src/recommend.ts"],"names":["Array","prototype","flat","Object","defineProperty","configurable","value","r","t","isNaN","arguments","Number","reduce","call","this","a","e","isArray","push","apply","slice","writable","flatMap","map","clone","_instanceof","obj","type","nativeMap","nativeSet","nativePromise","Map","_","Set","Promise","parent","circular","depth","includeNonEnumerable","allParents","allChildren","useBuffer","Buffer","Infinity","_clone","child","proto","resolve","reject","then","err","__isArray","__isRegExp","RegExp","source","__getRegExpFlags","lastIndex","__isDate","Date","getTime","isBuffer","allocUnsafe","length","copy","Error","create","getPrototypeOf","index","indexOf","i","forEach","key","keyChild","valueChild","set","entryChild","add","attrs","getOwnPropertyDescriptor","getOwnPropertySymbols","symbols","symbol","descriptor","enumerable","allPropertyNames","getOwnPropertyNames","propertyName","__objToStr","o","toString","re","flags","global","ignoreCase","multiline","clonePrototype","c","module","exports","accessor","fn","fields","name","fname","getter","path","get1","getN","field","len","error","message","splitAccessPath","p","n","j","q","b","s","substring","log$1","method","level","input","args","concat","console","opt","get","isObject","isBoolean","isString","$","x","JSON","stringify","replace","toSet","contains","array","item","some","arr","f","k","entries","data","opts","cmp","cycles","node","aobj","bobj","seen","toJSON","undefined","isFinite","out","TypeError","seenIndex","keys","sort","splice","stableStringify","join","varName","alphanumericS","match","escapePathAccess","string","ROW","COLUMN","FACET","X","Y","X2","Y2","RADIUS","RADIUS2","THETA","THETA2","LATITUDE","LONGITUDE","LATITUDE2","LONGITUDE2","COLOR","FILL","STROKE","SHAPE","SIZE","ANGLE","OPACITY","FILLOPACITY","STROKEOPACITY","STROKEWIDTH","STROKEDASH","TEXT","ORDER","DETAIL","KEY","TOOLTIP","HREF","URL","DESCRIPTION","UNIT_CHANNEL_INDEX","assign","y","x2","y2","theta","theta2","radius","radius2","longitude","longitude2","latitude","latitude2","color","fill","stroke","opacity","fillOpacity","strokeOpacity","strokeWidth","strokeDash","size","angle","shape","order","text","detail","tooltip","href","url","description","isColorChannel","channel","CHANNEL_INDEX","row","column","facet","CHANNELS","SINGLE_DEF_CHANNEL_INDEX","__rest$2","NONPOSITION_CHANNEL_INDEX","NONPOSITION_CHANNELS","POSITION_SCALE_CHANNEL_INDEX","POLAR_POSITION_SCALE_CHANNEL_INDEX","NONPOSITION_SCALE_CHANNEL_INDEX","SCALE_CHANNEL_INDEX","isScaleChannel","supportMark","mark","ALL_MARKS","ALL_MARKS_EXCEPT_GEOSHAPE","area","bar","image","rect","rule","circle","point","square","tick","line","trail","geoshape","arc","getSupportedMark","rangeType","AXIS_PROPERTIES_INDEX","orient","aria","bandPosition","domain","domainCap","domainColor","domainDash","domainDashOffset","domainOpacity","domainWidth","format","formatType","grid","gridCap","gridColor","gridDash","gridDashOffset","gridOpacity","gridWidth","labelAlign","labelAngle","labelBaseline","labelBound","labelColor","labelFlush","labelFlushOffset","labelFont","labelFontSize","labelFontStyle","labelFontWeight","labelLimit","labelLineHeight","labelOffset","labelOpacity","labelOverlap","labelPadding","labels","labelSeparation","maxExtent","minExtent","offset","position","tickBand","tickCap","tickColor","tickCount","tickDash","tickDashOffset","tickExtra","tickMinStep","tickOffset","tickOpacity","tickRound","ticks","tickSize","tickWidth","title","titleAlign","titleAnchor","titleAngle","titleBaseline","titleColor","titleFont","titleFontSize","titleFontStyle","titleFontWeight","titleLimit","titleLineHeight","titleOpacity","titlePadding","titleX","titleY","translate","values","zindex","style","labelExpr","encoding","AXIS_PROPERTIES","LEGEND_PROPERTIES","clipHeight","columnPadding","columns","cornerRadius","direction","fillColor","gradientLength","gradientOpacity","gradientStrokeColor","gradientStrokeWidth","gradientThickness","gridAlign","legendX","legendY","padding","rowPadding","strokeColor","symbolDash","symbolDashOffset","symbolFillColor","symbolLimit","symbolOffset","symbolOpacity","symbolSize","symbolStrokeColor","symbolStrokeWidth","symbolType","titleOrient","invalidFieldType","facetChannelShouldBeDiscrete","discreteChannelCannotEncode","current","[object Object]","logger","warn","QUANTITATIVE","ORDINAL","TEMPORAL","NOMINAL","GEOJSON","ScaleType","CONTINUOUS_TO_CONTINUOUS_SCALES","CONTINUOUS_TO_CONTINUOUS_INDEX","CONTINUOUS_TO_DISCRETE_INDEX","CONTINUOUS_DOMAIN_INDEX","DISCRETE_DOMAIN_INDEX","hasDiscreteDomain","isContinuousToContinuous","isContinuousToDiscrete","SCALE_PROPERTY_INDEX","domainMax","domainMin","domainMid","align","range","rangeMax","rangeMin","scheme","bins","reverse","round","clamp","nice","base","exponent","constant","interpolate","zero","paddingInner","paddingOuter","SCALE_PROPERTIES","scaleTypeSupportProperty","scaleType","propName","hasContinuousDomain","channelScalePropertyIncompatability","every","thisArg","without","excludedItems","filter","flagKeys","u","FNAME","namedfunc","identity","true","false","duplicate","parse","equal","extend","vals","toMap","list","keystr","String","isFunction","isNumber","isDate","isValid","number","boolean","date","d","str","field_re","strrep","truncateOnWord","rev","cnt","tok","split","truncate_word_re","w","trim","Function","mutator","v","$func","op","$valid","$length","$in","comparator","sign","numcmp","stablesort","sortBy","keyFn","indices","idx","sa","sb","permute","swap","m","Math","floor","random","pad","pos","padchar","ceil","truncate","word","ellipsis","l","max","l1","l2","nestedMap","isEncodingNestedProp","ENCODING_TOPLEVEL_PROP_INDEX","aggregate","autoCount","bin","timeUnit","hasFn","stack","scale","axis","legend","ENCODING_TOPLEVEL_PROPS","isEncodingTopLevelProperty","ENCODING_NESTED_PROP_PARENT_INDEX","isEncodingNestedParent","prop","BIN_CHILD_PROPS","SORT_CHILD_PROPS","BIN_PROPS","SORT_PROPS","SCALE_PROPS","AXIS_PROPS","LEGEND_PROPS","ENCODING_NESTED_PROPS","VIEW_PROPS","toKey","fromKey","ENCODING_NESTED_PROP_INDEX","getEncodingNestedProp","isEncodingProperty","ALL_ENCODING_PROPS","DEFAULT_PROP_PRECEDENCE","Property","MARK","TRANSFORM","STACK","FORMAT","CHANNEL","AGGREGATE","AUTOCOUNT","BIN","HAS_FN","TIMEUNIT","FIELD","TYPE","SORT","SCALE","AXIS","LEGEND","WIDTH","HEIGHT","BACKGROUND","PADDING","TITLE","Mark","ARC","AREA","BAR","LINE","POINT","RECT","RULE","TICK","CIRCLE","SQUARE","isPathMark","SHORT_WILDCARD","isWildcard","isShortWildcard","isWildcardDef","enum","initWildcard","defaultName","defaultEnumValues","initNestedPropName","fullNames","has","fullName","initialIndices","charAt","toUpperCase","shortName","toLowerCase","shortNameWithNo","DEFAULT_NAME","binProps","maxbins","min","step","steps","minstep","divide","sortProps","scaleProps","axisProps","legendProps","getDefaultName","DEFAULT_BOOLEAN_ENUM","DEFAULT_ENUM_INDEX","MARK.POINT","MARK.BAR","MARK.LINE","MARK.AREA","MARK.RECT","MARK.TICK","MARK.TEXT","band","TYPE.NOMINAL","TYPE.ORDINAL","TYPE.QUANTITATIVE","TYPE.TEMPORAL","extent","binned","anchor","getDefaultEnumValues","schema","fieldNames","val","DEFAULT_QUERY_CONFIG","verbose","defaultSpecConfig","useUnaggregatedDomain","propertyPrecedence","numberNominalProportion","numberNominalLimit","constraintManuallySpecifiedValue","autoAddCount","hasAppropriateGraphicTypeForMark","omitAggregate","omitAggregatePlotWithDimensionOnlyOnFacet","omitAggregatePlotWithoutDimension","omitBarLineAreaWithOcclusion","omitBarTickWithSize","omitMultipleNonPositionalChannels","omitRaw","omitRawContinuousFieldForAggregatePlot","omitRepeatedField","omitNonPositionalOrFacetOverPositionalChannels","omitTableWithOcclusionIfAutoAddCount","omitVerticalDotPlot","omitInvalidStackSpec","omitNonSumStack","preferredBinAxis","CHANNEL.X","preferredTemporalAxis","preferredOrdinalAxis","CHANNEL.Y","preferredNominalAxis","preferredFacet","CHANNEL.ROW","minCardinalityForBin","maxCardinalityForCategoricalColor","maxCardinalityForFacet","maxCardinalityForShape","timeUnitShouldHaveVariation","typeMatchesSchemaType","stylize","smallRangeStepForHighCardinalityOrFacet","maxCardinality","rangeStep","nominalColorScaleForHighCardinality","palette","xAxisOnTopForHighYCardinalityWithoutColumn","maxGoodCardinalityForFacet","maxGoodCardinalityForColor","minPercentUniqueForKey","minCardinalityForKey","extendEnumIndex","enumIndex","extendNestedEnumIndex","AGGREGATE_OP_INDEX","argmax","argmin","average","count","distinct","product","mean","median","missing","q1","q3","ci0","ci1","stderr","stdev","stdevp","sum","valid","variance","variancep","SUM_OPS","binToString","autoMaxBins","normalizeBin","isBinning","isBinParams","substr","LOCAL_SINGLE_TIMEUNIT_INDEX","year","quarter","month","week","day","dayofyear","hours","minutes","seconds","milliseconds","TIMEUNIT_PARTS","isLocalSingleTimeUnit","isUTCTimeUnit","startsWith","containsTimeUnit","fullTimeUnit","normalizeTimeUnit","params","unit","utc","hasConditionalFieldDef","channelDef","condition","isFieldDef","channelDefType","vgField","fieldDef","prefix","suffix","argAccessor","isCount","isInternalField","internalField","nofn","isOpFieldDef","_a","binSuffix","_b","isArgminDef","tu","rest","__rest","timeUnitToString","_c","forAs","expr","datum","stringValue","flatAccessWithDatum","replacePathInField","isDiscrete","def","log.message.invalidFieldType","isContinuous","getFieldDef","COMPATIBLE","compatible","specifiedScale","defaultScaleType","log.warn","log.message.discreteChannelCannotEncode","util.contains","defaultType","CHANNEL.isScaleChannel","CHANNEL.THETA","CHANNEL.RADIUS","CHANNEL.SIZE","CHANNEL.STROKEWIDTH","CHANNEL.OPACITY","CHANNEL.FILLOPACITY","CHANNEL.STROKEOPACITY","CHANNEL.ANGLE","CHANNEL.COLOR","CHANNEL.FILL","CHANNEL.STROKE","CHANNEL.STROKEDASH","CHANNEL.SHAPE","channelSupportScaleType","specifiedType","fieldDefType","log.message.scaleTypeNotWorkWithFieldDef","log.message.scaleTypeNotWorkWithChannel","ExpandedType","fieldType","PropIndex","channelHasField","STACK_OFFSET_INDEX","center","normalize","STACKABLE_MARKS","STACK_BY_DEFAULT_MARKS","potentialStackedChannel","xDef","yDef","xAggregate","xScale","yScale","isMarkDef","fieldChannel","stackedFieldDef","stackedField","dimensionChannel","getDimensionChannel","dimensionDef","dimensionField","stackBy","sc","cDef","isAggregate","disallowNonLinearStack","log.message.cannotStackNonLinearScale","getSecondaryRangeChannel","isDatumDef","groupbyChannel","groupbyField","impute","fromSpec","spec","transform","width","height","background","encodings","encQ","isFieldQuery","config","specQ","isEnabledAutoCountQuery","getVlStack","hasRequiredStackProperties","toEncoding","wildcardMode","getStackOffset","getStackChannel","requiredEncodingProps","exclude","isDisabledAutoCountQuery","objectContainsWildcard","childProp","hasOwnProperty","getReplacerIndex","replaceIndex","getReplacer","replacer","REPLACE_NONE","INCLUDE_ALL","pi","PROPERTY_SUPPORTED_CHANNELS","include","parts","encQs","viewProp","propString","fieldDefStr","isValueQuery","isAutoCountQuery","fieldQ","func","props","localeCompare","parentValue","nestedPropChildren","nestedProp","nestedPropObject","fieldDefProps","fieldAndParams","splitWithTail","delim","result","indexOfDelim","shorthandParser","rawFieldDef","fieldDefPart","getFullName","partParams","closingBraceIndex","propEqualSignIndex","parsedValue","openingBraceIndex","getClosingIndex","openingBracketIndex","closingBracketIndex","propIndex","nextCommaIndex","closingChar","fieldDefShorthand","fnEnumIndex","encodingProperty","insideFnParts","encQMixins","vlspec","shorthand","splitShorthand","splitPart","splitPartKey","splitPartValue","DEFAULT_PROPS","toValueDef","toFieldDef","valueQ","ordinalDomain","fieldSchema","isMeasure","isDimension","vlChannelDef.isDiscrete","compileScaleType","vlChannelDef.isContinuous","t0","t1","newInterval","floori","offseti","interval","d0","d1","start","stop","test","setTime","end","millisecond","second","setMilliseconds","getSeconds","minute","setSeconds","getMinutes","hour","setMinutes","getHours","setHours","setDate","getDate","getTimezoneOffset","weekday","getDay","sunday","monday","tuesday","wednesday","thursday","friday","saturday","setMonth","getMonth","getFullYear","setFullYear","utcSecond","setUTCMilliseconds","getUTCSeconds","utcMinute","setUTCSeconds","getUTCMinutes","utcHour","setUTCMinutes","getUTCHours","utcDay","setUTCHours","setUTCDate","getUTCDate","utcWeekday","getUTCDay","utcSunday","utcMonday","utcTuesday","utcWednesday","utcThursday","utcFriday","utcSaturday","utcMonth","setUTCMonth","getUTCMonth","getUTCFullYear","utcYear","setUTCFullYear","days","sundays","mondays","tuesdays","wednesdays","thursdays","fridays","saturdays","weeks","months","years","utcMillisecond","utcMilliseconds","utcSeconds","utcMinutes","utcHours","utcDays","utcSundays","utcMondays","utcTuesdays","utcWednesdays","utcThursdays","utcFridays","utcSaturdays","utcWeeks","utcMonths","utcYears","version","utcWeek","factory","d3_time","require$$0","tempDate","baseDate","utcBaseDate","UTC","entry","locale","STEPS","toUnitMap","units","find","span","minb","maxb","timeModule","util","time","require$$1","precision","eps","logb","log","div","lo","hi","mid","bisect","pow","date_value","date_index","dmin","dmax","minbins","raw","bins_1","TYPES","PARSERS","integer","TESTS","bracket","fieldName","infer","ignore","types","annotation","all","inferAll","parsers","type_1","gen","repeat","zeros","uniform","samples","pdf","cdf","icdf","NaN","normal","next","rds","sqrt","exp","PI","cd","z","Z","abs","SQRT2","bootstrap","smooth","require$$2","stats","ztest1","nullH","nullh","gaussian","mu","SE","ztestP","n1","n2","diffs","ztest2","meanDiff","unique","results","quantile","quartile","H","h","geometric","harmonic","delta","M2","modeskew","avg","med","std","dot","dist","L2","cohensd","x1","s1","s2","covariance","vx","vy","xm","ym","rank","tie","cor","mua","mub","sda","sdb","ra","rb","aa","bb","ab","A","mat","B","linearRegression","res","xy","sx","sy","slope","icept","fit","intercept","R","rss","ci","N","alpha","bs","means","paired","M","entropy","counts","LN2","mutual","px","py","I","info","profile","sd","summary","__summary__","previous","durationSecond","durationMinute","durationHour","durationDay","durationWeek","getMilliseconds","YEAR","QUARTER","MONTH","WEEK","DATE","DAY","DAYOFYEAR","HOURS","MINUTES","SECONDS","MILLISECONDS","timeMonth","dlBin","dlBin_","nominal","ordinal","temporal","quantitative","Schema","tableSchema","_tableSchema","vlType","_fieldSchemaIndex","fieldSchemas","originalIndex","augmentTimeUnitDomain","excludeInvalid","binStats","binSummary","vegaTime.SECONDS","vegaTime.MINUTES","vegaTime.HOURS","vegaTime.DAY","vegaTime.DATE","vegaTime.MONTH","vegaTime.QUARTER","vegaTime.MILLISECONDS","timeStats","timeSummary","invalidCount","dateEncQ","cardinality","timeUnitPart","singleUnitEncQ","fieldQueryParts","PrimitiveType","DATETIME","INTEGER","NUMBER","oldUnique","newUnique","bucket","binUnique","SET_DATE_METHOD","dateMethods","singleUnit","isUtc","rawSetDateMethod","setDateMethod","getDateMethod","timeunit","dateString","isUTC","vegaTime.DAYOFYEAR","vegaTime.WEEK","convert","prev","cur","summaries","tableSchemaFieldIndex","fieldProfile","dataEntry","orgFieldSchema","derivedTableSchema","AbstractConstraintModel","constraint","properties","strict","EncodingConstraintModel","super","encWildcardIndex","allowWildcardForProperties","hasAllRequiredPropertiesSpecific","satisfy","FIELD_CONSTRAINTS","__","___","fieldQwithoutBin","warning","log.message.facetChannelShouldBeDiscrete","channelCompatibility","isFacet","timeUnitHasVariation","sType","scaleProp","sProp","primitiveType","BOOLEAN","STRING","CHANNEL.COLUMN","ec","FIELD_CONSTRAINTS_BY_PROPERTY","VALUE_CONSTRAINTS","VALUE_CONSTRAINTS_BY_PROPERTY","checkEncoding","wildcard","specM","encodingConstraints","getEncodingQueryByIndex","wildcardIndex","violatedConstraint","toShorthand","valueContraints","NONPOSITION_CHANNELS_INDEX","SpecConstraintModel","specConstraint","getMark","getEncodings","SPEC_CONSTRAINTS","usedChannel","encodingIndicesByProperty","channelUsed","CHANNEL.TEXT","MARK.CIRCLE","MARK.SQUARE","MARK.RULE","hasProperty","hasNonFacetDim","hasDim","hasEnumeratedFacetDim","specQuery","hasEncodingProperty","channelEncodingField","nonPositionChannelCount","hasEnumeratedNonPositionChannel","hasNonPositionalChannelOrFacet","hasEnumeratedNonPositionOrFacetChannel","hasX","hasY","CHANNEL.DETAIL","fieldUsed","fieldEnumerated","xEncQ","getEncodingQueryByChannel","yEncQ","xIsMeasure","yIsMeasure","xIsDimension","yIsDimension","colorEncQ","colorIsQuantitative","colorIsOrdinal","correctChannels","correctColor","stackProps","specStack","stackParentEncQ","SPEC_CONSTRAINT_INDEX","SPEC_CONSTRAINTS_BY_PROPERTY","checkSpec","specConstraints","ENUMERATOR_INDEX","getEnumerator","EncodingPropertyGeneratorFactory","answerSet","enumerate","jobIndex","propWildcard","getEncodingProperty","propVal","setEncodingProperty","resetEncodingProperty","setMark","resetMark","isExtendedGroupBy","g","parseGroupBy","groupBy","grpBy","setByKey","property","GROUP_BY_FIELD_TRANSFORM","GROUP_BY_ENCODING","*","valFrom","valTo","groupRegistry","registerKeyFn","FIELD_TRANSFORM","ENCODING","SPEC","nest","specModels","queryNest","rootGroup","items","groupIndex","includes","replaces","replacers","parsedGroupBy","group","orderGroupBy","specShorthand","PARSED_GROUP_BY_FIELD","getGroupByKey","PARSED_GROUP_BY_FIELD_TRANSFORM","PARSED_GROUP_BY_ENCODING","WildcardIndex","_mark","_encodings","_encodingIndicesByProperty","encodingsIndex","indicesByProp","SpecQueryModel","wildcardAssignment","_rankingScore","_spec","_channelFieldCount","_wildcardIndex","_assignedWildcardIndex","_opt","_schema","defaultWildcardName","propObj","countEncQ","specEncoding","rankingName","score","orderBy","normalizedQ","chooseBy","isResultTree","getTopResultTreeItem","topItem","ExtendedType","mapLeaves","Scorer","scoreIndex","initScore","feature","Q","BIN_Q","T","TIMEUNIT_T","TIMEUNIT_O","O","K","NONE","getExtendedType","TERRIBLE","featurize","xType","yType","hasOcclusion","SCORERS","pAxis","features","featureScore","getFeatureScore","maxFScore","MEASURES","DISCRETE_OR_NONE","SCORE","feature2","ttMark","tdMark","ddMark","init","bar_size","tick_size","featureScores","CONTINUOUS_TYPE_CHANNEL_SCORE","ORDERED_TYPE_CHANNEL_SCORE","NOMINAL_TYPE_CHANNEL_SCORE","encodingQueryByField","fieldKey","bestFieldFeature","best","effectiveness","scorer","scores","getScore","hasCount","hasBin","aggregationQualityFeature","fieldWildcardIndices","numFields","totalScore","fieldWildcard","fieldIndex","rankingRegistry","register","query","subgroup","groupComparatorFactory","comparatorFactory","m1","m2","getScoreDifference","g1","g2","scoreDifference","model","getRankingScore","setRankingScore","EFFECTIVENESS","aggregation.name","aggregation.score","fieldOrder.name","fieldOrder.score","encQIndex","yScaleType","xScaleType","generate","build","propKey","reducer","enumerator"],"mappings":"2OAAAA,MAAMC,UAAUC,MAAMC,OAAOC,eAAeJ,MAAMC,UAAU,OAAO,CAACI,cAAa,EAAGC,MAAM,SAASC,IAAI,IAAIC,EAAEC,MAAMC,UAAU,IAAI,EAAEC,OAAOD,UAAU,IAAI,OAAOF,EAAER,MAAMC,UAAUW,OAAOC,KAAKC,MAAK,SAASC,EAAEC,GAAG,OAAOhB,MAAMiB,QAAQD,GAAGD,EAAEG,KAAKC,MAAMJ,EAAER,EAAEM,KAAKG,EAAER,EAAE,IAAIO,EAAEG,KAAKF,GAAGD,IAAG,IAAIf,MAAMC,UAAUmB,MAAMP,KAAKC,OAAOO,UAAS,IAAKrB,MAAMC,UAAUqB,SAASnB,OAAOC,eAAeJ,MAAMC,UAAU,UAAU,CAACI,cAAa,EAAGC,MAAM,SAASC,GAAG,OAAOP,MAAMC,UAAUsB,IAAIJ,MAAML,KAAKJ,WAAWR,QAAQmB,UAAS,8JCArf,IAAIG,EAAQ,WAGZ,SAASC,EAAYC,EAAKC,GACxB,OAAe,MAARA,GAAgBD,aAAeC,EAGxC,IAAIC,EASAC,EAOAC,EAfJ,IACEF,EAAYG,IACZ,MAAMC,GAGNJ,EAAY,aAId,IACEC,EAAYI,IACZ,MAAMD,GACNH,EAAY,aAId,IACEC,EAAgBI,QAChB,MAAMF,GACNF,EAAgB,aAwBlB,SAASN,EAAMW,EAAQC,EAAUC,EAAOpC,EAAWqC,GACzB,iBAAbF,IACTC,EAAQD,EAASC,MACjBpC,EAAYmC,EAASnC,UACrBqC,EAAuBF,EAASE,qBAChCF,EAAWA,EAASA,UAItB,IAAIG,EAAa,GACbC,EAAc,GAEdC,EAA6B,oBAAVC,OA0IvB,YAxIuB,IAAZN,IACTA,GAAW,QAEO,IAATC,IACTA,EAAQM,EAAAA,GAGV,SAASC,EAAOT,EAAQE,GAEtB,GAAe,OAAXF,EACF,OAAO,KAET,GAAc,IAAVE,EACF,OAAOF,EAET,IAAIU,EACAC,EACJ,GAAqB,iBAAVX,EACT,OAAOA,EAGT,GAAIV,EAAYU,EAAQP,GACtBiB,EAAQ,IAAIjB,OACP,GAAIH,EAAYU,EAAQN,GAC7BgB,EAAQ,IAAIhB,OACP,GAAIJ,EAAYU,EAAQL,GAC7Be,EAAQ,IAAIf,GAAc,SAAUiB,EAASC,GAC3Cb,EAAOc,MAAK,SAAS3C,GACnByC,EAAQH,EAAOtC,EAAO+B,EAAQ,OAC7B,SAASa,GACVF,EAAOJ,EAAOM,EAAKb,EAAQ,eAG1B,GAAIb,EAAM2B,UAAUhB,GACzBU,EAAQ,QACH,GAAIrB,EAAM4B,WAAWjB,GAC1BU,EAAQ,IAAIQ,OAAOlB,EAAOmB,OAAQC,EAAiBpB,IAC/CA,EAAOqB,YAAWX,EAAMW,UAAYrB,EAAOqB,gBAC1C,GAAIhC,EAAMiC,SAAStB,GACxBU,EAAQ,IAAIa,KAAKvB,EAAOwB,eACnB,CAAA,GAAIlB,GAAaC,OAAOkB,SAASzB,GAStC,OANEU,EAFEH,OAAOmB,YAEDnB,OAAOmB,YAAY1B,EAAO2B,QAG1B,IAAIpB,OAAOP,EAAO2B,QAE5B3B,EAAO4B,KAAKlB,GACLA,EACEpB,EAAYU,EAAQ6B,OAC7BnB,EAAQ1C,OAAO8D,OAAO9B,QAEE,IAAblC,GACT6C,EAAQ3C,OAAO+D,eAAe/B,GAC9BU,EAAQ1C,OAAO8D,OAAOnB,KAGtBD,EAAQ1C,OAAO8D,OAAOhE,GACtB6C,EAAQ7C,GAIZ,GAAImC,EAAU,CACZ,IAAI+B,EAAQ5B,EAAW6B,QAAQjC,GAE/B,IAAc,GAAVgC,EACF,OAAO3B,EAAY2B,GAErB5B,EAAWrB,KAAKiB,GAChBK,EAAYtB,KAAK2B,GAiBnB,IAAK,IAAIwB,KAdL5C,EAAYU,EAAQP,IACtBO,EAAOmC,SAAQ,SAAShE,EAAOiE,GAC7B,IAAIC,EAAW5B,EAAO2B,EAAKlC,EAAQ,GAC/BoC,EAAa7B,EAAOtC,EAAO+B,EAAQ,GACvCQ,EAAM6B,IAAIF,EAAUC,MAGpBhD,EAAYU,EAAQN,IACtBM,EAAOmC,SAAQ,SAAShE,GACtB,IAAIqE,EAAa/B,EAAOtC,EAAO+B,EAAQ,GACvCQ,EAAM+B,IAAID,MAIAxC,EAAQ,CACpB,IAAI0C,EACA/B,IACF+B,EAAQ1E,OAAO2E,yBAAyBhC,EAAOuB,IAG7CQ,GAAsB,MAAbA,EAAMH,MAGnB7B,EAAMwB,GAAKzB,EAAOT,EAAOkC,GAAIhC,EAAQ,IAGvC,GAAIlC,OAAO4E,sBACT,CAAA,IAAIC,EAAU7E,OAAO4E,sBAAsB5C,GAC3C,IAASkC,EAAI,EAAGA,EAAIW,EAAQlB,OAAQO,IAAK,CAGvC,IAAIY,EAASD,EAAQX,MACjBa,EAAa/E,OAAO2E,yBAAyB3C,EAAQ8C,KACtCC,EAAWC,YAAe7C,KAG7CO,EAAMoC,GAAUrC,EAAOT,EAAO8C,GAAS5C,EAAQ,GAC1C6C,EAAWC,YACdhF,OAAOC,eAAeyC,EAAOoC,EAAQ,CACnCE,YAAY,MAMpB,GAAI7C,EACF,CAAA,IAAI8C,EAAmBjF,OAAOkF,oBAAoBlD,GAClD,IAASkC,EAAI,EAAGA,EAAIe,EAAiBtB,OAAQO,IAAK,CAChD,IACIa,EADAI,EAAeF,EAAiBf,IAChCa,EAAa/E,OAAO2E,yBAAyB3C,EAAQmD,KACvCJ,EAAWC,aAG7BtC,EAAMyC,GAAgB1C,EAAOT,EAAOmD,GAAejD,EAAQ,GAC3DlC,OAAOC,eAAeyC,EAAOyC,EAAc,CACzCH,YAAY,MAKlB,OAAOtC,EAGFD,CAAOT,EAAQE,GAqBxB,SAASkD,EAAWC,GAClB,OAAOrF,OAAOF,UAAUwF,SAAS5E,KAAK2E,GAmBxC,SAASjC,EAAiBmC,GACxB,IAAIC,EAAQ,GAIZ,OAHID,EAAGE,SAAQD,GAAS,KACpBD,EAAGG,aAAYF,GAAS,KACxBD,EAAGI,YAAWH,GAAS,KACpBA,EAIT,OAxCAnE,EAAMuE,eAAiB,SAAwB5D,GAC7C,GAAe,OAAXA,EACF,OAAO,KAET,IAAI6D,EAAI,aAER,OADAA,EAAE/F,UAAYkC,EACP,IAAI6D,GAQbxE,EAAM+D,WAAaA,EAKnB/D,EAAMiC,SAHN,SAAkB+B,GAChB,MAAoB,iBAANA,GAAoC,kBAAlBD,EAAWC,IAO7ChE,EAAM2B,UAHN,SAAmBqC,GACjB,MAAoB,iBAANA,GAAoC,mBAAlBD,EAAWC,IAO7ChE,EAAM4B,WAHN,SAAoBoC,GAClB,MAAoB,iBAANA,GAAoC,oBAAlBD,EAAWC,IAW7ChE,EAAM+B,iBAAmBA,EAElB/B,EA3PK,GA8PsByE,EAAOC,UACvCD,EAAAC,QAAiB1E,kBC/PnB,SAAS2E,EAAUC,EAAIC,EAAQC,GAG7B,OAFAF,EAAGC,OAASA,GAAU,GACtBD,EAAGG,MAAQD,EACJF,EAST,SAASI,EAAQC,GACf,OAAuB,IAAhBA,EAAK3C,OAAe4C,EAAKD,EAAK,IAAME,EAAKF,GAGlD,MAAMC,EAAOE,GAAS,SAAUlF,GAC9B,OAAOA,EAAIkF,IAGPD,EAAOF,IACX,MAAMI,EAAMJ,EAAK3C,OACjB,OAAO,SAAUpC,GACf,IAAK,IAAI2C,EAAI,EAAGA,EAAIwC,IAAOxC,EACzB3C,EAAMA,EAAI+E,EAAKpC,IAGjB,OAAO3C,IAIX,SAASoF,EAAOC,GACd,MAAM/C,MAAM+C,GAGd,SAASC,EAAiBC,GACxB,MAAMR,EAAO,GACPS,EAAID,EAAEnD,OACZ,IAGIO,EACA8C,EACAnB,EALAoB,EAAI,KACJC,EAAI,EACJC,EAAI,GAMR,SAASpG,IACPuF,EAAKvF,KAAKoG,EAAIL,EAAEM,UAAUlD,EAAG8C,IAC7BG,EAAI,GACJjD,EAAI8C,EAAI,EAGV,IARAF,GAAQ,GAQH5C,EAAI8C,EAAI,EAAGA,EAAID,IAAKC,EAGvB,GAFAnB,EAAIiB,EAAEE,GAEI,OAANnB,EACFsB,GAAKL,EAAEM,UAAUlD,EAAG8C,GACpBG,GAAKL,EAAEM,YAAYJ,IAAKA,GACxB9C,EAAI8C,OACC,GAAInB,IAAMoB,EACflG,IACAkG,EAAI,KACJC,GAAK,MACA,CAAA,GAAID,EACT,SACS/C,IAAMgD,GAAW,MAANrB,GAGX3B,IAAMgD,GAAW,MAANrB,GAFpB3B,EAAI8C,EAAI,EACRC,EAAIpB,GAIW,MAANA,GAAcqB,EAMR,MAANrB,GACLmB,EAAI9C,GAAGnD,IACXmG,EAAIhD,EAAI8C,EAAI,GACG,MAANnB,IACJqB,GAAGP,EAAM,qCAAuCG,GACjDI,EAAI,GAAGnG,IACXmG,EAAI,EACJhD,EAAI8C,EAAI,GAZJA,EAAI9C,EACNnD,IAEAmD,EAAI8C,EAAI,EAqBd,OARIE,GAAGP,EAAM,wCAA0CG,GACnDG,GAAGN,EAAM,sCAAwCG,GAEjDE,EAAI9C,IACN8C,IACAjG,KAGKuF,EAgBT,SAASe,EAAMC,EAAQC,EAAOC,GAC5B,MAAMC,EAAO,CAACF,GAAOG,OAAO,GAAGzG,MAAMP,KAAK8G,IAC1CG,QAAQL,GAAQtG,MAAM2G,QAASF,IAfjC,SAAgBhB,EAAON,EAAMyB,GAC3B,MAAMtB,EAAOO,EAAgBJ,GAC7BA,EAAwB,IAAhBH,EAAK3C,OAAe2C,EAAK,GAAKG,EAC/BT,GAAU4B,GAAOA,EAAIC,KAAOxB,GAAQC,GAAO,CAACG,GAAQN,GAAQM,GAG1DA,CAAM,MACAT,GAASnE,GAAKA,GAAG,GAAI,YACzBmE,GAAS,IAAM,GAAG,GAAI,QACvBA,GAAS,IAAM,GAAG,GAAI,OACnBA,GAAS,KAAM,GAAM,GAAI,QAC1BA,GAAS,KAAM,GAAO,GAAI,SA+CxC,IAAIlF,EAAUjB,MAAMiB,QAEpB,SAASgH,EAAUjG,GACjB,OAAOA,IAAM7B,OAAO6B,GA6dtB,SAASkG,EAAWlG,GAClB,MAAoB,kBAANA,EAmBhB,SAASmG,EAAUnG,GACjB,MAAoB,iBAANA,EA+HhB,SAASoG,EAAEC,GACT,OAAOpH,EAAQoH,GAAK,IAAMA,EAAE9G,IAAI6G,GAAK,IAAMH,EAASI,IAAMF,EAASE,GAEnEC,KAAKC,UAAUF,GAAGG,QAAQ,SAAU,WAAWA,QAAQ,SAAU,WAAaH,EAkBhF,SAASI,EAAOzG,GACd,MAAMsF,EAAI,GACJJ,EAAIlF,EAAE8B,OAEZ,IAAK,IAAIO,EAAI,EAAGA,EAAI6C,IAAK7C,EAAGiD,EAAEtF,EAAEqC,KAAM,EAEtC,OAAOiD,WC1tBOoB,EAAYC,EAAqBC,GAC/C,OAAOD,EAAMvE,QAAQwE,IAAS,WAMhBC,EAAQC,EAAmBC,GACzC,IAAI1E,EAAI,EACR,IAAK,MAAO2E,EAAGjI,KAAM+H,EAAIG,UACvB,GAAIF,EAAEhI,EAAGiI,EAAG3E,KACV,OAAO,EAGX,OAAO,EApDTpC,IAAIhC,UAAkB,OAAI,WACxB,MAAO,OAAO,IAAIa,MAAMS,KAAI8G,GC3Cb,SAAUa,EAAMC,GACxBA,IAAMA,EAAO,IACE,mBAATA,IAAqBA,EAAO,CAAEC,IAAKD,IAC9C,IAEiCJ,EAF7BM,EAAiC,kBAAhBF,EAAKE,QAAwBF,EAAKE,OAEnDD,EAAMD,EAAKC,MAAkBL,EAQ9BI,EAAKC,IAPG,SAAUE,GACb,OAAO,SAAUvI,EAAGsG,GAChB,IAAIkC,EAAO,CAAEhF,IAAKxD,EAAGT,MAAOgJ,EAAKvI,IAC7ByI,EAAO,CAAEjF,IAAK8C,EAAG/G,MAAOgJ,EAAKjC,IACjC,OAAO0B,EAAEQ,EAAMC,MAKvBC,EAAO,GACX,OAAO,SAAUlB,EAAWe,GAKxB,GAJIA,GAAQA,EAAKI,QAAiC,mBAAhBJ,EAAKI,SACnCJ,EAAOA,EAAKI,eAGHC,IAATL,EAAJ,CACA,GAAmB,iBAARA,EAAkB,OAAOM,SAASN,GAAQ,GAAKA,EAAO,OACjE,GAAoB,iBAATA,EAAmB,OAAOhB,KAAKC,UAAUe,GAEpD,IAAIjF,EAAGwF,EACP,GAAI7J,MAAMiB,QAAQqI,GAAO,CAErB,IADAO,EAAM,IACDxF,EAAI,EAAGA,EAAIiF,EAAKxF,OAAQO,IACrBA,IAAGwF,GAAO,KACdA,GAAOtB,EAAUe,EAAKjF,KAAO,OAEjC,OAAOwF,EAAM,IAGjB,GAAa,OAATP,EAAe,MAAO,OAE1B,IAA4B,IAAxBG,EAAKrF,QAAQkF,GAAc,CAC3B,GAAID,EAAQ,OAAOf,KAAKC,UAAU,aAClC,MAAM,IAAIuB,UAAU,yCAGxB,IAAIC,EAAYN,EAAKvI,KAAKoI,GAAQ,EAC9BU,EAAO7J,OAAO6J,KAAKV,GAAMW,KAAKb,GAAOA,EAAIE,IAE7C,IADAO,EAAM,GACDxF,EAAI,EAAGA,EAAI2F,EAAKlG,OAAQO,IAAK,CAC9B,IAAIE,EAAMyF,EAAK3F,GACX/D,EAAQiI,EAAUe,EAAK/E,IAEtBjE,IACDuJ,IAAKA,GAAO,KAChBA,GAAOvB,KAAKC,UAAUhE,GAAO,IAAMjE,GAGvC,OADAmJ,EAAKS,OAAOH,EAAW,GAChB,IAAMF,EAAM,KAtChB,CAuCJX,GDZ4BiB,CAAgB9B,KAAI+B,KAAK,SA8KrD,MAAMJ,EAAO7J,OAAO6J,KAIdf,EAAU9I,OAAO8I,iBAadoB,EAAQ/C,GAEtB,MAAMgD,EAAgBhD,EAAEkB,QAAQ,MAAO,KAGvC,OAAQlB,EAAEiD,MAAM,QAAU,IAAM,IAAMD,EA0DxC,SAASE,EAAiBC,GACxB,OAAOA,EAAOjC,QAAQ,kBAAmB,wVE7RpC,MAAMkC,EAAM,MACNC,EAAS,SAETC,EAAQ,QAGRC,EAAI,IACJC,EAAI,IACJC,EAAK,KACLC,EAAK,KAGLC,EAAS,SACTC,EAAU,UACVC,EAAQ,QACRC,EAAS,SAGTC,EAAW,WACXC,EAAY,YACZC,EAAY,YACZC,EAAa,aAGbC,EAAQ,QAERC,EAAO,OAEPC,EAAS,SAETC,EAAQ,QACRC,EAAO,OAEPC,EAAQ,QAERC,EAAU,UACVC,EAAc,cAEdC,EAAgB,gBAEhBC,EAAc,cACdC,EAAa,aAGbC,EAAO,OACPC,EAAQ,QACRC,EAAS,SACTC,EAAM,MAENC,EAAU,UACVC,EAAO,OAEPC,EAAM,MACNC,GAAc,cAoDrBC,GAAkBzM,OAAA0M,OAAA1M,OAAA0M,OAAA1M,OAAA0M,OAAA1M,OAAA0M,OAAA,GAlDO,CAC7BxE,EAAG,EACHyE,EAAG,EACHC,GAAI,EACJC,GAAI,IAK+B,CACnCC,MAAO,EACPC,OAAQ,EACRC,OAAQ,EACRC,QAAS,IASwB,CACjCC,UAAW,EACXC,WAAY,EACZC,SAAU,EACVC,UAAW,IA4BkB,CAG7BC,MAAO,EACPC,KAAM,EACNC,OAAQ,EAGRC,QAAS,EACTC,YAAa,EACbC,cAAe,EAEfC,YAAa,EACbC,WAAY,EACZC,KAAM,EACNC,MAAO,EACPC,MAAO,EAGPC,MAAO,EACPC,KAAM,EACNC,OAAQ,EACR/J,IAAK,EACLgK,QAAS,EACTC,KAAM,EACNC,IAAK,EACLC,YAAa,aAKCC,GAAeC,GAC7B,OAAOA,IAAYnD,GAASmD,IAAYlD,GAAQkD,IAAYjD,EAK9D,MAQMkD,GAAa1O,OAAA0M,OAAA1M,OAAA0M,OAAA,GACdD,IATmE,CACtEkC,IAAK,EACLC,OAAQ,EACRC,MAAO,IAUIC,GAAWjF,EAAK6E,IAEmBK,GAAwBC,EAAIN,GAAtE,CAAA,QAAA,SAAA,cACqEK,GAArE,CAAA,MAAA,SAAA,gBAmLDE,GAAyBD,EAC1BvC,GAhBE,CAAA,IAAA,IAAA,KAAA,KAAA,WAAA,YAAA,YAAA,aAAA,QAAA,SAAA,SAAA,YAkBOyC,GAAuBrF,EAAKoF,IAG5BE,GAA+B,CAC1CjH,EAAG,EACHyE,EAAG,GASQyC,GAAqC,CAChDtC,MAAO,EACPE,OAAQ,GAwBLqC,GAA+BL,EAChCC,GAdE,CAAA,OAAA,UAAA,OAAA,MAAA,cAAA,SAAA,MAAA,UA4CAK,GAAmBtP,OAAA0M,OAAA1M,OAAA0M,OAAA1M,OAAA0M,OAAA,GACpByC,IACAC,IACAC,aAOWE,GAAed,GAC7B,QAASa,GAAoBb,YAWfe,GAAYf,EAAkBgB,GAC5C,OA4BF,SAA0BhB,GACxB,OAAQA,GACN,KAAKnD,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKgB,GACL,KAAKL,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKJ,EACL,KAAKN,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EAIL,KAAKtB,EACL,KAAKF,EACL,KAAKC,EACH,OAAOkF,GACT,KAAKhF,EACL,KAAKC,EACL,KAAKO,EACL,KAAKC,EAEH,OAAOwE,GACT,KAAK/E,EACL,KAAKC,EACL,KAAKO,EACL,KAAKC,EACH,MAAO,CACLuE,KAAM,SACNC,IAAK,SACLC,MAAO,SACPC,KAAM,SACNC,KAAM,SACNC,OAAQ,SACRC,MAAO,SACPC,OAAQ,SACRC,KAAM,SACNC,KAAM,SACNC,MAAO,UAEX,KAAK5E,EACH,MAAO,CACLwE,MAAO,SACPE,KAAM,SACNJ,KAAM,SACNC,OAAQ,SACRE,OAAQ,SACRN,IAAK,SACL3B,KAAM,SACNmC,KAAM,SACNC,MAAO,UAEX,KAAKtE,EACH,MAAO,CACLqE,KAAM,SACNH,MAAO,SACPE,KAAM,SACNJ,KAAM,SACNC,OAAQ,SACRE,OAAQ,SACRN,IAAK,SACLU,SAAU,UAEd,KAAK9E,EACH,MAAO,CAACyE,MAAO,SAAUK,SAAU,UACrC,KAAKtE,EACH,MAAO,CAACiC,KAAM,UAChB,KAAKvC,EACH,MAAO,CAACuE,MAAO,SAAUC,OAAQ,SAAUjC,KAAM,UACnD,KAAK3B,EACH,MAAO,CAACuD,MAAO,UACjB,KAAK9E,EAEL,KAAKF,EACH,MAAO,CAACoD,KAAM,SAAUsC,IAAK,UAC/B,KAAKvF,EACL,KAAKF,EACH,MAAO,CAACyF,IAAK,WAhHVC,CAAiBhC,GAASgB,GAGnC,MAAMC,GAAoC,CAExCc,IAAK,SACLZ,KAAM,SACNC,IAAK,SACLI,OAAQ,SACRM,SAAU,SACVT,MAAO,SACPO,KAAM,SACNL,KAAM,SACNE,MAAO,SACPH,KAAM,SACNI,OAAQ,SACRG,MAAO,SACPpC,KAAM,SACNkC,KAAM,UAGgBT,GAAyBX,EAAIU,GAA/C,CAAA,sBA+FUgB,GAAUjC,GACxB,OAAQA,GACN,KAAK/D,EACL,KAAKC,EACL,KAAKK,EACL,KAAKF,EACL,KAAKY,EACL,KAAKC,EACL,KAAKI,EACL,KAAKH,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKlB,EACL,KAAKC,EACL,KAAKI,EACL,KAAKF,EACH,OAEF,KAAKN,EACL,KAAKF,EACL,KAAKC,EACL,KAAKiB,EACL,KAAKO,EAEL,KAAKC,EACL,KAAKI,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,GACH,MAAO,WAGT,KAAKlB,EACL,KAAKC,EACL,KAAKC,EACH,MAAO,WAIT,KAAKN,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKc,EACL,KAAKC,EACL,KAAKF,EACH,QCtKC,MAgFDyE,GAAqB3Q,OAAA0M,OAAA1M,OAAA0M,OAAA,GAhFmD,CAC5EkE,OAAQ,EAERC,KAAM,EACNC,aAAc,EACdvC,YAAa,EACbwC,OAAQ,EACRC,UAAW,EACXC,YAAa,EACbC,WAAY,EACZC,iBAAkB,EAClBC,cAAe,EACfC,YAAa,EACbC,OAAQ,EACRC,WAAY,EACZC,KAAM,EACNC,QAAS,EACTC,UAAW,EACXC,SAAU,EACVC,eAAgB,EAChBC,YAAa,EACbC,UAAW,EACXC,WAAY,EACZC,WAAY,EACZC,cAAe,EACfC,WAAY,EACZC,WAAY,EACZC,WAAY,EACZC,iBAAkB,EAClBC,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZC,gBAAiB,EACjBC,YAAa,EACbC,aAAc,EACdC,aAAc,EACdC,aAAc,EACdC,OAAQ,EACRC,gBAAiB,EACjBC,UAAW,EACXC,UAAW,EACXC,OAAQ,EACRC,SAAU,EACVC,SAAU,EACVC,QAAS,EACTC,UAAW,EACXC,UAAW,EACXC,SAAU,EACVC,eAAgB,EAChBC,UAAW,EACXC,YAAa,EACbC,WAAY,EACZC,YAAa,EACbC,UAAW,EACXC,MAAO,EACPC,SAAU,EACVC,UAAW,EACXC,MAAO,EACPC,WAAY,EACZC,YAAa,EACbC,WAAY,EACZC,cAAe,EACfC,WAAY,EACZC,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZC,gBAAiB,EACjBC,aAAc,EACdC,aAAc,EACdC,OAAQ,EACRC,OAAQ,EACRC,UAAW,EACXC,OAAQ,EACRC,OAAQ,IAIuB,CAC/BC,MAAO,EACPC,UAAW,EACXC,SAAU,IAQCC,GAAkB7L,EAAK8G,ICnRvBgF,GAAoB9L,EApEiD,CAChFgH,KAAM,EACN+E,WAAY,EACZC,cAAe,EACfC,QAAS,EACTC,aAAc,EACdxH,YAAa,EACbyH,UAAW,EACXC,UAAW,EACX3E,OAAQ,EACRC,WAAY,EACZ2E,eAAgB,EAChBC,gBAAiB,EACjBC,oBAAqB,EACrBC,oBAAqB,EACrBC,kBAAmB,EACnBC,UAAW,EACXxE,WAAY,EACZE,cAAe,EACfE,WAAY,EACZG,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZE,YAAa,EACbC,aAAc,EACdC,aAAc,EACdC,aAAc,EACdE,gBAAiB,EACjBuD,QAAS,EACTC,QAAS,EACTrD,OAAQ,EACRxC,OAAQ,EACR8F,QAAS,EACTC,WAAY,EACZC,YAAa,EACbC,WAAY,EACZC,iBAAkB,EAClBC,gBAAiB,EACjBC,YAAa,EACbC,aAAc,EACdC,cAAe,EACfC,WAAY,EACZC,kBAAmB,EACnBC,kBAAmB,EACnBC,WAAY,EACZ7D,UAAW,EACXI,YAAa,EACbO,MAAO,EACPC,WAAY,EACZC,YAAa,EACbE,cAAe,EACfC,WAAY,EACZC,UAAW,EACXC,cAAe,EACfC,eAAgB,EAChBC,gBAAiB,EACjBC,WAAY,EACZC,gBAAiB,EACjBC,aAAc,EACduC,YAAa,EACbtC,aAAc,EACdzT,KAAM,EACN6T,OAAQ,EACRC,OAAQ,aClHMkC,GAAiBhW,GAC/B,MAAO,uBAAuBA,eA6ChBiW,GAA6BhJ,GAC3C,MAAO,GAAGA,uEAOIiJ,GAA4BjJ,EAAkBjN,GAC5D,MAAO,2BAA2BiN,iBAAuBjN,oDAC9C,YAATA,EAAqB,QAAU,eCpMnC,IAAImW,GP+GJ,SAAiB9V,EAAGyF,GAClB,IAAIC,EAAQ1F,GAND,EAOX,MAAO,CACL+V,MAAM/V,GACJ,OAAItB,UAAUoD,QACZ4D,GAAS1F,EACFlB,MAEA4G,GAIXqQ,QAEE,OADIrQ,GAjBM,GAiBYF,EAAMC,GAAU,QAAS,QAAS/G,WACjDI,MAGTiX,OAEE,OADIrQ,GArBG,GAqBYF,EAAMC,GAAU,OAAQ,OAAQ/G,WAC5CI,MAGTiX,OAEE,OADIrQ,GAzBG,GAyBYF,EAAMC,GAAU,MAAO,OAAQ/G,WAC3CI,MAGTiX,QAEE,OADIrQ,GA7BI,GA6BYF,EAAMC,GAAU,MAAO,QAAS/G,WAC7CI,OO7IAkX,CP6GA,YOrCGC,MAAQrQ,GACtBkQ,GAAQG,QAAQrQ,GC9EX,MAcMsQ,GAbG,eAcHC,GAbF,UAcEC,GAbD,WAcCC,GAbF,UAeEC,GAdF,2VCSJ,MAAMC,GAEH,SAFGA,GAGN,MAHMA,GAIN,MAJMA,GAKL,OALKA,GAMH,SANGA,GAYL,OAZKA,GAaN,MAbMA,GAgBD,WAhBCA,GAiBD,WAjBCA,GAkBA,YAmFAC,GAA+C,CAAC,SAAU,MAAO,MAAO,OAAQ,SAAU,OAAQ,OACzGC,GAAiChQ,EAAM+P,IAIX/P,EAFc,CAAC,SAAU,MAAO,MAAO,OAAQ,WAQ1E,MACDiQ,GAA+BjQ,EADqB,CAAC,WAAY,WAAY,cAU7EkQ,GAA0BlQ,EAPqB+P,GAAgC3Q,OAAO,CAC1F,WACA,WACA,YACA,aACA,cAKI+Q,GAAwBnQ,EADqB,CAAC,UAAW,cAAe,QAAS,kBAKvEoQ,GAAkBlX,GAChC,OAAOA,KAAQiX,YASDE,GACdnX,GAEA,OAAOA,KAAQ8W,YAGDM,GAAuBpX,GACrC,OAAOA,KAAQ+W,GAmfjB,MAAMM,GAA+C,CACnDrX,KAAM,EACNuP,OAAQ,EACR+H,UAAW,EACXC,UAAW,EACXC,UAAW,EACXC,MAAO,EACPC,MAAO,EACPC,SAAU,EACVC,SAAU,EACVC,OAAQ,EACRC,KAAM,EAENC,QAAS,EACTC,MAAO,EAEPC,MAAO,EACPC,KAAM,EAENC,KAAM,EACNC,SAAU,EACVC,SAAU,EACVC,YAAa,EACbC,KAAM,EAENrD,QAAS,EACTsD,aAAc,EACdC,aAAc,GAGHC,GAAmBrQ,EAAKgP,aAcrBsB,GAAyBC,EAAsBC,GAC7D,OAAQA,GACN,IAAK,OACL,IAAK,SACL,IAAK,UACL,IAAK,QACH,OAAO,EACT,IAAK,SACL,IAAK,cACH,OAAQ9R,EAAS,CAAC,QAAS,OAAQ,YAAa6R,GAClD,IAAK,OACH,OAAQ7R,EAAS,CAAC,QAAS,OAAQ,WAAY,WAAY6R,GAC7D,IAAK,QACH,OAAOzB,GAAyByB,IAA4B,SAAdA,GAAsC,UAAdA,EACxE,IAAK,UACL,IAAK,WACL,IAAK,WACH,OAAOzB,GAAyByB,IAAc7R,EAAS,CAAC,QAAS,QAAS6R,GAC5E,IAAK,eACL,IAAK,QACH,OAAO7R,EAAS,CAAC,QAAS,QAAS6R,GACrC,IAAK,eACH,MAAqB,SAAdA,EACT,IAAK,YACL,IAAK,YACL,IAAK,YACL,IAAK,QACH,OAAOzB,GAAyByB,GAClC,IAAK,OACH,OAAOzB,GAAyByB,IAA4B,aAAdA,GAA0C,cAAdA,EAC5E,IAAK,WACH,MAAqB,QAAdA,EACT,IAAK,OACH,MAAqB,QAAdA,EACT,IAAK,WACH,MAAqB,WAAdA,EACT,IAAK,OACH,gBAhlBJ5Y,GAEA,OAAOA,KAAQgX,GA+kBT8B,CAAoBF,KACnB7R,EACC,CACE,MACA,OACA,MACA,YACA,YAEF6R,aASMG,GAAoC9L,EAAkB4L,GACpE,OAAQA,GACN,IAAK,cACL,IAAK,SACL,IAAK,YACH,OAAK7L,GAAeC,QAGpB,EH3hBG,kCGyhBqDA,6BAG1D,IAAK,QACL,IAAK,OACL,IAAK,OACL,IAAK,SACL,IAAK,YACL,IAAK,YACL,IAAK,QACL,IAAK,OACL,IAAK,WACL,IAAK,WACL,IAAK,OACL,IAAK,UACL,IAAK,eACL,IAAK,eACL,IAAK,WACL,IAAK,WACL,IAAK,UACL,IAAK,QACL,IAAK,QACL,IAAK,OACH,WAzFFoK,GARE,CAAA,OAAA,SAAA,QAAA,WAAA,WAAA,wCC7qBUtQ,GAASC,EAAcC,GACrC,OAAgC,IAAzBD,EAAMvE,QAAQwE,YAGP+R,GAAS7R,EAAUC,GACjC,IAAK,IAAI1E,EAAI,EAAGA,EAAIyE,EAAIhF,OAAQO,IAC9B,IAAK0E,EAAED,EAAIzE,GAAIA,GACb,OAAO,EAGX,OAAO,WAGOC,GAAQ5C,EAAUqH,EAAyD6R,GACzF,GAAIlZ,EAAI4C,QACN5C,EAAI4C,QAAQzD,KAAK+Z,EAAS7R,QAE1B,IAAK,MAAMC,KAAKtH,EACdqH,EAAElI,KAAK+Z,EAASlZ,EAAIsH,GAAIA,EAAGtH,YAKjBmH,GAAQC,EAAUC,GAChC,IAAI1E,EAAI,EACR,IAAK,IAAI2E,EAAI,EAAGA,EAAIF,EAAIhF,OAAQkF,IAC9B,GAAID,EAAED,EAAIE,GAAIA,EAAG3E,KACf,OAAO,EAGX,OAAO,WAaOwW,GAAWlS,EAAiBmS,GAC1C,OAAOnS,EAAMoS,QAAO,SAAUnS,GAC5B,OAAQF,GAASoS,EAAelS,eAIpBoS,GAA2BjS,GACzC,OAAO5I,OAAO6J,KAAKjB,gBC7DrB,IAAIkS,EAAIhV,EAAOC,QAIXgV,EAAQ,WAEZD,EAAEE,UAAY,SAAS7U,EAAMyC,GAAK,OAAQA,EAAEmS,GAAS5U,EAAMyC,GAE3DkS,EAAE3U,KAAO,SAASyC,GAAK,OAAU,MAAHA,EAAU,KAAOA,EAAEmS,IAEjDD,EAAEG,SAAW,SAAS/S,GAAK,OAAOA,GAElC4S,EAAEI,KAAOJ,EAAEE,UAAU,QAAQ,WAAa,OAAO,KAEjDF,EAAEK,MAAQL,EAAEE,UAAU,SAAS,WAAa,OAAO,KAEnDF,EAAEM,UAAY,SAAS7Z,GACrB,OAAO4G,KAAKkT,MAAMlT,KAAKC,UAAU7G,KAGnCuZ,EAAEQ,MAAQ,SAAS1a,EAAGsG,GACpB,OAAOiB,KAAKC,UAAUxH,KAAOuH,KAAKC,UAAUlB,IAG9C4T,EAAES,OAAS,SAASha,GAClB,IAAK,IAAI2G,EAAG/B,EAAMjC,EAAE,EAAGwC,EAAInG,UAAUoD,OAAQO,EAAEwC,IAAOxC,EAEpD,IAAKiC,KADL+B,EAAI3H,UAAU2D,GACI3C,EAAI4E,GAAQ+B,EAAE/B,GAElC,OAAO5E,GAGTuZ,EAAEnX,OAAS,SAASuE,GAClB,OAAY,MAALA,GAAyB,MAAZA,EAAEvE,OAAiBuE,EAAEvE,OAAS,MAGpDmX,EAAEjR,KAAO,SAAS3B,GAChB,IAAeW,EAAXgB,EAAO,GACX,IAAKhB,KAAKX,EAAG2B,EAAK9I,KAAK8H,GACvB,OAAOgB,GAGTiR,EAAEU,KAAO,SAAStT,GAChB,IAAeW,EAAX2S,EAAO,GACX,IAAK3S,KAAKX,EAAGsT,EAAKza,KAAKmH,EAAEW,IACzB,OAAO2S,GAGTV,EAAEW,MAAQ,SAASC,EAAM9S,GACvB,OAAQA,EAAIkS,EAAE7S,EAAEW,IACd8S,EAAKjb,QAAO,SAASc,EAAK2G,GAAK,OAAQ3G,EAAIqH,EAAEV,IAAM,EAAG3G,IAAS,IAC/Dma,EAAKjb,QAAO,SAASc,EAAK2G,GAAK,OAAQ3G,EAAI2G,GAAK,EAAG3G,IAAS,KAGhEuZ,EAAEa,OAAS,SAAStG,GAElB,IAAItO,EAAIsO,EAAO1R,OACf,IAAKoD,EAAG,MAAO,GACf,IAAK,IAAII,EAAEyU,OAAOvG,EAAO,IAAKnR,EAAE,EAAGA,EAAE6C,IAAK7C,EACxCiD,GAAK,IAAMyU,OAAOvG,EAAOnR,IAE3B,OAAOiD,GAKT,IAAI7B,EAAWtF,OAAOF,UAAUwF,SAEhCwV,EAAEhT,SAAW,SAASvG,GACpB,OAAOA,IAAQvB,OAAOuB,IAGxBuZ,EAAEe,WAAa,SAASta,GACtB,MAA8B,sBAAvB+D,EAAS5E,KAAKa,IAGvBuZ,EAAE9S,SAAW,SAASzG,GACpB,MAAwB,iBAAVpB,OAA6C,oBAAvBmF,EAAS5E,KAAKa,IAGpDuZ,EAAEha,QAAUjB,MAAMiB,SAAW,SAASS,GACpC,MAA8B,mBAAvB+D,EAAS5E,KAAKa,IAGvBuZ,EAAEgB,SAAW,SAASva,GACpB,MAAsB,iBAARA,GAA2C,oBAAvB+D,EAAS5E,KAAKa,IAGlDuZ,EAAE/S,UAAY,SAASxG,GACrB,OAAe,IAARA,IAAwB,IAARA,GAAuC,oBAAtB+D,EAAS5E,KAAKa,IAGxDuZ,EAAEiB,OAAS,SAASxa,GAClB,MAA8B,kBAAvB+D,EAAS5E,KAAKa,IAGvBuZ,EAAEkB,QAAU,SAASza,GACnB,OAAc,MAAPA,GAAeA,GAAQA,GAGhCuZ,EAAErX,SAA8B,mBAAXlB,QAAyBA,OAAOkB,UAAaqX,EAAEK,MAIpEL,EAAEmB,OAAS,SAAS9U,GAClB,OAAY,MAALA,GAAmB,KAANA,EAAW,MAAQA,GAGzC2T,EAAEoB,QAAU,SAAS/U,GACnB,OAAY,MAALA,GAAmB,KAANA,EAAW,KAAW,UAAJA,KAAwBA,GAIhE2T,EAAEqB,KAAO,SAAShV,EAAGmK,GACnB,IAAI8K,EAAI9K,GAAkB/N,KAC1B,OAAY,MAAL4D,GAAmB,KAANA,EAAW,KAAOiV,EAAEf,MAAMlU,IAGhD2T,EAAEtS,MAAQ,SAASN,GACjB,OAAY,MAALA,EAAa4S,EAAEha,QAAQoH,GAAKA,EAAI,CAACA,GAAM,IAGhD4S,EAAEuB,IAAM,SAASnU,GACf,OAAO4S,EAAEha,QAAQoH,GAAK,IAAMA,EAAE9G,IAAI0Z,EAAEuB,KAAO,IACvCvB,EAAEhT,SAASI,IAAM4S,EAAE9S,SAASE,GAG5BC,KAAKC,UAAUF,GAAGG,QAAQ,SAAS,WAAWA,QAAQ,SAAU,WAChEH,GAKN,IAAIoU,EAAW,qBA+Hf,SAASC,EAAOxV,EAAGsV,GACjB,IAAYnY,EAARiD,EAAI,GACR,IAAKjD,EAAE,EAAGA,EAAE6C,IAAK7C,EAAGiD,GAAKkV,EACzB,OAAOlV,EAsBT,SAASqV,EAAerV,EAAGT,EAAK+V,GAC9B,IAAIC,EAAM,EAAGC,EAAMxV,EAAEyV,MAAMC,GAQ3B,OANE1V,EADEsV,GACGE,EAAMA,EAAIpD,WACZqB,QAAO,SAASkC,GAAsB,OAAjBJ,GAAOI,EAAEnZ,SAAsB+C,KACpD6S,UAECoD,EAAI/B,QAAO,SAASkC,GAAsB,OAAjBJ,GAAOI,EAAEnZ,SAAsB+C,MAErD/C,OAASwD,EAAE8C,KAAK,IAAI8S,OAASJ,EAAI,GAAG1b,MAAM,EAAGyF,GA/JxDoU,EAAErU,MAAQ,SAASmC,GACjB,OAAOgT,OAAOhT,GAAGwB,MAAMkS,GAAUlb,KAAI,SAASgb,GAC5C,MAAgB,MAATA,EAAE,GAAaA,EACX,MAATA,EAAE,IAAuB,MAATA,EAAE,GAAaA,EAAEnb,MAAM,GAAI,GAC3Cmb,EAAEnb,MAAM,GAAI,GAAGoH,QAAQ,YAAa,UAI1CyS,EAAE9U,SAAW,SAAS4C,GAEpB,OAAU,MAAHA,GAAWkS,EAAEe,WAAWjT,GAAKA,EAClCkS,EAAEE,UAAUpS,EAAGoU,SAAS,IAAK,YAAclC,EAAErU,MAAMmC,GAAGxH,IAAI0Z,EAAEuB,KAAKpS,KAAK,MAAQ,QAIlF6Q,EAAE7S,EAAI6S,EAAE9U,SAER8U,EAAEmC,QAAU,SAASrU,GACnB,IAAIzB,EACJ,OAAO2T,EAAE9S,SAASY,KAAOzB,EAAE2T,EAAErU,MAAMmC,IAAIjF,OAAS,EAC9C,SAASuE,EAAGgV,GACV,IAAK,IAAIhZ,EAAE,EAAGA,EAAEiD,EAAExD,OAAO,IAAKO,EAAGgE,EAAIA,EAAEf,EAAEjD,IACzCgE,EAAEf,EAAEjD,IAAMgZ,GAEZ,SAAShV,EAAGgV,GAAKhV,EAAEU,GAAKsU,IAI5BpC,EAAEqC,MAAQ,SAAShX,EAAMiX,GACvB,OAAO,SAASxU,GACdA,EAAIkS,EAAE7S,EAAEW,IAAMkS,EAAEG,SAChB,IAAIlU,EAAIZ,GAAQ2U,EAAE3U,KAAKyC,GAAK,IAAIkS,EAAE3U,KAAKyC,GAAK,IAC5C,OAAOkS,EAAEE,UAAUjU,GAAG,SAASqV,GAAK,OAAOgB,EAAGxU,EAAEwT,SAIpDtB,EAAEuC,OAAUvC,EAAEqC,MAAM,QAASrC,EAAEkB,SAC/BlB,EAAEwC,QAAUxC,EAAEqC,MAAM,SAAUrC,EAAEnX,QAEhCmX,EAAEyC,IAAM,SAAS3U,EAAGyM,GAClBzM,EAAIkS,EAAE7S,EAAEW,GACR,IAAIxH,EAAM0Z,EAAEha,QAAQuU,GAAUyF,EAAEW,MAAMpG,GAAUA,EAChD,OAAO,SAAS+G,GAAK,QAAShb,EAAIwH,EAAEwT,MAKtCtB,EAAE0C,WAAa,SAAS1T,GACtB,IAAI2T,EAAO,GASX,YARajU,IAATM,IAAoBA,EAAO,IAC/BA,EAAOgR,EAAEtS,MAAMsB,GAAM1I,KAAI,SAASwH,GAChC,IAAIzB,EAAI,EAIR,MAHkB,MAATyB,EAAE,IAAczB,GAAK,EAAGyB,EAAIA,EAAE3H,MAAM,IAC3B,MAAT2H,EAAE,KAAczB,EAAI,EAAIyB,EAAIA,EAAE3H,MAAM,IAC7Cwc,EAAK1c,KAAKoG,GACH2T,EAAE9U,SAAS4C,MAEb,SAAShI,EAAGsG,GACjB,IAAIhD,EAAG6C,EAAG6B,EAAG/C,EACb,IAAK3B,EAAE,EAAG6C,EAAE+C,EAAKnG,OAAQO,EAAE6C,IAAK7C,EAG9B,GAFA0E,EAAIkB,EAAK5F,GACT2B,EAAIiV,EAAE7R,IAAIL,EAAEhI,GAAIgI,EAAE1B,IACX,OAAOrB,EAAI4X,EAAKvZ,GAEzB,OAAO,IAIX4W,EAAE7R,IAAM,SAASrI,EAAGsG,GAClB,OAAQtG,EAAIsG,GAAU,MAALtG,IAAmB,MAALsG,GAAa,GACzCtG,EAAIsG,GAAU,MAALA,IAAmB,MAALtG,EAAY,GAClCsG,EAAIA,aAAa3D,MAAQ2D,EAAIA,GAC7BtG,EAAIA,aAAa2C,MAAQ3C,EAAIA,KAAQA,GAAKsG,GAAMA,GAAK,EACvDA,GAAMA,GAAKtG,GAAMA,EAAI,EAAI,IAG7Bka,EAAE4C,OAAS,SAAS9c,EAAGsG,GAAK,OAAOtG,EAAIsG,GAEvC4T,EAAE6C,WAAa,SAASnV,EAAOoV,EAAQC,GACrC,IAAIC,EAAUtV,EAAM/H,QAAO,SAASsd,EAAKb,EAAGhZ,GAC1C,OAAQ6Z,EAAIF,EAAMX,IAAMhZ,EAAG6Z,IAC1B,IASH,OAPAvV,EAAMsB,MAAK,SAASlJ,EAAGsG,GACrB,IAAI8W,EAAKJ,EAAOhd,GACZqd,EAAKL,EAAO1W,GAChB,OAAO8W,EAAKC,GAAM,EAAID,EAAKC,EAAK,EACxBH,EAAQD,EAAMjd,IAAMkd,EAAQD,EAAM3W,OAGrCsB,GAITsS,EAAEoD,QAAU,SAAStd,GAKnB,IAJA,IACIud,EACAja,EAFAka,EAAIxd,EAAE+C,OAIHya,GACLla,EAAIma,KAAKC,MAAMD,KAAKE,SAAWH,KAC/BD,EAAOvd,EAAEwd,GACTxd,EAAEwd,GAAKxd,EAAEsD,GACTtD,EAAEsD,GAAKia,GAMXrD,EAAE0D,IAAM,SAASrX,EAAGxD,EAAQ8a,EAAKC,GAC/BA,EAAUA,GAAW,IACrB,IAAItC,EAAIzY,EAASwD,EAAExD,OACnB,GAAIyY,GAAK,EAAG,OAAOjV,EACnB,OAAQsX,GACN,IAAK,OACH,OAAOlC,EAAOH,EAAGsC,GAAWvX,EAC9B,IAAK,SACL,IAAK,SACH,OAAOoV,EAAO8B,KAAKC,MAAMlC,EAAE,GAAIsC,GAC5BvX,EAAIoV,EAAO8B,KAAKM,KAAKvC,EAAE,GAAIsC,GAChC,QACE,OAAOvX,EAAIoV,EAAOH,EAAGsC,KAU3B5D,EAAE8D,SAAW,SAASzX,EAAGxD,EAAQ8a,EAAKI,EAAMC,GAC1C,IAAIpY,EAAMS,EAAExD,OACZ,GAAI+C,GAAO/C,EAAQ,OAAOwD,EAC1B2X,OAAwBtV,IAAbsV,EAAyBlD,OAAOkD,GAAY,IACvD,IAAIC,EAAIV,KAAKW,IAAI,EAAGrb,EAASmb,EAASnb,QAEtC,OAAQ8a,GACN,IAAK,OACH,OAAOK,GAAYD,EAAOrC,EAAerV,EAAE4X,EAAE,GAAK5X,EAAElG,MAAMyF,EAAIqY,IAChE,IAAK,SACL,IAAK,SACH,IAAIE,EAAKZ,KAAKM,KAAKI,EAAE,GAAIG,EAAKb,KAAKC,MAAMS,EAAE,GAC3C,OAAQF,EAAOrC,EAAerV,EAAE8X,GAAM9X,EAAElG,MAAM,EAAEge,IAC9CH,GAAYD,EAAOrC,EAAerV,EAAE+X,EAAG,GAAK/X,EAAElG,MAAMyF,EAAIwY,IAC5D,QACE,OAAQL,EAAOrC,EAAerV,EAAE4X,GAAK5X,EAAElG,MAAM,EAAE8d,IAAMD,IAgB3D,IAAIjC,EAAmB,mSD7PPsC,EAAU3W,EAAcI,GACtC,OAAOJ,EAAMpH,KAAKR,GACZE,GAAAA,QAAAA,QAAQF,GACHue,EAAUve,EAAGgI,GAEfA,EAAEhI,2NEFGwe,GAAqBtY,GACnC,QAASA,EAAU,OAGrB,MAAMuY,GAA2D,CAC/D5Q,QAAS,EACT6Q,UAAW,EACXC,UAAW,EACXC,IAAK,EACLC,SAAU,EACVC,MAAO,EACP5V,KAAM,EACN6V,MAAO,EACPlZ,MAAO,EACPjF,KAAM,EACN8P,OAAQ,EACRsO,MAAO,EACPC,KAAM,EACNC,OAAQ,EACR3f,MAAO,GAGI4f,GAA0BlF,GAASwE,aAEhCW,GAA2BlZ,GACzC,OAAOA,EAAExB,aAAc+Z,GAKzB,MAAMY,GAAoE,CACxET,IAAK,EACLI,MAAO,EACP9V,KAAM,EACN+V,KAAM,EACNC,OAAQ,YAGMI,GAAuBC,GACrC,OAAOF,GAAkCE,GAIpC,MAAMC,GAAuC,CAAC,UAAW,SAAU,SAAU,OAAQ,OAAQ,QAAS,WAChGC,GAAwD,CAAC,QAAS,KAAM,SAE/EC,GAAYF,GAAgBhf,KAAKyE,IAC9B,CAAC7D,OAAQ,MAAOU,MAAOmD,MAGnB0a,GAAaF,GAAiBjf,KAAKyE,IACvC,CAAC7D,OAAQ,OAAQU,MAAOmD,MAGpB2a,GAActG,GAAiB9Y,KAAKyE,IACxC,CAAC7D,OAAQ,QAASU,MAAOmD,MAG5B4a,GAAa/K,GAAgBtU,KAAKyE,IAC/B,CAAC7D,OAAQ,OAAQU,MAAOmD,MAG3B6a,GAAe/K,GAAkBvU,KAAKyE,IACnC,CAAC7D,OAAQ,SAAUU,MAAOmD,MAGtB8a,GAAyB,GAA4BjZ,OAChE4Y,GACAC,GACAC,GACAC,GACAC,IAGWE,GAAyB,CAAC,QAAS,SAAU,aAAc,UAAW,kBAInEC,GAAM/Z,GACpB,OAAIsY,GAAqBtY,GAChBA,EAAE9E,OAJc,IAIgB8E,EAAEpE,MAEpCoE,WAGOga,GAAQjY,GACtB,MAAM+T,EAAQ/T,EAAE+T,MAVS,KAYzB,GAAqB,IAAjBA,EAAMjZ,OACR,OAAOkF,EACF,GAAqB,IAAjB+T,EAAMjZ,OACf,MAAO,CACL3B,OAAQ4a,EAAM,GACdla,MAAOka,EAAM,IAGf,KAAM,6BAA6BA,EAAMjZ,gBAAgBkF,IAI7D,MAAMkY,GAA6BJ,GAAsBlgB,QAAO,CAACyD,EAAGic,KAClEjc,EAAEic,EAAKne,QAAUkC,EAAEic,EAAKne,SAAW,GACnCkC,EAAEic,EAAKne,QAAQme,EAAKzd,OAASyd,EACtBjc,IACN,aAGa8c,GAAsBhf,EAA8BU,GAClE,OAAQqe,GAA2B/e,IAAW,IAAIU,YAGpCue,GAAmBna,GACjC,OAAOkZ,GAA2BlZ,IAAMsY,GAAqBtY,GAGxD,MAAMoa,GAAsB,GAAkBxZ,OAAOqY,GAAyBY,IAExEQ,GACX,CACE,OACA,QAGA,MACA,WACA,YACA,YAGA,UAGA,OACA,QAEA,QACA,OACA,OACA,UAEFzZ,OAAO4Y,GAAWE,GAAaC,GAAYC,GAAcH,QAE1Ca,IAAjB,SAAiBA,GACFA,EAAAC,KAAe,OAEfD,EAAAE,UAAyB,YAEzBF,EAAAG,MAAiB,QAEjBH,EAAAI,OAAmB,SAKnBJ,EAAAK,QAAqB,UACrBL,EAAAM,UAAyB,YACzBN,EAAAO,UAAyB,YACzBP,EAAAQ,IAAa,MAEbR,EAAAS,OAAkB,QAClBT,EAAAU,SAAuB,WACvBV,EAAAW,MAAiB,QACjBX,EAAAY,KAAe,OAEfZ,EAAAa,KAAe,OAEfb,EAAAc,MAAiB,QACjBd,EAAAe,KAAe,OAEff,EAAAgB,OAAmB,SAEnBhB,EAAAiB,MAAiB,QACjBjB,EAAAkB,OAAmB,SACnBlB,EAAAmB,WAA2B,aAC3BnB,EAAAoB,QAAqB,UACrBpB,EAAAqB,MAAiB,QAjChC,CAAiBrB,KAAAA,GAAQ,gZCnLlB,MAAMsB,GAAO,CAClBlS,IAAK,MACLZ,KAAM,OACNC,IAAK,MACLC,MAAO,QACPO,KAAM,OACNH,MAAO,QACPH,KAAM,OACNC,KAAM,OACN9B,KAAM,OACNkC,KAAM,OACNE,MAAO,QACPL,OAAQ,SACRE,OAAQ,SACRI,SAAU,YAGCoS,GAAMD,GAAKlS,IACXoS,GAAOF,GAAK9S,KACZiT,GAAMH,GAAK7S,IAEXiT,GAAOJ,GAAKrS,KACZ0S,GAAQL,GAAKxS,MACb8S,GAAON,GAAK3S,KACZkT,GAAOP,GAAK1S,KACZ/D,GAAOyW,GAAKxU,KACZgV,GAAOR,GAAKtS,KAEZ+S,GAAST,GAAKzS,OACdmT,GAASV,GAAKvS,gBASXkT,GAAWjF,GACzB,OAAO7V,EAAS,CAAC,OAAQ,OAAQ,SAAU6V,GA8PhB9V,EAvPEuB,EAAK6Y,KCxC7B,MAAMY,GAAiC,aAkB9BC,GAAWpD,GACzB,OAAOqD,GAAgBrD,IAASsD,GAActD,YAGhCqD,GAAgBrD,GAC9B,OAAOA,IAASmD,YAGFG,GAActD,GAC5B,aAAgB3W,IAAT2W,GAA8B,MAARA,IAAmBA,EAAKuD,OAAUvD,EAAKha,MAAUrF,GAAAA,QAAAA,QAAQqf,aAGxEwD,GACdxD,EACAyD,EACAC,GAEA,OAAOtI,GAAAA,QAAAA,OACL,GACA,CACEpV,KAAMyd,EACNF,KAAMG,GAER1D,IAASmD,GAAiB,GAAKnD,GAQnC,SAAS2D,GAAmBC,GAC1B,MAAM/f,EAAQ,GACRggB,EAAM,GACZ,IAAK,MAAMC,KAAYF,EAAW,CAChC,MAAMG,EAAiB,CAAC,GACxB,IAAK,IAAIhgB,EAAI,EAAGA,EAAI+f,EAAStgB,OAAQO,IAC/B+f,EAASE,OAAOjgB,GAAGkgB,gBAAkBH,EAASE,OAAOjgB,IACvDggB,EAAenjB,KAAKmD,GAGxB,IAAImgB,EAAYH,EACb9iB,KAAK8C,GAAM+f,EAASE,OAAOjgB,KAC3B+F,KAAK,IACLqa,cACH,GAAKN,EAAIK,GAMT,GAAIH,EAAeA,EAAevgB,OAAS,KAAOsgB,EAAStgB,OAAS,IAClE0gB,EAAYH,EACTxc,OAAO,CAACuc,EAAStgB,OAAS,IAC1BvC,KAAK8C,GAAM+f,EAASE,OAAOjgB,KAC3B+F,KAAK,IACLqa,cACEN,EAAIK,IAMX,IAAK,IAAIngB,EAAI,GAAIF,EAAMigB,GAAW/f,IAAK,CACrC,MAAMqgB,EAAkB,GAAGF,KAAangB,IACxC,IAAK8f,EAAIO,GAAkB,CACzBvgB,EAAMigB,GAAYM,EAClBP,EAAIO,IAAmB,EACvB,YAVAvgB,EAAMigB,GAAYI,EAClBL,EAAIK,IAAa,OAbnBrgB,EAAMigB,GAAYI,EAClBL,EAAIK,IAAa,EAyBrB,OAAOrgB,EAGF,MAAMwgB,GAAe,CAC1B/U,KAAM,IACNhB,QAAS,IACT6Q,UAAW,IACXC,UAAW,IACXG,MAAO,IACPF,IAAK,IACL1V,KAAM,KACN6V,MAAO,KACPC,MAAO,IACPtO,OAAQ,IACRuO,KAAM,KACNC,OAAQ,IACR3f,MAAO,IAEPsf,SAAU,KACVhZ,MAAO,IACPjF,KAAM,IAENijB,SAAU,CACRC,QAAS,KACTC,IAAK,KACL3F,IAAK,KACLrF,KAAM,IACNiL,KAAM,IACNC,MAAO,KACPC,QAAS,KACTC,OAAQ,KAEVC,UAAW,CACTve,MAAO,IACP2W,GAAI,IACJnP,MAAO,MAETgX,WAAYnB,GAAmB5J,IAC/BgL,UAAWpB,GAAmBpO,IAC9ByP,YAAarB,GAAmBnO,cAGlByP,GAAejF,GAC7B,GAAIf,GAAqBe,GACvB,MAAO,GAAGqE,GAAarE,EAAKne,WAAWwiB,GAAa,GAAGrE,EAAKne,eAAeme,EAAKzd,SAElF,GAAI8hB,GAAarE,GACf,OAAOqE,GAAarE,GAGtB,MAAM,IAAItc,MAAM,8BAA8Bsc,KAQhD,MAAMkF,GAAuB,EAAC,GAAO,GAmPxBC,GAAgC,CAC3C7V,KAAM,CAAC8V,GAAYC,GAAUC,GAAWC,GAAWC,GAAWC,GAAWC,IACzEpX,QAAS,CAAC/D,EAAGC,EAAGJ,EAAKC,EAAQkB,EAAMJ,GACnCwa,KAAM,MAACtc,GAEP8V,UAAW,MAAC9V,EAAW,QACvB+V,UAAW8F,GACX7F,IAAK6F,GACL3F,MAAO2F,GACP5F,SAAU,MAACjW,EAAW,OAAQ,QAAS,UAAW,WAElD/C,MAAO,MAAC+C,GACRhI,KAAM,CAACukB,GAAcC,GAAcC,GAAmBC,IAEtDpc,KAAM,CAAC,YAAa,cACpB6V,MAAO,CAAC,OAAQ,YAAa,SAAU,MACvCxf,MAAO,MAACqJ,GAER8H,OAAQ,MAAC9H,GACT4K,MAAO,MAAC5K,GACRoW,MAAO,EAAC,GACRC,KAAMwF,GACNvF,OAAQuF,GAERZ,SApPsD,CACtDC,QAAS,CAAC,EAAG,GAAI,IACjByB,OAAQ,MAAC3c,GACTmQ,KAAM,CAAC,IACPiL,KAAM,MAACpb,GACPqb,MAAO,MAACrb,GACRsb,QAAS,MAACtb,GACVub,OAAQ,CAAC,CAAC,EAAG,IACbqB,OAAQ,EAAC,GACTC,OAAQ,MAAC7c,GACTkQ,KAAM,EAAC,IA2OPsL,UAxOkE,CAClEve,MAAO,MAAC+C,GACR4T,GAAI,CAAC,MAAO,QACZnP,MAAO,CAAC,YAAa,eAsOrBgX,WAnOoD,CACpDhM,MAAO,MAACzP,GACRhI,KAAM,MAACgI,EAAW4O,IAClBrH,OAAQ,MAACvH,GACTsP,UAAW,MAACtP,GACZwP,UAAW,MAACxP,GACZuP,UAAW,MAACvP,GACZmQ,KAAM,MAACnQ,GACPoQ,SAAU,CAAC,EAAG,GACdC,SAAU,MAACrQ,GAEX8P,KAAM,MAAC9P,GAEPiQ,MAAO4L,GACP3L,KAAM2L,GACN9L,QAAS8L,GACT7L,MAAO6L,GACPtL,KAAMsL,GAEN3O,QAAS,MAAClN,GACVwQ,aAAc,MAACxQ,GACfyQ,aAAc,MAACzQ,GAEfsQ,YAAa,MAACtQ,GAEd0P,MAAO,MAAC1P,GACR2P,SAAU,MAAC3P,GACX4P,SAAU,MAAC5P,GACX6P,OAAQ,MAAC7P,IAwMT0b,UArMkD,CAClDrU,KAAM,MAACrH,GACP+E,YAAa,MAAC/E,GACd8L,OAAQ,CAAC,EAAG,GACZlC,OAAQ,MAAC5J,GACToH,OAAQ,MAACpH,GACT6L,OAAQ,MAAC7L,GAETsH,aAAc,MAACtH,GACfiM,SAAU,MAACjM,GAEXuH,OAAQsU,GACRrU,UAAW,MAACxH,GACZyH,YAAa,MAACzH,GACd0H,WAAY,MAAC1H,GACb2H,iBAAkB,MAAC3H,GACnB4H,cAAe,MAAC5H,GAChB6H,YAAa,MAAC7H,GAEd+H,WAAY,MAAC/H,GAEbgI,KAAM6T,GACN5T,QAAS,MAACjI,GACVkI,UAAW,MAAClI,GACZmI,SAAU,MAACnI,GACXoI,eAAgB,MAACpI,GACjBqI,YAAa,MAACrI,GACdsI,UAAW,MAACtI,GAEZ8H,OAAQ,MAAC9H,GACTwJ,OAAQqS,GACRtT,WAAY,MAACvI,GACbwI,WAAY,MAACxI,GACbyI,cAAe,MAACzI,GAChB2I,WAAY,MAAC3I,GACbgM,UAAW,MAAChM,GACZ6I,iBAAkB,MAAC7I,GACnB8I,UAAW,MAAC9I,GACZ+I,cAAe,MAAC/I,GAChBgJ,eAAgB,MAAChJ,GACjBiJ,gBAAiB,MAACjJ,GAClBkJ,WAAY,MAAClJ,GACbmJ,gBAAiB,MAACnJ,GAClBoJ,YAAa,MAACpJ,GACdqJ,aAAc,MAACrJ,GACfyJ,gBAAiB,MAACzJ,GAClBsJ,aAAc,MAACtJ,GACfuJ,aAAc,MAACvJ,GACf0I,WAAY,MAAC1I,GACb4I,WAAY,MAAC5I,GAEb0J,UAAW,MAAC1J,GACZ2J,UAAW,MAAC3J,GACZ6J,SAAU,MAAC7J,GAEX+L,MAAO,MAAC/L,GAERyK,MAAOoR,GACP/R,SAAU,MAAC9J,GACX+J,QAAS,MAAC/J,GACVgK,UAAW,MAAChK,GACZiK,UAAW,MAACjK,GACZkK,SAAU,MAAClK,GACXoK,UAAW,MAACpK,GACZmK,eAAgB,MAACnK,GACjBqK,YAAa,MAACrK,GACdsK,WAAY,MAACtK,GACbuK,YAAa,MAACvK,GACdwK,UAAW,MAACxK,GACZ0K,SAAU,MAAC1K,GACX2K,UAAW,MAAC3K,GAEZ4K,MAAO,MAAC5K,GACR6K,WAAY,MAAC7K,GACb8K,YAAa,MAAC9K,GACd+K,WAAY,MAAC/K,GACbgL,cAAe,MAAChL,GAChBiL,WAAY,MAACjL,GACbkL,UAAW,MAAClL,GACZmL,cAAe,MAACnL,GAChBoL,eAAgB,MAACpL,GACjBqL,gBAAiB,MAACrL,GAClBsL,WAAY,MAACtL,GACbuL,gBAAiB,MAACvL,GAClBwL,aAAc,MAACxL,GACfyL,aAAc,MAACzL,GACf0L,OAAQ,MAAC1L,GACT2L,OAAQ,MAAC3L,GAET4L,UAAW,MAAC5L,IA6GZ2b,YA1G2D,CAC3DtU,KAAM,MAACrH,GACP+E,YAAa,MAAC/E,GACdoH,OAAQ,CAAC,OAAQ,SACjBU,OAAQ,MAAC9H,GACThI,KAAM,MAACgI,GACP6L,OAAQ,MAAC7L,GACT8L,OAAQ,MAAC9L,GAEToM,WAAY,MAACpM,GACbqM,cAAe,MAACrM,GAChBsM,QAAS,MAACtM,GACVuM,aAAc,MAACvM,GACfwM,UAAW,MAACxM,GACZiM,SAAU,MAACjM,GACXyM,UAAW,MAACzM,GACZ+H,WAAY,MAAC/H,GACb+M,UAAW,MAAC/M,GACZ4J,OAAQ,MAAC5J,GACTkN,QAAS,MAAClN,GACVmN,WAAY,MAACnN,GACboN,YAAa,MAACpN,GAEduI,WAAY,MAACvI,GACbyI,cAAe,MAACzI,GAChB2I,WAAY,MAAC3I,GACbgM,UAAW,MAAChM,GACZ8I,UAAW,MAAC9I,GACZ+I,cAAe,MAAC/I,GAChBgJ,eAAgB,MAAChJ,GACjBiJ,gBAAiB,MAACjJ,GAClBkJ,WAAY,MAAClJ,GACboJ,YAAa,MAACpJ,GACdqJ,aAAc,MAACrJ,GACfsJ,aAAc,MAACtJ,GACfuJ,aAAc,MAACvJ,GACfyJ,gBAAiB,MAACzJ,GAElBgN,QAAS,MAAChN,GACViN,QAAS,MAACjN,GAEV0M,eAAgB,MAAC1M,GACjB2M,gBAAiB,MAAC3M,GAClB4M,oBAAqB,MAAC5M,GACtB6M,oBAAqB,MAAC7M,GACtB8M,kBAAmB,MAAC9M,GAEpBqN,WAAY,MAACrN,GACbsN,iBAAkB,MAACtN,GACnBuN,gBAAiB,MAACvN,GAClBwN,YAAa,MAACxN,GACdyN,aAAc,MAACzN,GACf0N,cAAe,MAAC1N,GAChB2N,WAAY,MAAC3N,GACb4N,kBAAmB,MAAC5N,GACpB6N,kBAAmB,MAAC7N,GACpB8N,WAAY,MAAC9N,GAEbiK,UAAW,MAACjK,GACZqK,YAAa,MAACrK,GAEd4K,MAAO,MAAC5K,GACR8K,YAAa,MAAC9K,GACd6K,WAAY,MAAC7K,GACbgL,cAAe,MAAChL,GAChBiL,WAAY,MAACjL,GACbkL,UAAW,MAAClL,GACZmL,cAAe,MAACnL,GAChBoL,eAAgB,MAACpL,GACjBqL,gBAAiB,MAACrL,GAClBsL,WAAY,MAACtL,GACbuL,gBAAiB,MAACvL,GAClBwL,aAAc,MAACxL,GACf+N,YAAa,MAAC/N,GACdyL,aAAc,MAACzL,cAoCD8c,GAAqBnG,EAAgBoG,EAAgB3e,GACnE,GAAa,UAATuY,GAAqBf,GAAqBe,IAAyB,SAAhBA,EAAKne,QAAoC,UAAfme,EAAKzd,MAEpF,OAAO6jB,EAAOC,aAGhB,IAAIC,EAOJ,GALEA,EADErH,GAAqBe,GACjBvY,EAAI8b,KAAK,GAAGvD,EAAKne,eAAeme,EAAKzd,OAErCkF,EAAI8b,KAAKvD,QAGL3W,IAARid,EACF,OAAOA,EAIT,MAAM,IAAI5iB,MAAM,6BAA6BsE,KAAKC,UAAU+X,iNC1XvD,MAAMuG,GAAoC,CAC/CC,SAAS,EACTC,kBAAmB,CACjBvW,KAAM,CAACH,OAAO,GACd0P,MAAO,CAACiH,uBAAuB,IAEjCC,mBAAoB3F,GAAwB/f,IAAIyf,IAChD6C,KAAM4B,GAENyB,wBAAyB,IACzBC,mBAAoB,GAGpBC,kCAAkC,EAElCC,cAAc,EAEdC,kCAAkC,EAClCC,eAAe,EACfC,2CAA2C,EAC3CC,mCAAmC,EACnCC,8BAA8B,EAC9BC,qBAAqB,EACrBC,mCAAmC,EACnCC,SAAS,EACTC,wCAAwC,EACxCC,mBAAmB,EACnBC,gDAAgD,EAChDC,sCAAsC,EACtCC,qBAAqB,EACrBC,sBAAsB,EACtBC,iBAAiB,EAEjBC,iBAAkBC,EAClBC,sBAAuBD,EACvBE,qBAAsBC,EACtBC,qBAAsBD,EACtBE,eAAgBC,EAGhBC,qBAAsB,GACtBC,kCAAmC,GACnCC,uBAAwB,GACxBC,uBAAwB,EACxBC,6BAA6B,EAC7BC,uBAAuB,EAGvBC,SAAS,EACTC,wCAAyC,CAACC,eAAgB,GAAIC,UAAW,IACzEC,oCAAqC,CAACF,eAAgB,GAAIG,QAAS,cACnEC,2CAA4C,CAACJ,eAAgB,IAG7DK,2BAA4B,EAC5BC,2BAA4B,EAG5BC,uBAAwB,GACxBC,qBAAsB,IAWxB,SAASC,GAAgBC,GASvB,OARa5pB,OAAA0M,OAAA1M,OAAA0M,OAAA1M,OAAA0M,OAAA,GACR4Y,IACAsE,GAAS,CACZnF,SAAUoF,GAAsBD,EAAW,OAC3C3E,WAAY4E,GAAsBD,EAAW,SAC7C1E,UAAW2E,GAAsBD,EAAW,QAC5CzE,YAAa0E,GAAsBD,EAAW,YAKlD,SAASC,GAAsBD,EAA+BzJ,GAC5D,OAAAngB,OAAA0M,OAAA1M,OAAA0M,OAAA,GACK4Y,GAAmB,GAAGnF,WACtByJ,EAAU,GAAGzJ,8FAvBSvY,GAC3B,OAAA5H,OAAA0M,OAAA1M,OAAA0M,OAAA1M,OAAA0M,OAAA,GACKga,IACA9e,GAAG,CACN8b,KAAMiG,GAAgB/hB,EAAI8b,WC7I9B,MAAMoG,GAAwC,CAC5CC,OAAQ,EACRC,OAAQ,EACRC,QAAS,EACTC,MAAO,EACPC,SAAU,EACVC,QAAS,EACTpL,IAAK,EACLqL,KAAM,EACNC,OAAQ,EACR3F,IAAK,EACL4F,QAAS,EACTC,GAAI,EACJC,GAAI,EACJC,IAAK,EACLC,IAAK,EACLC,OAAQ,EACRC,MAAO,EACPC,OAAQ,EACRC,IAAK,EACLC,MAAO,EACP3V,OAAQ,EACR4V,SAAU,EACVC,UAAW,GA8CN,MAAMC,GAA+B,CAAC,QAAS,MAAO,WAAY,QAAS,oBCsBlEC,GAAY5L,GAI1B,OAHIzX,EAAUyX,KACZA,WCyhCyBA,EAAqC/Q,GAChE,OAAI1G,EAAUyX,GACL,CAACkF,QAAS2G,GAAY5c,IACZ,WAAR+Q,EACF,CACL4G,QAAQ,GAEA5G,EAAIkF,SAAYlF,EAAIoF,KAGvBpF,EAFPxf,OAAA0M,OAAA1M,OAAA0M,OAAA,GAAW8S,GAAG,CAAEkF,QAAS2G,GAAY5c,KDjiC/B6c,CAAa9L,OAAKhW,IAGxB,MACAK,EAAK2V,GACFpe,KAAI0F,IAAC,OAwBHqf,OADyBA,EAvBC3G,EAAI1Y,SAwBxB,EAANqf,EAAoB,WAxBgBjc,EAAQ,IAAIpD,KAAKgC,EAAQ0W,EAAI1Y,OAASoD,EAAQ,IAAIpD,KAAK0Y,EAAI1Y,UAuBtEqf,KAtB3Blc,KAAK,aAOIshB,GAAU/L,GACxB,OAAe,IAARA,YAUmBA,GAC1B,OAAO1X,EAAS0X,GAXQgM,CAAYhM,KAASA,EAAI4G,gBAkBnCiF,GAAY5c,GAC1B,OAAQA,GACN,KAAKlE,EACL,KAAKC,EACL,KAAKkB,EACL,KAAKJ,EACL,KAAKC,EACL,KAAKC,EACL,KAAKO,EACL,KAAKH,EACL,KAAKC,EACL,KAAKC,EAGL,KAAKL,EACH,OAAO,EACT,KAAKO,EACH,OAAO,EACT,QACE,OAAO,IDpEyB1D,EAFU,CAAC,OAAQ,UAAW,SAAU,KAAM,KAAM,MAAO,QGyD3E,CACpB,UACA,WACA,QACA,QACA,MACA,OACA,OACA,SACA,YACA,UACA,WACA,YAEiClH,KAAIgd,GAAKA,EAAEqN,OAAO,EAAG,KAEpC,CAAC,SAAU,SAAU,UAAW,YAAa,WAAY,SAAU,YACxDrqB,KAAIgb,GAAKA,EAAEqP,OAAO,EAAG,sVClJ7C,MAAMC,GAA8B,CACzCC,KAAM,EACNC,QAAS,EACTC,MAAO,EACPC,KAAM,EACNC,IAAK,EACLC,UAAW,EACX7P,KAAM,EACN8P,MAAO,EACPC,QAAS,EACTC,QAAS,EACTC,aAAc,GAKHC,GAAiBxiB,EAAK6hB,aAEnBY,GAAsB7M,GACpC,QAASiM,GAA4BjM,YAkHvB8M,GAAclsB,GAC5B,OAAOA,EAAEmsB,WAAW,gBAqENC,GAAiBC,EAAwBjN,GACvD,MAAMzb,EAAQ0oB,EAAazoB,QAAQwb,GAEnC,QAAIzb,EAAQ,OAKRA,EAAQ,GAAkB,YAAbyb,GAA6D,MAAnCiN,EAAavI,OAAOngB,EAAQ,QAKnE0oB,EAAa/oB,OAASK,EAAQ,GAAkB,QAAbyb,GAAyD,MAAnCiN,EAAavI,OAAOngB,EAAQ,OAGrFA,EAAQ,GAAkB,SAAbyb,GAA0D,MAAnCiN,EAAavI,OAAOngB,EAAQ,eAqEtD2oB,GAAkBlN,GAChC,IAAKA,EACH,OAGF,IAAImN,EAiBJ,OAhBI5kB,EAASyX,GACXmN,EAAS,CACPC,KAAMpN,GAEC3X,EAAS2X,KAClBmN,EAAM5sB,OAAA0M,OAAA1M,OAAA0M,OAAA,GACD+S,GACCA,EAASoN,KAAO,CAACA,KAAMpN,EAASoN,MAAQ,KAI5CN,GAAcK,EAAOC,QACvBD,EAAOE,KAAM,EACbF,EAAOC,KAAwBD,EAAOC,KAzK/BpB,OAAO,IA4KTmB,WFmROG,GACdC,GAEA,MAAMC,EAAYD,GAAcA,EAAsB,UACtD,QAASC,IAAcnsB,EAAQmsB,IAAcC,GAAWD,YAiB1CC,GACdF,GAGA,SAASA,IAAiBA,EAAkB,OAAiC,UAA5BA,EAAsB,oBAGzDG,GAAgCH,GAC9C,OAAOA,GAAcA,EAAiB,cA6FxBI,GACdC,EACAzlB,EAAsB,cAEtB,IAAInB,EAAQ4mB,EAAS5mB,MACrB,MAAM6mB,EAAS1lB,EAAI0lB,OACnB,IAAIC,EAAS3lB,EAAI2lB,OAEbC,EAAc,GAElB,YAwEsBH,GACtB,MAA8B,UAAvBA,EAAS/N,UAzEZmO,CAAQJ,GACV5mB,WjBhW0BN,GAC5B,gBAG8BA,GAC9B,OAA8B,IAAvBA,EAAKlC,QAAQ,MAJbypB,CAAgBvnB,GAAQA,EAAO,KAAKA,IiB+VjCwnB,CAAc,aACjB,CACL,IAAI1nB,EAEJ,IAAK2B,EAAIgmB,KACP,GAzBN,SACEP,GAEA,MAAO,OAAQA,EAsBPQ,CAAaR,GACfpnB,EAAKonB,EAASjQ,OACT,CACL,MAAMoC,IAACA,EAAGF,UAAEA,EAASG,SAAEA,GAAY4N,EAC/B9B,GAAU/L,IACZvZ,EAAKmlB,GAAY5L,GACjB+N,GAAuB,QAAdO,EAAClmB,EAAImmB,iBAAS,IAAAD,EAAAA,EAAI,KAAiB,QAAfE,EAAKpmB,EAAI2lB,cAAM,IAAAS,EAAAA,EAAI,KACvC1O,GF5qBS1e,EE6qBF0e,IF5qBR1e,EAAU,QE6qBhB4sB,EAAc,KAAK/mB,MACnBA,EAAQ,UAAU6Y,EAAUyK,oBFnrBZnpB,GAC1B,QAASA,KAAOA,EAAU,OEmrBPqtB,CAAY3O,GAIrBrZ,EAAK2V,OAAO0D,IAHZkO,EAAc,KAAK/mB,MACnBA,EAAQ,UAAU6Y,EAAU0K,UAIrBvK,IACTxZ,WE5auBioB,GAC/B,MAAMJ,EAAiBnB,GAAkBuB,IAAnCpB,IAACA,GAAGgB,EAAKK,EAAIC,GAAAN,EAAb,CAAA,QAEN,OAAIK,EAAKtB,MAEJC,EAAM,MAAQ,IACfjjB,EAAKskB,GACF/sB,KAAI0F,GAAKoD,EAAQ,GAAS,SAANpD,EAAe,GAAK,IAAIA,OAAOqnB,EAAKrnB,QACxDmD,KAAK,KAKP6iB,EAAM,MAAQ,IACf,WACAjjB,EAAKskB,GACF/sB,KAAI0F,GAAKoD,EAAQ,IAAIpD,KAAKqnB,EAAKrnB,QAC/BmD,KAAK,IF2ZCokB,CAAiB5O,GACtB8N,IAAYhlB,EAAS,CAAC,QAAS,OAAQX,EAAImmB,YAAcnmB,EAAImmB,WAAc,KAAiB,QAAfO,EAAK1mB,EAAI2lB,cAAM,IAAAe,EAAAA,EAAI,KAKlGroB,IACFQ,EAAQA,EAAQ,GAAGR,KAAMQ,IAAUR,OF9rBbrF,EE0sB1B,OARI2sB,IACF9mB,EAAQ,GAAGA,KAAS8mB,KAGlBD,IACF7mB,EAAQ,GAAG6mB,KAAU7mB,KAGnBmB,EAAI2mB,MjBvbD,GAAG1nB,EiBwbmBJ,GjBxbGwD,KAAK,OiByb1BrC,EAAI4mB,cjBzdmBloB,EAAcmoB,EAA4C,SAC5F,MAAO,GAAGA,KAASC,EAAY7nB,EAAgBP,GAAM2D,KAAK,SiB0djD0kB,CAAoBloB,EAAOmB,EAAI4mB,MAAQhB,WjB/cflnB,GACjC,MAAO,GAAGO,EAAgBP,GAAMlF,IAAIiJ,GAAkBJ,KAAK,SiBidlD2kB,CAAmBnoB,GAAS+mB,WAIvBqB,GAAWC,GACzB,OAAQA,EAAIttB,MACV,IAAK,UACL,IAAK,UACL,IAAK,UACH,OAAO,EACT,IAAK,eACH,OAAO0rB,GAAW4B,MAAUA,EAAItP,IAClC,IAAK,WACH,OAAO,EAEX,MAAM,IAAI3b,MAAMkrB,GAA6BD,EAAIttB,gBAGnCwtB,GAAa3B,GAC3B,OAAQwB,GAAWxB,YAsKL4B,GAA6BjC,GAC3C,OAAIE,GAAWF,GACNA,EACED,GAAuBC,GACzBA,EAAWC,eADb,EAuMT,MAAMiC,GAAa,CAACC,YAAY,YGvnChB/U,GACdgV,EACA3gB,EACA4e,EACA5d,GAEA,MAAM4f,EA8BR,SAAqB5gB,EAAkB4e,EAAiD5d,SACtF,OAAQ4d,EAAS7rB,MACf,IAAK,UACL,IAAK,UACH,GAAIgN,GAAeC,IAAmC,aAAvBiC,GAAUjC,GAIvC,MAHgB,UAAZA,GAAyC,YAAlB4e,EAAS7rB,MAClC8tB,GAASC,GAAwC9gB,EAAS,YAErD,UAGT,GAAIA,KAAWU,IACb,GAAIqgB,EAAc,CAAC,OAAQ,MAAO,QAAS,QAAS/f,GAGlD,MAAO,YAEJ,GAAa,QAATA,GAAkBhB,KAAWW,GACtC,MAAO,OAGT,YAAsB5F,IAAlB6jB,EAASvH,OH8kBjBkH,EG9kBkEK,KHglB5C,SAAUL,GAAc,UAAWA,GAAc,WAAYA,KGhlBS,QAAjBc,EAAIT,EAASxN,YAAI,IAAAiO,OAAA,EAAAA,EAAExa,UACjF,OAGF,QAET,IAAK,WACH,OAAI9E,GAAeC,GACV,OACyB,aAAvBiC,GAAUjC,IACnB6gB,GAASC,GAAwC9gB,EAAS,aAEnD,WACEye,GAAWG,IAAaA,EAAS5N,UAAYkN,GAAkBU,EAAS5N,UAAUqN,IACpF,MAEF,OAET,IAAK,eACH,OAAIte,GAAeC,GACbye,GAAWG,IAAa9B,GAAU8B,EAAS7N,KACtC,cAGF,SACyB,aAAvB9O,GAAUjC,IACnB6gB,GAASC,GAAwC9gB,EAAS,iBAEnD,WAGF,SAET,IAAK,UACH,WH4iBJue,EGxiBA,MAAM,IAAInpB,MAAMkrB,GAA6B1B,EAAS7rB,OAzF7BiuB,CAAYhhB,EAAS4e,EAAU5d,IAClDjO,KAACA,GAAQ4tB,EAEf,OAAK7f,GAAed,QAIPjF,IAAThI,WZwxBkCiN,EAAkB2L,GACxD,IAAKsV,GAAuBjhB,GAC1B,OAAO,EAET,OAAQA,GACN,KAAK0Z,EACL,KAAKG,EACL,KAAKqH,EACL,KAAKC,EACH,OAAOjX,GAAyByB,IAAc7R,EAAS,CAAC,OAAQ,SAAU6R,GAC5E,KAAKyV,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EAGH,OACEvX,GAAyByB,IACzBxB,GAAuBwB,IACvB7R,EAAS,CAAC,OAAQ,QAAS,WAAY6R,GAE3C,KAAK+V,EACL,KAAKC,EACL,KAAKC,EACH,MAAqB,SAAdjW,EACT,KAAKkW,EACH,MAAqB,YAAdlW,GAA2BxB,GAAuBwB,GAC3D,KAAKmW,EACH,MAAqB,YAAdnW,GYpzBJoW,CAAwB/hB,EAASjN,GAMlC0rB,GAAWG,KZuvBsBoD,EYvvBiBjvB,EZuvBSkvB,EYvvBHrD,EAAS7rB,OZwvBnE+G,EAAS,CAACyP,GAASE,IAAUwY,QACNlnB,IAAlBinB,GAA+B/X,GAAkB+X,GAC/CC,IAAiBzY,GACnB1P,EAAS,CAAC6P,GAAgBA,QAAe5O,GAAYinB,GACnDC,IAAiB3Y,IACnBxP,EACL,CACE6P,GACAA,GACAA,GACAA,GACAA,GACAA,GACAA,GACAA,QACA5O,GAEFinB,MYxwBAnB,YfyNuClV,EAAsBiV,GACjE,MAAO,gCAAgCjV,2BAAmCiV,oBe1N7DsB,CAAyCnvB,EAAM6tB,IACjDA,GAGF7tB,GAVL8tB,Yf2NsC7gB,EAAkB2L,EAAsBiV,GAClF,MAAO,YAAY5gB,0BAAgC2L,2BAAmCiV,oBe5NzEuB,CAAwCniB,EAASjN,EAAM6tB,IACzDA,GAYJA,EAlBE,SZiwB8BoB,EAA0BC,Ma1xBlDG,YAUDhC,GAAWiC,GACzB,OAAOA,IAAc9K,IAAgB8K,IAAc/K,IAAgB+K,IAAcD,GAAazkB,KAXhG,SAAiBykB,GACFA,EAAA9Y,aAAekO,GACf4K,EAAA7Y,QAAUgO,GACV6K,EAAA5Y,SAAWiO,GACX2K,EAAA3Y,QAAU6N,GACV8K,EAAAzkB,IAAa,MAL5B,CAAiBykB,KAAAA,GAAY,WCQhBE,GAGXnZ,YAAY1T,EAAa,MACvBvD,KAAKqD,MAAQE,EAAClE,OAAA0M,OAAA,GAAOxI,GAAK,GAGrB0T,IAAI9Q,GACT,OAAO+Z,GAAM/Z,KAAMnG,KAAKqD,MAGnB4T,IAAI9Q,GACT,OAAOnG,KAAKqD,MAAM6c,GAAM/Z,IAGnB8Q,IAAI9Q,EAAa3G,GAEtB,OADAQ,KAAKqD,MAAM6c,GAAM/Z,IAAM3G,EAChBQ,KAGFiX,SAASxT,EAAajE,GAC3BQ,KAAKqD,MAAMI,GAAOjE,EAGbyX,IAAOhP,GACZ,MAAM1E,EAAI,IAAI6sB,GACd,IAAK,MAAMloB,KAAKlI,KAAKqD,MACnBE,EAAEF,MAAM6E,GAAKD,EAAEjI,KAAKqD,MAAM6E,IAE5B,OAAO3E,EAGF0T,OACL,OAAO/N,GAAAA,QAAAA,KAAKlJ,KAAKqD,OAAOL,OAGnBiU,YACL,OAAO,IAAImZ,GAAapwB,KAAKqD,iBCsQjBgtB,GACdvb,EACAhH,GAEA,MAAMue,EAAavX,GAAYA,EAAShH,GACxC,QAAIue,IACElsB,EAAQksB,GACHtkB,EAAKskB,GAAYK,KAAcA,EAAS5mB,QAExCymB,GAAWF,IAAeD,GAA8BC,IC5RrE,MAAMiE,GAAqB,CACzBlX,KAAM,EACNmX,OAAQ,EACRC,UAAW,GAoCN,MAAMC,GAAkB,IAAItvB,IAAU,CAAC6gB,GAAKE,GAAKD,GAAMK,GAAMF,GAAOI,GAAQC,GAAQN,GAAM7W,GAAMiX,KAC1FmO,GAAyB,IAAIvvB,IAAU,CAAC+gB,GAAKD,GAAMD,KAEhE,SAAS2O,GACP7b,EACAvN,WAEA,MAAMyE,EAAU,MAANzE,EAAY,IAAM,SAEtBqpB,EAAO9b,EAASvN,GAChBspB,EAAO/b,EAAS9I,GAEtB,GAAIugB,GAAWqE,IAASrE,GAAWsE,GACjC,GAA6B,iBAAzBrE,GAAeoE,IAAqD,iBAAzBpE,GAAeqE,GAA0B,CACtF,GAAID,EAAK5R,MACP,OAAOzX,EACF,GAAIspB,EAAK7R,MACd,OAAOhT,EAET,MAAM8kB,EAAavE,GAAWqE,MAAWA,EAAKjS,UAG9C,GAAImS,KAFevE,GAAWsE,MAAWA,EAAKlS,WAG5C,OAAOmS,EAAavpB,EAAIyE,EACnB,CACL,MAAM+kB,EAAmB,QAAb5D,EAAGyD,EAAK3R,aAAK,IAAAkO,OAAA,EAAAA,EAAEtsB,KACrBmwB,EAAmB,QAAb3D,EAAGwD,EAAK5R,aAAK,IAAAoO,OAAA,EAAAA,EAAExsB,KAE3B,GAAIkwB,GAAqB,WAAXA,EACZ,OAAO/kB,EACF,GAAIglB,GAAqB,WAAXA,EACnB,OAAOzpB,OAGN,CAAA,GAA6B,iBAAzBilB,GAAeoE,GACxB,OAAOrpB,EACF,GAA6B,iBAAzBilB,GAAeqE,GACxB,OAAO7kB,MAEJ,CAAA,GAA6B,iBAAzBwgB,GAAeoE,GACxB,OAAOrpB,EACF,GAA6B,iBAAzBilB,GAAeqE,GACxB,OAAO7kB,YAoBKgT,GACdvB,EACA3I,EACA7N,EAEI,IAEJ,MAAM6H,WZ4JkBA,GACxB,OAAOA,EAAW,KY7JLmiB,CAAUxT,GAAKA,EAAE5c,KAAO4c,EAErC,IAAKgT,GAAgBpN,IAAIvU,GACvB,OAAO,KAQT,MAAMoiB,EAAeP,GAAwB7b,EAAU,MAAQ6b,GAAwB7b,EAAU,SAEjG,IAAKoc,EACH,OAAO,KAGT,MAAMC,EAAkBrc,EAASoc,GAC3BE,EAAe7E,GAAW4E,GAAmB1E,GAAQ0E,EAAiB,SAAMtoB,EAElF,IAAIwoB,EA1CN,SAA6BvjB,GAC3B,OAAQA,GACN,IAAK,IACH,MAAO,IACT,IAAK,IACH,MAAO,IACT,IAAK,QACH,MAAO,SACT,IAAK,SACH,MAAO,SAiC4CwjB,CAAoBJ,GACvEK,EAAezc,EAASuc,GAExBG,EAAiBjF,GAAWgF,GAAgB9E,GAAQ8E,EAAc,SAAM1oB,EAGxE2oB,IAAmBJ,IACrBI,OAAiB3oB,EACjB0oB,OAAe1oB,EACfwoB,OAAmBxoB,GAIrB,MAAM4oB,EAAUljB,GAAqBzO,QAAO,CAAC4xB,EAAI5jB,KAE/C,GAAgB,YAAZA,GAAyBuiB,GAAgBvb,EAAUhH,GAAU,CAC/D,MAAMue,EAAavX,EAAShH,GAC5B,IAAK,MAAM6jB,KzBgHH,OADEzwB,EyB/GemrB,GzBgHVlsB,EAAQe,GAAKA,EAAI,CAACA,GAAK,GyBhHA,CACpC,MAAMwrB,EAAW4B,GAAYqD,GAC7B,GAAIjF,EAAS/N,UACX,SAIF,MAAM1W,EAAIwkB,GAAQC,EAAU,IAGzBzkB,GAEDA,IAAMupB,GAENE,EAAGtxB,KAAK,CAAC0N,QAAAA,EAAS4e,SAAAA,KzBiG5B,IAAgBxrB,EyB7FZ,OAAOwwB,IACN,IAGH,IAAIjf,EAYJ,QAX8B5J,IAA1BsoB,EAAgBnS,MAEhBvM,EADErL,EAAU+pB,EAAgBnS,OACnBmS,EAAgBnS,MAAQ,OAAS,KAEjCmS,EAAgBnS,MAElByS,EAAQzuB,OAAS,GAAK0tB,GAAuBrN,IAAIvU,KAE1D2D,EAAS,SAGNA,KAAyBA,KA1KlB6d,IA2KV,OAAO,SnBoG2BxiB,EY2UpCue,EO5aA,YD2G0BvX,GAC1B,OAAO/M,EAAKoG,IAAUL,IACpB,GAAIuiB,GAAgBvb,EAAUhH,GAAU,CACtC,MAAMue,EAAavX,EAAShH,GAC5B,GAAI3N,EAAQksB,GACV,OAAOtkB,EAAKskB,GAAYK,KAAcA,EAAS/N,YAC1C,CACL,MAAM+N,EAAW4B,GAAYjC,GAC7B,OAAOK,KAAcA,EAAS/N,WAGlC,OAAO,KCtHLiT,CAAY9c,IAAgC,IAAnB2c,EAAQzuB,OACnC,OAAO,KAIT,GAAImuB,EAAgBlS,OAASkS,EAAgBlS,MAAMpe,MAAQswB,EAAgBlS,MAAMpe,OAAS4W,GAAkB,CAC1G,GAAIxQ,EAAI4qB,uBACN,OAAO,KAEPlD,YnB4FoClV,GACxC,MAAO,kCAAkCA,MmB7F5BqY,CAAsCX,EAAgBlS,MAAMpe,OAKzE,OPgaO0rB,GAFPF,EO9ZsBvX,WtBgDoChH,GAC1D,OAAQA,GACN,KAAK/D,EACH,OAAOE,EACT,KAAKD,EACH,OAAOE,EACT,KAAKK,EACH,OAAOE,EACT,KAAKD,EACH,OAAOE,EACT,KAAKL,EACH,OAAOC,EACT,KAAKH,EACH,OAAOC,GsB7DoB2nB,CAAyBb,ePwYxD7E,GAEA,QAASA,GAAc,UAAWA,EAsBD2F,CAAW3F,SO/ZZxjB,IAA1BsoB,EAAgBnS,OAClB2P,GnBkFG,iBAD6B7gB,EmBjFWojB,2BnBkFUpjB,QmBhFhD,OAILye,GAAW4E,IAAoBA,EAAgBxS,YAAc/W,EAAS4iB,GAAS2G,EAAgBxS,YACjGgQ,GnBmFK,6EmBnF2CwC,EAAgBxS,gBAG3D,CACLsT,eAAgBV,EAAeF,OAAmBxoB,EAClDqpB,aAAcV,EACdN,aAAAA,EACAiB,OAAmC,OAA3BhB,EAAgBgB,QAA0BzP,GAAW5T,GAC7D2iB,QAAAA,EACAhf,OAAAA,aCxKY2f,GAASC,GACvB,OAAOzX,GAAAA,QAAAA,OACLyX,EAAKjqB,KAAO,CAACA,KAAMiqB,EAAKjqB,MAAQ,GAChCiqB,EAAKC,UAAY,CAACA,UAAWD,EAAKC,WAAa,GAC/CD,EAAKE,MAAQ,CAACA,MAAOF,EAAKE,OAAS,GACnCF,EAAKG,OAAS,CAACA,OAAQH,EAAKG,QAAU,GACtCH,EAAKI,WAAa,CAACA,WAAYJ,EAAKI,YAAc,GAClDJ,EAAKtc,QAAU,CAACA,QAASsc,EAAKtc,SAAW,GACzCsc,EAAK5e,MAAQ,CAACA,MAAO4e,EAAK5e,OAAS,GACnC,CACE3E,KAAMujB,EAAKvjB,KACX4jB,UAAWxpB,GAAAA,QAAAA,KAAKmpB,EAAKvd,UAAUrU,KAAKqN,IAClC,MAAM6kB,EAAsB,CAAC7kB,QAASA,GAChCue,EAAagG,EAAKvd,SAAShH,GAEjC,IAAK,MAAM0R,KAAQ6M,EACbhN,GAA2BG,SAA0C3W,IAArBwjB,EAAW7M,KAGzD5X,GAAS,CAAC,MAAO,QAAS,OAAQ,UAAW4X,IAA8B,OAArB6M,EAAW7M,GACnEmT,EAAKnT,IAAQ,EAEbmT,EAAKnT,GAAQ6M,EAAW7M,IAS9B,OAJIoT,GAAaD,IAA4B,UAAnBA,EAAKhU,YAA0BgU,EAAK7sB,QAC5D6sB,EAAK7sB,MAAQ,KAGR6sB,MAGXN,EAAKQ,OAAS,CAACA,OAAQR,EAAKQ,QAAU,aAI1BjB,GAAYkB,GAC1B,OAAO/qB,GAAK+qB,EAAMJ,WAAYC,GACpBC,GAAaD,KAAU/P,GAAW+P,EAAKhU,cAAgBgU,EAAKhU,WAAcoU,GAAwBJ,cAQ9FK,GAAWF,GACzB,IAAKG,GAA2BH,GAC9B,OAAO,KAGT,MAAMhe,EAAWoe,GAAWJ,EAAMJ,UAAW,CAAC9M,OAAQ,KAAMuN,aAAc,SAG1E,OAAOnU,GAFM8T,EAAMhkB,KAEAgG,EAAU,CAAC+c,wBAAwB,aAOxCuB,GAAeN,GAC7B,IAAK,MAAMH,KAAQG,EAAMJ,UACvB,QAA6B7pB,IAAzB8pB,EAAKlS,GAASG,SAAyBgC,GAAW+P,EAAKlS,GAASG,QAClE,OAAO+R,EAAKlS,GAASG,gBAUXyS,GAAgBP,GAC9B,IAAK,MAAMH,KAAQG,EAAMJ,UACvB,QAA6B7pB,IAAzB8pB,EAAKlS,GAASG,SAAyBgC,GAAW+P,EAAK7kB,SACzD,OAAO6kB,EAAK7kB,QAGhB,OAAO,cAQOmlB,GAA2BH,GAGzC,GAAIlQ,GAAWkQ,EAAMhkB,MACnB,OAAO,EAGT,MAAMwkB,EAAwB,CAC5B7S,GAASG,MACTH,GAASK,QACTL,GAASC,KACTD,GAASW,MACTX,GAASM,UACTN,GAASO,UACTP,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAELkS,EAAUzY,GAAAA,QAAAA,MAAMf,GAAQwG,GAAoB+S,IAE5CZ,EAAYI,EAAMJ,UAAUzY,QAAQ0Y,IAAUa,GAAyBb,KAC7E,IAAK,MAAMA,KAAQD,EACjB,GAAIe,GAAuBd,EAAM,CAACY,QAASA,IACzC,OAAO,EAGX,OAAO,EAUT,SAASE,GAAuB7yB,EAAUqG,EAAsC,IAC9E,IAAKE,GAAAA,QAAAA,SAASvG,GACZ,OAAO,EAGT,IAAK,MAAM8yB,KAAa9yB,EACtB,GAAIA,EAAI+yB,eAAeD,GAAY,CAEjC,GADiB9Q,GAAWhiB,EAAI8yB,OACbzsB,EAAIssB,UAAYtsB,EAAIssB,QAAQG,KAAgBD,GAAuB7yB,EAAI8yB,GAAYzsB,GACpG,OAAO,EAIb,OAAO,wKASmB6rB,EAAkB7rB,EAA8B,IAC1E,MAAMssB,EAAUtsB,EAAIssB,QAAUzY,GAAAA,QAAAA,MAAM7T,EAAIssB,QAAQ9yB,IAAIyf,KAAU,GAC9D,GAAI0C,GAAWkQ,EAAMhkB,QAAUykB,EAAc,KAC3C,OAAO,EAGT,IAAK,MAAMZ,KAAQG,EAAMJ,UACvB,GAAIe,GAAuBd,EAAMY,GAC/B,OAAO,EAGX,OAAO,cC9MOK,GAAiBC,GAC/B,OAAOA,EAAapzB,KAAKhB,GAAMq0B,GAAYr0B,cAG7Bq0B,GAAYpsB,GAC1B,OAAQlB,QACaqC,IAAfnB,EAAQlB,GACHkB,EAAQlB,GAEVA,WAIKhH,GAAM+c,EAAQwX,GAC5B,OAAInR,GAAWrG,IAERsG,GAAgBtG,IAAMA,EAAEwG,KACpBJ,GAAiBnb,KAAKC,UAAU8U,EAAEwG,MAElCJ,GAGPoR,EACKA,EAASxX,GAEXA,WAGO7U,GAAQ6U,EAAQwX,GAC9B,OAAIA,EACKA,EAASxX,GAEXA,EAGF,MAAMyX,GAAe,IAAI5D,GAEnB6D,GAEX,GACGltB,OAAOyZ,GAAyBZ,GAAY,CAACa,GAASE,UAAWF,GAASG,OAAQX,IAClFngB,QAAO,CAACo0B,EAAI1U,IAAmB0U,EAAGtwB,IAAI4b,GAAM,IAAO,IAAI4Q,IAWrD,MAAM+D,GAA8B,CACzCjV,KAAM,CAAC3X,GAAG,EAAMyE,GAAG,EAAMgC,KAAK,EAAMC,QAAQ,GAC5CkR,OAAQ,CAACxS,OAAO,EAAMG,SAAS,EAAMK,MAAM,EAAME,OAAO,GACxD4R,MAAO,CAAC1X,GAAG,EAAMyE,GAAG,EAAMW,OAAO,EAAMG,SAAS,EAAMkB,KAAK,EAAMC,QAAQ,EAAMd,MAAM,EAAME,OAAO,GAClGlE,KAAM,CAAC5B,GAAG,EAAMyE,GAAG,EAAMrG,MAAM,EAAM2H,OAAO,GAC5C0R,MAAO,CAACzX,GAAG,EAAMyE,GAAG,aASNqmB,GACdS,EACAsB,EAA8BH,GAC9BvsB,EAA+BssB,IAE/B,MAAMK,EAAkB,GAUxB,IAAIrV,EAKJ,GAbIoV,EAAQltB,IAAIuZ,GAASC,OACvB2T,EAAMj0B,KAAKZ,GAAMszB,EAAMhkB,KAAMpH,EAAQR,IAAIuZ,GAASC,QAGhDoS,EAAMR,WAAaQ,EAAMR,UAAUtvB,OAAS,GAC9CqxB,EAAMj0B,KAAK,aAAaoH,KAAKC,UAAUqrB,EAAMR,cAI3C8B,EAAQltB,IAAIuZ,GAASG,SACvB5B,EAAQgU,GAAWF,IAGjBA,EAAMJ,UAAW,CACnB,MAAMA,EAAYI,EAAMJ,UACrB5yB,QAAO,CAACw0B,EAAO3B,KAEd,IAAKa,GAAyBb,GAAO,CACnC,IAAIjX,EAEFA,EADIsD,GAAS2T,EAAK7kB,UAAYkR,EAAMkS,aAC9Bpc,GAAQzV,OAAA0M,OAAA1M,OAAA0M,OAAA,GAAK4mB,GAAI,CAAE3T,MAAOA,EAAMvM,SAAS2hB,EAAS1sB,GAElDoN,GAAS6d,EAAMyB,EAAS1sB,GAE5BgU,GAEF4Y,EAAMl0B,KAAKsb,GAGf,OAAO4Y,IACN,IACFnrB,OACAG,KAAK,KAEJopB,GACF2B,EAAMj0B,KAAKsyB,GAIf,IAAK,MAAM6B,KAAYtU,GAAY,CACjC,MAAMuU,EAAaD,EAAS5vB,WAC5B,GAAIyvB,EAAQltB,IAAIqtB,IAAezB,EAAM0B,GAAa,CAChD,MAAMh1B,EAAQszB,EAAM0B,GACpBH,EAAMj0B,KAAK,GAAGo0B,KAAchtB,KAAKC,UAAUjI,OAI/C,OAAO60B,EAAM/qB,KAAK,cASJwL,GACd6d,EACAyB,EAA8BH,GAC9BvsB,EAA+BssB,IAE/B,MAAMK,EAAQ,GAKd,GAJID,EAAQltB,IAAIuZ,GAASK,UACvBuT,EAAMj0B,KAAKZ,GAAMmzB,EAAK7kB,QAASpG,EAAQR,IAAIuZ,GAASK,WAGlD8R,GAAaD,GAAO,CACtB,MAAM8B,EAAc/H,GAASiG,EAAMyB,EAAS1sB,GAExC+sB,GACFJ,EAAMj0B,KAAKq0B,QAEJC,GAAa/B,GACtB0B,EAAMj0B,KAAKuyB,EAAKnzB,OACPm1B,GAAiBhC,IAC1B0B,EAAMj0B,KAAK,eAGb,OAAOi0B,EAAM/qB,KAAK,cASJojB,GACdiG,EACAyB,EAA8BH,GAC9BF,EAAgCC,IAEhC,GAAII,EAAQltB,IAAIuZ,GAASM,YAAcyS,GAAyBb,GAC9D,MAAO,IAGT,MAAMrtB,EAyCR,SAAcsvB,EAAoBR,EAA6BL,GAC7D,GAAIK,EAAQltB,IAAIuZ,GAASM,YAAc6T,EAAOjW,YAAciE,GAAWgS,EAAOjW,WAC5E,OAAOjX,GAAQktB,EAAOjW,UAAWoV,EAAS7sB,IAAIuZ,GAASM,YAClD,GAAIqT,EAAQltB,IAAIuZ,GAASM,YAAcgS,GAAwB6B,GAEpE,OAAOltB,GAAQ,QAASqsB,EAAS7sB,IAAIuZ,GAASM,YACzC,GAAIqT,EAAQltB,IAAIuZ,GAASU,WAAayT,EAAO9V,WAAa8D,GAAWgS,EAAO9V,UACjF,OAAOpX,GAAQktB,EAAO9V,SAAUiV,EAAS7sB,IAAIuZ,GAASU,WACjD,GAAIiT,EAAQltB,IAAIuZ,GAASQ,MAAQ2T,EAAO/V,MAAQ+D,GAAWgS,EAAO/V,KACvE,MAAO,MACF,CACL,IAAIvZ,EAAU,KACd,IAAK,MAAMka,IAAQ,CAACiB,GAASM,UAAWN,GAASO,UAAWP,GAASU,SAAUV,GAASQ,KAAM,CAC5F,MAAM6E,EAAM8O,EAAOpV,GACf4U,EAAQltB,IAAIsY,IAASoV,EAAOpV,IAASoD,GAAWkD,KAElDxgB,EAAKA,GAAM,GACXA,EAAGka,GAAQqD,GAAgBiD,GAAOA,EAAMA,EAAI/C,MAMhD,OAHIzd,GAAMsvB,EAAO7V,QACfzZ,EAAGyZ,OAAQ,GAENzZ,GAhEEuvB,CAAKlC,EAAMyB,EAASL,GACzBe,EAsER,SAAuBF,EAAoBR,EAA6BL,GAEtE,MAAMe,EAAkD,GAGxD,IAAK1tB,GAAAA,QAAAA,UAAUwtB,EAAO/V,OAASgE,GAAgB+R,EAAO/V,KAAM,CAC1D,MAAMA,EAAM+V,EAAO/V,IACnB,IAAK,MAAM9c,KAAS8c,EAAK,CACvB,MAAMW,EAAOa,GAAsB,MAAOte,GACtCyd,GAAQ4U,EAAQltB,IAAIsY,SAAwB3W,IAAfgW,EAAI9c,IACnC+yB,EAAM10B,KAAK,CACTqD,IAAK1B,EACLvC,MAAOA,GAAMqf,EAAI9c,GAAQgyB,EAAS7sB,IAAIsY,MAK5CsV,EAAM3rB,MAAK,CAAClJ,EAAGsG,IAAMtG,EAAEwD,IAAIsxB,cAAcxuB,EAAE9C,OAG7C,IAAK,MAAMpC,IAAU,CAACof,GAASc,MAAOd,GAASa,KAAMb,GAASG,MAAOH,GAASe,KAAMf,GAASgB,QAC3F,IAAKmB,GAAWgS,EAAO9mB,UAAaqmB,GAA4B9yB,GAAQuzB,EAAO9mB,WAI3EsmB,EAAQltB,IAAI7F,SAA8BwH,IAAnB+rB,EAAOvzB,GAAuB,CACvD,MAAM2zB,EAAcJ,EAAOvzB,GAC3B,GAAI+F,GAAAA,QAAAA,UAAU4tB,IAAgC,OAAhBA,EAE5BF,EAAM10B,KAAK,CACTqD,IAAK,GAAGpC,IACR7B,MAAOw1B,IAAe,SAEnB,GAAI3tB,GAAAA,QAAAA,SAAS2tB,GAElBF,EAAM10B,KAAK,CACTqD,IAAK,GAAGpC,IACR7B,MAAOkI,GAAQF,KAAKC,UAAUutB,GAAcjB,EAAS7sB,IAAI7F,UAEtD,CACL,MAAM4zB,EAAqB,GAC3B,IAAK,MAAMlzB,KAASizB,EAAa,CAC/B,MAAME,EAAa7U,GAAsBhf,EAAQU,GAC7CmzB,GAAcd,EAAQltB,IAAIguB,SAAsCrsB,IAAvBmsB,EAAYjzB,IACvDkzB,EAAmB70B,KAAK,CACtBqD,IAAK1B,EACLvC,MAAOA,GAAMw1B,EAAYjzB,GAAQgyB,EAAS7sB,IAAIguB,MAKpD,GAAID,EAAmBjyB,OAAS,EAAG,CACjC,MAAMmyB,EAAmBF,EACtB9rB,MAAK,CAAClJ,EAAGsG,IAAMtG,EAAEwD,IAAIsxB,cAAcxuB,EAAE9C,OACrC3D,QAAO,CAAC4E,EAAGoD,KACVpD,EAAEoD,EAAKrE,KAAOqE,EAAKtI,MACZkF,IACN,IAGLowB,EAAM10B,KAAK,CACTqD,IAAK,GAAGpC,IACR7B,MAAOgI,KAAKC,UAAU0tB,OAMhC,OAAOL,EA1IOM,CAAczC,EAAMyB,EAASL,GAE3C,IAAIsB,EACJ,GAAIzC,GAAaD,GAAO,CAItB,GAFA0C,EAAiBjB,EAAQltB,IAAI,SAAW1H,GAAMmzB,EAAK7sB,MAAOiuB,EAAS7sB,IAAI,UAAY,MAE/EktB,EAAQltB,IAAIuZ,GAASY,MACvB,GAAIuB,GAAW+P,EAAK9xB,MAClBw0B,GAAkB,IAAI71B,GAAMmzB,EAAK9xB,KAAMkzB,EAAS7sB,IAAIuZ,GAASY,aACxD,CAELgU,GAAkB,IAAI71B,GADJ,GAAGmzB,EAAK9xB,MAAQykB,KAAoBwF,OAAO,EAAG,GACzBiJ,EAAS7sB,IAAIuZ,GAASY,SAIjEgU,GAAkBP,EACfr0B,KAAK0F,IACJ,MAAM2f,EAAM3f,EAAE3G,iBAAiBN,MAAQ,IAAIiH,EAAE3G,SAAW2G,EAAE3G,MAC1D,MAAO,IAAI2G,EAAE1C,OAAOqiB,OAErBxc,KAAK,SACCqrB,GAAiBhC,KAC1B0C,EAAiB,OAGnB,IAAKA,EACH,OAAO,KAET,GAAI/vB,EAAI,CAGN,MAAO,GAFU+B,GAAAA,QAAAA,SAAS/B,GAAMA,EAAKqd,IAAkBzZ,GAAAA,QAAAA,KAAK5D,GAAItC,OAAS,EAAIwE,KAAKC,UAAUnC,GAAM,OAE5E+vB,KAExB,OAAOA,WAgJOC,GAAc5Z,EAAa6Z,EAAehM,GACxD,MAAMiM,EAAS,GACf,IAAI9yB,EAAY,EAEhB,IAAK,IAAIa,EAAI,EAAGA,EAAIgmB,EAAOhmB,IAAK,CAC9B,MAAMkyB,EAAe/Z,EAAIpY,QAAQiyB,EAAO7yB,GAExC,IAAsB,IAAlB+yB,EAIF,MAHAD,EAAOp1B,KAAKsb,EAAIjV,UAAU/D,EAAW+yB,IACrC/yB,EAAY+yB,EAAe,EAU/B,GAJAD,EAAOp1B,KAAKsb,EAAIoP,OAAOpoB,IAInB8yB,EAAOxyB,SAAWumB,EAAQ,EAC5B,KAAOiM,EAAOxyB,SAAWumB,EAAQ,GAC/BiM,EAAOp1B,KAAK,IAIhB,OAAOo1B,MAGQE,IAAjB,SAAiBA,GAYf,SAAgBC,EAAYC,GAC1B,MAAMhB,EAAyB,GAC/BA,EAAO9uB,MAAQ8vB,EAAa,GAC5BhB,EAAO/zB,cnBvYiBA,GAC1B,GAAIA,EAEF,OADAA,EAAOA,EAAK8iB,eAEV,IAAK,IACL,KAAKvM,GACH,MAAO,eACT,IAAK,IACL,KAAKE,GACH,MAAO,WACT,IAAK,IACL,KAAKD,GACH,MAAO,UACT,IAAK,IACL,KAAKE,GACH,MAAO,UACT,KAAKC,GACH,MAAO,WmBsXGqe,CAAYD,EAAa,GAAGnS,gBAAkB,IAE5D,MAAMqS,EAAaF,EAAa,GAChC,IAAIG,EAAoB,EACpBxyB,EAAI,EAER,KAAOA,EAAIuyB,EAAW9yB,QAAQ,CAC5B,MAAMgzB,EAAqBF,EAAWxyB,QAAQ,IAAKC,GACnD,IAAI0yB,EACJ,IAA4B,IAAxBD,EA0CF,MA1C6B,CAC7B,MAAMxW,EAAOsW,EAAWrvB,UAAUlD,EAAGyyB,GACrC,GAAwC,MAApCF,EAAWvyB,EAAIic,EAAKxc,OAAS,GAAY,CAC3C,MAAMkzB,EAAoB3yB,EAAIic,EAAKxc,OAAS,EAC5C+yB,EAAoBI,EAAgBD,EAAmBJ,EAAY,KACnE,MAAMt2B,EAAQs2B,EAAWrvB,UAAUyvB,EAAmBH,EAAoB,GAC1EE,EAAczuB,KAAKkT,MAAMlb,GAGzB+D,EAAIwyB,EAAoB,OACnB,GAAwC,MAApCD,EAAWvyB,EAAIic,EAAKxc,OAAS,GAAY,CAElD,MAAMozB,EAAsB7yB,EAAIic,EAAKxc,OAAS,EACxCqzB,EAAsBF,EAAgBC,EAAqBN,EAAY,KACvEt2B,EAAQs2B,EAAWrvB,UAAU2vB,EAAqBC,EAAsB,GAC9EJ,EAAczuB,KAAKkT,MAAMlb,GAGzB+D,EAAI8yB,EAAsB,MACrB,CACL,MAAMC,EAAY/yB,EAElB,IAAIgzB,EAAiBT,EAAWxyB,QAAQ,IAAKC,EAAIic,EAAKxc,SAC9B,IAApBuzB,IACFA,EAAiBT,EAAW9yB,QAG9BO,EAAIgzB,EAAiB,EAErBN,EAAczuB,KAAKkT,MAAMob,EAAWrvB,UAAU6vB,EAAY9W,EAAKxc,OAAS,EAAGuzB,IAGzEhX,GAAuBC,GACzBoV,EAAOpV,GAAQyW,GAGfrB,EAAO/V,IAAM+V,EAAO/V,KAAO,GAC3B+V,EAAO/V,IAAIW,GAAQyW,IAQzB,OAAOrB,EAGT,SAAgBuB,EAAgBD,EAA2Bxa,EAAa8a,GACtE,IAAK,IAAIjzB,EAAI2yB,EAAmB3yB,EAAImY,EAAI1Y,OAAQO,IAC9C,GAAImY,EAAInY,KAAOizB,EACb,OAAOjzB,EAKb,SAAgB+B,EAAGmxB,GACjB,MAAM7B,EAAyB,GAE/B,GAA6B,MAAzB6B,EAAkB,GAAY,CAChC,MAAMV,EAAoBI,EAAgB,EAAGM,EAAmB,KAE1DC,EAAclvB,KAAKkT,MAAM+b,EAAkBhwB,UAAU,EAAGsvB,EAAoB,IAElF,IAAK,MAAMY,KAAoBD,EACzBv2B,GAAAA,QAAAA,QAAQu2B,EAAYC,IACtB/B,EAAO+B,GAAoB,CAAC5T,KAAM2T,EAAYC,IAG9C/B,EAAO+B,GAAoBD,EAAYC,GAI3C,OAAAt3B,OAAA0M,OAAA1M,OAAA0M,OAAA,GACK6oB,GACAe,EACDL,GAAcmB,EAAkBhwB,UAAUsvB,EAAoB,EAAGU,EAAkBzzB,OAAS,GAAI,IAAK,KAGpG,CACL,MAAM6xB,EAAO4B,EAAkBhwB,UAAU,EAAGgwB,EAAkBnzB,QAAQ,MAEhEszB,EAAgBtB,GADLmB,EAAkBhwB,UAAUouB,EAAK7xB,OAAS,EAAGyzB,EAAkBzzB,OAAS,GAC3C,IAAK,GAEnD,GX5cGqE,EADqBpH,EW6cN40B,IX5cE1L,GAAmBlpB,GW6crC,OAAAZ,OAAA0M,OAAA,CACE4S,UAAWkW,GACRc,EAAYiB,IAEZ,GAAIhL,GAAciJ,IAASlJ,GAAsBkJ,GACtD,OAAAx1B,OAAA0M,OAAA,CACE+S,SAAU+V,GACPc,EAAYiB,IAEZ,GAAa,QAAT/B,EACT,OAAAx1B,OAAA0M,OAAA,CACE8S,IAAK,IACF8W,EAAYiB,QX1dK32B,EWkWZy1B,EAAA5gB,SAAhB,SAAyBhH,EAAmC2oB,GAC1D,MAAMI,GACgC,IAApCJ,EAAkBnzB,QAAQ,KACtBgC,EAAGmxB,GACHd,EAAYL,GAAcmB,EAAmB,IAAK,IACxD,OAAAp3B,OAAA0M,OAAA,CACE+B,QAAAA,GACG+oB,IAISnB,EAAAC,YAAWA,EA4DXD,EAAAS,gBAAeA,EAQfT,EAAApwB,GAAEA,EAhFpB,CAAiBowB,KAAAA,GAAe,gJA5U9BoB,EACA1C,EAA8BH,GAC9BvsB,EAA+BssB,IAG/B,OAAO3B,GADOD,GAAS0E,GACJ1C,EAAS1sB,kFAsQRqvB,GAGpB,MAAMC,EAAiBD,EAAU9a,MAAM,KAEjC6W,EAAmB,CACvBhkB,KAAMkoB,EAAe,GACrBtE,UAAW,IAGb,IAAK,IAAInvB,EAAI,EAAGA,EAAIyzB,EAAeh0B,OAAQO,IAAK,CAC9C,MACM0zB,EAAY3B,GADL0B,EAAezzB,GACU,IAAK,GACrC2zB,EAAeD,EAAU,GACzBE,EAAiBF,EAAU,GAEjC,GxBlKOlpB,GwBkKOmpB,IAAkC,MAAjBA,EAA/B,CACE,MAAMvE,EAAO+C,GAAgB5gB,SAASoiB,EAAcC,GACpDrE,EAAMJ,UAAUtyB,KAAKuyB,OAIF,cAAjBuE,IACFpE,EAAMR,UAAY9qB,KAAKkT,MAAMyc,IAKjC,OAAOrE,gECnVO4B,GAAa/B,GAC3B,OAAOA,MAAAA,QAAyD9pB,IAAlB8pB,EAAY,eAG5CC,GAAaD,GAC3B,OAAOA,MAAAA,IAAwCA,EAAY,OAA2B,UAAtBA,EAAgB,oBAGlEgC,GAAiBhC,GAC/B,OAAOA,MAAAA,GAAuC,cAAeA,WAG/Ca,GAAyBb,GACvC,OAAOgC,GAAiBhC,KAA4B,IAAnBA,EAAK/T,mBAGxBmU,GAAwBJ,GACtC,OAAOgC,GAAiBhC,KAA4B,IAAnBA,EAAK/T,UAsExC,MAAMwY,GAAgB,CACpB3W,GAASM,UACTN,GAASQ,IACTR,GAASU,SACTV,GAASW,MACTX,GAASY,KACTZ,GAASc,MACTd,GAASa,KACTb,GAASe,KACTf,GAASgB,OACThB,GAASG,MACTH,GAASI,iBASKqS,GAAWoB,EAAwBrI,GAEjD,MAAMnX,EAA6B,GAEnC,IAAK,MAAM6d,KAAQ2B,EAAO,CACxB,GAAId,GAAyBb,GAC3B,SAGF,MAAM7kB,QAACA,GAAW6kB,EAGlB,GAAI/P,GAAW9U,GACb,MAAM,IAAI5K,MAAM,sDAElB,MAAMmpB,EAAaqI,GAAa/B,GAAQ0E,GAAW1E,GAAQ2E,GAAW3E,EAAM1G,GAE5E,GAAmB,OAAfI,EAQJvX,EAAShH,GAAWue,OAPlB,GAA4B,SAAxBJ,EAAOkH,aAET,OAAO,KAOb,OAAOre,WAGOuiB,GAAWE,GACzB,MAAM/3B,MAACA,GAAS+3B,EAChB,OAAI3U,GAAWpjB,GACN,KAEF,CAACA,MAAAA,YAGM83B,GACd3E,EACA1G,EAA2B,IAE3B,MAAM6I,MAACA,EAAQsC,GAAaxR,OAAEA,EAAMuN,aAAEA,EAAe,QAAUlH,EAE/D,GAAI2G,GAAaD,GAAO,CACtB,MAAMjG,EAAW,GACjB,IAAK,MAAMlN,KAAQsV,EAAO,CACxB,IAAI6B,EAAmBhE,EAAKnT,GAC5B,GAAIoD,GAAW+T,GAAmB,CAChC,GAAqB,SAAjBxD,EAAyB,SAC7B,OAAO,KAGT,QAAyBtqB,IAArB8tB,EAAgC,CAIlC,MADGxC,GAA4B3U,IAAS2U,GAA4B3U,GAAMmT,EAAK7kB,UAE7E,SAGF,GAAIyR,GAAuBC,IAASrY,GAAAA,QAAAA,SAASwvB,GAAmB,CAC9DA,EAAgBt3B,OAAA0M,OAAA,GAAO4qB,GACvB,IAAK,MAAMjD,KAAaiD,EAEtB,GAAI/T,GAAW+T,EAAiBjD,IAAa,CAC3C,GAAqB,SAAjBP,EACF,OAAO,YAEFwD,EAAiBjD,IAK9B,GAAa,QAATlU,IAAuC,IAArBmX,EACpB,SACkB,SAATnX,GAAwC,QAArBmX,EAC5BjK,EAAS7rB,KAAO,UAEhB6rB,EAASlN,GAAQmX,EAIrB,GAAInX,IAASiB,GAASc,OAASqE,GAAU+M,EAAK9xB,OAASwkB,GAAc,CACnE,MAAMpG,EAAQ0T,EAAK1T,OACbuY,cAACA,GAAiB5R,EAAO6R,YAAY9E,EAAK7sB,OAElC,OAAVmZ,GAAkBuY,IACpB9K,EAASjM,GAASc,OAAMliB,OAAA0M,OAAA,CACtBqE,OAAQonB,GAEJrwB,GAAAA,QAAAA,SAAS8X,GAASA,EAAQ,MAKtC,OAAOyN,EAEP,IAAuB,IAAnBiG,EAAK/T,UACP,MAAM,IAAI1b,MAAM,sDAEhB,MAAO,CACLyb,UAAW,QACX7Y,MAAO,IACPjF,KAAM,yBAiBE62B,GAAU/E,GACxB,OAAIC,GAAaD,IACPgF,GAAYhF,IAAuB,aAAdA,EAAK9xB,KAE7B8zB,GAAiBhC,YAOVgF,GAAYhF,GAC1B,GAAIC,GAAaD,GAAO,CACtB,MACMjG,EAAW4K,GAAW3E,EAAM,CAACmC,MADTnC,EAAY,MAAI,CAAC,QAAS,MAAO,WAAY,QAAU,CAAC,MAAO,WAAY,UAErG,OAAOiF,GAAwBlL,MAAeA,EAAS5N,SAEzD,OAAO,WASOrF,GAAUmb,GACxB,MAAM3V,GAAqC,IAAjB2V,EAAO3V,OAAkB2V,EAAO3V,QAAU0D,GAAiB,GAAKiS,EAAO3V,OAAS,IAEpGpe,KAACA,EAAIiN,QAAEA,EAAOgR,SAAEA,EAAQD,IAAEA,GAAO+V,EAUvC,GAAIhS,GAAW3D,EAAMpe,OAAS+hB,GAAW/hB,IAAS+hB,GAAW9U,IAAY8U,GAAW/D,GAClF,OAGF,GAAgB,QAAZ/Q,GAAiC,WAAZA,GAAoC,UAAZA,EAC/C,OAIF,GAAImR,EAAMpe,KACR,OAAOoe,EAAMpe,KAIf,GAAa,aAATA,GAAuB+hB,GAAW9D,GACpC,OAIF,GAAa,iBAATje,GAA2B+hB,GAAW/D,GACxC,OAGF,MAEM6N,EAAW,CACf7rB,KAH2BA,IAASqvB,GAAazkB,IAAM,UAAY5K,EAInEie,SAAUA,EACVD,IAAKA,GAEP,OAAOgZ,GAAiB,CAACh3B,KAAMoe,EAAMpe,MAAOiN,EAAS4e,EAhC9B7jB,2NA5CI8pB,GAC3B,OAAIC,GAAaD,GACRmF,GAA0BR,GAAW3E,EAAM,CAACmC,MAAO,CAAC,MAAO,WAAY,QAAS,WAElFH,GAAiBhC,+FChQlB,SAAUvtB,GAEhB,IAAI2yB,EAAK,IAAIn1B,KACTo1B,EAAK,IAAIp1B,KACb,SAASq1B,EAAYC,EAAQC,EAAS5O,EAAOzjB,GAE3C,SAASsyB,EAAS5c,GAChB,OAAO0c,EAAO1c,EAAO,IAAI5Y,MAAM4Y,IAAQA,EAyDzC,OAtDA4c,EAASza,MAAQya,EAEjBA,EAASvf,MAAQ,SAAS2C,GACxB,IAAI6c,EAAK,IAAIz1B,MAAM4Y,GACf8c,EAAK,IAAI11B,KAAK4Y,EAAO,GAEzB,OADA0c,EAAOG,GAAKH,EAAOI,GAAKH,EAAQG,EAAI,GAC7B9c,EAAO6c,EAAKC,EAAK9c,EAAO6c,EAAKC,GAGtCF,EAASpa,KAAO,SAASxC,GACvB,OAAO0c,EAAO1c,EAAO,IAAI5Y,KAAK4Y,EAAO,IAAK2c,EAAQ3c,EAAM,GAAIA,GAG9D4c,EAAS3lB,OAAS,SAAS+I,EAAMyI,GAC/B,OAAOkU,EAAQ3c,EAAO,IAAI5Y,MAAM4Y,GAAe,MAARyI,EAAe,EAAIvG,KAAKC,MAAMsG,IAAQzI,GAG/E4c,EAAS7f,MAAQ,SAASggB,EAAOC,EAAMvU,GACrC,IAAI1L,EAAQ,GAIZ,GAHAggB,EAAQ,IAAI31B,KAAK21B,EAAQ,GACzBC,EAAO,IAAI51B,MAAM41B,GACjBvU,EAAe,MAARA,EAAe,EAAIvG,KAAKC,MAAMsG,KAC/BsU,EAAQC,GAAWvU,EAAO,GAAI,OAAO1L,EAG3C,IAFA4f,EAAQI,EAAO,GAAIL,EAAOK,GACtBA,EAAQC,GAAMjgB,EAAMnY,KAAK,IAAIwC,MAAM21B,IAChCJ,EAAQI,EAAOtU,GAAOiU,EAAOK,GAAQA,EAAQC,GAAMjgB,EAAMnY,KAAK,IAAIwC,MAAM21B,IAC/E,OAAOhgB,GAGT6f,EAASne,OAAS,SAASwe,GACzB,OAAOR,GAAY,SAASzc,GAC1B,KAAO0c,EAAO1c,IAAQid,EAAKjd,IAAOA,EAAKkd,QAAQld,EAAO,MACrD,SAASA,EAAMyI,GAChB,OAASA,GAAQ,QAAUkU,EAAQ3c,EAAM,IAAKid,EAAKjd,UAInD+N,IACF6O,EAAS7O,MAAQ,SAASgP,EAAOI,GAG/B,OAFAZ,EAAGW,SAASH,GAAQP,EAAGU,SAASC,GAChCT,EAAOH,GAAKG,EAAOF,GACZta,KAAKC,MAAM4L,EAAMwO,EAAIC,KAG9BI,EAASve,MAAQ,SAASoK,GAExB,OADAA,EAAOvG,KAAKC,MAAMsG,GACVnb,SAASmb,IAAWA,EAAO,EAC3BA,EAAO,EACTmU,EAASne,OAAOnU,EACZ,SAAS2V,GAAK,OAAO3V,EAAM2V,GAAKwI,GAAS,GACzC,SAASxI,GAAK,OAAO2c,EAAS7O,MAAM,EAAG9N,GAAKwI,GAAS,IAH3CmU,EADoB,OAQrCA,EAGT,IAAIQ,EAAcX,GAAY,eAE3B,SAASzc,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,MACpB,SAASsU,EAAOI,GACjB,OAAOA,EAAMJ,KAIfK,EAAY/e,MAAQ,SAAS3R,GAE3B,OADAA,EAAIwV,KAAKC,MAAMzV,GACVY,SAASZ,IAAQA,EAAI,EACpBA,EAAI,EACH+vB,GAAY,SAASzc,GAC1BA,EAAKkd,QAAQhb,KAAKC,MAAMnC,EAAOtT,GAAKA,MACnC,SAASsT,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAO/b,MAC3B,SAASqwB,EAAOI,GACjB,OAAQA,EAAMJ,GAASrwB,KANJ0wB,EADgB,MAWvC,IAAIC,EAASZ,GAAY,SAASzc,GAChCA,EAAKsd,gBAAgB,MACpB,SAAStd,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAc,IAAPyI,MACpB,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,OACtB,SAAS/c,GACV,OAAOA,EAAKud,gBAGVC,EAASf,GAAY,SAASzc,GAChCA,EAAKyd,WAAW,EAAG,MAClB,SAASzd,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAc,IAAPyI,MACpB,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,OACtB,SAAS/c,GACV,OAAOA,EAAK0d,gBAGVC,EAAOlB,GAAY,SAASzc,GAC9BA,EAAK4d,WAAW,EAAG,EAAG,MACrB,SAAS5d,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAc,KAAPyI,MACpB,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,QACtB,SAAS/c,GACV,OAAOA,EAAK6d,cAGVjO,EAAM6M,GAAY,SAASzc,GAC7BA,EAAK8d,SAAS,EAAG,EAAG,EAAG,MACtB,SAAS9d,EAAMyI,GAChBzI,EAAK+d,QAAQ/d,EAAKge,UAAYvV,MAC7B,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,EAAgE,KAAvDI,EAAIc,oBAAsBlB,EAAMkB,sBAA8B,SACpF,SAASje,GACV,OAAOA,EAAKge,UAAY,KAG1B,SAASE,EAAQn2B,GACf,OAAO00B,GAAY,SAASzc,GAC1BA,EAAK8d,SAAS,EAAG,EAAG,EAAG,GACvB9d,EAAK+d,QAAQ/d,EAAKge,WAAahe,EAAKme,SAAW,EAAIp2B,GAAK,MACvD,SAASiY,EAAMyI,GAChBzI,EAAK+d,QAAQ/d,EAAKge,UAAmB,EAAPvV,MAC7B,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,EAAgE,KAAvDI,EAAIc,oBAAsBlB,EAAMkB,sBAA8B,UAIzF,IAAIG,EAASF,EAAQ,GACjBG,EAASH,EAAQ,GACjBI,EAAUJ,EAAQ,GAClBK,EAAYL,EAAQ,GACpBM,EAAWN,EAAQ,GACnBO,EAASP,EAAQ,GACjBQ,EAAWR,EAAQ,GAEnBxO,EAAQ+M,GAAY,SAASzc,GAC/BA,EAAK8d,SAAS,EAAG,EAAG,EAAG,GACvB9d,EAAK+d,QAAQ,MACZ,SAAS/d,EAAMyI,GAChBzI,EAAK2e,SAAS3e,EAAK4e,WAAanW,MAC/B,SAASsU,EAAOI,GACjB,OAAOA,EAAIyB,WAAa7B,EAAM6B,WAAyD,IAA3CzB,EAAI0B,cAAgB9B,EAAM8B,kBACrE,SAAS7e,GACV,OAAOA,EAAK4e,cAGVpP,EAAOiN,GAAY,SAASzc,GAC9BA,EAAK8d,SAAS,EAAG,EAAG,EAAG,GACvB9d,EAAK2e,SAAS,EAAG,MAChB,SAAS3e,EAAMyI,GAChBzI,EAAK8e,YAAY9e,EAAK6e,cAAgBpW,MACrC,SAASsU,EAAOI,GACjB,OAAOA,EAAI0B,cAAgB9B,EAAM8B,iBAChC,SAAS7e,GACV,OAAOA,EAAK6e,iBAGVE,EAAYtC,GAAY,SAASzc,GACnCA,EAAKgf,mBAAmB,MACvB,SAAShf,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAc,IAAPyI,MACpB,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,OACtB,SAAS/c,GACV,OAAOA,EAAKif,mBAGVC,EAAYzC,GAAY,SAASzc,GACnCA,EAAKmf,cAAc,EAAG,MACrB,SAASnf,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAc,IAAPyI,MACpB,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,OACtB,SAAS/c,GACV,OAAOA,EAAKof,mBAGVC,EAAU5C,GAAY,SAASzc,GACjCA,EAAKsf,cAAc,EAAG,EAAG,MACxB,SAAStf,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAc,KAAPyI,MACpB,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,QACtB,SAAS/c,GACV,OAAOA,EAAKuf,iBAGVC,EAAS/C,GAAY,SAASzc,GAChCA,EAAKyf,YAAY,EAAG,EAAG,EAAG,MACzB,SAASzf,EAAMyI,GAChBzI,EAAK0f,WAAW1f,EAAK2f,aAAelX,MACnC,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,SACtB,SAAS/c,GACV,OAAOA,EAAK2f,aAAe,KAG7B,SAASC,EAAW73B,GAClB,OAAO00B,GAAY,SAASzc,GAC1BA,EAAKyf,YAAY,EAAG,EAAG,EAAG,GAC1Bzf,EAAK0f,WAAW1f,EAAK2f,cAAgB3f,EAAK6f,YAAc,EAAI93B,GAAK,MAChE,SAASiY,EAAMyI,GAChBzI,EAAK0f,WAAW1f,EAAK2f,aAAsB,EAAPlX,MACnC,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS,UAI3B,IAAI+C,EAAYF,EAAW,GACvBG,EAAYH,EAAW,GACvBI,EAAaJ,EAAW,GACxBK,EAAeL,EAAW,GAC1BM,EAAcN,EAAW,GACzBO,EAAYP,EAAW,GACvBQ,EAAcR,EAAW,GAEzBS,EAAW5D,GAAY,SAASzc,GAClCA,EAAKyf,YAAY,EAAG,EAAG,EAAG,GAC1Bzf,EAAK0f,WAAW,MACf,SAAS1f,EAAMyI,GAChBzI,EAAKsgB,YAAYtgB,EAAKugB,cAAgB9X,MACrC,SAASsU,EAAOI,GACjB,OAAOA,EAAIoD,cAAgBxD,EAAMwD,cAAkE,IAAjDpD,EAAIqD,iBAAmBzD,EAAMyD,qBAC9E,SAASxgB,GACV,OAAOA,EAAKugB,iBAGVE,EAAUhE,GAAY,SAASzc,GACjCA,EAAKyf,YAAY,EAAG,EAAG,EAAG,GAC1Bzf,EAAKsgB,YAAY,EAAG,MACnB,SAAStgB,EAAMyI,GAChBzI,EAAK0gB,eAAe1gB,EAAKwgB,iBAAmB/X,MAC3C,SAASsU,EAAOI,GACjB,OAAOA,EAAIqD,iBAAmBzD,EAAMyD,oBACnC,SAASxgB,GACV,OAAOA,EAAKwgB,oBAGVvQ,EAAemN,EAAYrgB,MAC3BiT,EAAUqN,EAAOtgB,MACjBgT,EAAUyN,EAAOzgB,MACjB+S,EAAQ6N,EAAK5gB,MACb4jB,EAAO/Q,EAAI7S,MACX6jB,EAAUxC,EAAOrhB,MACjB8jB,EAAUxC,EAAOthB,MACjB+jB,EAAWxC,EAAQvhB,MACnBgkB,EAAaxC,EAAUxhB,MACvBikB,EAAYxC,EAASzhB,MACrBkkB,EAAUxC,EAAO1hB,MACjBmkB,EAAYxC,EAAS3hB,MACrBokB,EAAQ/C,EAAOrhB,MACfqkB,EAAS1R,EAAM3S,MACfskB,EAAQ7R,EAAKzS,MAEbukB,EAAiBlE,EACjBmE,EAAkBtR,EAClBuR,EAAazC,EAAUhiB,MACvB0kB,EAAavC,EAAUniB,MACvB2kB,EAAWrC,EAAQtiB,MACnB4kB,EAAUnC,EAAOziB,MACjB6kB,GAAa9B,EAAU/iB,MACvB8kB,GAAa9B,EAAUhjB,MACvB+kB,GAAc9B,EAAWjjB,MACzBglB,GAAgB9B,EAAaljB,MAC7BilB,GAAe9B,EAAYnjB,MAC3BklB,GAAa9B,EAAUpjB,MACvBmlB,GAAe9B,EAAYrjB,MAC3BolB,GAAWrC,EAAU/iB,MACrBqlB,GAAY/B,EAAStjB,MACrBslB,GAAW5B,EAAQ1jB,MAEnBulB,GAAU,QAEd14B,EAAQ04B,QAAUA,GAClB14B,EAAQqmB,aAAeA,EACvBrmB,EAAQomB,QAAUA,EAClBpmB,EAAQmmB,QAAUA,EAClBnmB,EAAQkmB,MAAQA,EAChBlmB,EAAQ+2B,KAAOA,EACf/2B,EAAQg3B,QAAUA,EAClBh3B,EAAQi3B,QAAUA,EAClBj3B,EAAQk3B,SAAWA,EACnBl3B,EAAQm3B,WAAaA,EACrBn3B,EAAQo3B,UAAYA,EACpBp3B,EAAQq3B,QAAUA,EAClBr3B,EAAQs3B,UAAYA,EACpBt3B,EAAQu3B,MAAQA,EAChBv3B,EAAQw3B,OAASA,EACjBx3B,EAAQy3B,MAAQA,EAChBz3B,EAAQ03B,eAAiBA,EACzB13B,EAAQ23B,gBAAkBA,EAC1B33B,EAAQ43B,WAAaA,EACrB53B,EAAQ63B,WAAaA,EACrB73B,EAAQ83B,SAAWA,EACnB93B,EAAQ+3B,QAAUA,EAClB/3B,EAAQg4B,WAAaA,GACrBh4B,EAAQi4B,WAAaA,GACrBj4B,EAAQk4B,YAAcA,GACtBl4B,EAAQm4B,cAAgBA,GACxBn4B,EAAQo4B,aAAeA,GACvBp4B,EAAQq4B,WAAaA,GACrBr4B,EAAQs4B,aAAeA,GACvBt4B,EAAQu4B,SAAWA,GACnBv4B,EAAQw4B,UAAYA,GACpBx4B,EAAQy4B,SAAWA,GACnBz4B,EAAQwzB,YAAcA,EACtBxzB,EAAQyzB,OAASA,EACjBzzB,EAAQ4zB,OAASA,EACjB5zB,EAAQ+zB,KAAOA,EACf/zB,EAAQgmB,IAAMA,EACdhmB,EAAQw0B,OAASA,EACjBx0B,EAAQy0B,OAASA,EACjBz0B,EAAQ00B,QAAUA,EAClB10B,EAAQ20B,UAAYA,EACpB30B,EAAQ40B,SAAWA,EACnB50B,EAAQ60B,OAASA,EACjB70B,EAAQ80B,SAAWA,EACnB90B,EAAQ+lB,KAAOyO,EACfx0B,EAAQ8lB,MAAQA,EAChB9lB,EAAQ4lB,KAAOA,EACf5lB,EAAQm1B,UAAYA,EACpBn1B,EAAQs1B,UAAYA,EACpBt1B,EAAQy1B,QAAUA,EAClBz1B,EAAQ41B,OAASA,EACjB51B,EAAQk2B,UAAYA,EACpBl2B,EAAQm2B,UAAYA,EACpBn2B,EAAQo2B,WAAaA,EACrBp2B,EAAQq2B,aAAeA,EACvBr2B,EAAQs2B,YAAcA,EACtBt2B,EAAQu2B,UAAYA,EACpBv2B,EAAQw2B,YAAcA,EACtBx2B,EAAQ24B,QAAUzC,EAClBl2B,EAAQy2B,SAAWA,EACnBz2B,EAAQ62B,QAAUA,EAClB72B,EAAQgzB,SAAWH,EA9V4C+F,CAAQ54B,kBCDzE,IAAI64B,GAAUC,GAAAA,QAEVC,GAAW,IAAIv7B,KACfw7B,GAAW,IAAIx7B,KAAK,IAAM,EAAG,GAC7By7B,GAAc,IAAIz7B,KAAKA,KAAK07B,IAAI,IAAM,EAAG,IAE7C,SAAS9iB,GAAKC,GACZ,OAAQ0iB,GAASzF,SAASjd,GAAI0iB,GAIhC,SAASI,GAAM19B,EAAM2a,EAAM0Q,EAAMjI,EAAMD,EAAK3F,GAC1C,IAAIne,EAAI,CACNW,KAAMA,EACN2a,KAAMA,EACN0Q,KAAMA,GASR,OAPIjI,EACF/jB,EAAE+jB,KAAOA,EAET/jB,EAAEikB,QAAU,EAEH,MAAPH,IAAa9jB,EAAE8jB,IAAMA,GACd,MAAP3F,IAAane,EAAEme,IAAMA,GAClBne,EAGT,SAASiD,GAAOtC,EAAMqrB,EAAMlT,EAAMiL,EAAMD,EAAK3F,GAC3C,OAAOkgB,GAAM19B,GACX,SAAS4a,GAAK,OAAOyQ,EAAKzZ,OAAOuG,EAAMyC,MACvC,SAASA,GAAK,OAAOyQ,EAAK3C,MAAMvQ,EAAMyC,KACtCwI,EAAMD,EAAK3F,GAGf,IAAImgB,GAAS,CACXr7B,GAAO,SAAU86B,GAAQpF,OAAQuF,IACjCj7B,GAAO,SAAU86B,GAAQjF,OAAQoF,IACjCj7B,GAAO,OAAU86B,GAAQ9E,KAAQiF,IACjCj7B,GAAO,MAAU86B,GAAQ7S,IAAQgT,GAAU,CAAC,EAAG,IAC/Cj7B,GAAO,QAAU86B,GAAQ/S,MAAQkT,GAAU,CAAC,EAAG,EAAG,IAClDj7B,GAAO,OAAU86B,GAAQjT,KAAQ,IAAIpoB,KAAKw7B,IAAU9D,YAAY,IAGhEiE,GAAM,WACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAK,KAAM,EAAG,EAAG,EAAG,EAAG6Y,MAChD,SAASA,GAAK,OAAOD,GAAKC,GAAGsd,eAC7B,KAAM,EAAG,IAEXwF,GAAM,WACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAK,KAAM,EAAG,EAAG,EAAG6Y,MAC7C,SAASA,GAAK,OAAOD,GAAKC,GAAGyd,eAC7B,KAAM,EAAG,IAEXqF,GAAM,SACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAK,KAAM,EAAG,EAAG6Y,MAC1C,SAASA,GAAK,OAAOD,GAAKC,GAAG4d,aAC7B,KAAM,EAAG,IAEXkF,GAAM,YACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAK,KAAM,EAAG,EAAE6Y,MACzC,SAASA,GAAK,OAAOD,GAAKC,GAAGke,WAC7B,CAAC,GAAI,EAAG,GAEV4E,GAAM,SACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAK,KAAM,EAAG6Y,MACvC,SAASA,GAAK,OAAOD,GAAKC,GAAG+d,YAC7B,CAAC,GAAI,EAAG,IAEV+E,GAAM,UACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAK,KAAM6Y,EAAI,GAAI,MAC5C,SAASA,GAAK,OAAOD,GAAKC,GAAG2e,aAC7B,CAAC,GAAI,EAAG,KAIRjO,GAAM,CACRhpB,GAAO,SAAU86B,GAAQ1D,UAAW8D,IACpCl7B,GAAO,SAAU86B,GAAQvD,UAAW2D,IACpCl7B,GAAO,OAAU86B,GAAQpD,QAAWwD,IACpCl7B,GAAO,MAAU86B,GAAQjD,OAAWqD,GAAa,CAAC,EAAG,IACrDl7B,GAAO,QAAU86B,GAAQpC,SAAWwC,GAAa,CAAC,EAAG,EAAG,IACxDl7B,GAAO,OAAU86B,GAAQhC,QAAW,IAAIr5B,KAAKy7B,IAAanC,eAAe,IAGzEqC,GAAM,WACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAKA,KAAK07B,IAAI,KAAM,EAAG,EAAG,EAAG,EAAG7iB,OACzD,SAASA,GAAK,OAAOD,GAAKC,GAAGgf,kBAC7B,KAAM,EAAG,IAEX8D,GAAM,WACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAKA,KAAK07B,IAAI,KAAM,EAAG,EAAG,EAAG7iB,OACtD,SAASA,GAAK,OAAOD,GAAKC,GAAGmf,kBAC7B,KAAM,EAAG,IAEX2D,GAAM,SACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAKA,KAAK07B,IAAI,KAAM,EAAG,EAAG7iB,OACnD,SAASA,GAAK,OAAOD,GAAKC,GAAGsf,gBAC7B,KAAM,EAAG,IAEXwD,GAAM,YACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAKA,KAAK07B,IAAI,KAAM,EAAG,EAAE7iB,OAClD,SAASA,GAAK,OAAOD,GAAKC,GAAG4f,cAC7B,CAAC,GAAI,EAAG,GAEVkD,GAAM,SACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAKA,KAAK07B,IAAI,KAAM,EAAG7iB,OAChD,SAASA,GAAK,OAAOD,GAAKC,GAAG0f,eAC7B,CAAC,GAAI,EAAG,IAEVoD,GAAM,UACJ,SAAS9iB,GAAK,OAAO,IAAI7Y,KAAKA,KAAK07B,IAAI,KAAM7iB,EAAI,GAAI,OACrD,SAASA,GAAK,OAAOD,GAAKC,GAAGsgB,gBAC7B,CAAC,GAAI,EAAG,KAIR0C,GAAQ,CACV,CAAC,QAAS,GACV,CAAC,OAAQ,GACT,CAAC,OAAQ,GACT,CAAC,QAAS,GACV,CAAC,OAAQ,GACT,CAAC,OAAQ,GACT,CAAC,MAAO,GACR,CAAC,MAAO,GACR,CAAC,MAAO,GACR,CAAC,MAAO,GACR,CAAC,KAAM,GACP,CAAC,KAAM,GACP,CAAC,IAAK,GACN,CAAC,IAAK,GACN,CAAC,IAAK,GACN,CAAC,IAAK,GACN,CAAC,KAAM,GACP,CAAC,IAAK,GACN,CAAC,IAAK,IAqBR,SAASC,GAAUC,GACjB,IAAcp7B,EAAG6C,EAAb3F,EAAM,GACV,IAAK8C,EAAE,EAAG6C,EAAEu4B,EAAM37B,OAAQO,EAAE6C,IAAK7C,EAC/B9C,EAAIk+B,EAAMp7B,GAAG1C,MAAQ89B,EAAMp7B,GAK7B,OAHA9C,EAAIm+B,KAAO,SAASC,EAAMC,EAAMC,GAC9B,OAxBJ,SAAcJ,EAAOE,EAAMC,EAAMC,GAC/B,IAAqBx7B,EAAG6C,EAAGuS,EAAvBsL,EAAOwa,GAAM,GAEjB,IAAKl7B,EAAE,EAAG6C,EAAEq4B,GAAMz7B,OAAQO,EAAE6C,IAAK7C,EAE/B,GAAIs7B,GADJ5a,EAAOwa,GAAMl7B,IACG,GAAI,CAElB,IADAoV,EAAOkmB,EAAO5a,EAAK,IACR8a,EACT,OAAOJ,EAAMF,GAAMl7B,EAAE,GAAG,IAE1B,GAAIoV,GAAQmmB,EACV,OAAOH,EAAM1a,EAAK,IAIxB,OAAO0a,EAAMF,GAAMr4B,EAAE,GAAG,IASfw4B,CAAKD,EAAOE,EAAMC,EAAMC,IAE1Bt+B,EAGTu+B,GAAAA,QAAiBN,GAAUF,mBACNE,GAAUvS,ICxK/B,IAAI8S,GAAOf,GAAAA,QACPgB,GAAOC,GAAAA,QAGX,SAASxmB,GAAK1R,GACZ,IAAKA,EAAO,MAAM/D,MAAM,4BAGxB,IAOI+gB,EAAMrd,EAAOud,EAASib,EAAW7iB,EAAGhZ,EAAG87B,EAPvCN,EAAO93B,EAAI8c,SAAW,GACtB/K,EAAO/R,EAAI+R,MAAQ,GACnBsmB,EAAO5hB,KAAK6hB,IAAIvmB,GAChBwmB,EAAMv4B,EAAIu4B,KAAO,CAAC,EAAG,GACrBxb,EAAM/c,EAAI+c,IACV3F,EAAMpX,EAAIoX,IACVwgB,EAAOxgB,EAAM2F,EAGjB,GAAI/c,EAAIgd,KAENA,EAAOhd,EAAIgd,UACN,GAAIhd,EAAIid,MAEbD,EAAOhd,EAAIid,MAAMxG,KAAKsG,IACpB/c,EAAIid,MAAMlhB,OAAS,EAuCzB,SAAgB/C,EAAGsH,EAAGk4B,EAAIC,GACxB,KAAOD,EAAKC,GAAI,CACd,IAAIC,EAAMF,EAAKC,IAAO,EAClBT,GAAK32B,IAAIrI,EAAE0/B,GAAMp4B,GAAK,EAAKk4B,EAAKE,EAAM,EACnCD,EAAKC,EAEd,OAAOF,EA5CHG,CAAO34B,EAAIid,MAAO2a,EAAKE,EAAM,EAAG93B,EAAIid,MAAMlhB,cAEvC,CAUL,IARA4D,EAAQ8W,KAAKM,KAAKN,KAAK6hB,IAAIR,GAAQO,GACnCnb,EAAUld,EAAIkd,SAAW,EACzBF,EAAOvG,KAAKW,IACV8F,EACAzG,KAAKmiB,IAAI7mB,EAAM0E,KAAK7E,MAAM6E,KAAK6hB,IAAIV,GAAQS,GAAQ14B,IAI9C8W,KAAKM,KAAK6gB,EAAK5a,GAAQ8a,GAAQ9a,GAAQjL,EAG9C,IAAKzV,EAAE,EAAGA,EAAEi8B,EAAIx8B,SAAUO,GACxBgZ,EAAI0H,EAAOub,EAAIj8B,KACN4gB,GAAW0a,EAAOtiB,GAAKwiB,IAAM9a,EAAO1H,GAWjD,OALA6iB,GADA7iB,EAAImB,KAAK6hB,IAAItb,KACI,EAAI,EAAoB,MAAZ1H,EAAI+iB,GACjCD,EAAM3hB,KAAKmiB,IAAI7mB,GAAOomB,EAAY,GAI3B,CACL7G,MAJFvU,EAAMtG,KAAKsG,IAAIA,EAAKtG,KAAKC,MAAMqG,EAAMC,EAAOob,GAAOpb,GAKjDuU,KAJFna,EAAMX,KAAKM,KAAKK,EAAM4F,GAAQA,EAK5BA,KAAOA,EACPiI,KAAO,CAACkT,UAAWA,GACnB5/B,MAAOA,GACP6D,MAAOA,IAaX,SAAS7D,GAAM+c,GACb,OAAOvc,KAAKu4B,MAAQv4B,KAAKikB,KAAOvG,KAAKC,OAAkBpB,EAAIvc,KAAKu4B,MAtEpD,OAsE8Dv4B,KAAKikB,MAIjF,SAAS5gB,GAAMkZ,GACb,OAAOmB,KAAKC,OAAOpB,EAAIvc,KAAKu4B,OAASv4B,KAAKikB,KA3E9B,OA8Ed,SAAS6b,GAAWvjB,GAClB,OAAOvc,KAAKksB,KAAK1Q,KAAKhc,GAAMO,KAAKC,KAAMuc,IAGzC,SAASwjB,GAAWxjB,GAClB,OAAOlZ,GAAMtD,KAAKC,KAAMA,KAAKksB,KAAKA,KAAK3P,IAGzC5D,GAAK6C,KAAO,SAASvU,GACnB,IAAKA,EAAO,MAAM/D,MAAM,iCAGxB,IAAIy7B,EAAQ13B,EAAIklB,IAAM+S,GAAK/S,IAAM+S,GAC7Bc,EAAO/4B,EAAI+c,IACXic,EAAOh5B,EAAIoX,IACX0gB,EAAO93B,EAAI8c,SAAW,GACtB+a,EAAO73B,EAAIi5B,SAAW,EACtBrB,GAASoB,GAAUD,EACnB9T,EAAOjlB,EAAIilB,KAAOyS,EAAM13B,EAAIilB,MAAQyS,EAAMC,KAAKC,EAAMC,EAAMC,GAC3D1M,EAAO1Z,GAAK,CACVqL,IAAqB,MAAZkI,EAAKlI,IAAckI,EAAKlI,IAAMkI,EAAKA,KAAK8T,GACjD3hB,IAAqB,MAAZ6N,EAAK7N,IAAc6N,EAAK7N,IAAM6N,EAAKA,KAAK+T,GACjDlc,QAASgb,EACT5a,QAAS+H,EAAK/H,QACdD,MAASgI,EAAKjI,OAMpB,OAHAoO,EAAKnG,KAAOA,EACZmG,EAAKhvB,MAAQ08B,GACR94B,EAAIk5B,MAAK9N,EAAK7yB,MAAQsgC,IACpBzN,OAGT+N,GAAiBznB,GCjHbsmB,GAAOf,GAAAA,QAEPmC,GAAQ,YAERC,GAAU,CACZ/kB,QAAS0jB,GAAK1jB,QACdglB,QAAStB,GAAK3jB,OACdA,OAAS2jB,GAAK3jB,OACdE,KAASyjB,GAAKzjB,KACd7R,OAAS,SAASpC,GAAK,OAAY,MAALA,GAAmB,KAANA,EAAW,KAAOA,EAAI,KAG/Di5B,GAAQ,CACVjlB,QAAS,SAAShU,GAAK,MAAW,SAAJA,GAAkB,UAAJA,GAAe03B,GAAK73B,UAAUG,IAC1Eg5B,QAAS,SAASh5B,GAAK,OAAOi5B,GAAMllB,OAAO/T,KAAOA,GAAGA,MAASA,GAC9D+T,OAAQ,SAAS/T,GAAK,OAAQ5H,OAAO4H,KAAO03B,GAAK7jB,OAAO7T,IACxDiU,KAAM,SAASjU,GAAK,OAAQ5H,MAAMiD,KAAK8X,MAAMnT,MAQ/C,SAASse,GAAWiI,GAClB,OAAOmR,GAAK/1B,KAAK4kB,GAGnB,SAAS2S,GAAQC,GACf,MAAO,IAAMA,EAAY,IAG3B,SAAS7/B,GAAK6T,EAAQzM,GAGpB,IAAIsU,EAAGhZ,EAAG6C,EAGV,GALAsO,EAASuqB,GAAKp3B,MAAM6M,GACpBzM,EAAIg3B,GAAK33B,EAAEW,GAIPyM,EAAO2rB,MACT9jB,EAAItU,EAAEyM,EAAO2rB,KACTpB,GAAK53B,SAASkV,IAAI,OAAOA,EAG/B,IAAKhZ,EAAE,EAAG6C,EAAEsO,EAAO1R,QAASi8B,GAAK5jB,QAAQkB,IAAMhZ,EAAE6C,IAAK7C,EACpDgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAGhC,OAAO07B,GAAK7jB,OAAOmB,GAAK,OACtB0iB,GAAK9jB,SAASoB,GAAQ,SACtB0iB,GAAK73B,UAAUmV,GAAO,UACtB0iB,GAAK53B,SAASkV,GAAQ,SAAW,KAWrC,SAASokB,GAAMjsB,EAAQzM,EAAG24B,GAGxB,IAAIr9B,EAAG8C,EAAGkW,EAFV7H,EAASuqB,GAAKp3B,MAAM6M,GACpBzM,EAAIg3B,GAAK33B,EAAEW,GAIX,IAAI44B,EAAQ,CAAC,UAAW,UAAW,SAAU,QAE7C,IAAKt9B,EAAE,EAAGA,EAAEmR,EAAO1R,SAAUO,EAAG,CAI9B,IAFAgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAEzB8C,EAAE,EAAGA,EAAEw6B,EAAM79B,SAAUqD,EACpBu6B,GAAWA,EAAOnI,KAAKlc,KAAO0iB,GAAK5jB,QAAQkB,IAAOikB,GAAMK,EAAMx6B,IAAIkW,KACtEskB,EAAMz3B,OAAO/C,EAAG,GAChBA,GAAK,GAIT,GAAqB,IAAjBw6B,EAAM79B,OAAc,MAAO,SAGjC,OAAO69B,EAAM,GAWfhgC,GAAKigC,WA3EL,SAAoB14B,EAAMy4B,GACxB,IAAKA,EAAO,OAAOz4B,GAAQA,EAAKi4B,KAAU,KAC1Cj4B,EAAKi4B,IAASQ,GA0EhBhgC,GAAKkgC,IA1CL,SAAiB34B,EAAM7C,GACrB,GAAK6C,EAAKpF,OAAV,CACA,IAAIkE,EAAM3B,EAAS05B,GAAK3kB,UAAY/U,EAASsgB,GAAWzd,EAAK,IAAKq4B,IAClE,OAAOl7B,EAAOzF,QAAO,SAAS+gC,EAAO54B,GACnC,OAAQ44B,EAAM54B,GAAKpH,GAAKuH,EAAMlB,EAAIe,IAAK44B,IACtC,MAsCLhgC,GAAK8/B,MAAQA,GACb9/B,GAAKmgC,SAXL,SAAkB54B,EAAM7C,EAAQq7B,GAC9B,IAAI15B,EAAM3B,EAAS05B,GAAK3kB,UAAY/U,EAASsgB,GAAWzd,EAAK,IAAKq4B,IAClE,OAAOl7B,EAAOzF,QAAO,SAAS+gC,EAAO54B,GAEnC,OADA44B,EAAM54B,GAAK04B,GAAMv4B,EAAMlB,EAAIe,GAAI24B,GACxBC,IACN,KAOLhgC,GAAKogC,QAAUX,OACfY,GAAiBrgC,gDCnGjB,IAAIo+B,EAAOf,GAAAA,QACPiD,EAAMh8B,EAAOC,QAEjB+7B,EAAIC,OAAS,SAAStb,EAAK1f,GACzB,IAAkB7C,EAAdtD,EAAIf,MAAMkH,GACd,IAAK7C,EAAE,EAAGA,EAAE6C,IAAK7C,EAAGtD,EAAEsD,GAAKuiB,EAC3B,OAAO7lB,GAGTkhC,EAAIE,MAAQ,SAASj7B,GACnB,OAAO+6B,EAAIC,OAAO,EAAGh7B,IAGvB+6B,EAAI5oB,MAAQ,SAASggB,EAAOC,EAAMvU,GAQhC,GAPIrkB,UAAUoD,OAAS,IACrBihB,EAAO,EACHrkB,UAAUoD,OAAS,IACrBw1B,EAAOD,EACPA,EAAQ,KAGPC,EAAOD,GAAStU,GAAQpiB,EAAAA,EAAU,MAAM,IAAIqB,MAAM,kBACvD,IAAwBmD,EAApBkS,EAAQ,GAAIhV,GAAK,EACrB,GAAI0gB,EAAO,EAAG,MAAQ5d,EAAIkyB,EAAQtU,IAAS1gB,GAAKi1B,GAAMjgB,EAAMnY,KAAKiG,QAC5D,MAAQA,EAAIkyB,EAAQtU,IAAS1gB,GAAKi1B,GAAMjgB,EAAMnY,KAAKiG,GACxD,OAAOkS,GAGT4oB,EAAIvjB,OAAS,GAEbujB,EAAIvjB,OAAO0jB,QAAU,SAAStd,EAAK3F,QACrBxV,IAARwV,IACFA,OAAcxV,IAARmb,EAAoB,EAAIA,EAC9BA,EAAM,GAER,IAAIvI,EAAI4C,EAAM2F,EACV/b,EAAI,WACN,OAAO+b,EAAMvI,EAAIiC,KAAKE,UAcxB,OAZA3V,EAAEs5B,QAAU,SAASn7B,GACnB,OAAO+6B,EAAIE,MAAMj7B,GAAG3F,IAAIwH,IAE1BA,EAAEu5B,IAAM,SAASj6B,GACf,OAAQA,GAAKyc,GAAOzc,GAAK8W,EAAO,EAAE5C,EAAI,GAExCxT,EAAEw5B,IAAM,SAASl6B,GACf,OAAOA,EAAIyc,EAAM,EAAIzc,EAAI8W,EAAM,GAAK9W,EAAIyc,GAAOvI,GAEjDxT,EAAEy5B,KAAO,SAASv7B,GAChB,OAAQA,GAAK,GAAKA,GAAK,EAAK6d,EAAM7d,EAAEsV,EAAIkmB,KAEnC15B,GAGTk5B,EAAIvjB,OAAO2iB,QAAU,SAAStgC,EAAGsG,QACrBsC,IAANtC,IACFA,EAAItG,EACJA,EAAI,GAEN,IAAIwb,EAAIlV,EAAItG,EACRgI,EAAI,WACN,OAAOhI,EAAIyd,KAAKC,MAAMlC,EAAIiC,KAAKE,WAejC,OAbA3V,EAAEs5B,QAAU,SAASn7B,GACnB,OAAO+6B,EAAIE,MAAMj7B,GAAG3F,IAAIwH,IAE1BA,EAAEu5B,IAAM,SAASj6B,GACf,OAAQA,IAAMmW,KAAKC,MAAMpW,IAAMA,GAAKtH,GAAKsH,EAAIhB,EAAK,EAAEkV,EAAI,GAE1DxT,EAAEw5B,IAAM,SAASl6B,GACf,IAAIgV,EAAImB,KAAKC,MAAMpW,GACnB,OAAOgV,EAAItc,EAAI,EAAIsc,GAAKhW,EAAI,GAAKgW,EAAItc,EAAI,GAAKwb,GAEhDxT,EAAEy5B,KAAO,SAASv7B,GAChB,OAAQA,GAAK,GAAKA,GAAK,EAAKlG,EAAI,EAAIyd,KAAKC,MAAMxX,EAAEsV,GAAKkmB,KAEjD15B,GAGTk5B,EAAIvjB,OAAOgkB,OAAS,SAASlY,EAAMQ,GAGjC,IAAI2X,EAFJnY,EAAOA,GAAQ,EACfQ,EAAQA,GAAS,EAEjB,IAAIjiB,EAAI,WACN,IAAkB65B,EAAK58B,EAAnBqC,EAAI,EAAGyE,EAAI,EACf,QAAanD,IAATg5B,EAGF,OAFAt6B,EAAIs6B,EACJA,OAAOh5B,EACAtB,EAET,GAGEu6B,GAFAv6B,EAAkB,EAAdmW,KAAKE,SAAW,GAEZrW,GADRyE,EAAkB,EAAd0R,KAAKE,SAAW,GACN5R,QACC,IAAR81B,GAAaA,EAAM,GAG5B,OAFA58B,EAAIwY,KAAKqkB,MAAM,EAAErkB,KAAK6hB,IAAIuC,GAAKA,GAC/BD,EAAOnY,EAAO1d,EAAE9G,EAAEglB,EACXR,EAAOniB,EAAErC,EAAEglB,GAwDpB,OAtDAjiB,EAAEs5B,QAAU,SAASn7B,GACnB,OAAO+6B,EAAIE,MAAMj7B,GAAG3F,IAAIwH,IAE1BA,EAAEu5B,IAAM,SAASj6B,GACf,IAAIy6B,EAAMtkB,KAAKskB,IAAItkB,KAAKmiB,IAAIt4B,EAAEmiB,EAAM,KAAO,EAAIhM,KAAKmiB,IAAI3V,EAAO,KAC/D,OAAQ,GAAKA,EAAQxM,KAAKqkB,KAAK,EAAErkB,KAAKukB,KAAQD,GAEhD/5B,EAAEw5B,IAAM,SAASl6B,GAGf,IAAI26B,EACAC,GAAK56B,EAAImiB,GAAQQ,EACjBkY,EAAI1kB,KAAK2kB,IAAIF,GACjB,GAAIC,EAAI,GACNF,EAAK,MACA,CACL,IAASF,EAAMtkB,KAAKskB,KAAKI,EAAEA,EAAE,GACzBA,EAAI,kBAONF,EAAKF,QANC,kBAAuBI,EAAI,kBACrBA,EAAI,kBACJA,EAAI,iBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBAShBF,SAPM,kBAAuBE,EAAI,kBACrBA,EAAI,iBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBACJA,EAAI,kBAQhBF,EAAKF,GADCI,EAAI,GADJA,EAAI,GADJA,EAAI,GADJA,EAAI,GADJA,EAAI,SAKO,eAGrB,OAAOD,EAAI,EAAI,EAAID,EAAKA,GAE1Bj6B,EAAEy5B,KAAO,SAASv7B,GAEhB,GAAIA,GAAK,GAAKA,GAAK,EAAG,OAAOw7B,IAC7B,IAAIp6B,EAAI,EAAEpB,EAAI,EACVoW,EAAK,GAAKmB,KAAKukB,GAAK,IAAO,EAAIvkB,KAAKukB,IAAM,EAAEvkB,KAAKukB,KACjDhiC,EAAK,GAAKyd,KAAKukB,GAAG1lB,GAAOmB,KAAK6hB,IAAI,EAAI7hB,KAAKmiB,IAAIt4B,EAAE,IAAM,EACvDhB,EAAImX,KAAK6hB,IAAI,EAAKh4B,EAAEA,GAAMgV,EAC1B/V,GAAKe,EAAI,EAAI,GAAK,GAAKmW,KAAKqkB,KAAKrkB,KAAKqkB,KAAM9hC,EAAEA,EAAKsG,GAAKtG,GAC5D,OAAOypB,EAAOQ,EAAQxM,KAAK4kB,MAAQ97B,GAE9ByB,GAGTk5B,EAAIvjB,OAAO2kB,UAAY,SAASnyB,EAAQoyB,GAGtC,IAAI1c,EAAM1V,EAAO6J,OAAOglB,EAAK5jB,SACzBtV,EAAM+f,EAAI9iB,OACVZ,EAAMogC,EAASrB,EAAIvjB,OAAOgkB,OAAO,EAAGY,GAAU,KAC9Cv6B,EAAI,WACN,OAAO6d,KAAOpI,KAAKE,SAAS7X,KAAS3D,EAAMA,IAAQ,IAKrD,OAHA6F,EAAEs5B,QAAU,SAASn7B,GACnB,OAAO+6B,EAAIE,MAAMj7B,GAAG3F,IAAIwH,IAEnBA,oBCxKT,IAAIg3B,EAAOf,GAAAA,QACPr9B,EAAOs+B,GACPgC,EAAMsB,GAAAA,QAENC,EAAQv9B,EAAOC,QAqfnB,SAASu9B,EAAO17B,EAAK8C,EAAG9B,GACtB,IAAI26B,EAAQ37B,GAAOA,EAAI47B,OAAS,EAC5BC,EAAW3B,EAAIvjB,OAAOgkB,OAAO,EAAG,GAChCmB,EAAKL,EAAMhZ,KAAK3f,EAAE9B,GAClB+6B,EAAKN,EAAMxY,MAAMngB,EAAE9B,GAAKyV,KAAKqkB,KAAKW,EAAMnZ,MAAMc,MAAMtgB,EAAE9B,IAE1D,GAAS,IAAL+6B,EAEF,OAAQD,EAAKH,GAAW,EAAI,EAAI,EAGlC,IAAIT,GAAKY,EAAKH,GAASI,EACvB,OAAO,EAAIF,EAASrB,KAAK/jB,KAAK2kB,IAAIF,IAIpC,SAASc,EAAOh8B,EAAKyN,EAAQzU,EAAGsG,GAC9B,IAIqBhD,EAJjBwG,EAAIxD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAChC1K,EAAIzD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EAChCijC,EAAKR,EAAMnZ,MAAMxf,GACjBo5B,EAAKT,EAAMnZ,MAAMvf,GACjBo5B,EAAQlkC,QAEZ,GAAIgkC,IAAOC,EACT,MAAMjgC,MAAM,6BAEd,IAAKK,EAAE,EAAGA,EAAE2/B,IAAM3/B,EAEZ07B,EAAK5jB,QAAQtR,EAAExG,KAAO07B,EAAK5jB,QAAQrR,EAAEzG,KACvC6/B,EAAMhjC,KAAK2J,EAAExG,GAAKyG,EAAEzG,IAGxB,OAAOm/B,EAAMP,EAAE1J,KAAK2K,EAAOn8B,GAAOA,EAAI47B,OAAS,GAIjD,SAASQ,EAAOp8B,EAAKyN,EAAQzU,EAAGsG,GAC9B,IAAIwD,EAAIxD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAChC1K,EAAIzD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EAChCijC,EAAKR,EAAMnZ,MAAMc,MAAMtgB,GACvBo5B,EAAKT,EAAMnZ,MAAMc,MAAMrgB,GACvB84B,EAAW3B,EAAIvjB,OAAOgkB,OAAO,EAAG,GAChC0B,EAAWZ,EAAMhZ,KAAK3f,GAAK24B,EAAMhZ,KAAK1f,IAAM/C,GAAOA,EAAI47B,OAAS,GAChEG,EAAKtlB,KAAKqkB,KAAKW,EAAMpY,SAASvgB,GAAGm5B,EAAKR,EAAMpY,SAAStgB,GAAGm5B,GAE5D,GAAS,IAALH,EAEF,OAAkB,IAAXM,EAAe,EAAI,EAG5B,IAAInB,EAAImB,EAAWN,EACnB,OAAO,EAAIF,EAASrB,KAAK/jB,KAAK2kB,IAAIF,IApiBpCO,EAAMa,OAAS,SAAS7uB,EAAQzM,EAAGu7B,GACjCv7B,EAAIg3B,EAAK33B,EAAEW,GACXu7B,EAAUA,GAAW,GACrB,IAAYjnB,EAAGhZ,EAAG6C,EAAd+T,EAAI,GACR,IAAK5W,EAAE,EAAG6C,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,GAChCgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,MACrB4W,IACTA,EAAEoC,GAAK,EACPinB,EAAQpjC,KAAKmc,IAEf,OAAOinB,GAITd,EAAMnZ,MAAQ,SAAS7U,GACrB,OAAOA,GAAUA,EAAO1R,QAAU,GAIpC0/B,EAAMnZ,MAAMc,MAAQ,SAAS3V,EAAQzM,GACnCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAIsU,EAAGhZ,EAAG6C,EAAGikB,EAAQ,EACrB,IAAK9mB,EAAE,EAAG6C,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,EAChCgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KAAI8N,GAAS,GAEhC,OAAOA,GAITqY,EAAMnZ,MAAMK,QAAU,SAASlV,EAAQzM,GACrCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAO1E,EAAG6C,EAAGmjB,EAAQ,EACrB,IAAKhmB,EAAE,EAAG6C,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,EAEvB,OADL0E,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,MACfgmB,GAAS,GAE1B,OAAOA,GAKTmZ,EAAMnZ,MAAMC,SAAW,SAAS9U,EAAQzM,GACtCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAYsU,EAAGhZ,EAAG6C,EAAd+T,EAAI,GAAaoP,EAAQ,EAC7B,IAAKhmB,EAAE,EAAG6C,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,GAChCgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,MACrB4W,IACTA,EAAEoC,GAAK,EACPgN,GAAS,GAEX,OAAOA,GAITmZ,EAAMnZ,MAAM9oB,IAAM,SAASiU,EAAQzM,GACjCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAcsU,EAAGhZ,EAAG6C,EAAhB3F,EAAM,GACV,IAAK8C,EAAE,EAAG6C,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,EAEhC9C,EADA8b,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,IACpBgZ,KAAK9b,EAAOA,EAAI8b,GAAK,EAAI,EAErC,OAAO9b,GAITiiC,EAAM/Y,OAAS,SAASjV,EAAQzM,GAG9B,OAFIA,IAAGyM,EAASA,EAAOjU,IAAIw+B,EAAK33B,EAAEW,KAClCyM,EAASA,EAAOuF,OAAOglB,EAAK5jB,SAASlS,KAAK81B,EAAK32B,KACxCo6B,EAAMe,SAAS/uB,EAAQ,KAIhCguB,EAAMgB,SAAW,SAAShvB,EAAQzM,GAC5BA,IAAGyM,EAASA,EAAOjU,IAAIw+B,EAAK33B,EAAEW,KAClCyM,EAASA,EAAOuF,OAAOglB,EAAK5jB,SAASlS,KAAK81B,EAAK32B,KAC/C,IAAIhC,EAAIo8B,EAAMe,SACd,MAAO,CAACn9B,EAAEoO,EAAQ,KAAOpO,EAAEoO,EAAQ,IAAOpO,EAAEoO,EAAQ,OAKtDguB,EAAMe,SAAW,SAAS/uB,EAAQzM,EAAG9B,QACzB0C,IAAN1C,IAAmBA,EAAI8B,EAAGA,EAAIg3B,EAAK3kB,UACvCrS,EAAIg3B,EAAK33B,EAAEW,GACX,IAAI07B,GAAKjvB,EAAO1R,OAAS,GAAKmD,EAAI,EAC9By9B,EAAIlmB,KAAKC,MAAMgmB,GACfpnB,GAAKtU,EAAEyM,EAAOkvB,EAAI,IAClB1jC,EAAIyjC,EAAIC,EACZ,OAAO1jC,EAAIqc,EAAIrc,GAAK+H,EAAEyM,EAAOkvB,IAAMrnB,GAAKA,GAI1CmmB,EAAMtY,IAAM,SAAS1V,EAAQzM,GAC3BA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAK,IAAiCsU,EAA7B6N,EAAI,EAAG7mB,EAAE,EAAG6C,EAAEsO,EAAO1R,OAAWO,EAAE6C,IAAK7C,EAC9CgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KAAI6N,GAAO7N,GAE9B,OAAO6N,GAITsY,EAAMhZ,KAAO,SAAShV,EAAQzM,GAC5BA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAqB1E,EAAG6C,EAAGlB,EAAGqX,EAA1BmN,EAAO,EACX,IAAKnmB,EAAE,EAAG2B,EAAE,EAAGkB,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,EACrCgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KAEfmN,IADQnN,EAAImN,KACaxkB,GAG7B,OAAOwkB,GAITgZ,EAAMhZ,KAAKma,UAAY,SAASnvB,EAAQzM,GACtCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAc/C,EAAGkB,EAAGmW,EAAGhZ,EAAnBmmB,EAAO,EACX,IAAKnmB,EAAE,EAAG2B,EAAE,EAAGkB,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,EAErC,GADAgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,GAAI,CACnB,GAAIA,GAAK,EACP,MAAMrZ,MAAM,oDAEdwmB,GAAQnN,IACNrX,EAIN,OADAwkB,EAAOxkB,EAAI,EAAIwY,KAAKmiB,IAAInW,EAAM,EAAExkB,GAAK,GAKvCw9B,EAAMhZ,KAAKoa,SAAW,SAASpvB,EAAQzM,GACrCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAc/C,EAAGkB,EAAGmW,EAAGhZ,EAAnBmmB,EAAO,EACX,IAAKnmB,EAAE,EAAG2B,EAAE,EAAGkB,EAAEsO,EAAO1R,OAAQO,EAAE6C,IAAK7C,EACrCgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KACfmN,GAAQ,EAAEnN,IACRrX,GAGN,OAAOA,EAAIwkB,GAIbgZ,EAAMpY,SAAW,SAAS5V,EAAQzM,GAEhC,GADAA,EAAIg3B,EAAK33B,EAAEW,IACNg3B,EAAK9+B,QAAQuU,IAAWA,EAAO1R,OAAS,EAAG,OAAO,EACvD,IAAsB+gC,EAAOxgC,EAAG2B,EAAGqX,EAA/BmN,EAAO,EAAGsa,EAAK,EACnB,IAAKzgC,EAAE,EAAG2B,EAAE,EAAG3B,EAAEmR,EAAO1R,SAAUO,EAChCgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KAGfynB,IAFAD,EAAQxnB,EAAImN,IAEOnN,GADnBmN,GAAcqa,IAAW7+B,KAK7B,OADA8+B,GAAW9+B,EAAI,GAKjBw9B,EAAMxY,MAAQ,SAASxV,EAAQzM,GAC7B,OAAOyV,KAAKqkB,KAAKW,EAAMpY,SAAS5V,EAAQzM,KAI1Cy6B,EAAMuB,SAAW,SAASvvB,EAAQzM,GAChC,IAAIi8B,EAAMxB,EAAMhZ,KAAKhV,EAAQzM,GACzBk8B,EAAMzB,EAAM/Y,OAAOjV,EAAQzM,GAC3Bm8B,EAAM1B,EAAMxY,MAAMxV,EAAQzM,GAC9B,OAAe,IAARm8B,EAAY,GAAKF,EAAMC,GAAOC,GAIvC1B,EAAM1e,IAAM,SAAStP,EAAQzM,GAC3B,OAAOy6B,EAAMld,OAAO9Q,EAAQzM,GAAG,IAIjCy6B,EAAMrkB,IAAM,SAAS3J,EAAQzM,GAC3B,OAAOy6B,EAAMld,OAAO9Q,EAAQzM,GAAG,IAIjCy6B,EAAMld,OAAS,SAAS9Q,EAAQzM,GAC9BA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAIhI,EAAGsG,EAAGgW,EAAGhZ,EAAG6C,EAAIsO,EAAO1R,OAC3B,IAAKO,EAAE,EAAGA,EAAE6C,IAAK7C,EAEf,GADAgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,GAAI,CAAEtc,EAAIsG,EAAIgW,EAAG,MAEpC,KAAOhZ,EAAE6C,IAAK7C,EACZgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KACXA,EAAItc,IAAGA,EAAIsc,GACXA,EAAIhW,IAAGA,EAAIgW,IAGnB,MAAO,CAACtc,EAAGsG,IAIbm8B,EAAMld,OAAOniB,MAAQ,SAASqR,EAAQzM,GACpCA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAoBhI,EAAGsG,EAAGgW,EAAGhZ,EAAzBgE,GAAK,EAAGyE,GAAK,EAAe5F,EAAIsO,EAAO1R,OAC3C,IAAKO,EAAE,EAAGA,EAAE6C,IAAK7C,EAEf,GADAgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,GAAI,CAAEtc,EAAIsG,EAAIgW,EAAGhV,EAAIyE,EAAIzI,EAAG,MAE/C,KAAOA,EAAE6C,IAAK7C,EACZgZ,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,GAC1B07B,EAAK5jB,QAAQkB,KACXA,EAAItc,IAAKA,EAAIsc,EAAGhV,EAAIhE,GACpBgZ,EAAIhW,IAAKA,EAAIgW,EAAGvQ,EAAIzI,IAG5B,MAAO,CAACgE,EAAGyE,IAIb02B,EAAM2B,IAAM,SAAS3vB,EAAQzU,EAAGsG,GAC9B,IAAahD,EAAGgZ,EAAZ6N,EAAM,EACV,GAAK7jB,EAWH,IAFAtG,EAAIg/B,EAAK33B,EAAErH,GACXsG,EAAI04B,EAAK33B,EAAEf,GACNhD,EAAE,EAAGA,EAAEmR,EAAO1R,SAAUO,GAC3BgZ,EAAItc,EAAEyU,EAAOnR,IAAMgD,EAAEmO,EAAOnR,MAClBgZ,IAAG6N,GAAO7N,OAbhB,CACN,GAAI7H,EAAO1R,SAAW/C,EAAE+C,OACtB,MAAME,MAAM,6BAEd,IAAKK,EAAE,EAAGA,EAAEmR,EAAO1R,SAAUO,GAC3BgZ,EAAI7H,EAAOnR,GAAKtD,EAAEsD,KACRgZ,IAAG6N,GAAO7N,GAUxB,OAAO6N,GAKTsY,EAAM4B,KAAO,SAAS5vB,EAAQzU,EAAGsG,EAAGy7B,GAClC,IAK8BvmB,EAAGlY,EAL7B0E,EAAIg3B,EAAK/jB,WAAW3U,IAAM04B,EAAK53B,SAASd,GACxCwD,EAAI2K,EACJ1K,EAAI/B,EAAIyM,EAASzU,EACjBC,EAAI+H,EAAI+5B,EAAMz7B,EACdg+B,EAAW,IAANrkC,GAAgB,MAALA,EAChBkG,EAAIsO,EAAO1R,OAAQwD,EAAI,EAK3B,IAJIyB,IACFhI,EAAIg/B,EAAK33B,EAAErH,GACXsG,EAAI04B,EAAK33B,EAAEf,IAERhD,EAAE,EAAGA,EAAE6C,IAAK7C,EACfkY,EAAIxT,EAAKhI,EAAE8J,EAAExG,IAAIgD,EAAEyD,EAAEzG,IAAQwG,EAAExG,GAAGyG,EAAEzG,GACpCiD,GAAK+9B,EAAK9oB,EAAEA,EAAIiC,KAAKmiB,IAAIniB,KAAK2kB,IAAI5mB,GAAIvb,GAExC,OAAOqkC,EAAK7mB,KAAKqkB,KAAKv7B,GAAKkX,KAAKmiB,IAAIr5B,EAAG,EAAEtG,IAI3CwiC,EAAM8B,QAAU,SAAS9vB,EAAQzU,EAAGsG,GAClC,IAAIwD,EAAIxD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAChC1K,EAAIzD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EAChCwkC,EAAK/B,EAAMhZ,KAAK3f,GAChBkC,EAAKy2B,EAAMhZ,KAAK1f,GAChBk5B,EAAKR,EAAMnZ,MAAMc,MAAMtgB,GACvBo5B,EAAKT,EAAMnZ,MAAMc,MAAMrgB,GAE3B,GAAKk5B,EAAGC,EAAG,GAAM,EAEf,OAAO,EAGT,IAAIuB,EAAKhC,EAAMpY,SAASvgB,GACpB46B,EAAKjC,EAAMpY,SAAStgB,GACpBxD,EAAIkX,KAAKqkB,OAAQmB,EAAG,GAAGwB,GAAQvB,EAAG,GAAGwB,IAAQzB,EAAGC,EAAG,IAEvD,OAAW,IAAJ38B,EAAQ,GAAKi+B,EAAKx4B,GAAMzF,GAIjCk8B,EAAMkC,WAAa,SAASlwB,EAAQzU,EAAGsG,GACrC,IAKoBhD,EAAGgE,EAAGyE,EAAG64B,EAAIC,EAL7B/6B,EAAIxD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAChC1K,EAAIzD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EAChCmG,EAAI2D,EAAE/G,OACN+hC,EAAKrC,EAAMhZ,KAAK3f,GAChBi7B,EAAKtC,EAAMhZ,KAAK1f,GAChBogB,EAAM,EAAGllB,EAAI,EAEjB,GAAIkB,IAAM4D,EAAEhH,OACV,MAAME,MAAM,6BAGd,IAAKK,EAAE,EAAGA,EAAE6C,IAAK7C,EAGf,GAFAgE,EAAIwC,EAAExG,GAAIshC,EAAK5F,EAAK5jB,QAAQ9T,GAC5ByE,EAAIhC,EAAEzG,GAAIuhC,EAAK7F,EAAK5jB,QAAQrP,GACxB64B,GAAMC,EACR1a,IAAQ7iB,EAAEw9B,IAAO/4B,EAAEg5B,KACjB9/B,OACG,GAAI2/B,GAAMC,EACf,MAAM5hC,MAAM,4BAGhB,OAAOknB,GAAOllB,EAAE,IAKlBw9B,EAAMuC,KAAO,SAASvwB,EAAQzM,GAC5BA,EAAIg3B,EAAK33B,EAAEW,IAAMg3B,EAAK3kB,SACtB,IAOsB/W,EAAGgZ,EAAGwmB,EAPxB9iC,EAAIyU,EAAOjU,KAAI,SAAS8b,EAAGhZ,GAC3B,MAAO,CAAC6Z,IAAK7Z,EAAGuiB,IAAK7d,EAAEsU,OAExBpT,KAAK81B,EAAKpiB,WAAW,QAEpBzW,EAAIsO,EAAO1R,OACXvD,EAAIP,MAAMkH,GACV8+B,GAAO,EAAG/+B,EAAI,GAElB,IAAK5C,EAAE,EAAGA,EAAE6C,IAAK7C,EAAG,CAElB,GADAgZ,EAAItc,EAAEsD,GAAGuiB,IACLof,EAAM,GAAK/+B,IAAMoW,EACnB2oB,EAAM3hC,EAAI,OACL,GAAI2hC,GAAO,GAAK/+B,IAAMoW,EAAG,CAE9B,IADAwmB,EAAK,GAAKx/B,EAAE,EAAI2hC,GAAO,EAChBA,EAAI3hC,IAAK2hC,EAAKzlC,EAAEQ,EAAEilC,GAAK9nB,KAAO2lB,EACrCmC,GAAO,EAETzlC,EAAEQ,EAAEsD,GAAG6Z,KAAO7Z,EAAI,EAClB4C,EAAIoW,EAGN,GAAI2oB,GAAO,EAET,IADAnC,EAAK,GAAK38B,EAAE,EAAI8+B,GAAO,EAChBA,EAAI9+B,IAAK8+B,EAAKzlC,EAAEQ,EAAEilC,GAAK9nB,KAAO2lB,EAGvC,OAAOtjC,GAITijC,EAAMyC,IAAM,SAASzwB,EAAQzU,EAAGsG,GAC9B,IAAIjB,EAAKiB,EACTA,EAAIjB,EAAKoP,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EACjCA,EAAIqF,EAAKoP,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAEjC,IAAI2vB,EAAM3B,EAAM2B,IAAIpkC,EAAGsG,GACnB6+B,EAAM1C,EAAMhZ,KAAKzpB,GACjBolC,EAAM3C,EAAMhZ,KAAKnjB,GACjB++B,EAAM5C,EAAMxY,MAAMjqB,GAClBslC,EAAM7C,EAAMxY,MAAM3jB,GAClBH,EAAIsO,EAAO1R,OAEf,OAAQqhC,EAAMj+B,EAAEg/B,EAAIC,KAASj/B,EAAE,GAAKk/B,EAAMC,IAI5C7C,EAAMyC,IAAIF,KAAO,SAASvwB,EAAQzU,EAAGsG,GACnC,IAEuBhD,EAAGiD,EAAGiV,EAFzB+pB,EAAKj/B,EAAIm8B,EAAMuC,KAAKvwB,EAAQzU,GAAKyiC,EAAMuC,KAAKvwB,GAC5C+wB,EAAKl/B,EAAIm8B,EAAMuC,KAAKvwB,EAAQnO,GAAKm8B,EAAMuC,KAAKhlC,GAC5CmG,EAAIsO,EAAO1R,OAEf,IAAKO,EAAE,EAAGiD,EAAE,EAAGjD,EAAE6C,IAAK7C,EAEpBiD,IADAiV,EAAI+pB,EAAGjiC,GAAKkiC,EAAGliC,IACNkY,EAGX,OAAO,EAAI,EAAEjV,GAAKJ,GAAKA,EAAEA,EAAE,KAK7Bs8B,EAAMyC,IAAIb,KAAO,SAAS5vB,EAAQzU,EAAGsG,GACnC,IAMIhD,EAAGmiC,EAAIC,EAAIC,EANX77B,EAAIxD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAChC1K,EAAIzD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EAEhC4lC,EAAInD,EAAM4B,KAAKwB,IAAI/7B,GACnBg8B,EAAIrD,EAAM4B,KAAKwB,IAAI97B,GACnB5D,EAAIy/B,EAAE7iC,OAGV,IAAKO,EAAE,EAAGmiC,EAAG,EAAGC,EAAG,EAAGC,EAAG,EAAGriC,EAAE6C,IAAK7C,EACjCmiC,GAAMG,EAAEtiC,GAAGsiC,EAAEtiC,GACboiC,GAAMI,EAAExiC,GAAGwiC,EAAExiC,GACbqiC,GAAMC,EAAEtiC,GAAGwiC,EAAExiC,GAGf,OAAOma,KAAKqkB,KAAK6D,EAAKloB,KAAKqkB,KAAK2D,EAAGC,KAMrCjD,EAAMsD,iBAAmB,SAAStxB,EAAQzU,EAAGsG,GAC3C,IASI0/B,EAAK1iC,EATLwG,EAAIxD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EAChC1K,EAAIzD,EAAImO,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EAChCmG,EAAI2D,EAAE/G,OACNkjC,EAAKxD,EAAMkC,WAAW76B,EAAGC,GACzBm8B,EAAKzD,EAAMxY,MAAMngB,GACjBq8B,EAAK1D,EAAMxY,MAAMlgB,GACjBq8B,EAAQH,GAAMC,EAAGA,GACjBG,EAAQ5D,EAAMhZ,KAAK1f,GAAKq8B,EAAQ3D,EAAMhZ,KAAK3f,GAC3Cw8B,EAAM,CAACF,MAAOA,EAAOG,UAAWF,EAAOG,EAAGP,GAAMC,EAAGC,GAAKM,IAAK,GAGjE,IAAKnjC,EAAE,EAAGA,EAAE6C,IAAK7C,EACX07B,EAAK5jB,QAAQtR,EAAExG,KAAO07B,EAAK5jB,QAAQrR,EAAEzG,MACvC0iC,EAAOI,EAAMt8B,EAAExG,GAAK+iC,EAASt8B,EAAEzG,GAC/BgjC,EAAIG,KAAOT,EAAMA,GAIrB,OAAOM,GAIT7D,EAAMH,UAAY,GAKlBG,EAAMH,UAAUoE,GAAK,SAASjyB,EAAQzU,EAAGsG,EAAGrB,EAAGuW,GAC7C,IAAI1R,EAAG68B,EAAGC,EAAOrE,EAAQsE,EAAIC,EAAOxjC,EAgBpC,IAfI07B,EAAK/jB,WAAWjb,IAAMg/B,EAAK53B,SAASpH,IACtC8J,EAAI2K,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IACtB2mC,EAAIrgC,EACJsgC,EAAQ3hC,EACRs9B,EAAS/mB,IAET1R,EAAI2K,EACJkyB,EAAI3mC,EACJ4mC,EAAQtgC,EACRi8B,EAASt9B,GAEX0hC,EAAIA,GAAKA,EAAI,IACbC,EAAQA,GAAS,IAEjBC,EAAK3F,EAAIvjB,OAAO2kB,UAAUx4B,EAAGy4B,GACxBj/B,EAAE,EAAGwjC,EAAQ7nC,MAAM0nC,GAAIrjC,EAAEqjC,IAAKrjC,EACjCwjC,EAAMxjC,GAAKm/B,EAAMhZ,KAAKod,EAAGvF,QAAQx3B,EAAE/G,SAGrC,OADA+jC,EAAM59B,KAAK81B,EAAKliB,QACT,CACL2lB,EAAMe,SAASsD,EAAOF,EAAM,GAC5BnE,EAAMe,SAASsD,EAAO,EAAGF,EAAM,KAKnCnE,EAAMP,EAAI,GAIVO,EAAMP,EAAEwE,GAAK,SAASjyB,EAAQzU,EAAGsG,GAC/B,IAAIwD,EAAI2K,EAAQmyB,EAAQ5mC,GACpBg/B,EAAK/jB,WAAWjb,IAAMg/B,EAAK53B,SAASpH,MACtC8J,EAAI2K,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IACtB4mC,EAAQtgC,GAIV,IAAI47B,EAAY,OAFhB0E,EAAQA,GAAS,KAEM,KAAO1F,EAAIvjB,OAAOgkB,OAAO,EAAG,GAAGF,KAAK,EAAGmF,EAAM,GAChE9D,EAAKL,EAAMhZ,KAAK3f,GAChBi5B,EAAKN,EAAMxY,MAAMngB,GAAK2T,KAAKqkB,KAAKW,EAAMnZ,MAAMc,MAAMtgB,IACtD,MAAO,CAACg5B,EAAMZ,EAAEa,EAAKD,EAAMZ,EAAEa,IAW/BN,EAAMP,EAAE1J,KAAO,SAAS/jB,EAAQzU,EAAGsG,EAAGU,GACpC,OAAIg4B,EAAK/jB,WAAW3U,IAAM04B,EAAK53B,SAASd,IAC9BU,GAAOA,EAAI+/B,OAAS/D,EAASI,GAAQp8B,EAAKyN,EAAQzU,EAAGsG,GACpD04B,EAAK9+B,QAAQF,IACdsG,GAAKA,EAAEygC,OAAS/D,EAASI,GAAQ98B,EAAGmO,EAAQzU,GAC3Cg/B,EAAK/jB,WAAWjb,IAAMg/B,EAAK53B,SAASpH,GACtC0iC,EAAOp8B,EAAGmO,EAAQzU,GAElB0iC,EAAO1iC,EAAGyU,IA8DrBguB,EAAM4B,KAAKwB,IAAM,SAAS/7B,GACxB,IAIWwS,EAAGhZ,EAAG8C,EAJbD,EAAI2D,EAAE/G,OACNya,EAAIrX,EAAEA,EACNy/B,EAAI3mC,MAAMue,GACVgpB,EAAItF,EAAIE,MAAMj7B,GACd6gC,EAAI,EAER,IAAK1jC,EAAE,EAAGA,EAAE6C,IAAK7C,EAEf,IADAsiC,EAAEtiC,EAAE6C,EAAE7C,GAAK,EACN8C,EAAE9C,EAAE,EAAG8C,EAAED,IAAKC,EACjBw/B,EAAEtiC,EAAE6C,EAAEC,GAAMkW,EAAImB,KAAK2kB,IAAIt4B,EAAExG,GAAKwG,EAAE1D,IAClCw/B,EAAEx/B,EAAED,EAAE7C,GAAKgZ,EACXkqB,EAAEljC,IAAMgZ,EACRkqB,EAAEpgC,IAAMkW,EAIZ,IAAKhZ,EAAE,EAAGA,EAAE6C,IAAK7C,EACf0jC,GAAKR,EAAEljC,GACPkjC,EAAEljC,IAAM6C,EAIV,IAFA6gC,GAAKxpB,EAEAla,EAAE,EAAGA,EAAE6C,IAAK7C,EACf,IAAK8C,EAAE9C,EAAG8C,EAAED,IAAKC,EACfw/B,EAAEtiC,EAAE6C,EAAEC,IAAM4gC,EAAIR,EAAEljC,GAAKkjC,EAAEpgC,GACzBw/B,EAAEx/B,EAAED,EAAE7C,GAAKsiC,EAAEtiC,EAAE6C,EAAEC,GAIrB,OAAOw/B,GAITnD,EAAMwE,QAAU,SAASC,EAAQl/B,GAC/BA,EAAIg3B,EAAK33B,EAAEW,GACX,IAAI1E,EAAG4C,EAAGK,EAAI,EAAGm9B,EAAI,EAAGv9B,EAAI+gC,EAAOnkC,OACnC,IAAKO,EAAE,EAAGA,EAAE6C,IAAK7C,EACfiD,GAAMyB,EAAIA,EAAEk/B,EAAO5jC,IAAM4jC,EAAO5jC,GAElC,GAAU,IAANiD,EAAS,OAAO,EACpB,IAAKjD,EAAE,EAAGA,EAAE6C,IAAK7C,GACf4C,GAAK8B,EAAIA,EAAEk/B,EAAO5jC,IAAM4jC,EAAO5jC,IAAMiD,KAC9Bm9B,GAAKx9B,EAAIuX,KAAK6hB,IAAIp5B,IAE3B,OAAQw9B,EAAIjmB,KAAK0pB,KAOnB1E,EAAM2E,OAAS,SAAS3yB,EAAQzU,EAAGsG,EAAG4gC,GACpC,IAOyBhhC,EAAGzG,EAAG6D,EAP3BgE,EAAI4/B,EAASzyB,EAAOjU,IAAIw+B,EAAK33B,EAAErH,IAAMyU,EACrC1I,EAAIm7B,EAASzyB,EAAOjU,IAAIw+B,EAAK33B,EAAEf,IAAMtG,EACrCkiC,EAAIgF,EAASzyB,EAAOjU,IAAIw+B,EAAK33B,EAAE6/B,IAAW5gC,EAE1C+gC,EAAK,GACLC,EAAK,GACLnhC,EAAI+7B,EAAEn/B,OACNwD,EAAI,EAAGghC,EAAI,EAAG7D,EAAI,EAEtB,IAAKpgC,EAAE,EAAGA,EAAE6C,IAAK7C,EACf+jC,EAAG//B,EAAEhE,IAAM,EACXgkC,EAAGv7B,EAAEzI,IAAM,EAGb,IAAKA,EAAE,EAAGA,EAAE6C,IAAK7C,EACf+jC,EAAG//B,EAAEhE,KAAO4+B,EAAE5+B,GACdgkC,EAAGv7B,EAAEzI,KAAO4+B,EAAE5+B,GACdiD,GAAK27B,EAAE5+B,GAIT,IADA7D,EAAI,GAAK8G,EAAIkX,KAAK0pB,KACb7jC,EAAE,EAAGA,EAAE6C,IAAK7C,EACF,IAAT4+B,EAAE5+B,KACN4C,EAAKK,EAAI27B,EAAE5+B,IAAO+jC,EAAG//B,EAAEhE,IAAMgkC,EAAGv7B,EAAEzI,KAClCikC,GAAKrF,EAAE5+B,GAAK7D,EAAIge,KAAK6hB,IAAIp5B,GACzBw9B,GAAKxB,EAAE5+B,GAAK7D,EAAIge,KAAK6hB,IAAI4C,EAAE5+B,GAAGiD,IAGhC,MAAO,CAACghC,EAAG,EAAIA,EAAE7D,IAInBjB,EAAM2E,OAAOI,KAAO,SAAS/yB,EAAQzU,EAAGsG,EAAG4gC,GACzC,OAAOzE,EAAM2E,OAAO3yB,EAAQzU,EAAGsG,EAAG4gC,GAAQ,IAK5CzE,EAAM2E,OAAO/C,KAAO,SAAS5vB,EAAQzU,EAAGsG,EAAG4gC,GACzC,OAAOzE,EAAM2E,OAAO3yB,EAAQzU,EAAGsG,EAAG4gC,GAAQ,IAI5CzE,EAAMgF,QAAU,SAAShzB,EAAQzM,GAC/B,IAQY87B,EAAO4D,EAAIpkC,EAAGgZ,EAAGhV,EARzBmiB,EAAO,EACPW,EAAQ,EACRT,EAAU,EACVJ,EAAW,EACXxF,EAAM,KACN3F,EAAM,KACN2lB,EAAK,EACLnpB,EAAO,GACPV,EAAI,GAGR,IAAK5W,EAAE,EAAGA,EAAEmR,EAAO1R,SAAUO,EAI3B4W,EAHAoC,EAAItU,EAAIA,EAAEyM,EAAOnR,IAAMmR,EAAOnR,IAGtBgZ,KAAKpC,EAAKA,EAAEoC,GAAK,GAAKiN,GAAY,EAAG,GAEpC,MAALjN,IACAqN,EACOqV,EAAK5jB,QAAQkB,KAEtBhV,EAAkB,iBAANgV,EAAkBA,EAAEvZ,OAASuZ,GAC/B,OAANyH,GAAczc,EAAIyc,KAAKA,EAAMzc,IACvB,OAAN8W,GAAc9W,EAAI8W,KAAKA,EAAM9W,GAGjCy8B,IAFAD,EAAQx8B,EAAImiB,IAEOniB,GADnBmiB,GAAcqa,IAAW1Z,IAEzBxP,EAAKza,KAAKmH,IASd,OANAy8B,GAAW3Z,EAAQ,EACnBsd,EAAKjqB,KAAKqkB,KAAKiC,GAGfnpB,EAAK1R,KAAK81B,EAAK32B,KAER,CACLzH,KAAUA,EAAK6T,EAAQzM,GACvBs7B,OAAUppB,EACVoP,MAAU7U,EAAO1R,OACjBqnB,MAAUA,EACVT,QAAUA,EACVJ,SAAUA,EACVxF,IAAUA,EACV3F,IAAUA,EACVqL,KAAUA,EACVQ,MAAUyd,EACVhe,OAAWpN,EAAImmB,EAAMe,SAAS5oB,EAAM,IACpCgP,GAAU6Y,EAAMe,SAAS5oB,EAAM,KAC/BiP,GAAU4Y,EAAMe,SAAS5oB,EAAM,KAC/BopB,SAAiB,IAAP0D,EAAW,GAAKje,EAAOnN,GAAKorB,IAK1CjF,EAAMkF,QAAU,SAASx/B,EAAM7C,GAE7B,IAAIiB,GADJjB,EAASA,GAAU05B,EAAK/1B,KAAKd,EAAK,KACnB3H,KAAI,SAASwH,GAC1B,IAAI9B,EAAIu8B,EAAMgF,QAAQt/B,EAAM62B,EAAK33B,EAAEW,IACnC,OAAQ9B,EAAEL,MAAQmC,EAAG9B,KAEvB,OAAQK,EAAEqhC,aAAc,EAAMrhC,QC9sBhC,IAAIuxB,GAAK,IAAIn1B,KACTo1B,GAAK,IAAIp1B,KAEE,SAASq1B,GAAYC,EAAQC,EAAS5O,EAAOzjB,GAE1D,SAASsyB,EAAS5c,GAChB,OAAO0c,EAAO1c,EAA4B,IAArB5b,UAAUoD,OAAe,IAAIJ,KAAO,IAAIA,MAAM4Y,IAAQA,EA8D7E,OA3DA4c,EAASza,MAAQ,SAASnC,GACxB,OAAO0c,EAAO1c,EAAO,IAAI5Y,MAAM4Y,IAAQA,GAGzC4c,EAASpa,KAAO,SAASxC,GACvB,OAAO0c,EAAO1c,EAAO,IAAI5Y,KAAK4Y,EAAO,IAAK2c,EAAQ3c,EAAM,GAAI0c,EAAO1c,GAAOA,GAG5E4c,EAASvf,MAAQ,SAAS2C,GACxB,IAAI6c,EAAKD,EAAS5c,GACd8c,EAAKF,EAASpa,KAAKxC,GACvB,OAAOA,EAAO6c,EAAKC,EAAK9c,EAAO6c,EAAKC,GAGtCF,EAAS3lB,OAAS,SAAS+I,EAAMyI,GAC/B,OAAOkU,EAAQ3c,EAAO,IAAI5Y,MAAM4Y,GAAe,MAARyI,EAAe,EAAIvG,KAAKC,MAAMsG,IAAQzI,GAG/E4c,EAAS7f,MAAQ,SAASggB,EAAOC,EAAMvU,GACrC,IAAgB6jB,EAAZvvB,EAAQ,GAGZ,GAFAggB,EAAQH,EAASpa,KAAKua,GACtBtU,EAAe,MAARA,EAAe,EAAIvG,KAAKC,MAAMsG,KAC/BsU,EAAQC,GAAWvU,EAAO,GAAI,OAAO1L,EAC3C,GAAGA,EAAMnY,KAAK0nC,EAAW,IAAIllC,MAAM21B,IAASJ,EAAQI,EAAOtU,GAAOiU,EAAOK,SAClEuP,EAAWvP,GAASA,EAAQC,GACnC,OAAOjgB,GAGT6f,EAASne,OAAS,SAASwe,GACzB,OAAOR,IAAY,SAASzc,GAC1B,GAAIA,GAAQA,EAAM,KAAO0c,EAAO1c,IAAQid,EAAKjd,IAAOA,EAAKkd,QAAQld,EAAO,MACvE,SAASA,EAAMyI,GAChB,GAAIzI,GAAQA,EACV,GAAIyI,EAAO,EAAG,OAASA,GAAQ,GAC7B,KAAOkU,EAAQ3c,GAAO,IAAKid,EAAKjd,UAC3B,OAASyI,GAAQ,GACtB,KAAOkU,EAAQ3c,EAAM,IAAMid,EAAKjd,UAMpC+N,IACF6O,EAAS7O,MAAQ,SAASgP,EAAOI,GAG/B,OAFAZ,GAAGW,SAASH,GAAQP,GAAGU,SAASC,GAChCT,EAAOH,IAAKG,EAAOF,IACZta,KAAKC,MAAM4L,EAAMwO,GAAIC,MAG9BI,EAASve,MAAQ,SAASoK,GAExB,OADAA,EAAOvG,KAAKC,MAAMsG,GACVnb,SAASmb,IAAWA,EAAO,EAC3BA,EAAO,EACTmU,EAASne,OAAOnU,EACZ,SAAS2V,GAAK,OAAO3V,EAAM2V,GAAKwI,GAAS,GACzC,SAASxI,GAAK,OAAO2c,EAAS7O,MAAM,EAAG9N,GAAKwI,GAAS,IAH3CmU,EADoB,OAQrCA,EClET,IAAIQ,GAAcR,IAAS,eAExB,SAAS5c,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,MACpB,SAASsU,EAAOI,GACjB,OAAOA,EAAMJ,KAIfK,GAAY/e,MAAQ,SAAS3R,GAE3B,OADAA,EAAIwV,KAAKC,MAAMzV,GACVY,SAASZ,IAAQA,EAAI,EACpBA,EAAI,EACHkwB,IAAS,SAAS5c,GACvBA,EAAKkd,QAAQhb,KAAKC,MAAMnC,EAAOtT,GAAKA,MACnC,SAASsT,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAO/b,MAC3B,SAASqwB,EAAOI,GACjB,OAAQA,EAAMJ,GAASrwB,KANJ0wB,GADgB,MCbhC,IAAImP,GAAiB,IACjBC,GAAiB,IACjBC,GAAe,KACfC,GAAc,MACdC,GAAe,OCDb/P,IAAS,SAAS5c,GAC7BA,EAAKkd,QAAQld,EAAOA,EAAK4sB,sBACxB,SAAS5sB,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAO8jB,OAC3B,SAASxP,EAAOI,GACjB,OAAQA,EAAMJ,GAASwP,MACtB,SAASvsB,GACV,OAAOA,EAAKif,mBCPDrC,IAAS,SAAS5c,GAC7BA,EAAKkd,QAAQld,EAAOA,EAAK4sB,kBAAoB5sB,EAAKud,aAAegP,OAChE,SAASvsB,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAO+jB,OAC3B,SAASzP,EAAOI,GACjB,OAAQA,EAAMJ,GAASyP,MACtB,SAASxsB,GACV,OAAOA,EAAK0d,gBCPHd,IAAS,SAAS5c,GAC3BA,EAAKkd,QAAQld,EAAOA,EAAK4sB,kBAAoB5sB,EAAKud,aAAegP,GAAiBvsB,EAAK0d,aAAe8O,OACrG,SAASxsB,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAOgkB,OAC3B,SAAS1P,EAAOI,GACjB,OAAQA,EAAMJ,GAAS0P,MACtB,SAASzsB,GACV,OAAOA,EAAK6d,cCPJjB,IACR5c,GAAQA,EAAK8d,SAAS,EAAG,EAAG,EAAG,KAC/B,CAAC9d,EAAMyI,IAASzI,EAAK+d,QAAQ/d,EAAKge,UAAYvV,KAC9C,CAACsU,EAAOI,KAASA,EAAMJ,GAASI,EAAIc,oBAAsBlB,EAAMkB,qBAAuBuO,IAAkBE,KACzG1sB,GAAQA,EAAKge,UAAY,ICJ3B,SAASE,GAAQn2B,GACf,OAAO60B,IAAS,SAAS5c,GACvBA,EAAK+d,QAAQ/d,EAAKge,WAAahe,EAAKme,SAAW,EAAIp2B,GAAK,GACxDiY,EAAK8d,SAAS,EAAG,EAAG,EAAG,MACtB,SAAS9d,EAAMyI,GAChBzI,EAAK+d,QAAQ/d,EAAKge,UAAmB,EAAPvV,MAC7B,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAASI,EAAIc,oBAAsBlB,EAAMkB,qBAAuBuO,IAAkBG,MAIhFzO,GAAQ,GACRA,GAAQ,GACPA,GAAQ,GACNA,GAAQ,GACTA,GAAQ,GACVA,GAAQ,GACNA,GAAQ,GClB9B,IAAIxO,GAAQkN,IAAS,SAAS5c,GAC5BA,EAAK+d,QAAQ,GACb/d,EAAK8d,SAAS,EAAG,EAAG,EAAG,MACtB,SAAS9d,EAAMyI,GAChBzI,EAAK2e,SAAS3e,EAAK4e,WAAanW,MAC/B,SAASsU,EAAOI,GACjB,OAAOA,EAAIyB,WAAa7B,EAAM6B,WAAyD,IAA3CzB,EAAI0B,cAAgB9B,EAAM8B,kBACrE,SAAS7e,GACV,OAAOA,EAAK4e,cCRVpP,GAAOoN,IAAS,SAAS5c,GAC3BA,EAAK2e,SAAS,EAAG,GACjB3e,EAAK8d,SAAS,EAAG,EAAG,EAAG,MACtB,SAAS9d,EAAMyI,GAChBzI,EAAK8e,YAAY9e,EAAK6e,cAAgBpW,MACrC,SAASsU,EAAOI,GACjB,OAAOA,EAAI0B,cAAgB9B,EAAM8B,iBAChC,SAAS7e,GACV,OAAOA,EAAK6e,iBAIdrP,GAAKnR,MAAQ,SAAS3R,GACpB,OAAQY,SAASZ,EAAIwV,KAAKC,MAAMzV,KAASA,EAAI,EAAYkwB,IAAS,SAAS5c,GACzEA,EAAK8e,YAAY5c,KAAKC,MAAMnC,EAAK6e,cAAgBnyB,GAAKA,GACtDsT,EAAK2e,SAAS,EAAG,GACjB3e,EAAK8d,SAAS,EAAG,EAAG,EAAG,MACtB,SAAS9d,EAAMyI,GAChBzI,EAAK8e,YAAY9e,EAAK6e,cAAgBpW,EAAO/b,MALG,MCZpCkwB,IAAS,SAAS5c,GAChCA,EAAKmf,cAAc,EAAG,MACrB,SAASnf,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAO+jB,OAC3B,SAASzP,EAAOI,GACjB,OAAQA,EAAMJ,GAASyP,MACtB,SAASxsB,GACV,OAAOA,EAAKof,mBCPAxC,IAAS,SAAS5c,GAC9BA,EAAKsf,cAAc,EAAG,EAAG,MACxB,SAAStf,EAAMyI,GAChBzI,EAAKkd,SAASld,EAAOyI,EAAOgkB,OAC3B,SAAS1P,EAAOI,GACjB,OAAQA,EAAMJ,GAAS0P,MACtB,SAASzsB,GACV,OAAOA,EAAKuf,iBCPD3C,IAAS,SAAS5c,GAC7BA,EAAKyf,YAAY,EAAG,EAAG,EAAG,MACzB,SAASzf,EAAMyI,GAChBzI,EAAK0f,WAAW1f,EAAK2f,aAAelX,MACnC,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS2P,MACtB,SAAS1sB,GACV,OAAOA,EAAK2f,aAAe,KCP7B,SAASC,GAAW73B,GAClB,OAAO60B,IAAS,SAAS5c,GACvBA,EAAK0f,WAAW1f,EAAK2f,cAAgB3f,EAAK6f,YAAc,EAAI93B,GAAK,GACjEiY,EAAKyf,YAAY,EAAG,EAAG,EAAG,MACzB,SAASzf,EAAMyI,GAChBzI,EAAK0f,WAAW1f,EAAK2f,aAAsB,EAAPlX,MACnC,SAASsU,EAAOI,GACjB,OAAQA,EAAMJ,GAAS4P,MAIJ/M,GAAW,GACXA,GAAW,GACVA,GAAW,GACTA,GAAW,GACZA,GAAW,GACbA,GAAW,GACTA,GAAW,GClBpC,IAAIS,GAAWzD,IAAS,SAAS5c,GAC/BA,EAAK0f,WAAW,GAChB1f,EAAKyf,YAAY,EAAG,EAAG,EAAG,MACzB,SAASzf,EAAMyI,GAChBzI,EAAKsgB,YAAYtgB,EAAKugB,cAAgB9X,MACrC,SAASsU,EAAOI,GACjB,OAAOA,EAAIoD,cAAgBxD,EAAMwD,cAAkE,IAAjDpD,EAAIqD,iBAAmBzD,EAAMyD,qBAC9E,SAASxgB,GACV,OAAOA,EAAKugB,iBCRVE,GAAU7D,IAAS,SAAS5c,GAC9BA,EAAKsgB,YAAY,EAAG,GACpBtgB,EAAKyf,YAAY,EAAG,EAAG,EAAG,MACzB,SAASzf,EAAMyI,GAChBzI,EAAK0gB,eAAe1gB,EAAKwgB,iBAAmB/X,MAC3C,SAASsU,EAAOI,GACjB,OAAOA,EAAIqD,iBAAmBzD,EAAMyD,oBACnC,SAASxgB,GACV,OAAOA,EAAKwgB,oBAIdC,GAAQpiB,MAAQ,SAAS3R,GACvB,OAAQY,SAASZ,EAAIwV,KAAKC,MAAMzV,KAASA,EAAI,EAAYkwB,IAAS,SAAS5c,GACzEA,EAAK0gB,eAAexe,KAAKC,MAAMnC,EAAKwgB,iBAAmB9zB,GAAKA,GAC5DsT,EAAKsgB,YAAY,EAAG,GACpBtgB,EAAKyf,YAAY,EAAG,EAAG,EAAG,MACzB,SAASzf,EAAMyI,GAChBzI,EAAK0gB,eAAe1gB,EAAKwgB,iBAAmB/X,EAAO/b,MALH,MCXpD,MAAMmgC,GAAO,OACPC,GAAU,UACVC,GAAQ,QACRC,GAAO,OACPC,GAAO,OACPC,GAAM,MACNC,GAAY,YACZC,GAAQ,QACRC,GAAU,UACVC,GAAU,UACVC,GAAe,eACF,CAACV,GAAMC,GAASC,GAAOC,GAAMC,GAAMC,GAAKC,GAAWC,GAAOC,GAASC,GAASC,IACtEjpC,QAAO,CAAC4E,EAAGyV,EAAG5W,KAAOmB,EAAEyV,GAAK,EAAI5W,EAAGmB,IAAI,IA+MnDskC,GAAUnvB,MAAM,GAahBgiB,GAAShiB,MAAM,GCxN5B,MAAMovB,GAAQC,GAiLd,MAAM57B,GAAQ,CACZ67B,QAAS,EACT1lC,IAAK,EACL2lC,QAAS,EACTC,SAAU,EACVC,aAAc,SAGHC,GAIXtyB,YAAYuyB,GACVxpC,KAAKypC,aAAeD,EAEpBA,EAAYjkC,OAAO4D,MAAK,SAAUlJ,EAAgBsG,GAEhD,OAAI+G,GAAMrN,EAAEypC,QAAUp8B,GAAM/G,EAAEmjC,SACpB,EACCp8B,GAAMrN,EAAEypC,QAAUp8B,GAAM/G,EAAEmjC,QAC5B,EAGAzpC,EAAEuF,KAAKuvB,cAAcxuB,EAAEf,SAKlCgkC,EAAYjkC,OAAO/B,SAAQ,CAACi0B,EAAap0B,IAAWo0B,EAAYp0B,MAAQA,IAExErD,KAAK2pC,kBAAoBH,EAAYjkC,OAAOzF,QAAO,CAAC2d,EAAGga,KACrDha,EAAEga,EAAYjyB,MAAQiyB,EACfha,IACN,IAIExG,aACL,OAAOjX,KAAKypC,aAAalkC,OAAO9E,KAAKg3B,GAAgBA,EAAYjyB,OAInEokC,mBACE,OAAO5pC,KAAKypC,aAAalkC,OAGpB0R,YAAYypB,GACjB,OAAO1gC,KAAK2pC,kBAAkBjJ,GAGzBzpB,cAIL,MAAMuyB,EAAc/uB,GAAAA,QAAAA,UAAUza,KAAKypC,cAEnC,OADAD,EAAYjkC,OAAO4D,MAAK,CAAClJ,EAAGsG,IAAMtG,EAAE4pC,cAAgBtjC,EAAEsjC,gBAC/CL,EAMFvyB,cAAcypB,GACnB,OAAO1gC,KAAK2pC,kBAAkBjJ,GAAa1gC,KAAK2pC,kBAAkBjJ,GAAW7/B,KAAO,KAM/EoW,OAAOypB,GACZ,OAAO1gC,KAAK2pC,kBAAkBjJ,GAAa1gC,KAAK2pC,kBAAkBjJ,GAAWgJ,OAAS,KAMjFzyB,YAAY2d,EAAoBkV,GAAwB,EAAMC,GAAiB,GACpF,MAAMtS,EAAcz3B,KAAK2pC,kBAAkB/U,EAAO9uB,OAClD,GAAI8uB,EAAOjW,WAAcgW,GAAiBC,IAAWA,EAAOhW,UAC1D,OAAO,EACF,GAAIgW,EAAO/V,IAAK,CAErB,IAAIA,EAGFA,EAFwB,kBAAf+V,EAAO/V,IAEV,CACJkF,QAAS2G,GAAYkK,EAAO9mB,UAEN,MAAf8mB,EAAO/V,IACV,CACJkE,KAAM,EAAC,GAAM,IAGT6R,EAAO/V,IAEf,MAAMkF,EAAelF,EAAIkF,QAMzB,OALK0T,EAAYuS,SAASjmB,KAExB0T,EAAYuS,SAASjmB,GAAWkmB,GAAWlmB,EAAS0T,EAAYiL,QAG3DjL,EAAYuS,SAASjmB,GAASyF,SAChC,GAAIoL,EAAO9V,SAAU,CAC1B,GAAIgrB,EACF,OAAQlV,EAAO9V,UAEb,KAAKorB,GAEL,KAAKC,GACH,OAAO,GACT,KAAKC,GACH,OAAO,GACT,KAAKC,GACH,OAAO,EACT,KAAKC,GACH,OAAO,GACT,KAAKC,GACH,OAAO,GACT,KAAKC,GACH,OAAO,EACT,KAAKC,GACH,OAAO,IAGb,MAAMve,EAAO0I,EAAO9V,SACpB,IAAI4rB,EAAYjT,EAAYiT,UAS5B,OAPKA,GAAcA,EAAUxe,KAC3Bwe,EAASrrC,OAAA0M,OAAA1M,OAAA0M,OAAA,GACJ2+B,GAAS,CACZzzB,CAACiV,GAAOye,GAAY/V,EAAO9V,SAAsB2Y,EAAYiL,UAI7DqH,EACKW,EAAUxe,GAAM1C,SAAWohB,GAAaF,EAAUxe,GAAMqX,OAAQ,CAAC,eAAgB,OAEjFmH,EAAUxe,GAAM1C,SAGzB,OAAIiO,EACEsS,EACKtS,EAAYiL,MAAMlZ,SAAWohB,GAAanT,EAAYiL,MAAMa,OAAQ,CAAC5B,IAAK,OAE1ElK,EAAYiL,MAAMlZ,SAGpB,KAaNvS,qBAAqB2d,GAC1B,IAAKA,EAAO9V,SACV,OAIF,GAAI8V,EAAO9V,WAAaurB,GAAc,CACpC,MAAMQ,EAA0BjwB,GAAAA,QAAAA,OAAO,GAAIga,EAAQ,CAAC9V,SAAUwrB,KAC9D,GAAItqC,KAAK8qC,YAAYD,GAAU,GAAO,IAAS,EAC7C,OAAO,EAIX,MAAM9e,EAAe6I,EAAO9V,SAC5B,IAAK,MAAMisB,KAAgBrf,GACzB,GAAII,GAAiBC,EAA0Bgf,GAAe,CAE5D,MAAMC,EAAiBpwB,GAAAA,QAAAA,OAAO,GAAIga,EAAQ,CAAC9V,SAAUisB,IACrD,GAAI/qC,KAAK8qC,YAAYE,GAAgB,GAAO,IAAS,EACnD,OAAO,EAIb,OAAO,EAGF/zB,OAAOg0B,GAEZ,MAAMxT,EAAcz3B,KAAK2pC,kBAAkBsB,EAAgBnlC,OAC3D,IAAIsK,EAAgBlH,GAAAA,QAAAA,KAAKuuB,EAAYiL,MAAMa,QAC3C,OAAI9L,EAAYiS,SAAWpkB,GAElB,EAAEmS,EAAYiL,MAAM1e,KAAMyT,EAAYiL,MAAMrkB,KAC1CoZ,EAAY52B,OAASqqC,GAAcC,SAErC,CAAC1T,EAAYiL,MAAM1e,IAAKyT,EAAYiL,MAAMrkB,KACxCoZ,EAAY52B,OAASqqC,GAAcE,SAAW3T,EAAY52B,OAASqqC,GAAcG,QAE1Fj7B,EAASA,EAAO3P,KAAK8G,IAAOA,IACrB6I,EAAOjH,KAAKb,GAAAA,QAAAA,MACVmvB,EAAYiS,SAAWrkB,IAAgBoS,EAAYD,cACrDC,EAAYD,cAGdpnB,EACJ3P,KAAK8G,GAGS,SAANA,EAAe,KAAOA,IAE9B4B,KAAKb,GAAAA,QAAAA,KAMH2O,MAAM2d,GAEX,MAAM6C,EAAcz3B,KAAK2pC,kBAAkB/U,EAAO9uB,OAClD,OAAO2xB,EAAcA,EAAYiL,MAAQ,MAO7C,SAASuH,GAAWlmB,EAAiB6jB,GACnC,MAAM/oB,EAAMoqB,GAAM,CAChBjlB,IAAK4jB,EAAQ5jB,IACb3F,IAAKupB,EAAQvpB,IACb0F,QAASA,IAILyR,EAAS5a,GAAAA,QAAAA,OAAO,GAAIgtB,GAM1B,OALApS,EAAO+N,OA4FT,SAAmB1kB,EAAUysB,GAC3B,MAAMC,EAAY,GAClB,IAAK,MAAM/rC,KAAS8rC,EAAW,CAC7B,IAAIE,EAEFA,EADY,OAAVhsC,EACO,KACAG,MAAME,OAAOL,IACbmiC,IAEA9iB,EAAIrf,MAAMK,OAAOL,IAE5B+rC,EAAUC,IAAWD,EAAUC,IAAW,GAAKF,EAAU9rC,GAE3D,OAAO+rC,EAzGSE,CAAU5sB,EAAK+oB,EAAQrE,QACvC/N,EAAOhM,UAAY3K,EAAI2Z,KAAO3Z,EAAI0Z,OAAS1Z,EAAIoF,KAC/CuR,EAAOxR,IAAMnF,EAAI0Z,MACjB/C,EAAOnX,IAAMQ,EAAI2Z,KAEVhD,EAGT,MAAMkW,GAAoD,CACxD1gB,KAAM,cACNE,MAAO,WACP1P,KAAM,UACN8P,MAAO,WACPC,QAAS,aACTC,QAAS,aACTC,aAAc,kBAEdJ,UAAW,KACXF,KAAM,KACNF,QAAS,KACTG,IAAK,MAGP,SAASugB,GAAYC,EAA4BC,GAC/C,MAAMC,EAAmBJ,GAAgBE,GAGzC,MAAO,CAACG,cAFcF,EAAQ,SAASC,EAAiBhhB,OAAO,KAAOghB,EAE/CE,cADD,MAAMH,EAAQ,MAAQ,KAAKC,EAAiBhhB,OAAO,MAsC3E,SAAS6f,GAAYsB,EAAoBrE,GACvC,MAAMpS,EAAS5a,GAAAA,QAAAA,OAAO,GAAIgtB,GAEpBrE,EAAoC,GAmB1C,OAlBAr6B,GAAAA,QAAAA,KAAK0+B,EAAQrE,QAAQ//B,SAAQ,SAAU0oC,GAErC,MAAM1wB,EAA4B,SAAf0wB,EAAwB,KAAO,IAAItpC,KAAKspC,GAE3D,IAAIzoC,EAEFA,EADW,OAAT+X,EACI,KACG7b,MAAM6b,EAAK3Y,WACd,gBAECopC,IAAa5B,GAAe7uB,EAAKme,SAhD9C,SAAiBzN,EAAgB1Q,GAC/B,MAAM2wB,EAAQvgB,GAAcM,GACtBsJ,EAAe2W,EAEjB,IAAIvpC,KAAKA,KAAK07B,IAAI,KAAM,EAAG,EAAG,EAAG,EAAG,EAAG,IACvC,IAAI17B,KAAK,KAAM,EAAG,EAAG,EAAG,EAAG,EAAG,GAClC,IAAK,MAAMmoC,KAAgBrf,GACzB,GAAII,GAAiBI,EAAM6e,GACzB,OAAQA,GACN,KAAKV,GACH,MAAM,IAAInnC,MAAM,gDAClB,KAAKkpC,GACH,MAAM,IAAIlpC,MAAM,sDAClB,KAAKmpC,GACH,MAAM,IAAInpC,MAAM,iDAClB,KAAKsnC,GAAkB,CACrB,MAAMwB,cAACA,EAAaD,cAAEA,GAAiBJ,GAAY,QAASQ,GAE5D3W,EAAOuW,GAAuD,EAAxCruB,KAAKC,MAAMnC,EAAKwwB,KAAmB,IACzD,MAEF,QAAS,CACP,MAAMA,cAACA,EAAaD,cAAEA,GAAiBJ,GAAYZ,EAAcoB,GACjE3W,EAAOuW,GAAevwB,EAAKwwB,OAKnC,OAAOxW,EAoBgD8W,CAAQL,EAAUzwB,IAAO7W,WAE9E4+B,EAAO9/B,IAAQ8/B,EAAO9/B,IAAQ,GAAKmkC,EAAQrE,OAAO2I,MAGpD1W,EAAO+N,OAASA,EAChB/N,EAAOhM,SAAWtgB,GAAAA,QAAAA,KAAKq6B,GAAQvgC,OAExBwyB,EAuBT,SAASoV,GAAarH,EAAYxoB,GAChC,OAAOA,EAAKjb,QAAO,SAAUysC,EAAMC,GACjC,OAAOjJ,EAAOiJ,GAAOD,EAAO,EAAIA,IAC/B,GAGL,IAAYrB,IAAZ,SAAYA,GACVA,EAAAA,EAAA,OAAS,UAAe,SACxBA,EAAAA,EAAA,OAAS,UAAe,SACxBA,EAAAA,EAAA,QAAU,WAAgB,UAC1BA,EAAAA,EAAA,QAAU,WAAgB,UAC1BA,EAAAA,EAAA,SAAW,YAAiB,WAL9B,CAAYA,KAAAA,GAAa,yDA5cvB9iC,EACAnB,EAAmB,GACnBuiC,EAAuD,CAACjkC,OAAQ,KAEhE0B,EAAM2T,GAAAA,QAAAA,OAAO,GAAImL,GAAsB9e,GAGvC,MAAMwlC,EAA8B7E,GAAAA,QAAAA,QAAQx/B,GACtCy4B,EAAQG,GAAAA,SAAS54B,GAEjBskC,EAAwBlD,EAAYjkC,OAAOzF,QAAO,CAAC2d,EAAG3X,KAC1D2X,EAAE3X,EAAMN,MAAQM,EACT2X,IACN,IAEGmsB,EAA8B6C,EAAUhsC,KAAI,SAAUksC,EAActpC,GACxE,MAAMmC,EAAemnC,EAAa7mC,MAE5BjF,EAAsC,SAAhBggC,EAAMr7B,GAAmB0lC,GAAcC,SAAYtK,EAAMr7B,GAC/EgkB,EAAmBmjB,EAAanjB,SACtC,IAAIkgB,EAEJ,GAAI7oC,IAASqqC,GAAcG,OACzB3B,EAASpkB,QACJ,GAAIzkB,IAASqqC,GAAcE,QAG9B1B,EADElgB,EAAWviB,EAAIof,oBAAsBmD,EAAWmjB,EAAapjB,MAAQtiB,EAAImf,wBAClEhB,GAEAE,QAEN,GAAIzkB,IAASqqC,GAAcC,SAAU,CAC1CzB,EAASnkB,GAGTonB,EAAa3oB,IAAM,IAAIphB,KAAKwF,EAAK,GAAG5C,IACpCmnC,EAAatuB,IAAM,IAAIzb,KAAKwF,EAAK,GAAG5C,IACpC,IAAK,MAAMonC,KAAaxkC,EAAM,CAC5B,MAAM82B,EAAO,IAAIt8B,KAAKgqC,EAAUpnC,IAAO3C,UACnCq8B,EAAQyN,EAAa3oB,IAAanhB,YACpC8pC,EAAa3oB,IAAM,IAAIphB,KAAKs8B,IAE1BA,EAAQyN,EAAatuB,IAAaxb,YACpC8pC,EAAatuB,IAAM,IAAIzb,KAAKs8B,UAIhCwK,EAAStkB,GAITskB,IAAWtkB,IACXoE,EAAWmjB,EAAapjB,MAAQtiB,EAAI6hB,wBACpC6jB,EAAapjB,MAAQtiB,EAAI8hB,uBAEzB2gB,EAASxZ,GAAazkB,KAGxB,IAAIgsB,EAAc,CAChBjyB,KAAMA,EAENqkC,cAAexmC,EACfqmC,OAAQA,EACR7oC,KAAMA,EACN6hC,MAAOiK,EACPjC,UAAW,GACXV,SAAU,IAIZ,MAAM6C,EAAiBH,EAAsBjV,EAAYjyB,MAGzD,OAFAiyB,EAAc7c,GAAAA,QAAAA,OAAO6c,EAAaoV,GAE3BpV,KAIT,IAAK,MAAMA,KAAemS,EACxB,GAAInS,EAAYiS,SAAWpkB,GACzB,IAAK,MAAMvB,KAAW9c,EAAI8b,KAAKe,SAASC,QACtC0T,EAAYuS,SAASjmB,GAAWkmB,GAAWlmB,EAAS0T,EAAYiL,YAE7D,GAAIjL,EAAYiS,SAAWnkB,GAChC,IAAK,MAAM2G,KAAQjlB,EAAI8b,KAAKjE,SAC1B,QAAajW,IAATqjB,EACF,GAAoB,iBAATA,EAAmB,CAC5B,KAAI,SAAUA,GAIZ,MAAM,IAAIhpB,MAAM,iEAFhBu0B,EAAYiT,UAAUxe,EAAKA,MAAQye,GAAYze,EAAKA,KAAMuL,EAAYiL,YAKxEjL,EAAYiT,UAAUxe,GAAQye,GAAYze,EAAMuL,EAAYiL,OAOtE,MAAMoK,EAAkBztC,OAAA0M,OAAA1M,OAAA0M,OAAA,GACnBy9B,GAAW,CACdjkC,OAAQqkC,IAGV,OAAO,IAAIL,GAAOuD,qDChKPC,GAGX91B,YAAY+1B,GACVhtC,KAAKgtC,WAAaA,EAGb/1B,OACL,OAAOjX,KAAKgtC,WAAWxnC,KAGlByR,cACL,OAAOjX,KAAKgtC,WAAWp/B,YAGlBqJ,aACL,OAAOjX,KAAKgtC,WAAWC,WAGlBh2B,SACL,OAAOjX,KAAKgtC,WAAWE,cAadC,WAA6DJ,GACxE91B,YAAY+1B,GACVI,MAAMJ,GAGD/1B,iCAAiC0b,GACtC,OAAO9Y,GAAM7Z,KAAKgtC,WAAWC,YAAaztB,IACxC,GAAIf,GAAqBe,GAAO,CAC9B,MAAMne,EAASme,EAAKne,OACdU,EAAQyd,EAAKzd,MAEnB,OAAK4wB,EAAKtxB,KAIFuhB,GAAW+P,EAAKtxB,GAAQU,IAGlC,OAAK4wB,EAAKnT,KAIFoD,GAAW+P,EAAKnT,OAIrBvI,QAAQ0b,EAAS/M,EAAgBynB,EAA4CpmC,GAElF,OAAKjH,KAAKgtC,WAAWM,6BAGdttC,KAAKutC,iCAAiC5a,IAIrC3yB,KAAKgtC,WAAqCQ,QAAQ7a,EAAM/M,EAAQynB,EAAkBpmC,IC9EvF,MAAMwmC,GAA2D,CACtE,CACEjoC,KAAM,6BACNoI,YAAa,uDACbq/B,WAAY,CAACxsB,GAASY,KAAMZ,GAASM,WACrCusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACjE/Y,EAAOjW,YACDuP,GAAW0G,EAAO/zB,OAMhC,CACE2E,KAAM,6BACNoI,YAAa,0DACbq/B,WAAY,CAACxsB,GAASW,MAAOX,GAASM,WACtCusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,IAC5C,MAAjB/Y,EAAO9uB,QAAyC,UAArB8uB,EAAOjW,YAG9C,CACEnZ,KAAM,uBACNoI,YAAa,gEACbq/B,WAAY,CAACxsB,GAASQ,IAAKR,GAASW,MAAOX,GAASY,MACpDisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgB1kB,EAA6B+F,KACzE,GAAI2tB,EAAO/V,KAAO+V,EAAO/zB,OAASykB,GAAmB,CAEnD,MAAMsoB,EAA+B,CACnC9/B,QAAS8mB,EAAO9mB,QAChBhI,MAAO8uB,EAAO9uB,MACdjF,KAAM+zB,EAAO/zB,MAEf,OAAO+kB,EAAOklB,YAAY8C,IAAqB3mC,EAAI8gB,qBAErD,OAAO,IAGX,CACEviB,KAAM,4BACNoI,YAAa,oDACbq/B,WAAY,CAACxsB,GAASY,KAAMZ,GAASQ,KACrCqsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACjE/Y,EAAO/V,KAEF+V,EAAO/zB,OAASykB,IAK7B,CACE9f,KAAM,yBACNoI,YAAa,iEACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASY,KAAMZ,GAASQ,IAAKR,GAASU,UACrEmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgBynB,EAA4CpmC,WACxF,MAAMylB,EAAQrtB,OAAA0M,OAAA,CACZjG,MAAO,KACJwxB,GAAW1C,EAAQ,CAAChP,OAAAA,EAAQkP,MAAO,CAAC,MAAO,WAAY,YAGtDtG,WAACA,YpC8iCX9B,EACA5e,GAEA,MAAMjN,EAAO6rB,EAAS7rB,KAEtB,GAAa,YAATA,GAAkC,UAAZiN,EACxB,MAAO,CACL0gB,YAAY,EACZqf,QAAS,WAAW//B,6CAIxB,OAAQA,GACN,KAAKlE,EACL,KAAKC,EACL,KAAKC,EACH,OAAIukB,GAAa3B,GACR,CACL8B,YAAY,EACZqf,QAASC,GAAyChgC,IAG/CygB,GAET,KAAKxkB,EACL,KAAKC,EACL,KAAKW,EACL,KAAKC,EACL,KAAKC,EACL,KAAKS,EACL,KAAKE,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKZ,EACL,KAAKX,EACL,KAAKF,EACL,KAAK0B,GACH,OAAO0iB,GAET,KAAK/jB,EACL,KAAKE,EACL,KAAKH,EACL,KAAKE,EACH,OAAI5J,IAASuW,GACJ,CACLoX,YAAY,EACZqf,QAAS,WAAW//B,wDAA8D4e,EAAS7rB,eAGxF0tB,GAET,KAAKtjB,EACL,KAAKC,EACL,KAAKC,EACL,KAAKC,EACL,KAAKL,EACL,KAAKT,EACL,KAAKF,EACL,KAAKH,EACL,KAAKC,EACH,MAAa,YAATrJ,GAAuB6rB,EAAe,KAMnC6B,GALE,CACLC,YAAY,EACZqf,QAAS,WAAW//B,yDAK1B,KAAKzC,EACH,OAAKzD,EAAS,CAAC,UAAW,WAAY8kB,EAAS7rB,MAMxC0tB,GALE,CACLC,YAAY,EACZqf,QAAS,8DAKf,KAAK/iC,EACH,OAAKlD,EAAS,CAAC,UAAW,UAAW,WAAY8kB,EAAS7rB,MAMnD0tB,GALE,CACLC,YAAY,EACZqf,QAAS,2EAKf,KAAKtiC,EACH,MAAsB,YAAlBmhB,EAAS7rB,MAAwB,SAAU6rB,EAMxC6B,GALE,CACLC,YAAY,EACZqf,QAAS,mFoC1oCQE,CAAqBrhB,EAAUkI,EAAO9mB,SAE3D,GAAI0gB,EACF,OAAO,EACF,CAEL,MAAMwf,EAA6B,QAAnBpZ,EAAO9mB,SAAwC,WAAnB8mB,EAAO9mB,SAA2C,UAAnB8mB,EAAO9mB,QAE5Eoe,EAAOQ,EAAS5N,WAAgD,QAApCqO,EAAAnB,GAAkBU,EAAS5N,iBAAS,IAAAqO,OAAA,EAAAA,EAAEjB,MACxE,SAAI8hB,IAAW9hB,IAASP,GAAsBO,KAASN,GAAcM,OAO3E,CACE1mB,KAAM,QACNoI,YAAa,6EACbq/B,WAAY,CAACxsB,GAASM,UAAWN,GAASQ,IAAKR,GAASU,UACxDmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACjE/Y,EAAO7V,UACA6V,EAAOjW,aAAeiW,EAAO/V,OAAS+V,EAAO9V,WAK5D,CACEtZ,KAAM,+BACNoI,YAAa,0CACbq/B,WAAY,CAACxsB,GAASc,MAAOlB,GAAsB,QAAS,QAASI,GAASQ,KAC9EqsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACjE/Y,EAAO/V,MAAO+V,EAAO3V,QACmB,IAArC2V,EAAO3V,MAAqB7F,MAOvC,CACE5T,KAAM,wBACNoI,YAAa,wFACbq/B,WAAY,CAACxsB,GAASM,UAAWN,GAASO,UAAWP,GAASU,SAAUV,GAASQ,KACjFqsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAqC1zB,EAAWwsC,EAA8BC,KACtF,GAAI/a,GAAagC,GAAS,CAKxB,QAHIhS,GAAWgS,EAAOjW,YAAgBiW,EAAOjW,UAAY,EAAI,KACzDiE,GAAWgS,EAAO/V,MAAU+V,EAAO/V,IAAM,EAAI,KAC7C+D,GAAWgS,EAAO9V,WAAe8V,EAAO9V,SAAW,EAAI,IAC3C,EAGlB,OAAO,IAGX,CACEtZ,KAAM,6BACNoI,YAAa,sDACbq/B,WAAY,CAACxsB,GAASY,KAAMZ,GAASU,UACrCmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACjE/Y,EAAO9V,UAAY8V,EAAO/zB,OAAS0kB,IAM3C,CACE/f,KAAM,8BACNoI,YAAa,+EACbq/B,WAAY,CAACxsB,GAASU,SAAUV,GAASY,MACzCisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgBynB,EAA4CpmC,KACpF2tB,EAAO9V,UAAY8V,EAAO/zB,OAAS0kB,MAChC8nB,EAAiBhqB,IAAI,cAAgBpc,EAAIqf,kCAIvCV,EAAOqoB,qBAAqBrZ,KAKzC,CACEpvB,KAAM,sCACNoI,YAAa,2DACbq/B,WAAY,GAAGlmC,OAAO8Y,GAAa,CAACY,GAASc,MAAOd,GAASY,OAC7DisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACrE,GAAI/Y,EAAO3V,MAAO,CAChB,MAAMA,EAAoB2V,EAAO3V,MAM3BivB,EAAQz0B,GAAUmb,GAExB,GAAIsZ,MAAAA,EAEF,OAAO,EAGT,IAAK,MAAMC,KAAalvB,EAAO,CAC7B,GAAkB,SAAdkvB,GAAsC,SAAdA,GAAsC,SAAdA,EAElD,SAEF,MAAMC,EAAQD,EACd,GAAc,UAAVD,GAGF,IAAK10B,GAAyB,QAAS40B,KAAW50B,GAAyB,OAAQ40B,GACjF,OAAO,OAEJ,IAAK50B,GAAyB00B,EAAOE,GAC1C,OAAO,GAIb,OAAO,IAGX,CACE5oC,KAAM,oCACNoI,YAAa,kEACbq/B,WAAY,GAAGlmC,OAAO8Y,GAAa,CAACY,GAASc,MAAOd,GAASK,UAC7DwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACrE,GAAI/Y,EAAQ,CACV,MAAM9mB,EAA2B8mB,EAAO9mB,QAClCmR,EAAoB2V,EAAO3V,MACjC,GAAInR,IAAY8U,GAAW9U,IAAYmR,EAAO,CAC5C,GAAgB,QAAZnR,GAAiC,WAAZA,GAAoC,UAAZA,EAE/C,OAAO,EAET,IAAK,MAAMqgC,KAAalvB,EAAO,CAC7B,IAAKA,EAAM0U,eAAewa,GAAY,SACtC,GAAkB,SAAdA,GAAsC,SAAdA,GAAsC,SAAdA,EAElD,SAGF,UAD+FtlC,IAA3E+Q,GAAoC9L,EAASqgC,IAE/D,OAAO,IAKf,OAAO,IAGX,CACE3oC,KAAM,2BACNoI,YAAa,2DACbq/B,WAAY,CAACxsB,GAASW,MAAOX,GAASY,MACtCisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgBynB,EAA4CpmC,KACxF,GAAqB,MAAjB2tB,EAAO9uB,MACT,OAAO,EAGT,MAAMuoC,EAAgBzoB,EAAOyoB,cAAczZ,EAAO9uB,OAC5CjF,EAAO+zB,EAAO/zB,KAEpB,IAAKwsC,EAAiBhqB,IAAI,WAAagqB,EAAiBhqB,IAAI,UAAYpc,EAAIqf,iCAE1E,OAAO,EAGT,OAAQ+nB,GACN,KAAKnD,GAAcoD,QACnB,KAAKpD,GAAcqD,OACjB,OAAO1tC,IAASykB,IAAqBzkB,IAAS0kB,GAChD,KAAK2lB,GAAcG,OACnB,KAAKH,GAAcE,QACjB,OAAOvqC,IAAS0kB,GAClB,KAAK2lB,GAAcC,SAEjB,OAAOtqC,IAAS0kB,GAClB,KAAK,KAEH,OAAO,EAEX,MAAM,IAAIriB,MAAM,qBAGpB,CACEsC,KAAM,wBACNoI,YAAa,+EACbq/B,WAAY,CAACxsB,GAASW,MAAOX,GAASY,MACtCisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgBynB,EAA4CpmC,MACnFomC,EAAiBhqB,IAAI,UAAagqB,EAAiBhqB,IAAI,SAAYpc,EAAIqf,oCAKvD,MAAjBsO,EAAO9uB,MACF8uB,EAAO/zB,OAASykB,GAGlBM,EAAO8jB,OAAO9U,EAAO9uB,SAAqB8uB,EAAO/zB,OAG5D,CACE2E,KAAM,oCACNoI,YAAa,2DACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASW,OACxCksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgB1kB,EAA6B+F,IAGrE2tB,EAAO9mB,UAAY0hB,GAAkBoF,EAAO/zB,OAASukB,IAAgBwP,EAAO/zB,OAASqvB,GAAazkB,KAC7Fma,EAAOklB,YAAYlW,IAAW3tB,EAAI+gB,mCAK/C,CACExiB,KAAM,yBACNoI,YAAa,0DACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASW,MAAOX,GAASQ,IAAKR,GAASU,UACtEmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgB1kB,EAA6B+F,IACrE2tB,EAAO9mB,UAAYga,GAAe8M,EAAO9mB,UAAY0gC,GAChD5oB,EAAOklB,YAAYlW,IAAW3tB,EAAIghB,wBAK/C,CACEziB,KAAM,yBACNoI,YAAa,qDACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASW,MAAOX,GAASQ,IAAKR,GAASU,UACtEmsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoBhP,EAAgB1kB,EAA6B+F,IACrE2tB,EAAO9mB,UAAY8hB,GACdhK,EAAOklB,YAAYlW,IAAW3tB,EAAIihB,wBAK/C,CACE1iB,KAAM,oCACNoI,YAAa,kCACbq/B,WAAY,CACVxsB,GAASY,KACTZ,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASU,SACTV,GAASQ,KAEXqsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACrE,GAAI/Y,EAAO3V,MAAO,CAChB,MAAMpe,EAAO+zB,EAAO/zB,KACdqtC,EAAQz0B,GAAUmb,GAExB,GAAI1G,GAAWrtB,GACb,YAAiBgI,IAAVqlC,GAAuBn2B,GAAkBm2B,GAC3C,GAAIrtC,IAAS0kB,GAClB,OAAKqP,EAAO9V,SAGHlX,GAAS,CAAC6P,GAAgBA,QAAe5O,GAAYqlC,IAAUn2B,GAAkBm2B,GAFjFtmC,GAAS,CAAC6P,GAAgBA,QAAe5O,GAAYqlC,GAIzD,GAAIrtC,IAASykB,GAClB,OAAIsP,EAAO/V,IACFjX,GAAS,CAAC6P,QAAkB5O,GAAYqlC,GAExCtmC,GACL,CACE6P,GACAA,GACAA,GACAA,GACAA,GACAA,QACA5O,GAEFqlC,GAKR,OAAO,IAGX,CACE1oC,KAAM,wBACNoI,YAAa,oDACbq/B,WAAY,CAACxsB,GAASG,MAAOH,GAASK,SACtCwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAAC5Y,EAAoB1zB,EAAWwsC,EAA8BC,KACjE/Y,EAAO5V,QACF4V,EAAO9mB,UAAY0Z,GAAaoN,EAAO9mB,UAAY6Z,KAKhElnB,KAAKguC,GAAuC,IAAItB,GAAoCsB,KAIlFhB,GAAkB3tC,QAAO,CAAC2d,EAAGgxB,KAC/BhxB,EAAEgxB,EAAGjpC,QAAUipC,EACRhxB,IACN,IAEI,MAAMixB,GAAgCjB,GAAkB3tC,QAAO,CAACuD,EAAO6B,KAC5E,IAAK,MAAMsa,KAAQta,EAAE+nC,aAEnB5pC,EAAMO,IAAI4b,EAAMnc,EAAM6D,IAAIsY,IAAS,IACnCnc,EAAM6D,IAAIsY,GAAMpf,KAAK8E,GAEvB,OAAO7B,IACN,IAAI+sB,IClaMue,GAA2D,CACtE,CACEnpC,KAAM,8BACNoI,YAAa,6EACbq/B,WAAY,CAACxsB,GAASY,KAAMZ,GAASM,WACrCusB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACjW,EAAoBr2B,EAAWwsC,EAA8BC,KAC7D/lC,GAAS,CAAC,MAAO,SAAU,IAAK,IAAK,SAAU,SAAU2vB,EAAOzpB,WAG5ErN,KAAKguC,GAAuC,IAAItB,GAAoCsB,KAEOE,GAAkB7uC,QAC7G,CAAC2d,EAAGgxB,KACFhxB,EAAEgxB,EAAGjpC,QAAUipC,EACRhxB,IAET,IAGK,MAAMmxB,GAAgCD,GAAkB7uC,QAAO,CAACuD,EAAO6B,KAC5E,IAAK,MAAMsa,KAAQta,EAAE+nC,aACnB5pC,EAAMO,IAAI4b,EAAMnc,EAAM6D,IAAIsY,IAAS,IACnCnc,EAAM6D,IAAIsY,GAAMpf,KAAK8E,GAGvB,OAAO7B,IACN,IAAI+sB,aCzBSye,GACdrvB,EACAsvB,EACAzrC,EACA0rC,EACAnpB,EACA3e,GAGA,MAAM+nC,EAAsBN,GAA8BxnC,IAAIsY,IAAS,GACjEmT,EAAOoc,EAAME,wBAAwB5rC,GAE3C,IAAK,MAAM6B,KAAK8pC,EAEd,GAAI9pC,EAAEgoC,UAAcjmC,EAAI/B,EAAEM,QAAS,CAIjC,IADgBN,EAAEsoC,QAAQ7a,EAAM/M,EAAQmpB,EAAMG,cAAcxc,UAAUrvB,GAAQ4D,GAChE,CACZ,MAAMkoC,EAAqB,SAASjqC,EAAEM,SAKtC,OAHIyB,EAAI+e,SACNhf,QAAQu4B,IAAI,GAAG4P,iBAAkCJ,EAAMK,qBAAqBN,EAAStpC,QAEhF2pC,GAKb,MAAME,EAAkBT,GAA8B1nC,IAAIsY,IAAS,GAEnE,IAAK,MAAMta,KAAKmqC,EAEd,IAAKnqC,EAAEgoC,UAAcjmC,EAAI/B,EAAEM,UAAYkvB,GAAa/B,GAAO,CAGzD,IADgBztB,EAAEsoC,QAAQ7a,EAAM/M,EAAQmpB,EAAMG,cAAcxc,UAAUrvB,GAAQ4D,GAChE,CACZ,MAAMkoC,EAAqB,SAASjqC,EAAEM,SAKtC,OAHIyB,EAAI+e,SACNhf,QAAQu4B,IAAI,GAAG4P,iBAAkCJ,EAAMK,qBAAqBN,EAAStpC,QAEhF2pC,GAIb,OAAO,6DC7BT,MAAMG,GAA6B/gC,GAAqBzO,QAAO,CAAC2d,EAAG3P,KACjE2P,EAAE3P,IAAW,EACN2P,IACN,UAMU8xB,WAA4BxC,GACvC91B,YAAYu4B,GACVpC,MAAMoC,GAGDv4B,iCAAiC83B,GACtC,OAAOl1B,GAAM7Z,KAAKgtC,WAAWC,YAAaztB,IACxC,GAAIA,IAASiB,GAASC,KACpB,OAAQkC,GAAWmsB,EAAMU,WAK3B,GAAIhxB,GAAqBe,GAAO,CAC9B,MAAMne,EAASme,EAAKne,OACdU,EAAQyd,EAAKzd,MAEnB,OAAO8X,GAAMk1B,EAAMW,gBAAiB/c,IAC7BA,EAAKtxB,KAIFuhB,GAAW+P,EAAKtxB,GAAQU,MAIpC,IAAKue,GAAmBd,GACtB,MAAM,IAAItc,MAAM,iBAGlB,OAAO2W,GAAMk1B,EAAMW,gBAAiB/c,IAC7BA,EAAKnT,KAGFoD,GAAW+P,EAAKnT,SAKvBvI,QAAQ83B,EAAuBnpB,EAAgB3e,GAEpD,OAAKjH,KAAKgtC,WAAWM,6BACdttC,KAAKutC,iCAAiCwB,IAKrC/uC,KAAKgtC,WAA8BQ,QAAQuB,EAAOnpB,EAAQ3e,IAS/D,MAAM0oC,GAA0C,CACrD,CACEnqC,KAAM,oBACNoI,YAAa,kDACbq/B,WAAY,CAACxsB,GAASK,SACtBwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAMkC,EAAc,GAGpB,OAAO/1B,GAAMk1B,EAAMW,gBAAiB/c,KAC7B/P,GAAW+P,EAAK7kB,WAEf8hC,EAAYjd,EAAK7kB,WAGrB8hC,EAAYjd,EAAK7kB,UAAW,GACrB,OAMf,CACEtI,KAAM,sCACNoI,YAAa,4DACbq/B,WAAY,CACVxsB,GAASC,KACTD,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASK,QACTL,GAASY,MAEXisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAM5+B,EAAOigC,EAAMU,UACb/c,EAAYqc,EAAMW,eAExB,GAAI5gC,IAAS+V,GACX,IAAK,MAAM8N,KAAQD,EACjB,GACEE,GAAaD,KACZA,EAAK7kB,UAAY0Z,GAAamL,EAAK7kB,UAAY6Z,IAChDgL,EAAK9xB,OAASykB,IACdqN,EAAK1T,QAC+B,IAAnC0T,EAAK1T,MAAqB7F,KAG3B,OAAO,EAKb,OAAO,IAGX,CACE5T,KAAM,eACNoI,YACE,sHACFq/B,WAAY,CAACxsB,GAASQ,IAAKR,GAASU,SAAUV,GAASY,KAAMZ,GAASO,WACtEssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAG1C,GAFqB3lC,GAAKgnC,EAAMW,gBAAiB/c,GAAwBI,GAAwBJ,KAI/F,OAAO9Y,GAAMk1B,EAAMW,gBAAiB/c,IAClC,GAAI+B,GAAa/B,GACf,OAAO,EAGT,GAAIgC,GAAiBhC,GACnB,OAAO,EAGT,OAAQA,EAAK9xB,MACX,KAAKykB,GACH,QAASqN,EAAK9T,IAChB,KAAK0G,GACH,QAASoN,EAAK7T,SAChB,KAAKuG,GACL,KAAK6K,GAAazkB,IAClB,KAAK2Z,GACH,OAAO,EAGX,MAAM,IAAIliB,MAAM,uBAQlB,GAJ2B2W,GADDk1B,EAAMG,cAAcW,0BAA0B3oC,IAAI,cAAgB,IACvC7D,IACnD,MAAMsvB,EAAOoc,EAAME,wBAAwB5rC,GAC3C,OAAOsxB,GAAiBhC,KAAU/P,GAAW+P,EAAK/T,cASlD,OAAO7W,GAAKgnC,EAAMW,gBAAiB/c,IAC5BC,GAAaD,IAASgC,GAAiBhC,KAAUA,EAAK9xB,OAASykB,IAC9DkO,GAAyBb,KAGpBC,GAAaD,MAAWA,EAAK9T,KAAO+D,GAAW+P,EAAK9T,UAEpD+T,GAAaD,IAASA,EAAK9xB,OAAS0kB,OACrCoN,EAAK7T,UAAY8D,GAAW+P,EAAK7T,aAOjD,OAAO,IAGX,CACEtZ,KAAM,6BACNoI,YAAa,6DACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASC,MACxC4sB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAM5+B,EAAOigC,EAAMU,UAGnB,QAAI7sB,GAAW9T,IAGR+K,GAAMk1B,EAAMW,gBAAiB/c,KAE9B/P,GAAW+P,EAAK7kB,WAEC,QAAjB6kB,EAAK7kB,SAAsC,WAAjB6kB,EAAK7kB,SAAyC,UAAjB6kB,EAAK7kB,WAEvDe,GAAY8jB,EAAK7kB,QAASgB,QAIzC,CACEtJ,KAAM,gCACNoI,YAAa,mEACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASC,MACxC4sB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAM5+B,EAAOigC,EAAMU,UAEnB,OAAQ3gC,GACN,KAAKiW,GACL,KAAKD,GACH,OAAOiqB,EAAMe,YAAYtoB,IAAcunB,EAAMe,YAAYnoB,GAC3D,KAAKzC,GACH,OAAO6pB,EAAMe,YAAYC,GAC3B,KAAKlrB,GACL,KAAKmrB,GACL,KAAKC,GACL,KAAKhrB,GACL,KAAKirB,GACL,KAAKlrB,GACH,OAAO+pB,EAAMe,YAAYtoB,IAAcunB,EAAMe,YAAYnoB,GAC3D,KAAK/C,GAEH,OACGmqB,EAAMG,cAAciB,YAAY1vB,GAASK,UAC1CiuB,EAAMe,YAAYtoB,IAClBunB,EAAMe,YAAYnoB,GAIxB,MAAM,IAAIzkB,MAAM,yDAAyDsE,KAAKC,UAAUqH,QAG5F,CACEtJ,KAAM,gBACNoI,YAAa,wBACbq/B,WAAY,CAACxsB,GAASM,UAAWN,GAASO,WAC1CssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KACtCqB,EAAMnd,eAMd,CACEpsB,KAAM,4CACNoI,YAAa,iGACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASM,UAAWN,GAASO,WAC5DssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAC1C,GAAI8nC,EAAMnd,cAAe,CACvB,IAAIwe,GAAiB,EACjBC,GAAS,EACTC,GAAwB,EAiB5B,GAhBAvB,EAAMwB,UAAU7d,UAAUlvB,SAAQ,CAACmvB,EAAMtvB,KACnCqxB,GAAa/B,IAASa,GAAyBb,IAG/CC,GAAaD,KAAUA,EAAKhU,YAE9B0xB,GAAS,EACLzoC,GAAS,CAACkgB,EAAa0mB,GAAiB7b,EAAK7kB,SAC3CihC,EAAMG,cAAcsB,oBAAoBntC,EAAOod,GAASK,WAC1DwvB,GAAwB,GAG1BF,GAAiB,MAInBC,IAAWD,IACTE,GAAyBrpC,EAAIqf,kCAC/B,OAAO,EAIb,OAAO,IAGX,CACE9gB,KAAM,oCACNoI,YAAa,sDACbq/B,WAAY,CAACxsB,GAASM,UAAWN,GAASO,UAAWP,GAASQ,IAAKR,GAASU,SAAUV,GAASY,MAC/FisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KACtCqB,EAAMnd,eAED7pB,GAAKgnC,EAAMW,gBAAiB/c,MAC7BgF,GAAYhF,IAAUC,GAAaD,IAAuB,aAAdA,EAAK9xB,SAS7D,CAEE2E,KAAM,+BACNoI,YAAa,qFACbq/B,WAAY,CAACxsB,GAASC,KAAMD,GAASM,UAAWN,GAASO,WACzDssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KACtC9lC,GAAS,CAACid,GAAUC,GAAWC,IAAYgqB,EAAMU,YAC5CV,EAAMnd,eAKnB,CACEpsB,KAAM,sBACNoI,YAAa,0DACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASC,MACxC4sB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAC1C,MAAM6H,EAAOigC,EAAMU,UACnB,GAAI7nC,GAAS,CAACqd,GAAWJ,IAAW/V,IAC9BigC,EAAM0B,qBAAqBvhB,GAAe,CAC5C,GAAIjoB,EAAIqf,iCAGN,OAAO,EACF,CAEL,MAAMoM,EAAYqc,EAAMwB,UAAU7d,UAClC,IAAK,IAAInvB,EAAI,EAAGA,EAAImvB,EAAU1vB,OAAQO,IAAK,CAEzC,GADamvB,EAAUnvB,GACduK,UAAYohB,EACnB,OAAI6f,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASK,WAYlE,OAAO,IAGX,CACEtb,KAAM,yBACNoI,YAAa,uDACbq/B,WAAY,CACVxsB,GAASC,KACTD,GAASK,QACTL,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAEXisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAM5+B,EAAOigC,EAAMU,UACb/c,EAAYqc,EAAMW,eAGxB,GAAI5gC,IAASiW,IAAajW,IAAS+V,GACjC,IAAK,MAAM8N,KAAQD,EACjB,GAAIE,GAAaD,KAAUA,EAAK7kB,UAAY0Z,GAAamL,EAAK7kB,UAAY6Z,IAAcgL,EAAK1T,MAAO,CAGlG,GAFcxF,GAAUkZ,KAEVlb,GACZ,OAAO,EAKf,OAAO,IAGX,CACEjS,KAAM,oCACNoI,YACE,yGACFq/B,WAAY,CAACxsB,GAASK,SACtBwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAI1C,MAAMyrB,EAAYqc,EAAMwB,UAAU7d,UAClC,IAAIge,EAA0B,EAC1BC,GAAkC,EAEtC,IAAK,IAAIptC,EAAI,EAAGA,EAAImvB,EAAU1vB,OAAQO,IAAK,CACzC,MAAMovB,EAAOD,EAAUnvB,GACvB,GAAImxB,GAAa/B,IAASa,GAAyBb,GACjD,SAGF,MAAM7kB,EAAU6kB,EAAK7kB,QACrB,IAAK8U,GAAW9U,IACVwhC,GAA2B,GAAGxhC,OAChC4iC,GAA2B,EACvB3B,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASK,WACtD6vB,GAAkC,GAGlCD,EAA0B,IACzBC,GAAmC1pC,EAAIqf,mCAExC,OAAO,EAKf,OAAO,IAGX,CACE9gB,KAAM,iDACNoI,YAAa,6EACbq/B,WAAY,CAACxsB,GAASK,SACtBwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAC1C,MAAMyrB,EAAYqc,EAAMwB,UAAU7d,UAClC,IAAIke,GAAiC,EACjCC,GAAyC,EACzCC,GAAO,EACPC,GAAO,EACX,IAAK,IAAIxtC,EAAI,EAAGA,EAAImvB,EAAU1vB,OAAQO,IAAK,CACzC,MAAMovB,EAAOD,EAAUnvB,GACvB,GAAImxB,GAAa/B,IAASa,GAAyBb,GACjD,SAGF,MAAM7kB,EAAU6kB,EAAK7kB,QACjBA,IAAY0Z,EACdspB,GAAO,EACEhjC,IAAY6Z,EACrBopB,GAAO,EACGnuB,GAAW9U,KAErB8iC,GAAiC,EAC7B7B,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASK,WACtD+vB,GAAyC,IAK/C,QACEA,GACC5pC,EAAIqf,kCAAoCsqB,IAElCE,GAAQC,IAKrB,CACEvrC,KAAM,UACNoI,YAAa,kBACbq/B,WAAY,CAACxsB,GAASM,UAAWN,GAASO,WAC1CssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,MACrCqB,EAAMnd,eAMf,CACEpsB,KAAM,yCACNoI,YACE,0IAEFq/B,WAAY,CAACxsB,GAASM,UAAWN,GAASO,UAAWP,GAASU,SAAUV,GAASQ,IAAKR,GAASY,MAC/FisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAC1C,GAAI8nC,EAAMnd,cAAe,CACvB,MAAMc,EAAYqc,EAAMwB,UAAU7d,UAClC,IAAK,IAAInvB,EAAI,EAAGA,EAAImvB,EAAU1vB,OAAQO,IAAK,CACzC,MAAMovB,EAAOD,EAAUnvB,GACvB,IAAImxB,GAAa/B,KAASa,GAAyBb,GAAnD,CAIA,GAAIC,GAAaD,IAASA,EAAK9xB,OAAS0kB,KAGnCoN,EAAK7T,WACLiwB,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASU,WAAala,EAAIqf,kCAEtE,OAAO,EAGX,GAAIqM,EAAK9xB,OAASykB,IACZsN,GAAaD,KAAUA,EAAK9T,MAAQ8T,EAAKhU,UAAW,CAEtD,GACEowB,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASQ,MACpD8tB,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASM,YACpDguB,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASO,WAGpD,OAAO,EAET,GAAI/Z,EAAIqf,iCAEN,OAAO,KAMjB,OAAO,IAGX,CACE9gB,KAAM,gBACNoI,YAAa,2CACbq/B,WAAY,CAACxsB,GAASK,QAASL,GAASM,UAAWN,GAASO,WAC5DssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,MACtC8nC,EAAMnd,eAGH/X,GAAMk1B,EAAMwB,UAAU7d,WAAW,CAACC,EAAMtvB,OACzCqxB,GAAa/B,KAASa,GAAyBb,MAE/CA,EAAK7kB,UAAYkjC,IAIjBjC,EAAMG,cAAcsB,oBAAoBntC,EAAOod,GAASK,WACxD7Z,EAAIqf,qCASd,CACE9gB,KAAM,oBACNoI,YAAa,kDACbq/B,WAAY,CAACxsB,GAASW,OACtBksB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAC1C,MAAMgqC,EAAY,GACZC,EAAkB,GAElBxe,EAAYqc,EAAMwB,UAAU7d,UAClC,IAAK,IAAInvB,EAAI,EAAGA,EAAImvB,EAAU1vB,OAAQO,IAAK,CACzC,MAAMovB,EAAOD,EAAUnvB,GAEvB,GAAImxB,GAAa/B,IAASgC,GAAiBhC,GAAO,SAElD,IAAI7sB,EAQJ,GAPI6sB,EAAK7sB,QAAU8c,GAAW+P,EAAK7sB,SACjCA,EAAQ6sB,EAAK7sB,OAEX6uB,GAAiBhC,KAAU/P,GAAW+P,EAAK/T,aAC7C9Y,EAAQ,WAGNA,EAAO,CAST,GARIipC,EAAMG,cAAcsB,oBAAoBjtC,EAAGkd,GAASW,SACtD8vB,EAAgBprC,IAAS,GAOvBmrC,EAAUnrC,KACRorC,EAAgBprC,IAAUmB,EAAIqf,kCAChC,OAAO,EAIX2qB,EAAUnrC,IAAS,GAGvB,OAAO,IAIX,CACEN,KAAM,sBACNoI,YAAa,mCACbq/B,WAAY,CAACxsB,GAASK,SACtBwsB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAMhb,EAAYqc,EAAMW,eACxB,OAAyB,IAArBhd,EAAU1vB,QAAgB0vB,EAAU,GAAG5kB,UAAY6Z,IAO3D,CACEniB,KAAM,mCACNoI,YAAa,wCACbq/B,WAAY,CACVxsB,GAASK,QACTL,GAASC,KACTD,GAASY,KACTZ,GAASU,SACTV,GAASQ,IACTR,GAASM,UACTN,GAASO,WAEXssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAM5+B,EAAOigC,EAAMU,UAEnB,OAAQ3gC,GACN,KAAKiW,GACL,KAAKD,GACH,GAAIiqB,EAAMnd,cAAe,CAEvB,MAAMuf,EAAQpC,EAAMqC,0BAA0B5pB,GACxC6pB,EAAQtC,EAAMqC,0BAA0BzpB,GACxC2pB,EAAa5Z,GAAUyZ,GACvBI,EAAa7Z,GAAU2Z,GAG7B,OACEF,GACAE,GACAC,IAAeC,KAIb3e,GAAaue,KAAWG,GAAc1pC,GAAS,CAAC,UAAW,OAAQupC,EAAMtwC,UACzE+xB,GAAaye,KAAWE,GAAc3pC,GAAS,CAAC,UAAW,OAAQypC,EAAMxwC,OAI/E,OAAO,EACT,KAAKqkB,GAEH,OAAO,EACT,KAAKL,GACL,KAAKI,GAEH,GAAI8pB,EAAM0B,qBAAqBvhB,GAC7B,OAAO,EACF,CAEL,MAAMiiB,EAAQpC,EAAMqC,0BAA0B5pB,GACxC6pB,EAAQtC,EAAMqC,0BAA0BzpB,GAG9C,OAFmB+P,GAAUyZ,KACVzZ,GAAU2Z,GAMjC,KAAKrsB,GAKH,MAAMmsB,EAAQpC,EAAMqC,0BAA0B5pB,GACxC6pB,EAAQtC,EAAMqC,0BAA0BzpB,GACxC6pB,EAAe7Z,GAAYwZ,GAC3BM,EAAe9Z,GAAY0Z,GAE3BK,EAAY3C,EAAMqC,0BAA0B5hB,GAC5CmiB,EAAsBja,GAAUga,GAChCE,IAAiBhf,GAAa8e,IAAaA,EAAU7wC,OAASwkB,GAE9DwsB,EACHL,GAAgBC,GAChBD,IAAiBzC,EAAMe,YAAYnoB,IACnC8pB,IAAiB1C,EAAMe,YAAYtoB,GAEhCsqB,GAAgBJ,GAAcA,IAAcC,GAAuBC,GAEzE,OAAOC,GAAmBC,EAC5B,KAAK9B,GACL,KAAKprB,GACL,KAAKqrB,GACL,KAAKC,GACH,OAAO,EAGX,MAAM,IAAIhtC,MAAM,yDAAyD4L,OAG7E,CACEtJ,KAAM,uBACNoI,YAAa,2DACbq/B,WAAY,CACVxsB,GAASG,MACTH,GAASW,MACTX,GAASK,QACTL,GAASC,KACTD,GAASM,UACTN,GAASO,UACTP,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAEXisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,IAAKqB,EAAMG,cAAciB,YAAY1vB,GAASG,OAC5C,OAAO,EAGT,MAAMmxB,EAAahD,EAAM/b,aACzB,OAAmB,OAAf+e,GAAkD,OAA3BhD,EAAM3b,mBAI7B2e,EAAW7gB,eAAiB6d,EAAM1b,oBAO1C,CACE7tB,KAAM,kBACNoI,YAAa,gGACbq/B,WAAY,CACVxsB,GAASK,QACTL,GAASC,KACTD,GAASM,UACTN,GAASO,UACTP,GAASc,MACTlB,GAAsB,QAAS,QAC/BI,GAASY,MAEXisB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAWwsC,KAC1C,MAAMsE,EAAYjD,EAAM/b,aACxB,GAAiB,MAAbgf,EAAmB,CACrB,MAAMC,EAAkBlD,EAAMqC,0BAA0BY,EAAU9gB,cAClE,IAAKtpB,GAAS4iB,GAASynB,EAAgBtzB,WACrC,OAAO,EAGX,OAAO,IAGX,CACEnZ,KAAM,uCACNoI,YACE,sJACFq/B,WAAY,CACVxsB,GAASK,QACTL,GAASY,KACTZ,GAASU,SACTV,GAASQ,IACTR,GAASM,UACTN,GAASO,WAEXssB,4BAA4B,EAC5BJ,QAAQ,EACRM,QAAS,CAACuB,EAAuB7tC,EAAW+F,KAC1C,GAAIA,EAAIsf,aAAc,CACpB,MAAM4qB,EAAQpC,EAAMqC,0BAA0B,KACxCC,EAAQtC,EAAMqC,0BAA0B,KAE9C,KAAMxe,GAAaue,IAAUxZ,GAAYwZ,OAAave,GAAaye,IAAU1Z,GAAY0Z,IACvF,QAAKtC,EAAMnd,eAGF/X,GAAMk1B,EAAMW,gBAAiB/c,IAClC,MAAM7kB,EAAU6kB,EAAK7kB,QAErB,QACEA,IAAY0Z,GACZ1Z,IAAY6Z,GACZ7Z,IAAYga,GACZha,IAAY0gC,GAGR5b,GAAaD,KAAUA,EAAKhU,cAS1C,OAAO,KAGXle,KAAKixB,GAAO,IAAI6d,GAAoB7d,KAGzBwgB,GAA+DvC,GAAiB7vC,QAC3F,CAAC2d,EAAQvY,KACPuY,EAAEvY,EAAEM,QAAUN,EACPuY,IAET,IAGI00B,GAA+BxC,GAAiB7vC,QAAO,CAACuD,EAAO6B,KACnE,IAAK,MAAMsa,KAAQta,EAAE+nC,aAEnB5pC,EAAMO,IAAI4b,EAAMnc,EAAM6D,IAAIsY,IAAS,IACnCnc,EAAM6D,IAAIsY,GAAMpf,KAAK8E,GAEvB,OAAO7B,IACN,IAAI+sB,aAKSgiB,GACd5yB,EACAsvB,EACAC,EACAnpB,EACA3e,GAGA,MAAMorC,EAAkBF,GAA6BjrC,IAAIsY,IAAS,GAElE,IAAK,MAAMta,KAAKmtC,EAEd,GAAIntC,EAAEgoC,UAAcjmC,EAAI/B,EAAEM,QAAS,CAIjC,IADgBN,EAAEsoC,QAAQuB,EAAOnpB,EAAQ3e,GAC3B,CACZ,MAAMkoC,EAAqB,UAAUjqC,EAAEM,SAKvC,OAHIyB,EAAI+e,SACNhf,QAAQu4B,IAAI,GAAG4P,iBAAkCJ,EAAMK,qBAAqBN,EAAStpC,QAEhF2pC,GAIb,OAAO,oLCp3BT,MAAMmD,GAAmB,IAAIliB,YAMbmiB,GAAc/yB,GAC5B,OAAO8yB,GAAiBprC,IAAIsY,YAyCdgzB,GAAiChzB,GAI/C,MAAO,CAAC0vB,EAA8BtpB,EAAgB3e,IAC7C,CAACwrC,EAA6B1D,KAEnC,MAAM5xB,EAAU+xB,EAAcW,0BAA0B3oC,IAAIsY,GAyD5D,OAvDA,SAASkzB,EAAUC,GACjB,GAAIA,IAAax1B,EAAQna,OAGvB,YADAyvC,EAAUryC,KAAK2uC,EAAMt0B,aAGvB,MAAMpX,EAAQ8Z,EAAQw1B,GAChB7D,EAA0BI,EAAcxc,UAAUrvB,GAAO6D,IAAIsY,GAC7DmT,EAAOoc,EAAME,wBAAwB5rC,GACrCuvC,EAAe7D,EAAM8D,oBAAoBxvC,EAAOmc,GAGpDkV,GAAa/B,IAKba,GAAyBb,KAGxBigB,EAGDF,EAAUC,EAAW,IAErB7D,EAAS/rB,KAAKvf,SAASsvC,IACL,OAAZA,IAGFA,OAAUjqC,GAEZkmC,EAAMgE,oBAAoB1vC,EAAOmc,EAAMszB,EAAShE,GAIhD,GADmCD,GAAcrvB,EAAMsvB,EAAUzrC,EAAO0rC,EAAOnpB,EAAQ3e,GAErF,OAG6BmrC,GAAU5yB,EAAMsvB,EAAUC,EAAOnpB,EAAQ3e,IAKxEyrC,EAAUC,EAAW,MAIvB5D,EAAMiE,sBAAsB3vC,EAAOmc,EAAMsvB,IAK7C4D,CAAU,GAEHD,GAlGbH,GAAiB1uC,IAAI,QAAQ,CAACsrC,EAA8BtpB,EAAgB3e,IACnE,CAACwrC,EAAW1D,KACIA,EAAMU,UAGd1sB,KAAKvf,SAASsL,IACzBigC,EAAMkE,QAAQnkC,GAEiBsjC,GAAU,OAAQlD,EAAcpgC,KAAMigC,EAAOnpB,EAAQ3e,IAGlFwrC,EAAUryC,KAAK2uC,EAAMt0B,gBAKzBs0B,EAAMmE,YAECT,KAIXrzB,GAAwB5b,SAASgc,IAC/B8yB,GAAiB1uC,IAAI4b,EAAMgzB,GAAiChzB,OAG9DQ,GAAsBxc,SAAS0xB,IAC7Bod,GAAiB1uC,IAAIsxB,EAAYsd,GAAiCtd,4GChCpDie,GAAkBC,GAChC,OAAOjsC,GAAAA,QAAAA,SAASisC,MAAQA,EAAY,kBAUtBC,GACdC,EACAlf,EACAP,GAcA,OAZAO,EAAUA,GAAW,IAAIhE,GACzByD,EAAeA,GAAgB,IAAIzD,GAEnCkjB,EAAQ9vC,SAAS+vC,IACXJ,GAAkBI,IACpBnf,EAAQof,SAASD,EAAME,UAAU,GACjC5f,EAAa2f,SAASD,EAAME,SAAUF,EAAM7rC,UAE5C0sB,EAAQof,SAASD,GAAO,MAIrB,CACLnf,QAASA,EACTP,aAAcA,EACdE,SAAUH,GAAiBC,IAqCxB,MAAM6f,GAA2B,CACtCjzB,GAASW,MACTX,GAASY,KACTZ,GAASM,UACTN,GAASQ,IACTR,GAASU,SACTV,GAASG,OAGE+yB,GAAqBD,GAA6D3sC,OAAO,CACpG,CACE0sC,SAAUhzB,GAASK,QACnBpZ,QAAS,CACPH,EAAG,KACHyE,EAAG,KACHW,MAAO,QACPQ,KAAM,QACNE,MAAO,QACPP,QAAS,QACTkB,IAAK,QACLC,OAAQ,sEAlGoC,CAAC2lC,IAAK,wBACP,CAACrsC,EAAG,KAAMyE,EAAG,6BACV,CAACgC,IAAK,QAASC,OAAQ,qCAClB,CACvDtB,MAAO,QACPG,QAAS,QACTO,MAAO,QACPF,KAAM,gEAsCiBmmC,GACvB,OAAInzC,GAAAA,QAAAA,QAAQmzC,GACHA,EACJ7yC,KAAK2yC,IACJ,GAAID,GAAkBC,GAAI,CACxB,GAAIA,EAAE1rC,QAAS,CACb,MAAMmsB,EAAe3qB,GAAAA,QAAAA,KAAKkqC,EAAE1rC,SAAS5H,QAAO,CAACuD,EAAOwwC,KAClD,MAAMC,EAAQV,EAAE1rC,QAAQmsC,GAExB,OADCxwC,EAAMywC,GAASzwC,EAAMywC,IAAU,IAAI1zC,KAAKyzC,GAClCxwC,IACN,IAEH,MACE,GAAG+vC,EAAEK,YACLvqC,GAAAA,QAAAA,KAAK2qB,GACFpzB,KAAKqzC,GAEG,GADUjgB,EAAaigB,GAAO3qC,OAClBG,KAAK,SAASwqC,MAElCxqC,KAAK,KACR,IAGJ,OAAO8pC,EAAEK,SAEX,OAAOL,KAER9pC,KAAK,KAEDgqC,sDC1EX,MAAMS,GAAoD,YAK1CC,GAAcxuC,EAAc0X,GAC1C62B,GAAcvuC,GAAQ0X,EAGjB,MAAMkE,GAAQ,QACR6yB,GAAkB,iBAClBC,GAAW,WACXC,GAAO,gBAMJC,GAAKC,EAA8BC,GACjD,GAAIA,EAAW,CACb,MAAMC,EAAiC,CACrC/uC,KAAM,GACNG,KAAM,GACN6uC,MAAO,IAEHC,EAAwC,GAKxCC,EAAsC,GACtCC,EAA2C,GAC3CC,EAAwC,GAE9C,IAAK,IAAIx2B,EAAI,EAAGA,EAAIk2B,EAAUtxC,OAAQob,IAAK,CACzCs2B,EAASt0C,KAAKge,EAAI,EAAIs2B,EAASt2B,EAAI,GAAG3D,YAAc,IAAI2V,IACxDukB,EAASv0C,KAAKge,EAAI,EAAIu2B,EAASv2B,EAAI,GAAG3D,YAAc,IAAI2V,IAExD,MAAMkjB,EAAUgB,EAAUl2B,GAAGk1B,QAC7B,GAAInzC,GAAAA,QAAAA,QAAQmzC,GAAU,CAEpB,MAAMuB,EAAgBxB,GAAaC,EAASoB,EAASt2B,GAAIu2B,EAASv2B,IAClEw2B,EAAUx0C,KAAKy0C,EAAc9gB,WAgCjC,OA1BAsgB,EAAW7wC,SAASurC,IAClB,IAAIppC,EAAO,GACPmvC,EAA6BP,EACjC,IAAK,IAAIn2B,EAAI,EAAGA,EAAIk2B,EAAUtxC,OAAQob,IAAK,CACzC,MAAMk1B,EAAWwB,EAAMxB,QAAUgB,EAAUl2B,GAAGk1B,QAC9CwB,EAAMC,aAAeT,EAAUl2B,GAAG22B,aAElC,MAAMtxC,EAAMtD,GAAAA,QAAAA,QAAQmzC,GAChB0B,GAAcjG,EAAMwB,UAAWmE,EAASt2B,GAAIw2B,EAAUx2B,IACtD21B,GAAcT,GAASvE,EAAMwB,WAEjC5qC,GAAQ,IAAIlC,IACPgxC,EAAW9uC,KAEd8uC,EAAW9uC,GAAQ,CACjBH,KAAM/B,EACNkC,KAAMA,EACN6uC,MAAO,IAGTM,EAAMN,MAAMp0C,KAAKq0C,EAAW9uC,KAE9BmvC,EAAQL,EAAW9uC,GAErBmvC,EAAMN,MAAMp0C,KAAK2uC,MAEZwF,EAGP,MAAO,CACL/uC,KAAM,GACNG,KAAM,GACN6uC,MAAOH,GAMb,MACMY,GAAwB5B,GADP,CAAC5yB,GAASW,iBAGjB8zB,GAAcnG,EAAkBuE,GAC9C,OAAOS,GAAcT,GAASvE,GAGhCiF,GAAc5yB,IAAQ0R,GACbkiB,GAAcliB,EAAOmiB,GAAsB7gB,QAAS6gB,GAAsBlhB,YAG5E,MAAMohB,GAAkC9B,GAAaK,IAE5DM,GAAcC,IAAkBnhB,GACvBkiB,GAAcliB,EAAOqiB,GAAgC/gB,QAAS+gB,GAAgCphB,YAGhG,MAAMqhB,GAA2B/B,GAAaM,IAErDK,GAAcE,IAAWphB,GAChBkiB,GAAcliB,EAAOsiB,GAAyBhhB,QAASghB,GAAyBrhB,YAGzFigB,GAAcG,IAAOrhB,GAAqBtrB,KAAKC,UAAUqrB,2MC/G5CuiB,GAWXp+B,cACEjX,KAAKs1C,WAAQzsC,EACb7I,KAAKu1C,WAAa,GAClBv1C,KAAKw1C,2BAA6B,IAAIplB,GAGjCnZ,oBAAoB5T,EAAemc,EAAgBsvB,GACxD,MAAM2G,EAAiBz1C,KAAKu1C,YAGVE,EAAepyC,GAASoyC,EAAepyC,IAAU,IAAI+sB,IAC9DxsB,IAAI4b,EAAMsvB,GAGnB,MAAM4G,EAAgB11C,KAAKw1C,2BAI3B,OAHAE,EAAc9xC,IAAI4b,EAAMk2B,EAAcxuC,IAAIsY,IAAS,IACnDk2B,EAAcxuC,IAAIsY,GAAMpf,KAAKiD,GAEtBrD,KAGFiX,oBAAoB5T,EAAemc,GACxC,QAASxf,KAAKu1C,WAAWlyC,IAAUrD,KAAKu1C,WAAWlyC,GAAOggB,IAAI7D,GAGzDvI,YAAYuI,GACjB,GAAIc,GAAmBd,GACrB,OAAOxf,KAAK6vC,0BAA0BxsB,IAAI7D,GACrC,GAAa,SAATA,EACT,QAASxf,KAAK8O,KAGhB,MAAM,IAAI5L,MAAM,8BAA8Bsc,KAGzCvI,UACL,OAAQjX,KAAK8O,MAAkD,IAA1C9O,KAAK6vC,0BAA0B1iC,OAG/C8J,QAAQnI,GAEb,OADA9O,KAAKs1C,MAAQxmC,EACN9O,KAGT8O,WACE,OAAO9O,KAAKs1C,MAGd5iB,gBACE,OAAO1yB,KAAKu1C,WAGd1F,gCACE,OAAO7vC,KAAKw1C,kCCrCHG,GAuGX1+B,YACEob,EACA6c,EACAtpB,EACA3e,EACA2uC,GAlGM51C,KAAA61C,cAAoC,GAoG1C71C,KAAK81C,MAAQzjB,EACbryB,KAAK+1C,mBAAqB1jB,EAAKK,UAAU5yB,QAAO,CAAC2d,EAAGkV,KAC7C/P,GAAW+P,EAAK7kB,UAAc6mB,GAAiBhC,KAA4B,IAAnBA,EAAK/T,YAChEnB,EAAE,GAAGkV,EAAK7kB,WAAa,GAElB2P,IACN,IAEHzd,KAAKg2C,eAAiB9G,EACtBlvC,KAAKi2C,uBAAyBL,EAC9B51C,KAAKk2C,KAAOjvC,EACZjH,KAAKm2C,QAAUvwB,EAtGV3O,aAAa6b,EAAkBlN,EAAgB3e,GACpD,MAAMioC,EAA+B,IAAImG,GAEzC,GAAIzyB,GAAWkQ,EAAMhkB,MAAO,CAC1B,MAAMtJ,EAAOif,GAAehE,GAASC,MACrCoS,EAAMhkB,KAAOkU,GAAa8P,EAAMhkB,KAAMtJ,EAAMyB,EAAI8b,KAAKjU,MACrDogC,EAAc+D,QAAQngB,EAAMhkB,MAoD9B,GA9CAgkB,EAAMJ,UAAUlvB,SAAQ,CAACmvB,EAAMtvB,KACzBsxB,GAAiBhC,KAEnB3rB,QAAQmQ,KAAK,8FAEbwb,EAAK9xB,KAAOykB,IAGVsN,GAAaD,SAAuB9pB,IAAd8pB,EAAK9xB,OAE7B8xB,EAAK9xB,KAAO8hB,IAIdvD,GAAwB5b,SAASgc,IAC/B,GAAIoD,GAAW+P,EAAKnT,IAAQ,CAE1B,MAAM42B,EAAsB3xB,GAAejF,GAAQnc,EAC7C6f,EAAoByC,GAAqBnG,EAAMoG,EAAQ3e,GACvD6nC,EAAYnc,EAAKnT,GAAQwD,GAAa2P,EAAKnT,GAAO42B,EAAqBlzB,GAG7EgsB,EAAc6D,oBAAoB1vC,EAAOmc,EAAMsvB,OAKnD9uB,GAAsBxc,SAASgc,IAC7B,MAAM62B,EAAU1jB,EAAKnT,EAAKne,QAC1B,GAAIg1C,EAAS,CACX,MAAMt0C,EAAQyd,EAAKzd,MACnB,GAAI6gB,GAAWyzB,EAAQt0C,IAAS,CAE9B,MAAMq0C,EAAsB3xB,GAAejF,GAAQnc,EAC7C6f,EAAoByC,GAAqBnG,EAAMoG,EAAQ3e,GACvD6nC,EAAYuH,EAAQt0C,GAASihB,GAAaqzB,EAAQt0C,GAAQq0C,EAAqBlzB,GAGrFgsB,EAAc6D,oBAAoB1vC,EAAOmc,EAAMsvB,WAQnD7nC,EAAIsf,aAAc,CACpB,MAAMzY,EAAqC,CACzCtI,KAAMif,GAAehE,GAASK,SAAWgS,EAAMJ,UAAU1vB,OACzD+f,KAAM4C,GAAqBlF,GAASK,QAAS8E,EAAQ3e,IAEjD2X,EAA+B,CACnCpZ,KAAMif,GAAehE,GAASO,WAAa8R,EAAMJ,UAAU1vB,OAC3D+f,KAAM,EAAC,GAAO,IAEVuzB,EAA4B,CAChCxoC,QAAAA,EACA8Q,UAAAA,EACA/d,KAAMykB,IAERwN,EAAMJ,UAAUtyB,KAAKk2C,GAErB,MAAMjzC,EAAQyvB,EAAMJ,UAAU1vB,OAAS,EAGvCksC,EAAc6D,oBAAoB1vC,EAAOod,GAASK,QAAShT,GAC3DohC,EAAc6D,oBAAoB1vC,EAAOod,GAASO,UAAWpC,GAG/D,OAAO,IAAI+2B,GAAe7iB,EAAOoc,EAAetpB,EAAQ3e,EAAK,IAwB/DioC,oBACE,OAAOlvC,KAAKg2C,eAGdpwB,aACE,OAAO5lB,KAAKm2C,QAGd5F,gBACE,OAAOvwC,KAAK81C,MAGP7+B,YACL,OAAO,IAAI0+B,GACTl7B,GAAAA,QAAAA,UAAUza,KAAK81C,OACf91C,KAAKg2C,eACLh2C,KAAKm2C,QACLn2C,KAAKk2C,KACLz7B,GAAAA,QAAAA,UAAUza,KAAKi2C,yBAIZh/B,QAAQnI,GACb,MAAMtJ,EAAOxF,KAAKg2C,eAAelnC,KAAKtJ,KACtCxF,KAAKi2C,uBAAuBzwC,GAAQxF,KAAK81C,MAAMhnC,KAAOA,EAGjDmI,YACL,MAAM63B,EAAY9uC,KAAK81C,MAAMhnC,KAAO9O,KAAKg2C,eAAelnC,YACjD9O,KAAKi2C,uBAAuBnH,EAAStpC,MAGvCyR,UACL,OAAOjX,KAAK81C,MAAMhnC,KAGbmI,oBAAoB5T,EAAemc,GACxC,MAAMmT,EAAO3yB,KAAK81C,MAAMpjB,UAAUrvB,GAClC,OAAIob,GAAqBe,GAEhBmT,EAAKnT,EAAKne,QAAQme,EAAKzd,OAEzB4wB,EAAKnT,GAGPvI,oBAAoB5T,EAAemc,EAAgBhgB,EAAYsvC,GACpE,MAAMnc,EAAO3yB,KAAK81C,MAAMpjB,UAAUrvB,GAE9Bmc,IAASiB,GAASK,SAAW6R,EAAK7kB,UAAY8U,GAAW+P,EAAK7kB,UAEhE9N,KAAK+1C,mBAAmBpjB,EAAK7kB,WAG3B2Q,GAAqBe,GAEvBmT,EAAKnT,EAAKne,QAAQme,EAAKzd,OAASvC,EACvB+f,GAAuBC,KAAmB,IAAVhgB,EACzCmzB,EAAKnT,GAAQ5E,GAAAA,QAAAA,OACX,GACA+X,EAAKnT,GACL,CAACuD,UAAMla,EAAWrD,UAAMqD,IAI1B8pB,EAAKnT,GAAQhgB,EAGfQ,KAAKi2C,uBAAuBnH,EAAStpC,MAAQhG,EAEzCggB,IAASiB,GAASK,UAEpB9gB,KAAK+1C,mBAAmBv2C,IAAUQ,KAAK+1C,mBAAmBv2C,IAAU,GAAK,GAItEyX,sBAAsB5T,EAAemc,EAAgBsvB,GAC1D,MAAMnc,EAAO3yB,KAAK81C,MAAMpjB,UAAUrvB,GAC9Bmc,IAASiB,GAASK,SACpB9gB,KAAK+1C,mBAAmBpjB,EAAK7kB,WAI3B2Q,GAAqBe,GAEvBmT,EAAKnT,EAAKne,QAAQme,EAAKzd,OAAS+sC,EAGhCnc,EAAKnT,GAAQsvB,SAIR9uC,KAAKi2C,uBAAuBnH,EAAStpC,MAGvCyR,YAAYnJ,GAEjB,OAAO9N,KAAK+1C,mBAAmBjoC,GAAW,EAGrCmJ,qBAAqBnJ,GAE1B,OAAO8kB,GADe5yB,KAAKoxC,0BAA0BtjC,IAIhDmJ,eAEL,OAAOjX,KAAK81C,MAAMpjB,UAAUzY,QAAQ0Y,IAAUa,GAAyBb,KAGlE1b,0BAA0BnJ,GAC/B,IAAK,MAAMyoC,KAAgBv2C,KAAK81C,MAAMpjB,UACpC,GAAI6jB,EAAazoC,UAAYA,EAC3B,OAAOyoC,EAMNt/B,wBAAwB1T,GAC7B,OAAOvD,KAAK81C,MAAMpjB,UAAUnvB,GAGvB0T,cACL,OAAO2a,GAAY5xB,KAAK81C,OAOnB7+B,aACL,OAAO+b,GAAWhzB,KAAK81C,OAOlB7+B,iBACL,OAAOmc,GAAepzB,KAAK81C,OAOtB7+B,kBACL,OAAOoc,GAAgBrzB,KAAK81C,OAGvB7+B,YAAYq8B,GACjB,GAAIA,EAAS,CACX,GAAIjsC,GAAAA,QAAAA,SAASisC,GACX,OAAO4B,GAAcl1C,KAAKuwC,UAAW+C,GAEvC,MAAMuB,EAAgBxB,GAAaC,GACnC,OAAO0B,GAAch1C,KAAK81C,MAAOjB,EAAczgB,QAASygB,EAAc9gB,UAExE,OAAOihB,GAAch1C,KAAK81C,OAOrB7+B,OAAO7O,GACZ,GAAIwa,GAAW5iB,KAAK81C,MAAMhnC,MAAO,OAAO,KAExC,MAAMujB,EAAY,GA6BlB,OA5BAjqB,EAAOA,GAAQpI,KAAK81C,MAAM1tC,QAExBiqB,EAAKjqB,KAAOA,GAGVpI,KAAK81C,MAAMxjB,YACbD,EAAKC,UAAYtyB,KAAK81C,MAAMxjB,WAG9BD,EAAKvjB,KAAO9O,KAAK81C,MAAMhnC,KACvBujB,EAAKvd,SAAWoe,GAAWlzB,KAAKuwC,UAAU7d,UAAW,CAAC9M,OAAQ5lB,KAAKm2C,QAAShjB,aAAc,SAEtFnzB,KAAK81C,MAAMvjB,QACbF,EAAKE,MAAQvyB,KAAK81C,MAAMvjB,OAEtBvyB,KAAK81C,MAAMtjB,SACbH,EAAKG,OAASxyB,KAAK81C,MAAMtjB,QAEvBxyB,KAAK81C,MAAMrjB,aACbJ,EAAKI,WAAazyB,KAAK81C,MAAMrjB,YAE3BzyB,KAAK81C,MAAM//B,UACbsc,EAAKtc,QAAU/V,KAAK81C,MAAM//B,SAExB/V,KAAK81C,MAAMriC,QACb4e,EAAK5e,MAAQzT,KAAK81C,MAAMriC,OAGJ,OAAlB4e,EAAKvd,SACA,OAEL9U,KAAK81C,MAAMjjB,QAAU7yB,KAAKk2C,KAAKjwB,qBACjCoM,EAAKQ,OAASjY,GAAAA,QAAAA,OAAO,GAAI5a,KAAKk2C,KAAKjwB,kBAAmBjmB,KAAK81C,MAAMjjB,SAE5DR,GAGFpb,gBAAgBu/B,GACrB,OAAOx2C,KAAK61C,cAAcW,GAGrBv/B,gBAAgBu/B,EAAqBC,GAC1Cz2C,KAAK61C,cAAcW,GAAeC,wGC3WtBjmB,GAAUlqB,GACxB,GAAIA,EAAEgtC,QAAS,CACb,MAAMc,EAAa,CACjBd,QAAShtC,EAAEgtC,SAGThtC,EAAEowC,UACJtC,EAAKW,aAAezuC,EAAEowC,SAGxB,MAAMC,EAAqB,CACzBtkB,KAAM5X,GAAAA,QAAAA,UAAUnU,EAAE+rB,MAClB+hB,KAAM,CAACA,IAWT,OARI9tC,EAAEswC,WACJD,EAAYC,SAAWtwC,EAAEswC,UAGvBtwC,EAAEusB,SACJ8jB,EAAY9jB,OAASvsB,EAAEusB,QAGlB8jB,EAET,OAAOl8B,GAAAA,QAAAA,UAAUnU,yHCrBHuwC,GAAgB/uC,GAC9B,YAAuCe,IAAhBf,EAAM0sC,eAGfsC,GAAwBvG,GACtC,IAAIwG,EAAUxG,EAAUiE,MAAM,GAC9B,KAAOuC,GAAWF,GAAaE,IAC7BA,EAAUA,EAAQvC,MAAM,GAE1B,OAAUuC,MCdAC,+FDiBIC,EAAgBnC,EAAsB7sC,GACpD,OAAA5I,OAAA0M,OAAA1M,OAAA0M,OAAA,GACK+oC,GAAK,CACRN,MAAOM,EAAMN,MAAM/zC,KAAKqH,GAAU+uC,GAAa/uC,GAAQmvC,EAAUnvC,EAAMG,GAAKA,EAAEH,gBEtB5DovC,GAGpBjgC,YAAYpW,GACVb,KAAKa,KAAOA,EACZb,KAAKm3C,WAAan3C,KAAKo3C,YAKfngC,gBAAgBogC,GACxB,MAAMx2C,EAAOb,KAAKa,KACZ41C,EAAQz2C,KAAKm3C,WAAWE,GAC9B,QAAcxuC,IAAV4tC,EACF,MAAO,CAAC51C,KAAAA,EAAMw2C,QAAAA,EAASZ,MAAAA,KDZ7B,SAAYO,GACVA,EAAAA,EAAA,EAAI1xB,IAAwB,IAC5B0xB,EAAAA,EAAA,MAAQ,OAAO1xB,MAA0B,QACzC0xB,EAAAA,EAAA,EAAIzxB,IAAoB,IAKxByxB,EAAAA,EAAA,WAAa,iBAAsB,aAInCA,EAAAA,EAAA,WAAa,YAAY3xB,MAAqB,aAC9C2xB,EAAAA,EAAA,EAAI3xB,IAAmB,IACvB2xB,EAAAA,EAAA,EAAI5xB,IAAmB,IACvB4xB,EAAAA,EAAA,EAAI9mB,GAAazkB,KAAU,IAC3BurC,EAAAA,EAAA,KAAO,KAAU,OAhBnB,CAAYA,KAAAA,GAAY,KAmBjB,MAAMM,GAAIN,GAAaM,EACjBC,GAAQP,GAAaO,MACrBC,GAAIR,GAAaQ,EACjBC,GAAaT,GAAaS,WAC1BC,GAAaV,GAAaU,WAC1BC,GAAIX,GAAaW,EACjB/Q,GAAIoQ,GAAapQ,EACjBgR,GAAIZ,GAAaY,EACjBC,GAAOb,GAAaa,cAEjBC,GAAgBljB,GAC9B,GAAIA,EAAO/V,IACT,OAAOm4B,GAAaO,MACf,GAAI3iB,EAAO9V,SAAU,CAE1B,OAAO/G,GADO0B,GAAUmb,IACUoiB,GAAaU,WAAaV,GAAaS,WAE3E,OAAO7iB,EAAO/zB,KE/BT,MAAMk3C,IAAY,YC+BTC,GAAUC,EAAqBC,EAAqBC,EAAuBrpC,GACzF,MAAO,GAAGmpC,KAASC,KAASC,KAAgBrpC,IClC9C,MAAMspC,GAAU,CACd,kBCM8BlB,GAC9BjgC,cACEm2B,MAAM,QAEEn2B,UAAUhQ,EAAmB,IACrCA,EAAG5H,OAAA0M,OAAA1M,OAAA0M,OAAA,GAAOga,IAAyB9e,GACnC,MAAMwvC,EAAsB,GAuC5B,MArCsB,CACpB,CACEY,QAASE,GACTtwC,IAAK,oBAEP,CACEowC,QAASG,GACTvwC,IAAK,yBAEP,CACEowC,QAASI,GACTxwC,IAAK,yBAEP,CACEowC,QAASK,GACTzwC,IAAK,yBAEP,CACEowC,QAASM,GACT1wC,IAAK,wBAEP,CACEowC,QAASzQ,GACT3/B,IAAK,yBAIKzD,SAAS60C,IACjBpxC,EAAIoxC,EAAMpxC,OAASugB,EAErBivB,EAAM,GAAG4B,EAAMhB,WAAW1vB,MAAgB,IACjC1gB,EAAIoxC,EAAMpxC,OAAS0gB,IAE5B8uB,EAAM,GAAG4B,EAAMhB,WAAW7vB,MAAgB,QAIvCivB,EAGFx/B,UAAUpW,EAAoBiN,GACnC,MAAO,GAAGjN,KAAQiN,IAGbmJ,SAAS83B,EAAuB7tC,EAAWwsC,GAChD,OAAOqB,EAAMW,eAAe5vC,QAAO,CAACw4C,EAAU3lB,KAC5C,GAAIC,GAAaD,IAASgC,GAAiBhC,GAAO,CAChD,MAAM9xB,EAAOi3C,GAAgBnlB,GACvB0kB,EAAUr3C,KAAKg4C,UAAUn3C,EAAM8xB,EAAK7kB,SACpCyqC,EAAev4C,KAAKw4C,gBAAgBnB,GAEtCkB,GACFD,EAASl4C,KAAKm4C,GAGlB,OAAOD,IACN,MDrEL,kBEFmCpB,GACnCjgC,cACEm2B,MAAM,aAGEn2B,YACR,MAAO,CACLjJ,KAAM,EACNC,QAAS,EACTtB,MAAO,EACPG,QAAS,EACTK,KAAM,EACNE,MAAO,GAIJ4J,SAAS83B,EAAuB7tC,EAAWwsC,GAgBhD,OAfIqB,EAAMnd,eACRmd,EAAMW,eAAe5vC,QACnB,CAAC24C,EAAW9lB,KACV,GAAIgC,GAAiBhC,IAAUC,GAAaD,KAAUA,EAAKhU,UAAY,CAErE,MAAM45B,EAAev4C,KAAKw4C,gBAAgB,GAAG7lB,EAAK7kB,WAClD,GAAIyqC,GAAgBA,EAAa9B,MAAQgC,EAAUhC,MACjD,OAAO8B,EAGX,OAAOE,IAET,CAAC53C,KAAM,YAAaw2C,QAAS,eAAgBZ,OAAQ,IAGlD,KF7BT,kBGF+BS,GAC/BjgC,cACEm2B,MAAM,SAEEn2B,UAAUhQ,GAElB,MAAMwvC,EAAsB,GAU5B,OAXAxvC,EAAG5H,OAAA0M,OAAA1M,OAAA0M,OAAA,GAAOga,IAAyB9e,IAG3B4gB,iBAAmBC,EAEzB2uB,EAAMjI,IAAmB,IAChBvnC,EAAI4gB,iBAAmB2mB,IAEhCiI,EAAM3uB,IAAgB,KAGjB2uB,EAEFx/B,SAAS83B,EAAuB7tC,EAAWwsC,GAChD,OAAOqB,EAAMW,eAAe5vC,QAAO,CAACw4C,EAAU3lB,KAC5C,GAAIC,GAAaD,IAASgC,GAAiBhC,GAAO,CAChD,MAAM4lB,EAAev4C,KAAKw4C,gBAAgB7lB,EAAK7kB,SAC3CyqC,GACFD,EAASl4C,KAAKm4C,GAGlB,OAAOD,IACN,MHxBL,kBDJ8BpB,GAC9BjgC,cACEm2B,MAAM,QAGEn2B,YACR,OA+BJ,WACE,MAAMyhC,EAAW,CAACpB,GAAGE,IAEfmB,EADW,CAACpB,GAAOG,GAAYC,GAAG/Q,GAAGgR,IACT7wC,OAAO,CAAC8wC,KAEpCe,EAAQ,GAEdF,EAASl1C,SAASy0C,IAChBS,EAASl1C,SAAS00C,IAYhB10C,GAVuB,CACrB+L,MAAO,EACPhC,MAAO,GACPkC,MAAO,GACPL,MAAO,EACPF,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,MAEe,CAAConC,EAAO3nC,KAC9B,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAMppC,GAC9C8pC,EAAMvB,GAAWZ,KAcnBjzC,GATyB,CACvB+L,MAAO,EACPhC,MAAO,GACPkC,MAAO,GACPP,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,MAEiB,CAAConC,EAAO3nC,KAChC,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,WAMvBiC,EAASl1C,SAASy0C,IAEhBU,EAAiBn1C,SAAS00C,IAUxB10C,GATqC,CACnCiM,KAAM,EACNF,OAAQ,GACRhC,MAAO,GACP2B,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,MAE6B,CAAConC,EAAO3nC,KAC5C,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAMppC,GAC9C8pC,EAAMvB,GAAWZ,EAEjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAMnpC,GAC/C8pC,EAAMC,GAAYpC,QAItB,CAACgB,IAAYj0C,SAAS00C,IAWpB10C,GAVqC,CAEnC+L,MAAO,EACPhC,MAAO,GACPkC,MAAO,EACPP,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,MAE6B,CAAConC,EAAO3nC,KAC5C,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAMppC,GAC9C8pC,EAAMvB,GAAWZ,EAEjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAMnpC,GAC/C8pC,EAAMC,GAAYpC,QAKtB,CAACoB,GAAMjR,GAAG+Q,GAAGC,IAAGp0C,SAAS00C,IAYvB10C,GAXsB,CACpB0L,IAAK,EACLK,OAAQ,GACRE,MAAO,IACPlC,MAAO,GAEPmC,MAAO,EACPT,MAAO,EAEPI,MAAO,MAEc,CAAConC,EAAO3nC,KAC7B,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,EAGjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAOnpC,GAChD8pC,EAAMC,GAAYpC,QAItB,CAACc,IAAO/zC,SAAS00C,IAYf10C,GAXyB,CACvB0L,IAAK,EACLK,OAAQ,GACRE,MAAO,IACPlC,MAAO,GAEPmC,MAAO,GACPT,MAAO,GAEPI,MAAO,MAEiB,CAAConC,EAAO3nC,KAChC,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,EAGjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAOnpC,GAChD8pC,EAAMC,GAAYpC,QAItB,CAACgB,GAAYC,IAAYl0C,SAAS00C,IAahC10C,GAVyB,CACvBkM,KAAM,EACNT,MAAO,GACPC,KAAM,GACNK,OAAQ,GACRE,MAAO,IACPlC,MAAO,GAEP8B,MAAO,MAEiB,CAAConC,EAAO3nC,KAChC,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,EAGjB,MAAMoC,EAAWb,GAAUE,EAAOD,GAAO,EAAOnpC,GAChD8pC,EAAMC,GAAYpC,WAKxB,CAACgB,IAAYj0C,SAASy0C,IACpB,CAACR,IAAYj0C,SAAS00C,IAEpB,MAAMY,EAAS,CACbvpC,MAAO,EACPH,MAAO,GACP7B,MAAO,GACPkC,MAAO,EACPP,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,KAIT7L,GAAQs1C,GAAQ,CAACrC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAMppC,GAC9C8pC,EAAMvB,GAAWZ,KAEnBjzC,GAAQs1C,GAAQ,CAACrC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,QAIrBkC,EAAiBn1C,SAAS00C,IAExB,MAAMa,EAAS,CACbtpC,KAAM,EACNF,OAAQ,GACRhC,MAAO,GACP6B,MAAO,EACPF,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,KAIT7L,GAAQu1C,GAAQ,CAACtC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAMppC,GAC9C8pC,EAAMvB,GAAWZ,KAEnBjzC,GAAQu1C,GAAQ,CAACtC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUE,EAAOD,GAAO,EAAMnpC,GAC9C8pC,EAAMvB,GAAWZ,KAEnBjzC,GAAQu1C,GAAQ,CAACtC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,KAEnBjzC,GAAQu1C,GAAQ,CAACtC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUE,EAAOD,GAAO,EAAOnpC,GAC/C8pC,EAAMvB,GAAWZ,WAOvB,IAAK,MAAMwB,KAASU,EAClB,IAAK,MAAMT,KAASS,EAAkB,CAEpC,MAAMK,EAAS,CACbzpC,MAAO,EACPH,KAAM,EACN7B,MAAO,GACPkC,MAAO,EACPP,KAAM,EACNQ,MAAO,EACPT,MAAO,EACPI,MAAO,KAGT7L,GAAQw1C,GAAQ,CAACvC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAMppC,GAC9C8pC,EAAMvB,GAAWZ,KAInBjzC,GAAQw1C,GAAQ,CAACvC,EAAO3nC,KACtB,MAAMuoC,EAAUW,GAAUC,EAAOC,GAAO,EAAOppC,GAC/C8pC,EAAMvB,GAAWZ,KAKvB,OAAOmC,EAhREK,GAGFhiC,SAAS83B,EAAuB7tC,EAAWwsC,GAChD,IAAI5+B,EAAOigC,EAAMU,UACb3gC,IAASkhC,IAAelhC,IAASmhC,KACnCnhC,EAAO8V,IAET,MAAMusB,EAAQpC,EAAMqC,0BAA0B5pB,GACxCywB,EAAQ9G,EAAQ2G,GAAgB3G,GAAS0G,GAEzCxG,EAAQtC,EAAMqC,0BAA0BzpB,GAKxC0vB,EAAU,GAAGY,KAJL5G,EAAQyG,GAAgBzG,GAASwG,OAE3B9I,EAAMnd,iBAEyB9iB,IAC7CypC,EAAev4C,KAAKw4C,gBAAgBnB,GAE1C,OAAIkB,EACK,CAACA,IAEVvxC,QAAQhB,MAAM,4BAA6BqxC,GACpC,MCxBT,kBILqCH,GACrCjgC,cACEm2B,MAAM,eAGEn2B,YACR,MAAO,CACLiiC,UAAW,EACXC,WAAY,GAITliC,SAAS83B,EAAuB7tC,EAAWwsC,GAChD,MAAM5+B,EAAOigC,EAAMU,UACnB,OAAOV,EAAMW,eAAe5vC,QAAO,CAACs5C,EAAezmB,KACjD,GAAIC,GAAaD,IAASgC,GAAiBhC,GAAO,CAChD,MAAM0kB,EAAU,GAAGvoC,KAAQ6jB,EAAK7kB,UAC1ByqC,EAAev4C,KAAKw4C,gBAAgBnB,GACtCkB,GACFa,EAAch5C,KAAKm4C,GAGvB,OAAOa,IACN,MJjBL,kBFEqClC,GACrCjgC,cACEm2B,MAAM,eAEEn2B,YACR,MAAM2hC,EAAQ,GAGRS,EAAgC,CACpC9xC,EAAG,EACHyE,EAAG,EACHmB,MAAO,KACPR,OAAQ,KACRY,MAAO,EACPT,SAAU,EAEVO,MAAO0qC,GACP/pC,IAAK+pC,GACL9pC,OAAQ8pC,GACRvqC,QAAQ,IAGV,CAAC8pC,GAAGE,GAAGC,IAAYj0C,SAAS3C,IAC1BqI,GAAAA,QAAAA,KAAKmwC,GAA+B71C,SAASsK,IAC3C8qC,EAAM54C,KAAKg4C,UAAUn3C,EAAMiN,IAAYurC,EAA8BvrC,SAMzE,MAAMwrC,EAA6B1+B,GAAAA,QAAAA,OAAO,GAAIy+B,EAA+B,CAC3ErrC,KAAM,IACNC,QAAS,IAETZ,OAAQ,IACRE,MAAO,IACPC,QAAS,IAGX,CAAC+pC,GAAOG,GAAYC,IAAGn0C,SAAS3C,IAC9BqI,GAAAA,QAAAA,KAAKowC,GAA4B91C,SAASsK,IACxC8qC,EAAM54C,KAAKg4C,UAAUn3C,EAAMiN,IAAYwrC,EAA2BxrC,SAItE,MAAMyrC,EAA6B,CACjChyC,EAAG,EACHyE,EAAG,EACHW,OAAQ,GACRU,OAAQ,IACRW,KAAM,GACNC,QAAS,GACTV,MAAO,GAEPC,QAAS,EACTL,MAAO,EACPL,SAAU,KAUZ,OAPA5D,GAAAA,QAAAA,KAAKqwC,GAA4B/1C,SAASsK,IACxC8qC,EAAM54C,KAAKg4C,UAAUpR,GAAG94B,IAAYyrC,EAA2BzrC,GAC/D8qC,EAAM54C,KAAKg4C,UAAUJ,GAAG9pC,IAEtBlG,GAAS,CAAC,IAAK,IAAK,UAAWkG,IAAY,EAAIyrC,EAA2BzrC,GAAW,KAGlF8qC,EAGF3hC,UAAUpW,EAAoBiN,GACnC,MAAO,GAAGjN,KAAQiN,IAGbmJ,SAAS83B,EAAuBnpB,EAAgB3e,GACrD,MAAMuyC,EAAuBzK,EAAMW,eAAe5vC,QAAO,CAAC2d,EAAGkV,KAC3D,GAAIC,GAAaD,IAASgC,GAAiBhC,GAAO,CAChD,MAAM8mB,EAAWhjB,GAAkB9D,IAClClV,EAAEg8B,GAAYh8B,EAAEg8B,IAAa,IAAIr5C,KAAKuyB,GAEzC,OAAOlV,IACN,IAEG66B,EAA2B,GAoBjC,OAlBA90C,GAAQg2C,GAAuBllB,IAC7B,MAAMolB,EAAmBplB,EAAMx0B,QAAO,CAAC65C,EAAoBhnB,KACzD,GAAIC,GAAaD,IAASgC,GAAiBhC,GAAO,CAChD,MAAM9xB,EAAOi3C,GAAgBnlB,GACvB0kB,EAAUr3C,KAAKg4C,UAAUn3C,EAAM8xB,EAAK7kB,SACpCyqC,EAAev4C,KAAKw4C,gBAAgBnB,GAE1C,GAAa,OAATsC,GAAiBpB,EAAa9B,MAAQkD,EAAKlD,MAC7C,OAAO8B,EAGX,OAAOoB,IACN,MAEHrB,EAASl4C,KAAKs5C,MAITpB,cEjGKsB,GAAc7K,EAAuBnpB,EAAgB3e,GACnE,MAAMqxC,EAAWF,GAAQt4C,QAAO,CAACmI,EAAG4xC,KAClC,MAAMC,EAASD,EAAOE,SAAShL,EAAOnpB,EAAQ3e,GAC9C,OAAOgB,EAAElB,OAAO+yC,KACf,IAEH,MAAO,CACLrD,MAAO6B,EAASx4C,QAAO,CAAC0G,EAAGyB,IAClBzB,EAAIyB,EAAEwuC,OACZ,GACH6B,SAAUA,GK1BP,MAAM9yC,GAAO,8BAEJixC,GAAM1H,EAAuBnpB,EAAgB3e,GAC3D,MAAMowC,EAOR,SAAmCtI,EAAuB7tC,EAAWwsC,GACnE,MAAMhb,EAAYqc,EAAMW,eACxB,GAAIX,EAAMnd,cAAe,CASvB,GAAI7pB,GAAK2qB,GARgBC,GAErBC,GAAaD,KACXA,EAAK9xB,OAASykB,KAAsBqN,EAAK9T,MAAQ8T,EAAKhU,WACrDgU,EAAK9xB,OAAS0kB,KAAkBoN,EAAK7T,YAO1C,MAAO,CACLje,KAAM2E,GACNixC,MAAO,GACPY,QAAS,iCAIb,GAAItvC,GAAK2qB,GAAYC,GAASC,GAAaD,IAASgF,GAAYhF,KAAQ,CACtE,MAAMqnB,EAAWjyC,GAAK2qB,GAAYC,GACxBC,GAAaD,IAA4B,UAAnBA,EAAKhU,WAA0BoU,GAAwBJ,KAEjFsnB,EAASlyC,GAAK2qB,GAAYC,GACvBC,GAAaD,MAAWA,EAAK9T,MAGtC,OAAIm7B,EAGK,CACLn5C,KAAM2E,GACNixC,MAAO,GACPY,QAAS,wBAEF4C,EAEF,CACLp5C,KAAM2E,GACNixC,MAAO,GACPY,QAAS,wCAGJ,CACLx2C,KAAM2E,GACNixC,MAAO,GACPY,QAAS,2CAKf,MAAO,CACLx2C,KAAM2E,GACNixC,MAAO,GACPY,QAAS,+BAGX,OAAItvC,GAAK2qB,GAAYC,GAASC,GAAaD,KAAUgF,GAAYhF,KAExD,CACL9xB,KAAM2E,GACNixC,MAAO,EACPY,QAAS,oBAIN,CACLx2C,KAAM2E,GACNixC,MAAO,GACPY,QAAS,uBA9EG6C,CAA0BnL,GAC1C,MAAO,CACL0H,MAAOY,EAAQZ,MACf6B,SAAU,CAACjB,4DCPR,MAAM7xC,GAAO,sBAUJixC,GAAM1H,EAAuBnpB,EAAgB1kB,GAC3D,MAAMi5C,EAAuBpL,EAAMG,cAAcW,0BAA0B3oC,IAAI,SAC/E,IAAKizC,EACH,MAAO,CACL1D,MAAO,EACP6B,SAAU,IAId,MAAM5lB,EAAYqc,EAAMwB,UAAU7d,UAC5B0nB,EAAYx0B,EAAOgkB,aAAa5mC,OAEhCs1C,EAA2B,GACjC,IAAI+B,EAAa,EACbrhC,EAAO,EAEX,IAAK,IAAIzV,EAAI42C,EAAqBn3C,OAAS,EAAGO,GAAK,EAAGA,IAAK,CACzD,MAAMF,EAAQ82C,EAAqB52C,GAC7BuR,EAAW4d,EAAUrvB,GAG3B,IAAIyC,EAEJ,IAAI8sB,GAAa9d,GAIf,SAHAhP,EAAQgP,EAAShP,MAMnB,MAAMw0C,EAAgBvL,EAAMG,cAAcxc,UAAUrvB,GAAO6D,IAAI,SACzDqzC,EAAa30B,EAAO6R,YAAY3xB,GAAOzC,MAEvCozC,GAAS8D,EAAavhC,EAC5BqhC,GAAc5D,EAEd6B,EAASl4C,KAAK,CACZq2C,MAAOA,EACP51C,KAAM,aACNw2C,QAAS,SAASiD,EAAc90C,WAAWM,OAAWy0C,qBAGxDvhC,GAAQohC,EAGV,MAAO,CACL3D,MAAO4D,EACP/B,SAAUA,2DClBd,MAAMkC,GAAyC,YAK/BC,GAASj1C,EAAc0X,GACrCs9B,GAAgBh1C,GAAQ0X,WAGVhW,GAAI1B,GAClB,OAAOg1C,GAAgBh1C,YAGTy/B,GAAK6P,EAA4B4F,EAAc90B,EAAgBhf,GAoB7E,OAnBK8zC,EAAMtG,MAAQxtC,IAAU8zC,EAAMtG,KAAKpxC,QAYtC8xC,EAAMN,MAAMhxC,SAASm3C,IACnB1V,GAAK0V,EAAiCD,EAAO90B,EAAQhf,EAAQ,MAE3D8zC,EAAMtG,KAAKxtC,GAAOmuC,cACpBD,EAAMN,MAAMrrC,KAAKyxC,GAAuBF,EAAMtG,KAAKxtC,GAAOmuC,aAAcnvB,EAAQ80B,EAAM7nB,WAfpF6nB,EAAMhE,SAAWgE,EAAM9D,YACzB9B,EAAMN,MAAMrrC,KAAK0xC,GAAkBH,EAAMhE,SAAWgE,EAAM9D,SAAUhxB,EAAQ80B,EAAM7nB,SAC9E6nB,EAAM9D,UACJ9B,EAAMN,MAAMxxC,OAAS,GAEvB8xC,EAAMN,MAAMprC,OAAO,IAapB0rC,WAGO+F,GAAkBr1C,EAAyBogB,EAAgB3e,GACzE,MAAO,CAAC6zC,EAAoBC,IAEjBC,GADLx1C,aAAgBtG,MACQsG,EAEA,CAACA,GAFKs1C,EAAIC,EAAIn1B,EAAQ3e,YAOtC2zC,GACdp1C,EACAogB,EACA3e,GAEA,MAAO,CAACg0C,EAAyBC,KAC/B,MAAMJ,EAAKhE,GAAqBmE,GAC1BF,EAAKjE,GAAqBoE,GAChC,OACSF,GADLx1C,aAAgBtG,MACQsG,EAEA,CAACA,GAFKs1C,EAAIC,EAAIn1B,EAAQ3e,IAOtD,SAAS+zC,GACPx1C,EACAs1C,EACAC,EACAn1B,EACA3e,GAEA,IAAK,MAAMuvC,KAAehxC,EAAM,CAC9B,MAAM21C,EAAkBpB,GAASgB,EAAIvE,EAAa5wB,EAAQ3e,GAAKwvC,MAAQsD,GAASe,EAAItE,EAAa5wB,EAAQ3e,GAAKwvC,MAC9G,GAAwB,IAApB0E,EACF,OAAOA,EAGX,OAAO,WAGOpB,GAASqB,EAAuB5E,EAAqB5wB,EAAgB3e,GACnF,QAA2C4B,IAAvCuyC,EAAMC,gBAAgB7E,GACxB,OAAO4E,EAAMC,gBAAgB7E,GAE/B,MACMC,EADKvvC,GAAIsvC,EACDlxC,CAAG81C,EAAOx1B,EAAQ3e,GAEhC,OADAm0C,EAAME,gBAAgB9E,EAAaC,GAC5BA,EAGF,MAAM8E,GAAgB,gBAC7Bd,GAASc,GAAe3B,IAExBa,GAASe,GAAkBC,IAC3BhB,GAASiB,GAAiBC,yMChIVtzB,GAAQoqB,EAA6B7sB,EAAgB3e,GACnE,MAAM20C,EAAiC,GAgBvC,OAfAnJ,EAAYA,EAAUhyC,KAAI,SAAUsuC,GAYlC,OAXI9nC,EAAIqhB,0CACNymB,WAiBJA,EACAnpB,EACAg2B,EACA30C,GAEA,CAAC6gB,EAAaH,EAAW6mB,EAAgBhnB,GAAWhkB,SAASsK,IAC3D8tC,EAAU9tC,GAAWihC,EAAMqC,0BAA0BtjC,MAGvD,MAAMujC,EAAQuK,EAAUj0B,GACxB,QAAc9e,IAAVwoC,GAAuBze,GAAaye,KAEpCuK,EAAU9zB,IACVlC,EAAOklB,YAAYuG,GAASpqC,EAAIqhB,wCAAwCC,gBACxE,MAMoB1f,IAAhBwoC,EAAMpyB,QACRoyB,EAAMpyB,MAAQ,IAKhB,MAAM48B,EAAapiC,GAAU43B,GACzBA,EAAMpyB,aAAyBpW,IAAfgzC,GAA4B9jC,GAAkB8jC,MAC3D9M,EAAMwB,UAAU/d,SACnBuc,EAAMwB,UAAU/d,OAAS,CAACvO,KAAM,MAMxC,MAAMktB,EAAQyK,EAAUp0B,GACxB,GAAIoL,GAAaue,KAEbyK,EAAUpN,IACV5oB,EAAOklB,YAAYqG,GAASlqC,EAAIqhB,wCAAwCC,gBACxE,MAEoB1f,IAAhBsoC,EAAMlyB,QACRkyB,EAAMlyB,MAAQ,IAKhB,MAAM68B,EAAariC,GAAU03B,GACzBA,EAAMlyB,aAAyBpW,IAAfizC,GAA4B/jC,GAAkB+jC,MAC3D/M,EAAMwB,UAAUhe,QACnBwc,EAAMwB,UAAUhe,MAAQ,CAACtO,KAAM,MAMvC,OAAO8qB,EA1EKzmB,CAAwCymB,EAAOnpB,EAAQg2B,EAAW30C,IAGxEA,EAAIwhB,sCACNsmB,WA0EJA,EACAnpB,EACAg2B,EACA30C,GAEA20C,EAAuB,MAAI7M,EAAMqC,0BAA0B5hB,GAE3D,MAAMkiB,EAAYkK,EAAuB,MAEvChpB,GAAa8e,SACC7oC,IAAd6oC,IACCA,EAAU7wC,OAASukB,IAAgBssB,EAAU7wC,OAASqvB,GAAazkB,MACpEma,EAAOklB,YAAY4G,GAAazqC,EAAIwhB,oCAAoCF,sBAEhD1f,IAApB6oC,EAAUzyB,QACZyyB,EAAUzyB,MAAQ,IAGhByyB,EAAUzyB,QACNyyB,EAAUzyB,MAAqB1G,QAClCm5B,EAAUzyB,MAAqBvG,OAASzR,EAAIwhB,oCAAoCC,WAKvF,OAAOqmB,EAnGKtmB,CAAoCsmB,EAAOnpB,EAAQg2B,EAAW30C,IAGpEA,EAAI0hB,6CACNomB,WAmGJA,EACAnpB,EACAg2B,EACA30C,GAMA,GAJA,CAACunC,EAAgBhnB,EAAWG,GAAWnkB,SAASsK,IAC9C8tC,EAAU9tC,GAAWihC,EAAMqC,0BAA0BtjC,WAGrBjF,IAA9B+yC,EAAUpN,GAA+B,CAC3C,MAAM2C,EAAQyK,EAAUp0B,GAClB6pB,EAAQuK,EAAUj0B,GAEtBiL,GAAaue,IACbve,GAAaye,SACHxoC,IAAVwoC,GACAA,EAAMvrC,OACNiS,GAAkB0B,GAAU43B,UAEdxoC,IAAVsoC,GACEvrB,EAAOklB,YAAYuG,GAASpqC,EAAI0hB,2CAA2CJ,sBAC1D1f,IAAfsoC,EAAMjyB,OACRiyB,EAAMjyB,KAAO,IAGXiyB,EAAMjyB,OAAUiyB,EAAMjyB,KAAmBjP,SAC1CkhC,EAAMjyB,KAAmBjP,OAAS,QAO7C,OAAO8+B,EApIKpmB,CAA2ComB,EAAOnpB,EAAQg2B,EAAW30C,IAExE8nC,cChBKgN,GAASjpB,EAAkBlN,EAAgB3e,EAAmB8e,IAE5E,MAAMgpB,EAAQ4G,GAAeqG,MAAMlpB,EAAOlN,EAAQ3e,GAC5CioC,EAAgBH,EAAMG,cAI5B,IAAIuD,EAAY,CAAC1D,GAYjB,OAXA9nC,EAAIkf,mBAAmB3iB,SAASy4C,IAC9B,MAAMz8B,EAAOW,GAAQ87B,GAErB,GAAI/M,EAAciB,YAAY3wB,GAAO,CAEnC,MACM08B,EADa3J,GAAc/yB,EACjB28B,CAAWjN,EAAetpB,EAAQ3e,GAClDwrC,EAAYA,EAAU3yC,OAAOo8C,EAAS,SAItCj1C,EAAIohB,SAEwC,OAA5CphB,EAAIwhB,qCAC4C,OAAhDxhB,EAAIqhB,yCAC+C,OAAnDrhB,EAAI0hB,2CAMD8pB,EAJIpqB,GAAQoqB,EAAW7sB,EAAQ3e,4ICxBdX,EAAUsf,EAAgBiN,GAiBlD,MAAO,CACL6nB,MAdFp0C,EAACjH,OAAA0M,OAAA1M,OAAA0M,OAAA,GACIykB,GAAUlqB,IAAE,CACfusB,OAAMxzB,OAAA0M,OAAA1M,OAAA0M,OAAA1M,OAAA0M,OAAA,GACDga,IACA8M,GACAvsB,EAAEusB,UAUP2C,OAJayP,GADSmP,GADN2H,GAASz1C,EAAE+rB,KAAMzM,EAAQtf,EAAEusB,QACLvsB,EAAE8tC,MACL9tC,EAAGsf,EAAQ","file":"build/compassql.min.js.map","sourcesContent":["Array.prototype.flat||Object.defineProperty(Array.prototype,\"flat\",{configurable:!0,value:function r(){var t=isNaN(arguments[0])?1:Number(arguments[0]);return t?Array.prototype.reduce.call(this,function(a,e){return Array.isArray(e)?a.push.apply(a,r.call(e,t-1)):a.push(e),a},[]):Array.prototype.slice.call(this)},writable:!0}),Array.prototype.flatMap||Object.defineProperty(Array.prototype,\"flatMap\",{configurable:!0,value:function(r){return Array.prototype.map.apply(this,arguments).flat()},writable:!0})\n","var clone = (function() {\n'use strict';\n\nfunction _instanceof(obj, type) {\n  return type != null && obj instanceof type;\n}\n\nvar nativeMap;\ntry {\n  nativeMap = Map;\n} catch(_) {\n  // maybe a reference error because no `Map`. Give it a dummy value that no\n  // value will ever be an instanceof.\n  nativeMap = function() {};\n}\n\nvar nativeSet;\ntry {\n  nativeSet = Set;\n} catch(_) {\n  nativeSet = function() {};\n}\n\nvar nativePromise;\ntry {\n  nativePromise = Promise;\n} catch(_) {\n  nativePromise = function() {};\n}\n\n/**\n * Clones (copies) an Object using deep copying.\n *\n * This function supports circular references by default, but if you are certain\n * there are no circular references in your object, you can save some CPU time\n * by calling clone(obj, false).\n *\n * Caution: if `circular` is false and `parent` contains circular references,\n * your program may enter an infinite loop and crash.\n *\n * @param `parent` - the object to be cloned\n * @param `circular` - set to true if the object to be cloned may contain\n *    circular references. (optional - true by default)\n * @param `depth` - set to a number if the object is only to be cloned to\n *    a particular depth. (optional - defaults to Infinity)\n * @param `prototype` - sets the prototype to be used when cloning an object.\n *    (optional - defaults to parent prototype).\n * @param `includeNonEnumerable` - set to true if the non-enumerable properties\n *    should be cloned as well. Non-enumerable properties on the prototype\n *    chain will be ignored. (optional - false by default)\n*/\nfunction clone(parent, circular, depth, prototype, includeNonEnumerable) {\n  if (typeof circular === 'object') {\n    depth = circular.depth;\n    prototype = circular.prototype;\n    includeNonEnumerable = circular.includeNonEnumerable;\n    circular = circular.circular;\n  }\n  // maintain two arrays for circular references, where corresponding parents\n  // and children have the same index\n  var allParents = [];\n  var allChildren = [];\n\n  var useBuffer = typeof Buffer != 'undefined';\n\n  if (typeof circular == 'undefined')\n    circular = true;\n\n  if (typeof depth == 'undefined')\n    depth = Infinity;\n\n  // recurse this function so we don't reset allParents and allChildren\n  function _clone(parent, depth) {\n    // cloning null always returns null\n    if (parent === null)\n      return null;\n\n    if (depth === 0)\n      return parent;\n\n    var child;\n    var proto;\n    if (typeof parent != 'object') {\n      return parent;\n    }\n\n    if (_instanceof(parent, nativeMap)) {\n      child = new nativeMap();\n    } else if (_instanceof(parent, nativeSet)) {\n      child = new nativeSet();\n    } else if (_instanceof(parent, nativePromise)) {\n      child = new nativePromise(function (resolve, reject) {\n        parent.then(function(value) {\n          resolve(_clone(value, depth - 1));\n        }, function(err) {\n          reject(_clone(err, depth - 1));\n        });\n      });\n    } else if (clone.__isArray(parent)) {\n      child = [];\n    } else if (clone.__isRegExp(parent)) {\n      child = new RegExp(parent.source, __getRegExpFlags(parent));\n      if (parent.lastIndex) child.lastIndex = parent.lastIndex;\n    } else if (clone.__isDate(parent)) {\n      child = new Date(parent.getTime());\n    } else if (useBuffer && Buffer.isBuffer(parent)) {\n      if (Buffer.allocUnsafe) {\n        // Node.js >= 4.5.0\n        child = Buffer.allocUnsafe(parent.length);\n      } else {\n        // Older Node.js versions\n        child = new Buffer(parent.length);\n      }\n      parent.copy(child);\n      return child;\n    } else if (_instanceof(parent, Error)) {\n      child = Object.create(parent);\n    } else {\n      if (typeof prototype == 'undefined') {\n        proto = Object.getPrototypeOf(parent);\n        child = Object.create(proto);\n      }\n      else {\n        child = Object.create(prototype);\n        proto = prototype;\n      }\n    }\n\n    if (circular) {\n      var index = allParents.indexOf(parent);\n\n      if (index != -1) {\n        return allChildren[index];\n      }\n      allParents.push(parent);\n      allChildren.push(child);\n    }\n\n    if (_instanceof(parent, nativeMap)) {\n      parent.forEach(function(value, key) {\n        var keyChild = _clone(key, depth - 1);\n        var valueChild = _clone(value, depth - 1);\n        child.set(keyChild, valueChild);\n      });\n    }\n    if (_instanceof(parent, nativeSet)) {\n      parent.forEach(function(value) {\n        var entryChild = _clone(value, depth - 1);\n        child.add(entryChild);\n      });\n    }\n\n    for (var i in parent) {\n      var attrs;\n      if (proto) {\n        attrs = Object.getOwnPropertyDescriptor(proto, i);\n      }\n\n      if (attrs && attrs.set == null) {\n        continue;\n      }\n      child[i] = _clone(parent[i], depth - 1);\n    }\n\n    if (Object.getOwnPropertySymbols) {\n      var symbols = Object.getOwnPropertySymbols(parent);\n      for (var i = 0; i < symbols.length; i++) {\n        // Don't need to worry about cloning a symbol because it is a primitive,\n        // like a number or string.\n        var symbol = symbols[i];\n        var descriptor = Object.getOwnPropertyDescriptor(parent, symbol);\n        if (descriptor && !descriptor.enumerable && !includeNonEnumerable) {\n          continue;\n        }\n        child[symbol] = _clone(parent[symbol], depth - 1);\n        if (!descriptor.enumerable) {\n          Object.defineProperty(child, symbol, {\n            enumerable: false\n          });\n        }\n      }\n    }\n\n    if (includeNonEnumerable) {\n      var allPropertyNames = Object.getOwnPropertyNames(parent);\n      for (var i = 0; i < allPropertyNames.length; i++) {\n        var propertyName = allPropertyNames[i];\n        var descriptor = Object.getOwnPropertyDescriptor(parent, propertyName);\n        if (descriptor && descriptor.enumerable) {\n          continue;\n        }\n        child[propertyName] = _clone(parent[propertyName], depth - 1);\n        Object.defineProperty(child, propertyName, {\n          enumerable: false\n        });\n      }\n    }\n\n    return child;\n  }\n\n  return _clone(parent, depth);\n}\n\n/**\n * Simple flat clone using prototype, accepts only objects, usefull for property\n * override on FLAT configuration object (no nested props).\n *\n * USE WITH CAUTION! This may not behave as you wish if you do not know how this\n * works.\n */\nclone.clonePrototype = function clonePrototype(parent) {\n  if (parent === null)\n    return null;\n\n  var c = function () {};\n  c.prototype = parent;\n  return new c();\n};\n\n// private utility functions\n\nfunction __objToStr(o) {\n  return Object.prototype.toString.call(o);\n}\nclone.__objToStr = __objToStr;\n\nfunction __isDate(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Date]';\n}\nclone.__isDate = __isDate;\n\nfunction __isArray(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object Array]';\n}\nclone.__isArray = __isArray;\n\nfunction __isRegExp(o) {\n  return typeof o === 'object' && __objToStr(o) === '[object RegExp]';\n}\nclone.__isRegExp = __isRegExp;\n\nfunction __getRegExpFlags(re) {\n  var flags = '';\n  if (re.global) flags += 'g';\n  if (re.ignoreCase) flags += 'i';\n  if (re.multiline) flags += 'm';\n  return flags;\n}\nclone.__getRegExpFlags = __getRegExpFlags;\n\nreturn clone;\n})();\n\nif (typeof module === 'object' && module.exports) {\n  module.exports = clone;\n}\n","function accessor (fn, fields, name) {\n  fn.fields = fields || [];\n  fn.fname = name;\n  return fn;\n}\nfunction accessorName(fn) {\n  return fn == null ? null : fn.fname;\n}\nfunction accessorFields(fn) {\n  return fn == null ? null : fn.fields;\n}\n\nfunction getter (path) {\n  return path.length === 1 ? get1(path[0]) : getN(path);\n}\n\nconst get1 = field => function (obj) {\n  return obj[field];\n};\n\nconst getN = path => {\n  const len = path.length;\n  return function (obj) {\n    for (let i = 0; i < len; ++i) {\n      obj = obj[path[i]];\n    }\n\n    return obj;\n  };\n};\n\nfunction error (message) {\n  throw Error(message);\n}\n\nfunction splitAccessPath (p) {\n  const path = [],\n        n = p.length;\n  let q = null,\n      b = 0,\n      s = '',\n      i,\n      j,\n      c;\n  p = p + '';\n\n  function push() {\n    path.push(s + p.substring(i, j));\n    s = '';\n    i = j + 1;\n  }\n\n  for (i = j = 0; j < n; ++j) {\n    c = p[j];\n\n    if (c === '\\\\') {\n      s += p.substring(i, j);\n      s += p.substring(++j, ++j);\n      i = j;\n    } else if (c === q) {\n      push();\n      q = null;\n      b = -1;\n    } else if (q) {\n      continue;\n    } else if (i === b && c === '\"') {\n      i = j + 1;\n      q = c;\n    } else if (i === b && c === \"'\") {\n      i = j + 1;\n      q = c;\n    } else if (c === '.' && !b) {\n      if (j > i) {\n        push();\n      } else {\n        i = j + 1;\n      }\n    } else if (c === '[') {\n      if (j > i) push();\n      b = i = j + 1;\n    } else if (c === ']') {\n      if (!b) error('Access path missing open bracket: ' + p);\n      if (b > 0) push();\n      b = 0;\n      i = j + 1;\n    }\n  }\n\n  if (b) error('Access path missing closing bracket: ' + p);\n  if (q) error('Access path missing closing quote: ' + p);\n\n  if (j > i) {\n    j++;\n    push();\n  }\n\n  return path;\n}\n\nfunction field (field, name, opt) {\n  const path = splitAccessPath(field);\n  field = path.length === 1 ? path[0] : field;\n  return accessor((opt && opt.get || getter)(path), [field], name || field);\n}\n\nconst id = field('id');\nconst identity = accessor(_ => _, [], 'identity');\nconst zero = accessor(() => 0, [], 'zero');\nconst one = accessor(() => 1, [], 'one');\nconst truthy = accessor(() => true, [], 'true');\nconst falsy = accessor(() => false, [], 'false');\n\nfunction log$1(method, level, input) {\n  const args = [level].concat([].slice.call(input));\n  console[method].apply(console, args); // eslint-disable-line no-console\n}\n\nconst None = 0;\nconst Error$1 = 1;\nconst Warn = 2;\nconst Info = 3;\nconst Debug = 4;\nfunction logger (_, method) {\n  let level = _ || None;\n  return {\n    level(_) {\n      if (arguments.length) {\n        level = +_;\n        return this;\n      } else {\n        return level;\n      }\n    },\n\n    error() {\n      if (level >= Error$1) log$1(method || 'error', 'ERROR', arguments);\n      return this;\n    },\n\n    warn() {\n      if (level >= Warn) log$1(method || 'warn', 'WARN', arguments);\n      return this;\n    },\n\n    info() {\n      if (level >= Info) log$1(method || 'log', 'INFO', arguments);\n      return this;\n    },\n\n    debug() {\n      if (level >= Debug) log$1(method || 'log', 'DEBUG', arguments);\n      return this;\n    }\n\n  };\n}\n\nvar isArray = Array.isArray;\n\nfunction isObject (_) {\n  return _ === Object(_);\n}\n\nconst isLegalKey = key => key !== '__proto__';\n\nfunction mergeConfig(...configs) {\n  return configs.reduce((out, source) => {\n    for (const key in source) {\n      if (key === 'signals') {\n        // for signals, we merge the signals arrays\n        // source signals take precedence over\n        // existing signals with the same name\n        out.signals = mergeNamed(out.signals, source.signals);\n      } else {\n        // otherwise, merge objects subject to recursion constraints\n        // for legend block, recurse for the layout entry only\n        // for style block, recurse for all properties\n        // otherwise, no recursion: objects overwrite, no merging\n        const r = key === 'legend' ? {\n          layout: 1\n        } : key === 'style' ? true : null;\n        writeConfig(out, key, source[key], r);\n      }\n    }\n\n    return out;\n  }, {});\n}\nfunction writeConfig(output, key, value, recurse) {\n  if (!isLegalKey(key)) return;\n  let k, o;\n\n  if (isObject(value) && !isArray(value)) {\n    o = isObject(output[key]) ? output[key] : output[key] = {};\n\n    for (k in value) {\n      if (recurse && (recurse === true || recurse[k])) {\n        writeConfig(o, k, value[k]);\n      } else if (isLegalKey(k)) {\n        o[k] = value[k];\n      }\n    }\n  } else {\n    output[key] = value;\n  }\n}\n\nfunction mergeNamed(a, b) {\n  if (a == null) return b;\n  const map = {},\n        out = [];\n\n  function add(_) {\n    if (!map[_.name]) {\n      map[_.name] = 1;\n      out.push(_);\n    }\n  }\n\n  b.forEach(add);\n  a.forEach(add);\n  return out;\n}\n\nfunction peek (array) {\n  return array[array.length - 1];\n}\n\nfunction toNumber (_) {\n  return _ == null || _ === '' ? null : +_;\n}\n\nconst exp = sign => x => sign * Math.exp(x);\n\nconst log = sign => x => Math.log(sign * x);\n\nconst symlog = c => x => Math.sign(x) * Math.log1p(Math.abs(x / c));\n\nconst symexp = c => x => Math.sign(x) * Math.expm1(Math.abs(x)) * c;\n\nconst pow = exponent => x => x < 0 ? -Math.pow(-x, exponent) : Math.pow(x, exponent);\n\nfunction pan(domain, delta, lift, ground) {\n  const d0 = lift(domain[0]),\n        d1 = lift(peek(domain)),\n        dd = (d1 - d0) * delta;\n  return [ground(d0 - dd), ground(d1 - dd)];\n}\n\nfunction panLinear(domain, delta) {\n  return pan(domain, delta, toNumber, identity);\n}\nfunction panLog(domain, delta) {\n  var sign = Math.sign(domain[0]);\n  return pan(domain, delta, log(sign), exp(sign));\n}\nfunction panPow(domain, delta, exponent) {\n  return pan(domain, delta, pow(exponent), pow(1 / exponent));\n}\nfunction panSymlog(domain, delta, constant) {\n  return pan(domain, delta, symlog(constant), symexp(constant));\n}\n\nfunction zoom(domain, anchor, scale, lift, ground) {\n  const d0 = lift(domain[0]),\n        d1 = lift(peek(domain)),\n        da = anchor != null ? lift(anchor) : (d0 + d1) / 2;\n  return [ground(da + (d0 - da) * scale), ground(da + (d1 - da) * scale)];\n}\n\nfunction zoomLinear(domain, anchor, scale) {\n  return zoom(domain, anchor, scale, toNumber, identity);\n}\nfunction zoomLog(domain, anchor, scale) {\n  const sign = Math.sign(domain[0]);\n  return zoom(domain, anchor, scale, log(sign), exp(sign));\n}\nfunction zoomPow(domain, anchor, scale, exponent) {\n  return zoom(domain, anchor, scale, pow(exponent), pow(1 / exponent));\n}\nfunction zoomSymlog(domain, anchor, scale, constant) {\n  return zoom(domain, anchor, scale, symlog(constant), symexp(constant));\n}\n\nfunction quarter(date) {\n  return 1 + ~~(new Date(date).getMonth() / 3);\n}\nfunction utcquarter(date) {\n  return 1 + ~~(new Date(date).getUTCMonth() / 3);\n}\n\nfunction array (_) {\n  return _ != null ? isArray(_) ? _ : [_] : [];\n}\n\n/**\n * Span-preserving range clamp. If the span of the input range is less\n * than (max - min) and an endpoint exceeds either the min or max value,\n * the range is translated such that the span is preserved and one\n * endpoint touches the boundary of the min/max range.\n * If the span exceeds (max - min), the range [min, max] is returned.\n */\nfunction clampRange (range, min, max) {\n  let lo = range[0],\n      hi = range[1],\n      span;\n\n  if (hi < lo) {\n    span = hi;\n    hi = lo;\n    lo = span;\n  }\n\n  span = hi - lo;\n  return span >= max - min ? [min, max] : [lo = Math.min(Math.max(lo, min), max - span), lo + span];\n}\n\nfunction isFunction (_) {\n  return typeof _ === 'function';\n}\n\nconst DESCENDING = 'descending';\nfunction compare (fields, orders, opt) {\n  opt = opt || {};\n  orders = array(orders) || [];\n  const ord = [],\n        get = [],\n        fmap = {},\n        gen = opt.comparator || comparator;\n  array(fields).forEach((f, i) => {\n    if (f == null) return;\n    ord.push(orders[i] === DESCENDING ? -1 : 1);\n    get.push(f = isFunction(f) ? f : field(f, null, opt));\n    (accessorFields(f) || []).forEach(_ => fmap[_] = 1);\n  });\n  return get.length === 0 ? null : accessor(gen(get, ord), Object.keys(fmap));\n}\nconst ascending = (u, v) => (u < v || u == null) && v != null ? -1 : (u > v || v == null) && u != null ? 1 : (v = v instanceof Date ? +v : v, u = u instanceof Date ? +u : u) !== u && v === v ? -1 : v !== v && u === u ? 1 : 0;\n\nconst comparator = (fields, orders) => fields.length === 1 ? compare1(fields[0], orders[0]) : compareN(fields, orders, fields.length);\n\nconst compare1 = (field, order) => function (a, b) {\n  return ascending(field(a), field(b)) * order;\n};\n\nconst compareN = (fields, orders, n) => {\n  orders.push(0); // pad zero for convenient lookup\n\n  return function (a, b) {\n    let f,\n        c = 0,\n        i = -1;\n\n    while (c === 0 && ++i < n) {\n      f = fields[i];\n      c = ascending(f(a), f(b));\n    }\n\n    return c * orders[i];\n  };\n};\n\nfunction constant (_) {\n  return isFunction(_) ? _ : () => _;\n}\n\nfunction debounce (delay, handler) {\n  let tid;\n  return e => {\n    if (tid) clearTimeout(tid);\n    tid = setTimeout(() => (handler(e), tid = null), delay);\n  };\n}\n\nfunction extend (_) {\n  for (let x, k, i = 1, len = arguments.length; i < len; ++i) {\n    x = arguments[i];\n\n    for (k in x) {\n      _[k] = x[k];\n    }\n  }\n\n  return _;\n}\n\n/**\n * Return an array with minimum and maximum values, in the\n * form [min, max]. Ignores null, undefined, and NaN values.\n */\nfunction extent (array, f) {\n  let i = 0,\n      n,\n      v,\n      min,\n      max;\n\n  if (array && (n = array.length)) {\n    if (f == null) {\n      // find first valid value\n      for (v = array[i]; i < n && (v == null || v !== v); v = array[++i]);\n\n      min = max = v; // visit all other values\n\n      for (; i < n; ++i) {\n        v = array[i]; // skip null/undefined; NaN will fail all comparisons\n\n        if (v != null) {\n          if (v < min) min = v;\n          if (v > max) max = v;\n        }\n      }\n    } else {\n      // find first valid value\n      for (v = f(array[i]); i < n && (v == null || v !== v); v = f(array[++i]));\n\n      min = max = v; // visit all other values\n\n      for (; i < n; ++i) {\n        v = f(array[i]); // skip null/undefined; NaN will fail all comparisons\n\n        if (v != null) {\n          if (v < min) min = v;\n          if (v > max) max = v;\n        }\n      }\n    }\n  }\n\n  return [min, max];\n}\n\nfunction extentIndex (array, f) {\n  const n = array.length;\n  let i = -1,\n      a,\n      b,\n      c,\n      u,\n      v;\n\n  if (f == null) {\n    while (++i < n) {\n      b = array[i];\n\n      if (b != null && b >= b) {\n        a = c = b;\n        break;\n      }\n    }\n\n    if (i === n) return [-1, -1];\n    u = v = i;\n\n    while (++i < n) {\n      b = array[i];\n\n      if (b != null) {\n        if (a > b) {\n          a = b;\n          u = i;\n        }\n\n        if (c < b) {\n          c = b;\n          v = i;\n        }\n      }\n    }\n  } else {\n    while (++i < n) {\n      b = f(array[i], i, array);\n\n      if (b != null && b >= b) {\n        a = c = b;\n        break;\n      }\n    }\n\n    if (i === n) return [-1, -1];\n    u = v = i;\n\n    while (++i < n) {\n      b = f(array[i], i, array);\n\n      if (b != null) {\n        if (a > b) {\n          a = b;\n          u = i;\n        }\n\n        if (c < b) {\n          c = b;\n          v = i;\n        }\n      }\n    }\n  }\n\n  return [u, v];\n}\n\nconst hop = Object.prototype.hasOwnProperty;\nfunction has (object, property) {\n  return hop.call(object, property);\n}\n\nconst NULL = {};\nfunction fastmap (input) {\n  let obj = {},\n      test;\n\n  function has$1(key) {\n    return has(obj, key) && obj[key] !== NULL;\n  }\n\n  const map = {\n    size: 0,\n    empty: 0,\n    object: obj,\n    has: has$1,\n\n    get(key) {\n      return has$1(key) ? obj[key] : undefined;\n    },\n\n    set(key, value) {\n      if (!has$1(key)) {\n        ++map.size;\n        if (obj[key] === NULL) --map.empty;\n      }\n\n      obj[key] = value;\n      return this;\n    },\n\n    delete(key) {\n      if (has$1(key)) {\n        --map.size;\n        ++map.empty;\n        obj[key] = NULL;\n      }\n\n      return this;\n    },\n\n    clear() {\n      map.size = map.empty = 0;\n      map.object = obj = {};\n    },\n\n    test(_) {\n      if (arguments.length) {\n        test = _;\n        return map;\n      } else {\n        return test;\n      }\n    },\n\n    clean() {\n      const next = {};\n      let size = 0;\n\n      for (const key in obj) {\n        const value = obj[key];\n\n        if (value !== NULL && (!test || !test(value))) {\n          next[key] = value;\n          ++size;\n        }\n      }\n\n      map.size = size;\n      map.empty = 0;\n      map.object = obj = next;\n    }\n\n  };\n  if (input) Object.keys(input).forEach(key => {\n    map.set(key, input[key]);\n  });\n  return map;\n}\n\nfunction flush (range, value, threshold, left, right, center) {\n  if (!threshold && threshold !== 0) return center;\n  const t = +threshold;\n  let a = range[0],\n      b = peek(range),\n      l; // swap endpoints if range is reversed\n\n  if (b < a) {\n    l = a;\n    a = b;\n    b = l;\n  } // compare value to endpoints\n\n\n  l = Math.abs(value - a);\n  const r = Math.abs(b - value); // adjust if value is within threshold distance of endpoint\n\n  return l < r && l <= t ? left : r <= t ? right : center;\n}\n\nfunction inherits (child, parent, members) {\n  const proto = child.prototype = Object.create(parent.prototype);\n  Object.defineProperty(proto, 'constructor', {\n    value: child,\n    writable: true,\n    enumerable: true,\n    configurable: true\n  });\n  return extend(proto, members);\n}\n\n/**\n * Predicate that returns true if the value lies within the span\n * of the given range. The left and right flags control the use\n * of inclusive (true) or exclusive (false) comparisons.\n */\nfunction inrange (value, range, left, right) {\n  let r0 = range[0],\n      r1 = range[range.length - 1],\n      t;\n\n  if (r0 > r1) {\n    t = r0;\n    r0 = r1;\n    r1 = t;\n  }\n\n  left = left === undefined || left;\n  right = right === undefined || right;\n  return (left ? r0 <= value : r0 < value) && (right ? value <= r1 : value < r1);\n}\n\nfunction isBoolean (_) {\n  return typeof _ === 'boolean';\n}\n\nfunction isDate (_) {\n  return Object.prototype.toString.call(_) === '[object Date]';\n}\n\nfunction isIterable (_) {\n  return _ && isFunction(_[Symbol.iterator]);\n}\n\nfunction isNumber (_) {\n  return typeof _ === 'number';\n}\n\nfunction isRegExp (_) {\n  return Object.prototype.toString.call(_) === '[object RegExp]';\n}\n\nfunction isString (_) {\n  return typeof _ === 'string';\n}\n\nfunction key (fields, flat, opt) {\n  if (fields) {\n    fields = flat ? array(fields).map(f => f.replace(/\\\\(.)/g, '$1')) : array(fields);\n  }\n\n  const len = fields && fields.length,\n        gen = opt && opt.get || getter,\n        map = f => gen(flat ? [f] : splitAccessPath(f));\n\n  let fn;\n\n  if (!len) {\n    fn = function () {\n      return '';\n    };\n  } else if (len === 1) {\n    const get = map(fields[0]);\n\n    fn = function (_) {\n      return '' + get(_);\n    };\n  } else {\n    const get = fields.map(map);\n\n    fn = function (_) {\n      let s = '' + get[0](_),\n          i = 0;\n\n      while (++i < len) s += '|' + get[i](_);\n\n      return s;\n    };\n  }\n\n  return accessor(fn, fields, 'key');\n}\n\nfunction lerp (array, frac) {\n  const lo = array[0],\n        hi = peek(array),\n        f = +frac;\n  return !f ? lo : f === 1 ? hi : lo + f * (hi - lo);\n}\n\nconst DEFAULT_MAX_SIZE = 10000; // adapted from https://github.com/dominictarr/hashlru/ (MIT License)\n\nfunction lruCache (maxsize) {\n  maxsize = +maxsize || DEFAULT_MAX_SIZE;\n  let curr, prev, size;\n\n  const clear = () => {\n    curr = {};\n    prev = {};\n    size = 0;\n  };\n\n  const update = (key, value) => {\n    if (++size > maxsize) {\n      prev = curr;\n      curr = {};\n      size = 1;\n    }\n\n    return curr[key] = value;\n  };\n\n  clear();\n  return {\n    clear,\n    has: key => has(curr, key) || has(prev, key),\n    get: key => has(curr, key) ? curr[key] : has(prev, key) ? update(key, prev[key]) : undefined,\n    set: (key, value) => has(curr, key) ? curr[key] = value : update(key, value)\n  };\n}\n\nfunction merge (compare, array0, array1, output) {\n  const n0 = array0.length,\n        n1 = array1.length;\n  if (!n1) return array0;\n  if (!n0) return array1;\n  const merged = output || new array0.constructor(n0 + n1);\n  let i0 = 0,\n      i1 = 0,\n      i = 0;\n\n  for (; i0 < n0 && i1 < n1; ++i) {\n    merged[i] = compare(array0[i0], array1[i1]) > 0 ? array1[i1++] : array0[i0++];\n  }\n\n  for (; i0 < n0; ++i0, ++i) {\n    merged[i] = array0[i0];\n  }\n\n  for (; i1 < n1; ++i1, ++i) {\n    merged[i] = array1[i1];\n  }\n\n  return merged;\n}\n\nfunction repeat (str, reps) {\n  let s = '';\n\n  while (--reps >= 0) s += str;\n\n  return s;\n}\n\nfunction pad (str, length, padchar, align) {\n  const c = padchar || ' ',\n        s = str + '',\n        n = length - s.length;\n  return n <= 0 ? s : align === 'left' ? repeat(c, n) + s : align === 'center' ? repeat(c, ~~(n / 2)) + s + repeat(c, Math.ceil(n / 2)) : s + repeat(c, n);\n}\n\n/**\n * Return the numerical span of an array: the difference between\n * the last and first values.\n */\n\nfunction span (array) {\n  return array && peek(array) - array[0] || 0;\n}\n\nfunction $(x) {\n  return isArray(x) ? '[' + x.map($) + ']' : isObject(x) || isString(x) ? // Output valid JSON and JS source strings.\n  // See http://timelessrepo.com/json-isnt-a-javascript-subset\n  JSON.stringify(x).replace('\\u2028', '\\\\u2028').replace('\\u2029', '\\\\u2029') : x;\n}\n\nfunction toBoolean (_) {\n  return _ == null || _ === '' ? null : !_ || _ === 'false' || _ === '0' ? false : !!_;\n}\n\nconst defaultParser = _ => isNumber(_) ? _ : isDate(_) ? _ : Date.parse(_);\n\nfunction toDate (_, parser) {\n  parser = parser || defaultParser;\n  return _ == null || _ === '' ? null : parser(_);\n}\n\nfunction toString (_) {\n  return _ == null || _ === '' ? null : _ + '';\n}\n\nfunction toSet (_) {\n  const s = {},\n        n = _.length;\n\n  for (let i = 0; i < n; ++i) s[_[i]] = true;\n\n  return s;\n}\n\nfunction truncate (str, length, align, ellipsis) {\n  const e = ellipsis != null ? ellipsis : '\\u2026',\n        s = str + '',\n        n = s.length,\n        l = Math.max(0, length - e.length);\n  return n <= length ? s : align === 'left' ? e + s.slice(n - l) : align === 'center' ? s.slice(0, Math.ceil(l / 2)) + e + s.slice(n - ~~(l / 2)) : s.slice(0, l) + e;\n}\n\nfunction visitArray (array, filter, visitor) {\n  if (array) {\n    if (filter) {\n      const n = array.length;\n\n      for (let i = 0; i < n; ++i) {\n        const t = filter(array[i]);\n        if (t) visitor(t, i, array);\n      }\n    } else {\n      array.forEach(visitor);\n    }\n  }\n}\n\nexport { Debug, Error$1 as Error, Info, None, Warn, accessor, accessorFields, accessorName, array, ascending, clampRange, compare, constant, debounce, error, extend, extent, extentIndex, falsy, fastmap, field, flush, has as hasOwnProperty, id, identity, inherits, inrange, isArray, isBoolean, isDate, isFunction, isIterable, isNumber, isObject, isRegExp, isString, key, lerp, logger, lruCache, merge, mergeConfig, one, pad, panLinear, panLog, panPow, panSymlog, peek, quarter, repeat, span, splitAccessPath, $ as stringValue, toBoolean, toDate, toNumber, toSet, toString, truncate, truthy, utcquarter, visitArray, writeConfig, zero, zoomLinear, zoomLog, zoomPow, zoomSymlog };\n","import 'array-flat-polyfill';\nimport {default as clone_} from 'clone';\nimport deepEqual_ from 'fast-deep-equal';\nimport stableStringify from 'fast-json-stable-stringify';\nimport {hasOwnProperty, isNumber, isString, splitAccessPath, stringValue, writeConfig} from 'vega-util';\nimport {isLogicalAnd, isLogicalNot, isLogicalOr, LogicalComposition} from './logical';\n\nexport const deepEqual = deepEqual_;\nexport const duplicate = clone_;\n\n/**\n * Creates an object composed of the picked object properties.\n *\n * var object = {'a': 1, 'b': '2', 'c': 3};\n * pick(object, ['a', 'c']);\n * // → {'a': 1, 'c': 3}\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function pick<T extends object, K extends keyof T>(obj: T, props: readonly K[]): Pick<T, K> {\n  const copy: any = {};\n  for (const prop of props) {\n    if (hasOwnProperty(obj, prop)) {\n      copy[prop] = obj[prop];\n    }\n  }\n  return copy;\n}\n\n/**\n * The opposite of _.pick; this method creates an object composed of the own\n * and inherited enumerable string keyed properties of object that are not omitted.\n */\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function omit<T extends object, K extends keyof T>(obj: T, props: readonly K[]): Omit<T, K> {\n  const copy = {...(obj as any)};\n  for (const prop of props) {\n    delete copy[prop];\n  }\n  return copy;\n}\n\n/**\n * Monkey patch Set so that `stringify` produces a string representation of sets.\n */\nSet.prototype['toJSON'] = function () {\n  return `Set(${[...this].map(x => stableStringify(x)).join(',')})`;\n};\n\n/**\n * Converts any object to a string representation that can be consumed by humans.\n */\nexport const stringify = stableStringify;\n\n/**\n * Converts any object to a string of limited size, or a number.\n */\nexport function hash(a: any): string | number {\n  if (isNumber(a)) {\n    return a;\n  }\n\n  const str = isString(a) ? a : stableStringify(a);\n\n  // short strings can be used as hash directly, longer strings are hashed to reduce memory usage\n  if (str.length < 250) {\n    return str;\n  }\n\n  // from http://werxltd.com/wp/2010/05/13/javascript-implementation-of-javas-string-hashcode-method/\n  let h = 0;\n  for (let i = 0; i < str.length; i++) {\n    const char = str.charCodeAt(i);\n    h = (h << 5) - h + char;\n    h = h & h; // Convert to 32bit integer\n  }\n  return h;\n}\n\nexport function isNullOrFalse(x: any): x is false | null {\n  return x === false || x === null;\n}\n\nexport function contains<T>(array: readonly T[], item: T) {\n  return array.indexOf(item) > -1;\n}\n\n/**\n * Returns true if any item returns true.\n */\nexport function some<T>(arr: readonly T[], f: (d: T, k?: any, i?: any) => boolean) {\n  let i = 0;\n  for (const [k, a] of arr.entries()) {\n    if (f(a, k, i++)) {\n      return true;\n    }\n  }\n  return false;\n}\n\n/**\n * Returns true if all items return true.\n */\nexport function every<T>(arr: readonly T[], f: (d: T, k?: any, i?: any) => boolean) {\n  let i = 0;\n  for (const [k, a] of arr.entries()) {\n    if (!f(a, k, i++)) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * Like TS Partial but applies recursively to all properties.\n */\nexport type DeepPartial<T> = {[P in keyof T]?: DeepPartial<T[P]>};\n\n/**\n * recursively merges src into dest\n */\nexport function mergeDeep<T>(dest: T, ...src: readonly DeepPartial<T>[]): T {\n  for (const s of src) {\n    deepMerge_(dest, s ?? {});\n  }\n  return dest;\n}\n\nfunction deepMerge_(dest: any, src: any) {\n  for (const property of keys(src)) {\n    writeConfig(dest, property, src[property], true);\n  }\n}\n\nexport function unique<T>(values: readonly T[], f: (item: T) => string | number): T[] {\n  const results: T[] = [];\n  const u = {};\n  let v: string | number;\n  for (const val of values) {\n    v = f(val);\n    if (v in u) {\n      continue;\n    }\n    u[v] = 1;\n    results.push(val);\n  }\n  return results;\n}\n\nexport type Dict<T> = Record<string, T>;\n\n/**\n * Returns true if the two dictionaries disagree. Applies only to defined values.\n */\nexport function isEqual<T>(dict: Dict<T>, other: Dict<T>) {\n  const dictKeys = keys(dict);\n  const otherKeys = keys(other);\n  if (dictKeys.length !== otherKeys.length) {\n    return false;\n  }\n  for (const key of dictKeys) {\n    if (dict[key] !== other[key]) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function setEqual<T>(a: Set<T>, b: Set<T>) {\n  if (a.size !== b.size) {\n    return false;\n  }\n  for (const e of a) {\n    if (!b.has(e)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function hasIntersection<T>(a: ReadonlySet<T>, b: ReadonlySet<T>) {\n  for (const key of a) {\n    if (b.has(key)) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport function prefixGenerator(a: ReadonlySet<string>): ReadonlySet<string> {\n  const prefixes = new Set<string>();\n  for (const x of a) {\n    const splitField = splitAccessPath(x);\n    // Wrap every element other than the first in `[]`\n    const wrappedWithAccessors = splitField.map((y, i) => (i === 0 ? y : `[${y}]`));\n    const computedPrefixes = wrappedWithAccessors.map((_, i) => wrappedWithAccessors.slice(0, i + 1).join(''));\n    for (const y of computedPrefixes) {\n      prefixes.add(y);\n    }\n  }\n  return prefixes;\n}\n\n/**\n * Returns true if a and b have an intersection. Also return true if a or b are undefined\n * since this means we don't know what fields a node produces or depends on.\n */\nexport function fieldIntersection(a: ReadonlySet<string>, b: ReadonlySet<string>): boolean {\n  if (a === undefined || b === undefined) {\n    return true;\n  }\n  return hasIntersection(prefixGenerator(a), prefixGenerator(b));\n}\n\n// eslint-disable-next-line @typescript-eslint/ban-types\nexport function isEmpty(obj: object) {\n  return keys(obj).length === 0;\n}\n\n// This is a stricter version of Object.keys but with better types. See https://github.com/Microsoft/TypeScript/pull/12253#issuecomment-263132208\nexport const keys = Object.keys as <T>(o: T) => Extract<keyof T, string>[];\n\nexport const vals = Object.values;\n\nexport const entries = Object.entries;\n\n// Using mapped type to declare a collect of flags for a string literal type S\n// https://www.typescriptlang.org/docs/handbook/advanced-types.html#mapped-types\nexport type Flag<S extends string> = {[K in S]: 1};\n\nexport function isBoolean(b: any): b is boolean {\n  return b === true || b === false;\n}\n\n/**\n * Convert a string into a valid variable name\n */\nexport function varName(s: string): string {\n  // Replace non-alphanumeric characters (anything besides a-zA-Z0-9_) with _\n  const alphanumericS = s.replace(/\\W/g, '_');\n\n  // Add _ if the string has leading numbers.\n  return (s.match(/^\\d+/) ? '_' : '') + alphanumericS;\n}\n\nexport function logicalExpr<T>(op: LogicalComposition<T>, cb: (...args: readonly any[]) => string): string {\n  if (isLogicalNot(op)) {\n    return '!(' + logicalExpr(op.not, cb) + ')';\n  } else if (isLogicalAnd(op)) {\n    return '(' + op.and.map((and: LogicalComposition<T>) => logicalExpr(and, cb)).join(') && (') + ')';\n  } else if (isLogicalOr(op)) {\n    return '(' + op.or.map((or: LogicalComposition<T>) => logicalExpr(or, cb)).join(') || (') + ')';\n  } else {\n    return cb(op);\n  }\n}\n\n/**\n * Delete nested property of an object, and delete the ancestors of the property if they become empty.\n */\nexport function deleteNestedProperty(obj: any, orderedProps: string[]) {\n  if (orderedProps.length === 0) {\n    return true;\n  }\n  const prop = orderedProps.shift()!; // eslint-disable-line @typescript-eslint/no-non-null-assertion\n  if (prop in obj && deleteNestedProperty(obj[prop], orderedProps)) {\n    delete obj[prop];\n  }\n  return isEmpty(obj);\n}\n\nexport function titleCase(s: string) {\n  return s.charAt(0).toUpperCase() + s.substr(1);\n}\n\n/**\n * Converts a path to an access path with datum.\n * @param path The field name.\n * @param datum The string to use for `datum`.\n */\nexport function accessPathWithDatum(path: string, datum = 'datum') {\n  const pieces = splitAccessPath(path);\n  const prefixes = [];\n  for (let i = 1; i <= pieces.length; i++) {\n    const prefix = `[${pieces.slice(0, i).map(stringValue).join('][')}]`;\n    prefixes.push(`${datum}${prefix}`);\n  }\n  return prefixes.join(' && ');\n}\n\n/**\n * Return access with datum to the flattened field.\n *\n * @param path The field name.\n * @param datum The string to use for `datum`.\n */\nexport function flatAccessWithDatum(path: string, datum: 'datum' | 'parent' | 'datum.datum' = 'datum') {\n  return `${datum}[${stringValue(splitAccessPath(path).join('.'))}]`;\n}\n\nfunction escapePathAccess(string: string) {\n  return string.replace(/(\\[|\\]|\\.|'|\")/g, '\\\\$1');\n}\n\n/**\n * Replaces path accesses with access to non-nested field.\n * For example, `foo[\"bar\"].baz` becomes `foo\\\\.bar\\\\.baz`.\n */\nexport function replacePathInField(path: string) {\n  return `${splitAccessPath(path).map(escapePathAccess).join('\\\\.')}`;\n}\n\n/**\n * Replace all occurrences of a string with another string.\n *\n * @param string the string to replace in\n * @param find the string to replace\n * @param replacement the replacement\n */\nexport function replaceAll(string: string, find: string, replacement: string) {\n  return string.replace(new RegExp(find.replace(/[-/\\\\^$*+?.()|[\\]{}]/g, '\\\\$&'), 'g'), replacement);\n}\n\n/**\n * Remove path accesses with access from field.\n * For example, `foo[\"bar\"].baz` becomes `foo.bar.baz`.\n */\nexport function removePathFromField(path: string) {\n  return `${splitAccessPath(path).join('.')}`;\n}\n\n/**\n * Count the depth of the path. Returns 1 for fields that are not nested.\n */\nexport function accessPathDepth(path: string) {\n  if (!path) {\n    return 0;\n  }\n  return splitAccessPath(path).length;\n}\n\n/**\n * This is a replacement for chained || for numeric properties or properties that respect null so that 0 will be included.\n */\nexport function getFirstDefined<T>(...args: readonly T[]): T | undefined {\n  for (const arg of args) {\n    if (arg !== undefined) {\n      return arg;\n    }\n  }\n  return undefined;\n}\n\n// variable used to generate id\nlet idCounter = 42;\n\n/**\n * Returns a new random id every time it gets called.\n *\n * Has side effect!\n */\nexport function uniqueId(prefix?: string) {\n  const id = ++idCounter;\n  return prefix ? String(prefix) + id : id;\n}\n\n/**\n * Resets the id counter used in uniqueId. This can be useful for testing.\n */\nexport function resetIdCounter() {\n  idCounter = 42;\n}\n\nexport function internalField(name: string) {\n  return isInternalField(name) ? name : `__${name}`;\n}\n\nexport function isInternalField(name: string) {\n  return name.indexOf('__') === 0;\n}\n\n/**\n * Normalize angle to be within [0,360).\n */\nexport function normalizeAngle(angle: number) {\n  if (angle === undefined) {\n    return undefined;\n  }\n  return ((angle % 360) + 360) % 360;\n}\n\n/**\n * Returns whether the passed in value is a valid number.\n */\nexport function isNumeric(value: number | string): boolean {\n  if (isNumber(value)) {\n    return true;\n  }\n  return !isNaN(value as any) && !isNaN(parseFloat(value));\n}\n","'use strict';\n\nmodule.exports = function (data, opts) {\n    if (!opts) opts = {};\n    if (typeof opts === 'function') opts = { cmp: opts };\n    var cycles = (typeof opts.cycles === 'boolean') ? opts.cycles : false;\n\n    var cmp = opts.cmp && (function (f) {\n        return function (node) {\n            return function (a, b) {\n                var aobj = { key: a, value: node[a] };\n                var bobj = { key: b, value: node[b] };\n                return f(aobj, bobj);\n            };\n        };\n    })(opts.cmp);\n\n    var seen = [];\n    return (function stringify (node) {\n        if (node && node.toJSON && typeof node.toJSON === 'function') {\n            node = node.toJSON();\n        }\n\n        if (node === undefined) return;\n        if (typeof node == 'number') return isFinite(node) ? '' + node : 'null';\n        if (typeof node !== 'object') return JSON.stringify(node);\n\n        var i, out;\n        if (Array.isArray(node)) {\n            out = '[';\n            for (i = 0; i < node.length; i++) {\n                if (i) out += ',';\n                out += stringify(node[i]) || 'null';\n            }\n            return out + ']';\n        }\n\n        if (node === null) return 'null';\n\n        if (seen.indexOf(node) !== -1) {\n            if (cycles) return JSON.stringify('__cycle__');\n            throw new TypeError('Converting circular structure to JSON');\n        }\n\n        var seenIndex = seen.push(node) - 1;\n        var keys = Object.keys(node).sort(cmp && cmp(node));\n        out = '';\n        for (i = 0; i < keys.length; i++) {\n            var key = keys[i];\n            var value = stringify(node[key]);\n\n            if (!value) continue;\n            if (out) out += ',';\n            out += JSON.stringify(key) + ':' + value;\n        }\n        seen.splice(seenIndex, 1);\n        return '{' + out + '}';\n    })(data);\n};\n","/*\n * Constants and utilities for encoding channels (Visual variables)\n * such as 'x', 'y', 'color'.\n */\n\nimport {RangeType} from './compile/scale/type';\nimport {Encoding} from './encoding';\nimport {Mark} from './mark';\nimport {EncodingFacetMapping} from './spec/facet';\nimport {Flag, keys} from './util';\n\nexport type Channel = keyof Encoding<any>;\nexport type ExtendedChannel = Channel | FacetChannel;\n\n// Facet\nexport const ROW = 'row' as const;\nexport const COLUMN = 'column' as const;\n\nexport const FACET = 'facet' as const;\n\n// Position\nexport const X = 'x' as const;\nexport const Y = 'y' as const;\nexport const X2 = 'x2' as const;\nexport const Y2 = 'y2' as const;\n\n// Arc-Position\nexport const RADIUS = 'radius' as const;\nexport const RADIUS2 = 'radius2' as const;\nexport const THETA = 'theta' as const;\nexport const THETA2 = 'theta2' as const;\n\n// Geo Position\nexport const LATITUDE = 'latitude' as const;\nexport const LONGITUDE = 'longitude' as const;\nexport const LATITUDE2 = 'latitude2' as const;\nexport const LONGITUDE2 = 'longitude2' as const;\n\n// Mark property with scale\nexport const COLOR = 'color' as const;\n\nexport const FILL = 'fill' as const;\n\nexport const STROKE = 'stroke' as const;\n\nexport const SHAPE = 'shape' as const;\nexport const SIZE = 'size' as const;\n\nexport const ANGLE = 'angle' as const;\n\nexport const OPACITY = 'opacity' as const;\nexport const FILLOPACITY = 'fillOpacity' as const;\n\nexport const STROKEOPACITY = 'strokeOpacity' as const;\n\nexport const STROKEWIDTH = 'strokeWidth' as const;\nexport const STROKEDASH = 'strokeDash' as const;\n\n// Non-scale channel\nexport const TEXT = 'text' as const;\nexport const ORDER = 'order' as const;\nexport const DETAIL = 'detail' as const;\nexport const KEY = 'key' as const;\n\nexport const TOOLTIP = 'tooltip' as const;\nexport const HREF = 'href' as const;\n\nexport const URL = 'url' as const;\nexport const DESCRIPTION = 'description' as const;\n\nconst POSITION_CHANNEL_INDEX = {\n  x: 1,\n  y: 1,\n  x2: 1,\n  y2: 1\n} as const;\n\nexport type PositionChannel = keyof typeof POSITION_CHANNEL_INDEX;\n\nconst POLAR_POSITION_CHANNEL_INDEX = {\n  theta: 1,\n  theta2: 1,\n  radius: 1,\n  radius2: 1\n} as const;\n\nexport type PolarPositionChannel = keyof typeof POLAR_POSITION_CHANNEL_INDEX;\n\nexport function isPolarPositionChannel(c: Channel): c is PolarPositionChannel {\n  return c in POLAR_POSITION_CHANNEL_INDEX;\n}\n\nconst GEO_POSIITON_CHANNEL_INDEX = {\n  longitude: 1,\n  longitude2: 1,\n  latitude: 1,\n  latitude2: 1\n} as const;\n\nexport type GeoPositionChannel = keyof typeof GEO_POSIITON_CHANNEL_INDEX;\n\nexport function getPositionChannelFromLatLong(channel: GeoPositionChannel): PositionChannel {\n  switch (channel) {\n    case LATITUDE:\n      return 'y';\n    case LATITUDE2:\n      return 'y2';\n    case LONGITUDE:\n      return 'x';\n    case LONGITUDE2:\n      return 'x2';\n  }\n}\n\nexport function isGeoPositionChannel(c: Channel): c is GeoPositionChannel {\n  return c in GEO_POSIITON_CHANNEL_INDEX;\n}\n\nexport const GEOPOSITION_CHANNELS = keys(GEO_POSIITON_CHANNEL_INDEX);\n\nconst UNIT_CHANNEL_INDEX: Flag<Channel> = {\n  ...POSITION_CHANNEL_INDEX,\n  ...POLAR_POSITION_CHANNEL_INDEX,\n\n  ...GEO_POSIITON_CHANNEL_INDEX,\n\n  // color\n  color: 1,\n  fill: 1,\n  stroke: 1,\n\n  // other non-position with scale\n  opacity: 1,\n  fillOpacity: 1,\n  strokeOpacity: 1,\n\n  strokeWidth: 1,\n  strokeDash: 1,\n  size: 1,\n  angle: 1,\n  shape: 1,\n\n  // channels without scales\n  order: 1,\n  text: 1,\n  detail: 1,\n  key: 1,\n  tooltip: 1,\n  href: 1,\n  url: 1,\n  description: 1\n};\n\nexport type ColorChannel = 'color' | 'fill' | 'stroke';\n\nexport function isColorChannel(channel: Channel): channel is ColorChannel {\n  return channel === COLOR || channel === FILL || channel === STROKE;\n}\n\nexport type FacetChannel = keyof EncodingFacetMapping<any, any>;\n\nconst FACET_CHANNEL_INDEX: Flag<keyof EncodingFacetMapping<any, any>> = {\n  row: 1,\n  column: 1,\n  facet: 1\n};\n\nexport const FACET_CHANNELS = keys(FACET_CHANNEL_INDEX);\n\nconst CHANNEL_INDEX = {\n  ...UNIT_CHANNEL_INDEX,\n  ...FACET_CHANNEL_INDEX\n};\n\nexport const CHANNELS = keys(CHANNEL_INDEX);\n\nconst {order: _o, detail: _d, tooltip: _tt1, ...SINGLE_DEF_CHANNEL_INDEX} = CHANNEL_INDEX;\nconst {row: _r, column: _c, facet: _f, ...SINGLE_DEF_UNIT_CHANNEL_INDEX} = SINGLE_DEF_CHANNEL_INDEX;\n/**\n * Channels that cannot have an array of channelDef.\n * model.fieldDef, getFieldDef only work for these channels.\n *\n * (The only two channels that can have an array of channelDefs are \"detail\" and \"order\".\n * Since there can be multiple fieldDefs for detail and order, getFieldDef/model.fieldDef\n * are not applicable for them. Similarly, selection projection won't work with \"detail\" and \"order\".)\n */\n\nexport const SINGLE_DEF_CHANNELS = keys(SINGLE_DEF_CHANNEL_INDEX);\n\nexport type SingleDefChannel = typeof SINGLE_DEF_CHANNELS[number];\n\nexport const SINGLE_DEF_UNIT_CHANNELS = keys(SINGLE_DEF_UNIT_CHANNEL_INDEX);\n\nexport type SingleDefUnitChannel = typeof SINGLE_DEF_UNIT_CHANNELS[number];\n\nexport function isSingleDefUnitChannel(str: string): str is SingleDefUnitChannel {\n  return !!SINGLE_DEF_UNIT_CHANNEL_INDEX[str];\n}\n\nexport function isChannel(str: string): str is Channel {\n  return !!CHANNEL_INDEX[str];\n}\n\nexport type SecondaryRangeChannel = 'x2' | 'y2' | 'latitude2' | 'longitude2' | 'theta2' | 'radius2';\n\nexport const SECONDARY_RANGE_CHANNEL: SecondaryRangeChannel[] = [X2, Y2, LATITUDE2, LONGITUDE2, THETA2, RADIUS2];\n\nexport function isSecondaryRangeChannel(c: ExtendedChannel): c is SecondaryRangeChannel {\n  const main = getMainRangeChannel(c);\n  return main !== c;\n}\n\nexport type MainChannelOf<C extends ExtendedChannel> = C extends 'x2'\n  ? 'x'\n  : C extends 'y2'\n  ? 'y'\n  : C extends 'latitude2'\n  ? 'latitude'\n  : C extends 'longitude2'\n  ? 'longitude'\n  : C extends 'theta2'\n  ? 'theta'\n  : C extends 'radius2'\n  ? 'radius'\n  : C;\n\n/**\n * Get the main channel for a range channel. E.g. `x` for `x2`.\n */\nexport function getMainRangeChannel<C extends ExtendedChannel>(channel: C): MainChannelOf<C> {\n  switch (channel) {\n    case X2:\n      return X as MainChannelOf<C>;\n    case Y2:\n      return Y as MainChannelOf<C>;\n    case LATITUDE2:\n      return LATITUDE as MainChannelOf<C>;\n    case LONGITUDE2:\n      return LONGITUDE as MainChannelOf<C>;\n    case THETA2:\n      return THETA as MainChannelOf<C>;\n    case RADIUS2:\n      return RADIUS as MainChannelOf<C>;\n  }\n  return channel as MainChannelOf<C>;\n}\n\nexport type SecondaryChannelOf<C extends Channel> = C extends 'x'\n  ? 'x2'\n  : C extends 'y'\n  ? 'y2'\n  : C extends 'latitude'\n  ? 'latitude2'\n  : C extends 'longitude'\n  ? 'longitude2'\n  : C extends 'theta'\n  ? 'theta2'\n  : C extends 'radius'\n  ? 'radius2'\n  : undefined;\n\nexport function getVgPositionChannel(channel: PolarPositionChannel | PositionChannel) {\n  if (isPolarPositionChannel(channel)) {\n    switch (channel) {\n      case THETA:\n        return 'startAngle';\n      case THETA2:\n        return 'endAngle';\n      case RADIUS:\n        return 'outerRadius';\n      case RADIUS2:\n        return 'innerRadius';\n    }\n  }\n  return channel;\n}\n\n/**\n * Get the main channel for a range channel. E.g. `x` for `x2`.\n */\nexport function getSecondaryRangeChannel<C extends Channel>(channel: C): SecondaryChannelOf<C> | undefined {\n  switch (channel) {\n    case X:\n      return X2 as SecondaryChannelOf<C>;\n    case Y:\n      return Y2 as SecondaryChannelOf<C>;\n    case LATITUDE:\n      return LATITUDE2 as SecondaryChannelOf<C>;\n    case LONGITUDE:\n      return LONGITUDE2 as SecondaryChannelOf<C>;\n    case THETA:\n      return THETA2 as SecondaryChannelOf<C>;\n    case RADIUS:\n      return RADIUS2 as SecondaryChannelOf<C>;\n  }\n  return undefined;\n}\n\nexport function getSizeChannel(channel: PositionChannel): 'width' | 'height';\nexport function getSizeChannel(channel: Channel): 'width' | 'height' | undefined;\nexport function getSizeChannel(channel: Channel): 'width' | 'height' | undefined {\n  switch (channel) {\n    case X:\n    case X2:\n      return 'width';\n    case Y:\n    case Y2:\n      return 'height';\n  }\n  return undefined;\n}\n\n/**\n * Get the main channel for a range channel. E.g. `x` for `x2`.\n */\nexport function getOffsetChannel(channel: Channel) {\n  switch (channel) {\n    case X:\n      return 'xOffset';\n    case Y:\n      return 'yOffset';\n    case X2:\n      return 'x2Offset';\n    case Y2:\n      return 'y2Offset';\n    case THETA:\n      return 'thetaOffset';\n    case RADIUS:\n      return 'radiusOffset';\n    case THETA2:\n      return 'theta2Offset';\n    case RADIUS2:\n      return 'radius2Offset';\n  }\n  return undefined;\n}\n\n// CHANNELS without COLUMN, ROW\nexport const UNIT_CHANNELS = keys(UNIT_CHANNEL_INDEX);\n\n// NONPOSITION_CHANNELS = UNIT_CHANNELS without X, Y, X2, Y2;\nconst {\n  x: _x,\n  y: _y,\n  // x2 and y2 share the same scale as x and y\n  x2: _x2,\n  y2: _y2,\n  latitude: _latitude,\n  longitude: _longitude,\n  latitude2: _latitude2,\n  longitude2: _longitude2,\n  theta: _theta,\n  theta2: _theta2,\n  radius: _radius,\n  radius2: _radius2,\n  // The rest of unit channels then have scale\n  ...NONPOSITION_CHANNEL_INDEX\n} = UNIT_CHANNEL_INDEX;\n\nexport const NONPOSITION_CHANNELS = keys(NONPOSITION_CHANNEL_INDEX);\nexport type NonPositionChannel = typeof NONPOSITION_CHANNELS[number];\n\nexport const POSITION_SCALE_CHANNEL_INDEX = {\n  x: 1,\n  y: 1\n} as const;\nexport const POSITION_SCALE_CHANNELS = keys(POSITION_SCALE_CHANNEL_INDEX);\nexport type PositionScaleChannel = keyof typeof POSITION_SCALE_CHANNEL_INDEX;\n\nexport function isXorY(channel: ExtendedChannel): channel is PositionScaleChannel {\n  return channel in POSITION_SCALE_CHANNEL_INDEX;\n}\n\nexport const POLAR_POSITION_SCALE_CHANNEL_INDEX = {\n  theta: 1,\n  radius: 1\n} as const;\n\nexport const POLAR_POSITION_SCALE_CHANNELS = keys(POLAR_POSITION_SCALE_CHANNEL_INDEX);\nexport type PolarPositionScaleChannel = keyof typeof POLAR_POSITION_SCALE_CHANNEL_INDEX;\n\nexport function getPositionScaleChannel(sizeType: 'width' | 'height'): PositionScaleChannel {\n  return sizeType === 'width' ? X : Y;\n}\n\n// NON_POSITION_SCALE_CHANNEL = SCALE_CHANNELS without X, Y\nconst {\n  // x2 and y2 share the same scale as x and y\n  // text and tooltip have format instead of scale,\n  // href has neither format, nor scale\n  text: _t,\n  tooltip: _tt,\n  href: _hr,\n  url: _u,\n  description: _al,\n  // detail and order have no scale\n  detail: _dd,\n  key: _k,\n  order: _oo,\n  ...NONPOSITION_SCALE_CHANNEL_INDEX\n} = NONPOSITION_CHANNEL_INDEX;\nexport const NONPOSITION_SCALE_CHANNELS = keys(NONPOSITION_SCALE_CHANNEL_INDEX);\nexport type NonPositionScaleChannel = typeof NONPOSITION_SCALE_CHANNELS[number];\n\nexport function isNonPositionScaleChannel(channel: Channel): channel is NonPositionScaleChannel {\n  return !!NONPOSITION_CHANNEL_INDEX[channel];\n}\n\n/**\n * @returns whether Vega supports legends for a particular channel\n */\nexport function supportLegend(channel: NonPositionScaleChannel) {\n  switch (channel) {\n    case COLOR:\n    case FILL:\n    case STROKE:\n    case SIZE:\n    case SHAPE:\n    case OPACITY:\n    case STROKEWIDTH:\n    case STROKEDASH:\n      return true;\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    case ANGLE:\n      return false;\n  }\n}\n\n// Declare SCALE_CHANNEL_INDEX\nconst SCALE_CHANNEL_INDEX = {\n  ...POSITION_SCALE_CHANNEL_INDEX,\n  ...POLAR_POSITION_SCALE_CHANNEL_INDEX,\n  ...NONPOSITION_SCALE_CHANNEL_INDEX\n};\n\n/** List of channels with scales */\nexport const SCALE_CHANNELS = keys(SCALE_CHANNEL_INDEX);\nexport type ScaleChannel = typeof SCALE_CHANNELS[number];\n\nexport function isScaleChannel(channel: Channel): channel is ScaleChannel {\n  return !!SCALE_CHANNEL_INDEX[channel];\n}\n\nexport type SupportedMark = Partial<Record<Mark, 'always' | 'binned'>>;\n\n/**\n * Return whether a channel supports a particular mark type.\n * @param channel  channel name\n * @param mark the mark type\n * @return whether the mark supports the channel\n */\nexport function supportMark(channel: Channel, mark: Mark) {\n  return getSupportedMark(channel)[mark];\n}\n\nconst ALL_MARKS: Record<Mark, 'always'> = {\n  // all marks\n  arc: 'always',\n  area: 'always',\n  bar: 'always',\n  circle: 'always',\n  geoshape: 'always',\n  image: 'always',\n  line: 'always',\n  rule: 'always',\n  point: 'always',\n  rect: 'always',\n  square: 'always',\n  trail: 'always',\n  text: 'always',\n  tick: 'always'\n};\n\nconst {geoshape: _g, ...ALL_MARKS_EXCEPT_GEOSHAPE} = ALL_MARKS;\n\n/**\n * Return a dictionary showing whether a channel supports mark type.\n * @param channel\n * @return A dictionary mapping mark types to 'always', 'binned', or undefined\n */\nfunction getSupportedMark(channel: ExtendedChannel): SupportedMark {\n  switch (channel) {\n    case COLOR:\n    case FILL:\n    case STROKE:\n    // falls through\n\n    case DESCRIPTION:\n    case DETAIL:\n    case KEY:\n    case TOOLTIP:\n    case HREF:\n    case ORDER: // TODO: revise (order might not support rect, which is not stackable?)\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    case STROKEWIDTH:\n\n    // falls through\n\n    case FACET:\n    case ROW: // falls through\n    case COLUMN:\n      return ALL_MARKS;\n    case X:\n    case Y:\n    case LATITUDE:\n    case LONGITUDE:\n      // all marks except geoshape. geoshape does not use X, Y -- it uses a projection\n      return ALL_MARKS_EXCEPT_GEOSHAPE;\n    case X2:\n    case Y2:\n    case LATITUDE2:\n    case LONGITUDE2:\n      return {\n        area: 'always',\n        bar: 'always',\n        image: 'always',\n        rect: 'always',\n        rule: 'always',\n        circle: 'binned',\n        point: 'binned',\n        square: 'binned',\n        tick: 'binned',\n        line: 'binned',\n        trail: 'binned'\n      };\n    case SIZE:\n      return {\n        point: 'always',\n        tick: 'always',\n        rule: 'always',\n        circle: 'always',\n        square: 'always',\n        bar: 'always',\n        text: 'always',\n        line: 'always',\n        trail: 'always'\n      };\n    case STROKEDASH:\n      return {\n        line: 'always',\n        point: 'always',\n        tick: 'always',\n        rule: 'always',\n        circle: 'always',\n        square: 'always',\n        bar: 'always',\n        geoshape: 'always'\n      };\n    case SHAPE:\n      return {point: 'always', geoshape: 'always'};\n    case TEXT:\n      return {text: 'always'};\n    case ANGLE:\n      return {point: 'always', square: 'always', text: 'always'};\n    case URL:\n      return {image: 'always'};\n    case THETA:\n      return {text: 'always', arc: 'always'};\n    case RADIUS:\n      return {text: 'always', arc: 'always'};\n    case THETA2:\n    case RADIUS2:\n      return {arc: 'always'};\n  }\n}\n\nexport function rangeType(channel: ExtendedChannel): RangeType {\n  switch (channel) {\n    case X:\n    case Y:\n    case THETA:\n    case RADIUS:\n    case SIZE:\n    case ANGLE:\n    case STROKEWIDTH:\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n\n    // X2 and Y2 use X and Y scales, so they similarly have continuous range. [falls through]\n    case X2:\n    case Y2:\n    case THETA2:\n    case RADIUS2:\n      return undefined;\n\n    case FACET:\n    case ROW:\n    case COLUMN:\n    case SHAPE:\n    case STROKEDASH:\n    // TEXT, TOOLTIP, URL, and HREF have no scale but have discrete output [falls through]\n    case TEXT:\n    case TOOLTIP:\n    case HREF:\n    case URL:\n    case DESCRIPTION:\n      return 'discrete';\n\n    // Color can be either continuous or discrete, depending on scale type.\n    case COLOR:\n    case FILL:\n    case STROKE:\n      return 'flexible';\n\n    // No scale, no range type.\n\n    case LATITUDE:\n    case LONGITUDE:\n    case LATITUDE2:\n    case LONGITUDE2:\n    case DETAIL:\n    case KEY:\n    case ORDER:\n      return undefined;\n  }\n}\n","import {\n  Align,\n  Axis as VgAxis,\n  AxisEncode,\n  AxisOrient,\n  BaseAxis,\n  Color,\n  FontStyle,\n  FontWeight,\n  LabelOverlap,\n  SignalRef,\n  TextBaseline,\n  TimeInterval,\n  TimeIntervalStep\n} from 'vega';\nimport {ConditionalPredicate, Value, ValueDef} from './channeldef';\nimport {DateTime} from './datetime';\nimport {ExprRef} from './expr';\nimport {Guide, GuideEncodingEntry, TitleMixins, VlOnlyGuideConfig} from './guide';\nimport {Flag, keys} from './util';\nimport {MapExcludeValueRefAndReplaceSignalWith, VgEncodeChannel} from './vega.schema';\n\nexport type BaseAxisNoValueRefs<ES extends ExprRef | SignalRef> = AxisOverrideMixins<ES> &\n  VLOnlyAxisMixins &\n  Omit<MapExcludeValueRefAndReplaceSignalWith<BaseAxis, ES>, 'labelOverlap'>;\n\ninterface AxisOverrideMixins<ES extends ExprRef | SignalRef> {\n  // Position and tickMinStep are not config in Vega, but are in Vega-Lite. So we just copy them here.\n\n  /**\n   * The anchor position of the axis in pixels. For x-axes with top or bottom orientation, this sets the axis group x coordinate. For y-axes with left or right orientation, this sets the axis group y coordinate.\n   *\n   * __Default value__: `0`\n   */\n  position?: number | ES;\n\n  /**\n   * The minimum desired step between axis ticks, in terms of scale domain values. For example, a value of `1` indicates that ticks should not be less than 1 unit apart. If `tickMinStep` is specified, the `tickCount` value will be adjusted, if necessary, to enforce the minimum step value.\n   */\n  tickMinStep?: number | ES;\n\n  // Override comments to be Vega-Lite specific\n  /**\n   * A boolean flag indicating if grid lines should be included as part of the axis\n   *\n   * __Default value:__ `true` for [continuous scales](https://vega.github.io/vega-lite/docs/scale.html#continuous) that are not binned; otherwise, `false`.\n   */\n  grid?: boolean;\n\n  /**\n   * Indicates if the first and last axis labels should be aligned flush with the scale range. Flush alignment for a horizontal axis will left-align the first label and right-align the last label. For vertical axes, bottom and top text baselines are applied instead. If this property is a number, it also indicates the number of pixels by which to offset the first and last labels; for example, a value of 2 will flush-align the first and last labels and also push them 2 pixels outward from the center of the axis. The additional adjustment can sometimes help the labels better visually group with corresponding axis ticks.\n   *\n   * __Default value:__ `true` for axis of a continuous x-scale. Otherwise, `false`.\n   */\n  labelFlush?: boolean | number;\n\n  /**\n   * The strategy to use for resolving overlap of axis labels. If `false` (the default), no overlap reduction is attempted. If set to `true` or `\"parity\"`, a strategy of removing every other label is used (this works well for standard linear axes). If set to `\"greedy\"`, a linear scan of the labels is performed, removing any labels that overlaps with the last visible label (this often works better for log-scaled axes).\n   *\n   * __Default value:__ `true` for non-nominal fields with non-log scales; `\"greedy\"` for log scales; otherwise `false`.\n   */\n  labelOverlap?: LabelOverlap | ES;\n\n  /**\n   * The offset, in pixels, by which to displace the axis from the edge of the enclosing group or data rectangle.\n   *\n   * __Default value:__ derived from the [axis config](https://vega.github.io/vega-lite/docs/config.html#facet-scale-config)'s `offset` (`0` by default)\n   */\n  offset?: number;\n\n  /**\n   * The orientation of the axis. One of `\"top\"`, `\"bottom\"`, `\"left\"` or `\"right\"`. The orientation can be used to further specialize the axis type (e.g., a y-axis oriented towards the right edge of the chart).\n   *\n   * __Default value:__ `\"bottom\"` for x-axes and `\"left\"` for y-axes.\n   */\n  orient?: AxisOrient | ES;\n\n  /**\n   * A desired number of ticks, for axes visualizing quantitative scales. The resulting number may be different so that values are \"nice\" (multiples of 2, 5, 10) and lie within the underlying scale's range.\n   *\n   * For scales of type `\"time\"` or `\"utc\"`, the tick count can instead be a time interval specifier. Legal string values are `\"millisecond\"`, `\"second\"`, `\"minute\"`, `\"hour\"`, `\"day\"`, `\"week\"`, `\"month\"`, and `\"year\"`. Alternatively, an object-valued interval specifier of the form `{\"interval\": \"month\", \"step\": 3}` includes a desired number of interval steps. Here, ticks are generated for each quarter (Jan, Apr, Jul, Oct) boundary.\n   *\n   * __Default value__: Determine using a formula `ceil(width/40)` for x and `ceil(height/40)` for y.\n   *\n   * @minimum 0\n   */\n  tickCount?: number | TimeInterval | TimeIntervalStep | ES;\n\n  /**\n   * Explicitly set the visible axis tick values.\n   */\n  values?: number[] | string[] | boolean[] | DateTime[] | ES; // Vega already supports Signal -- we have to re-declare here since VL supports special Date Time object that's not valid in Vega.\n\n  /**\n   * A non-negative integer indicating the z-index of the axis.\n   * If zindex is 0, axes should be drawn behind all chart elements.\n   * To put them in front, set `zindex` to `1` or more.\n   *\n   * __Default value:__ `0` (behind the marks).\n   *\n   * @TJS-type integer\n   * @minimum 0\n   */\n  zindex?: number;\n}\n\ninterface VLOnlyAxisMixins {\n  /**\n   * [Vega expression](https://vega.github.io/vega/docs/expressions/) for customizing labels.\n   *\n   * __Note:__ The label text and value can be assessed via the `label` and `value` properties of the axis's backing `datum` object.\n   */\n  labelExpr?: string;\n\n  /**\n   * A string or array of strings indicating the name of custom styles to apply to the axis. A style is a named collection of axis property defined within the [style configuration](https://vega.github.io/vega-lite/docs/mark.html#style-config). If style is an array, later styles will override earlier styles.\n   *\n   * __Default value:__ (none)\n   * __Note:__ Any specified style will augment the default style. For example, an x-axis mark with `\"style\": \"foo\"` will use `config.axisX` and `config.style.foo` (the specified style `\"foo\"` has higher precedence).\n   */\n  style?: string | string[];\n}\n\nexport type ConditionalAxisProp =\n  | 'labelAlign'\n  | 'labelBaseline'\n  | 'labelColor'\n  | 'labelFont'\n  | 'labelFontSize'\n  | 'labelFontStyle'\n  | 'labelFontWeight'\n  | 'labelOpacity'\n  | 'labelOffset'\n  | 'labelPadding'\n  | 'gridColor'\n  | 'gridDash'\n  | 'gridDashOffset'\n  | 'gridOpacity'\n  | 'gridWidth'\n  | 'tickColor'\n  | 'tickDash'\n  | 'tickDashOffset'\n  | 'tickOpacity'\n  | 'tickSize'\n  | 'tickWidth';\n\nexport const CONDITIONAL_AXIS_PROP_INDEX: Record<\n  ConditionalAxisProp,\n  {\n    part: keyof AxisEncode;\n    vgProp: VgEncodeChannel;\n  } | null // null if we need to convert condition to signal\n> = {\n  labelAlign: {\n    part: 'labels',\n    vgProp: 'align'\n  },\n  labelBaseline: {\n    part: 'labels',\n    vgProp: 'baseline'\n  },\n  labelColor: {\n    part: 'labels',\n    vgProp: 'fill'\n  },\n  labelFont: {\n    part: 'labels',\n    vgProp: 'font'\n  },\n  labelFontSize: {\n    part: 'labels',\n    vgProp: 'fontSize'\n  },\n  labelFontStyle: {\n    part: 'labels',\n    vgProp: 'fontStyle'\n  },\n  labelFontWeight: {\n    part: 'labels',\n    vgProp: 'fontWeight'\n  },\n  labelOpacity: {\n    part: 'labels',\n    vgProp: 'opacity'\n  },\n  labelOffset: null,\n  labelPadding: null, // There is no fixed vgProp for tickSize, need to use signal.\n  gridColor: {\n    part: 'grid',\n    vgProp: 'stroke'\n  },\n  gridDash: {\n    part: 'grid',\n    vgProp: 'strokeDash'\n  },\n  gridDashOffset: {\n    part: 'grid',\n    vgProp: 'strokeDashOffset'\n  },\n  gridOpacity: {\n    part: 'grid',\n    vgProp: 'opacity'\n  },\n  gridWidth: {\n    part: 'grid',\n    vgProp: 'strokeWidth'\n  },\n  tickColor: {\n    part: 'ticks',\n    vgProp: 'stroke'\n  },\n  tickDash: {\n    part: 'ticks',\n    vgProp: 'strokeDash'\n  },\n  tickDashOffset: {\n    part: 'ticks',\n    vgProp: 'strokeDashOffset'\n  },\n  tickOpacity: {\n    part: 'ticks',\n    vgProp: 'opacity'\n  },\n  tickSize: null, // There is no fixed vgProp for tickSize, need to use signal.\n  tickWidth: {\n    part: 'ticks',\n    vgProp: 'strokeWidth'\n  }\n};\n\nexport type ConditionalAxisProperty<V extends Value | number[], ES extends ExprRef | SignalRef> = (ValueDef<V> | ES) & {\n  condition: ConditionalPredicate<ValueDef<V> | ES> | ConditionalPredicate<ValueDef<V> | ES>[];\n};\n\nexport function isConditionalAxisValue<V extends Value | number[], ES extends ExprRef | SignalRef>(\n  v: any\n): v is ConditionalAxisProperty<V, ES> {\n  return v && v['condition'];\n}\n\nexport type ConditionalAxisNumber<ES extends ExprRef | SignalRef = ExprRef | SignalRef> = ConditionalAxisProperty<\n  number | null,\n  ES\n>;\nexport type ConditionalAxisLabelAlign<ES extends ExprRef | SignalRef = ExprRef | SignalRef> = ConditionalAxisProperty<\n  Align | null,\n  ES\n>;\nexport type ConditionalAxisLabelBaseline<\n  ES extends ExprRef | SignalRef = ExprRef | SignalRef\n> = ConditionalAxisProperty<TextBaseline | null, ES>;\nexport type ConditionalAxisColor<ES extends ExprRef | SignalRef = ExprRef | SignalRef> = ConditionalAxisProperty<\n  Color | null,\n  ES\n>;\nexport type ConditionalAxisString<ES extends ExprRef | SignalRef = ExprRef | SignalRef> = ConditionalAxisProperty<\n  string | null,\n  ES\n>;\n\nexport type ConditionalAxisLabelFontStyle<\n  ES extends ExprRef | SignalRef = ExprRef | SignalRef\n> = ConditionalAxisProperty<FontStyle | null, ES>;\nexport type ConditionalAxisLabelFontWeight<\n  ES extends ExprRef | SignalRef = ExprRef | SignalRef\n> = ConditionalAxisProperty<FontWeight | null, ES>;\n\nexport type ConditionalAxisNumberArray<ES extends ExprRef | SignalRef = ExprRef | SignalRef> = ConditionalAxisProperty<\n  number[] | null,\n  ES\n>;\n\n// Vega axis config is the same as Vega axis base. If this is not the case, add specific type.\nexport type AxisConfigBaseWithConditionalAndSignal<ES extends ExprRef | SignalRef> = Omit<\n  BaseAxisNoValueRefs<ES>,\n  ConditionalAxisProp | 'title'\n> &\n  AxisPropsWithCondition<ES>;\n\nexport interface AxisPropsWithCondition<ES extends ExprRef | SignalRef> {\n  labelAlign?: BaseAxisNoValueRefs<ES>['labelAlign'] | ConditionalAxisLabelAlign<ES>;\n  labelBaseline?: BaseAxisNoValueRefs<ES>['labelBaseline'] | ConditionalAxisLabelBaseline<ES>;\n  labelColor?: BaseAxisNoValueRefs<ES>['labelColor'] | ConditionalAxisColor<ES>;\n  labelFont?: BaseAxisNoValueRefs<ES>['labelFont'] | ConditionalAxisString<ES>;\n  labelFontSize?: BaseAxisNoValueRefs<ES>['labelFontSize'] | ConditionalAxisNumber<ES>;\n  labelFontStyle?: BaseAxisNoValueRefs<ES>['labelFontStyle'] | ConditionalAxisLabelFontStyle<ES>;\n  labelFontWeight?: BaseAxisNoValueRefs<ES>['labelFontWeight'] | ConditionalAxisLabelFontWeight<ES>;\n  labelLineHeight?: BaseAxisNoValueRefs<ES>['labelLineHeight'] | ConditionalAxisNumber<ES>;\n  labelOpacity?: BaseAxisNoValueRefs<ES>['labelOpacity'] | ConditionalAxisNumber<ES>;\n  labelOffset?: BaseAxisNoValueRefs<ES>['labelOffset'] | ConditionalAxisNumber<ES>;\n  labelPadding?: BaseAxisNoValueRefs<ES>['labelPadding'] | ConditionalAxisNumber<ES>;\n  gridColor?: BaseAxisNoValueRefs<ES>['gridColor'] | ConditionalAxisColor<ES>;\n  gridDash?: BaseAxisNoValueRefs<ES>['gridDash'] | ConditionalAxisNumberArray<ES>;\n  gridDashOffset?: BaseAxisNoValueRefs<ES>['gridDashOffset'] | ConditionalAxisNumber<ES>;\n  gridOpacity?: BaseAxisNoValueRefs<ES>['gridOpacity'] | ConditionalAxisNumber<ES>;\n  gridWidth?: BaseAxisNoValueRefs<ES>['gridWidth'] | ConditionalAxisNumber<ES>;\n  tickColor?: BaseAxisNoValueRefs<ES>['tickColor'] | ConditionalAxisColor<ES>;\n  tickDash?: BaseAxisNoValueRefs<ES>['tickDash'] | ConditionalAxisNumberArray<ES>;\n  tickDashOffset?: BaseAxisNoValueRefs<ES>['tickDashOffset'] | ConditionalAxisNumber<ES>;\n  tickOpacity?: BaseAxisNoValueRefs<ES>['tickOpacity'] | ConditionalAxisNumber<ES>;\n  tickSize?: BaseAxisNoValueRefs<ES>['tickSize'] | ConditionalAxisNumber<ES>;\n  tickWidth?: BaseAxisNoValueRefs<ES>['tickWidth'] | ConditionalAxisNumber<ES>;\n  title?: TitleMixins['title'];\n}\n\nexport type AxisConfig<ES extends ExprRef | SignalRef> = Guide &\n  VlOnlyGuideConfig &\n  AxisConfigBaseWithConditionalAndSignal<ES> & {\n    /**\n     * Disable axis by default.\n     */\n    disable?: boolean;\n  };\n\nexport interface Axis<ES extends ExprRef | SignalRef = ExprRef | SignalRef>\n  extends AxisConfigBaseWithConditionalAndSignal<ES>,\n    Guide {\n  /**\n   * Mark definitions for custom axis encoding.\n   *\n   * @hidden\n   */\n  encoding?: AxisEncoding;\n}\n\nexport type AxisInternal = Axis<SignalRef>;\n\nexport type AxisPart = keyof AxisEncoding;\nexport const AXIS_PARTS: AxisPart[] = ['domain', 'grid', 'labels', 'ticks', 'title'];\n\n/**\n * A dictionary listing whether a certain axis property is applicable for only main axes or only grid axes.\n */\nexport const AXIS_PROPERTY_TYPE: Record<keyof VgAxis, 'main' | 'grid' | 'both'> = {\n  grid: 'grid',\n  gridCap: 'grid',\n  gridColor: 'grid',\n  gridDash: 'grid',\n  gridDashOffset: 'grid',\n  gridOpacity: 'grid',\n  gridScale: 'grid',\n  gridWidth: 'grid',\n\n  orient: 'main',\n\n  bandPosition: 'both', // Need to be applied to grid axis too, so the grid will align with ticks.\n\n  aria: 'main',\n  description: 'main',\n  domain: 'main',\n  domainCap: 'main',\n  domainColor: 'main',\n  domainDash: 'main',\n  domainDashOffset: 'main',\n  domainOpacity: 'main',\n  domainWidth: 'main',\n  format: 'main',\n  formatType: 'main',\n  labelAlign: 'main',\n  labelAngle: 'main',\n  labelBaseline: 'main',\n  labelBound: 'main',\n  labelColor: 'main',\n  labelFlush: 'main',\n  labelFlushOffset: 'main',\n  labelFont: 'main',\n  labelFontSize: 'main',\n  labelFontStyle: 'main',\n  labelFontWeight: 'main',\n  labelLimit: 'main',\n  labelLineHeight: 'main',\n  labelOffset: 'main',\n  labelOpacity: 'main',\n  labelOverlap: 'main',\n  labelPadding: 'main',\n  labels: 'main',\n  labelSeparation: 'main',\n  maxExtent: 'main',\n  minExtent: 'main',\n  offset: 'both',\n  position: 'main',\n  tickCap: 'main',\n  tickColor: 'main',\n  tickDash: 'main',\n  tickDashOffset: 'main',\n  tickMinStep: 'main',\n  tickOffset: 'both', // Need to be applied to grid axis too, so the grid will align with ticks.\n  tickOpacity: 'main',\n  tickRound: 'both', // Apply rounding to grid and ticks so they are aligned.\n  ticks: 'main',\n  tickSize: 'main',\n  tickWidth: 'both',\n  title: 'main',\n  titleAlign: 'main',\n  titleAnchor: 'main',\n  titleAngle: 'main',\n  titleBaseline: 'main',\n  titleColor: 'main',\n  titleFont: 'main',\n  titleFontSize: 'main',\n  titleFontStyle: 'main',\n  titleFontWeight: 'main',\n  titleLimit: 'main',\n  titleLineHeight: 'main',\n  titleOpacity: 'main',\n  titlePadding: 'main',\n  titleX: 'main',\n  titleY: 'main',\n\n  encode: 'both', // we hide this in Vega-Lite\n  scale: 'both',\n  tickBand: 'both',\n  tickCount: 'both',\n  tickExtra: 'both',\n  translate: 'both',\n  values: 'both',\n  zindex: 'both' // this is actually set afterward, so it doesn't matter\n};\n\nexport interface AxisEncoding {\n  /**\n   * Custom encoding for the axis container.\n   */\n  axis?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for the axis domain rule mark.\n   */\n  domain?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for axis gridline rule marks.\n   */\n  grid?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for axis label text marks.\n   */\n  labels?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for axis tick rule marks.\n   */\n  ticks?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for the axis title text mark.\n   */\n  title?: GuideEncodingEntry;\n}\n\nexport const COMMON_AXIS_PROPERTIES_INDEX: Flag<keyof (VgAxis | Axis<any>)> = {\n  orient: 1, // other things can depend on orient\n\n  aria: 1,\n  bandPosition: 1,\n  description: 1,\n  domain: 1,\n  domainCap: 1,\n  domainColor: 1,\n  domainDash: 1,\n  domainDashOffset: 1,\n  domainOpacity: 1,\n  domainWidth: 1,\n  format: 1,\n  formatType: 1,\n  grid: 1,\n  gridCap: 1,\n  gridColor: 1,\n  gridDash: 1,\n  gridDashOffset: 1,\n  gridOpacity: 1,\n  gridWidth: 1,\n  labelAlign: 1,\n  labelAngle: 1,\n  labelBaseline: 1,\n  labelBound: 1,\n  labelColor: 1,\n  labelFlush: 1,\n  labelFlushOffset: 1,\n  labelFont: 1,\n  labelFontSize: 1,\n  labelFontStyle: 1,\n  labelFontWeight: 1,\n  labelLimit: 1,\n  labelLineHeight: 1,\n  labelOffset: 1,\n  labelOpacity: 1,\n  labelOverlap: 1,\n  labelPadding: 1,\n  labels: 1,\n  labelSeparation: 1,\n  maxExtent: 1,\n  minExtent: 1,\n  offset: 1,\n  position: 1,\n  tickBand: 1,\n  tickCap: 1,\n  tickColor: 1,\n  tickCount: 1,\n  tickDash: 1,\n  tickDashOffset: 1,\n  tickExtra: 1,\n  tickMinStep: 1,\n  tickOffset: 1,\n  tickOpacity: 1,\n  tickRound: 1,\n  ticks: 1,\n  tickSize: 1,\n  tickWidth: 1,\n  title: 1,\n  titleAlign: 1,\n  titleAnchor: 1,\n  titleAngle: 1,\n  titleBaseline: 1,\n  titleColor: 1,\n  titleFont: 1,\n  titleFontSize: 1,\n  titleFontStyle: 1,\n  titleFontWeight: 1,\n  titleLimit: 1,\n  titleLineHeight: 1,\n  titleOpacity: 1,\n  titlePadding: 1,\n  titleX: 1,\n  titleY: 1,\n  translate: 1,\n  values: 1,\n  zindex: 1\n};\n\nconst AXIS_PROPERTIES_INDEX: Flag<keyof Axis<any>> = {\n  ...COMMON_AXIS_PROPERTIES_INDEX,\n  style: 1,\n  labelExpr: 1,\n  encoding: 1\n};\n\nexport function isAxisProperty(prop: string): prop is keyof Axis<any> {\n  return !!AXIS_PROPERTIES_INDEX[prop];\n}\n\n// Export for dependent projects\nexport const AXIS_PROPERTIES = keys(AXIS_PROPERTIES_INDEX);\n\nexport interface AxisConfigMixins<ES extends ExprRef | SignalRef = ExprRef | SignalRef> {\n  /**\n   * Axis configuration, which determines default properties for all `x` and `y` [axes](https://vega.github.io/vega-lite/docs/axis.html). For a full list of axis configuration options, please see the [corresponding section of the axis documentation](https://vega.github.io/vega-lite/docs/axis.html#config).\n   */\n  axis?: AxisConfig<ES>;\n\n  /**\n   * X-axis specific config.\n   */\n  axisX?: AxisConfig<ES>;\n\n  /**\n   * Y-axis specific config.\n   */\n  axisY?: AxisConfig<ES>;\n\n  /**\n   * Config for y-axis along the left edge of the chart.\n   */\n  axisLeft?: AxisConfig<ES>;\n\n  /**\n   * Config for y-axis along the right edge of the chart.\n   */\n  axisRight?: AxisConfig<ES>;\n\n  /**\n   * Config for x-axis along the top edge of the chart.\n   */\n  axisTop?: AxisConfig<ES>;\n\n  /**\n   * Config for x-axis along the bottom edge of the chart.\n   */\n  axisBottom?: AxisConfig<ES>;\n\n  /**\n   * Config for axes with \"band\" scales.\n   */\n  axisBand?: AxisConfig<ES>;\n\n  /**\n   * Config for axes with \"point\" scales.\n   */\n  axisPoint?: AxisConfig<ES>;\n\n  /**\n   * Config for axes with \"point\" or \"band\" scales.\n   */\n  axisDiscrete?: AxisConfig<ES>;\n\n  /**\n   * Config for quantitative axes.\n   */\n  axisQuantitative?: AxisConfig<ES>;\n\n  /**\n   * Config for temporal axes.\n   */\n  axisTemporal?: AxisConfig<ES>;\n\n  /**\n   * Config for x-axes with \"band\" scales.\n   */\n  axisXBand?: AxisConfig<ES>;\n\n  /**\n   * Config for x-axes with \"point\" scales.\n   */\n  axisXPoint?: AxisConfig<ES>;\n\n  /**\n   * Config for x-axes with \"point\" or \"band\" scales.\n   */\n  axisXDiscrete?: AxisConfig<ES>;\n\n  /**\n   * Config for x-quantitative axes.\n   */\n  axisXQuantitative?: AxisConfig<ES>;\n\n  /**\n   * Config for x-temporal axes.\n   */\n  axisXTemporal?: AxisConfig<ES>;\n\n  /**\n   * Config for y-axes with \"band\" scales.\n   */\n  axisYBand?: AxisConfig<ES>;\n\n  /**\n   * Config for y-axes with \"point\" scales.\n   */\n  axisYPoint?: AxisConfig<ES>;\n\n  /**\n   * Config for y-axes with \"point\" or \"band\" scales.\n   */\n  axisYDiscrete?: AxisConfig<ES>;\n\n  /**\n   * Config for y-quantitative axes.\n   */\n  axisYQuantitative?: AxisConfig<ES>;\n\n  /**\n   * Config for y-temporal axes.\n   */\n  axisYTemporal?: AxisConfig<ES>;\n}\n\nconst AXIS_CONFIGS_INDEX: Flag<keyof AxisConfigMixins<any>> = {\n  axis: 1,\n  axisBand: 1,\n  axisBottom: 1,\n  axisDiscrete: 1,\n  axisLeft: 1,\n  axisPoint: 1,\n  axisQuantitative: 1,\n  axisRight: 1,\n  axisTemporal: 1,\n  axisTop: 1,\n  axisX: 1,\n  axisXBand: 1,\n  axisXDiscrete: 1,\n  axisXPoint: 1,\n  axisXQuantitative: 1,\n  axisXTemporal: 1,\n  axisY: 1,\n  axisYBand: 1,\n  axisYDiscrete: 1,\n  axisYPoint: 1,\n  axisYQuantitative: 1,\n  axisYTemporal: 1\n};\n\nexport const AXIS_CONFIGS = keys(AXIS_CONFIGS_INDEX);\n","import {\n  BaseLegend,\n  LabelOverlap,\n  Legend as VgLegend,\n  LegendConfig as VgLegendConfig,\n  LegendOrient,\n  Orientation,\n  SignalRef\n} from 'vega';\nimport {DateTime} from './datetime';\nimport {ExprRef} from './expr';\nimport {Guide, GuideEncodingEntry, VlOnlyGuideConfig} from './guide';\nimport {Flag, keys} from './util';\nimport {MapExcludeValueRefAndReplaceSignalWith} from './vega.schema';\n\nexport const LEGEND_SCALE_CHANNELS = [\n  'size',\n  'shape',\n  'fill',\n  'stroke',\n  'strokeDash',\n  'strokeWidth',\n  'opacity'\n] as const;\n\ntype BaseLegendNoValueRefs<ES extends ExprRef | SignalRef> = MapExcludeValueRefAndReplaceSignalWith<BaseLegend, ES>;\n\nexport type LegendConfig<ES extends ExprRef | SignalRef> = LegendMixins<ES> &\n  VlOnlyGuideConfig &\n  MapExcludeValueRefAndReplaceSignalWith<VgLegendConfig, ES> & {\n    /**\n     * Max legend length for a vertical gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `200`\n     */\n    gradientVerticalMaxLength?: number;\n\n    /**\n     * Min legend length for a vertical gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `100`\n     */\n    gradientVerticalMinLength?: number;\n\n    /**\n     * Max legend length for a horizontal gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `200`\n     */\n    gradientHorizontalMaxLength?: number;\n\n    /**\n     * Min legend length for a horizontal gradient when `config.legend.gradientLength` is undefined.\n     *\n     * __Default value:__ `100`\n     */\n    gradientHorizontalMinLength?: number;\n\n    /**\n     * The length in pixels of the primary axis of a color gradient. This value corresponds to the height of a vertical gradient or the width of a horizontal gradient.\n     *\n     * __Default value:__ `undefined`. If `undefined`, the default gradient will be determined based on the following rules:\n     * - For vertical gradients, `clamp(plot_height, gradientVerticalMinLength, gradientVerticalMaxLength)`\n     * - For top-`orient`ed or bottom-`orient`ed horizontal gradients, `clamp(plot_width, gradientHorizontalMinLength, gradientHorizontalMaxLength)`\n     * - For other horizontal gradients, `gradientHorizontalMinLength`\n     *\n     * where `clamp(value, min, max)` restricts _value_ to be between the specified _min_ and _max_.\n     * @minimum 0\n     */\n    gradientLength?: number;\n\n    /**\n     * The opacity of unselected legend entries.\n     *\n     * __Default value:__ 0.35.\n     */\n    unselectedOpacity?: number;\n\n    /**\n     * Disable legend by default\n     */\n    disable?: boolean;\n  };\n\n/**\n * Properties of a legend or boolean flag for determining whether to show it.\n */\nexport interface Legend<ES extends ExprRef | SignalRef>\n  extends Omit<BaseLegendNoValueRefs<ES>, 'orient'>,\n    LegendMixins<ES>,\n    Guide {\n  /**\n   * Mark definitions for custom legend encoding.\n   *\n   * @hidden\n   */\n  encoding?: LegendEncoding;\n\n  /**\n   * [Vega expression](https://vega.github.io/vega/docs/expressions/) for customizing labels.\n   *\n   * __Note:__ The label text and value can be assessed via the `label` and `value` properties of the legend's backing `datum` object.\n   */\n  labelExpr?: string;\n\n  /**\n   * The minimum desired step between legend ticks, in terms of scale domain values. For example, a value of `1` indicates that ticks should not be less than 1 unit apart. If `tickMinStep` is specified, the `tickCount` value will be adjusted, if necessary, to enforce the minimum step value.\n   *\n   * __Default value__: `undefined`\n   */\n  tickMinStep?: number | ES;\n\n  /**\n   * Explicitly set the visible legend values.\n   */\n  values?: number[] | string[] | boolean[] | DateTime[] | ES; // Vega already supports Signal -- we have to re-declare here since VL supports special Date Time object that's not valid in Vega.\n\n  /**\n   * The type of the legend. Use `\"symbol\"` to create a discrete legend and `\"gradient\"` for a continuous color gradient.\n   *\n   * __Default value:__ `\"gradient\"` for non-binned quantitative fields and temporal fields; `\"symbol\"` otherwise.\n   */\n  type?: 'symbol' | 'gradient';\n\n  /**\n   * A non-negative integer indicating the z-index of the legend.\n   * If zindex is 0, legend should be drawn behind all chart elements.\n   * To put them in front, use zindex = 1.\n   *\n   * @TJS-type integer\n   * @minimum 0\n   */\n  zindex?: number;\n}\n\n// Change comments to be Vega-Lite specific\ninterface LegendMixins<ES extends ExprRef | SignalRef> {\n  /**\n   * The strategy to use for resolving overlap of labels in gradient legends. If `false`, no overlap reduction is attempted. If set to `true` or `\"parity\"`, a strategy of removing every other label is used. If set to `\"greedy\"`, a linear scan of the labels is performed, removing any label that overlaps with the last visible label (this often works better for log-scaled axes).\n   *\n   * __Default value:__ `\"greedy\"` for `log scales otherwise `true`.\n   */\n  labelOverlap?: LabelOverlap | ES; // override comment since our default differs from Vega\n\n  /**\n   * The direction of the legend, one of `\"vertical\"` or `\"horizontal\"`.\n   *\n   * __Default value:__\n   * - For top-/bottom-`orient`ed legends, `\"horizontal\"`\n   * - For left-/right-`orient`ed legends, `\"vertical\"`\n   * - For top/bottom-left/right-`orient`ed legends, `\"horizontal\"` for gradient legends and `\"vertical\"` for symbol legends.\n   */\n  direction?: Orientation; // Omit SignalRef\n\n  /**\n   * The orientation of the legend, which determines how the legend is positioned within the scene. One of `\"left\"`, `\"right\"`, `\"top\"`, `\"bottom\"`, `\"top-left\"`, `\"top-right\"`, `\"bottom-left\"`, `\"bottom-right\"`, `\"none\"`.\n   *\n   * __Default value:__ `\"right\"`\n   */\n  orient?: LegendOrient; // Omit SignalRef\n}\n\nexport type LegendInternal = Legend<SignalRef>;\n\nexport interface LegendEncoding {\n  /**\n   * Custom encoding for the legend container.\n   * This can be useful for creating legend with custom x, y position.\n   */\n  legend?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for the legend title text mark.\n   */\n  title?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for legend label text marks.\n   */\n  labels?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for legend symbol marks.\n   */\n  symbols?: GuideEncodingEntry;\n\n  /**\n   * Custom encoding for legend gradient filled rect marks.\n   */\n  gradient?: GuideEncodingEntry;\n}\n\nexport const defaultLegendConfig: LegendConfig<SignalRef> = {\n  gradientHorizontalMaxLength: 200,\n  gradientHorizontalMinLength: 100,\n  gradientVerticalMaxLength: 200,\n  gradientVerticalMinLength: 64, // This is Vega's minimum.\n  unselectedOpacity: 0.35\n};\n\nexport const COMMON_LEGEND_PROPERTY_INDEX: Flag<keyof (VgLegend | Legend<any>)> = {\n  aria: 1,\n  clipHeight: 1,\n  columnPadding: 1,\n  columns: 1,\n  cornerRadius: 1,\n  description: 1,\n  direction: 1,\n  fillColor: 1,\n  format: 1,\n  formatType: 1,\n  gradientLength: 1,\n  gradientOpacity: 1,\n  gradientStrokeColor: 1,\n  gradientStrokeWidth: 1,\n  gradientThickness: 1,\n  gridAlign: 1,\n  labelAlign: 1,\n  labelBaseline: 1,\n  labelColor: 1,\n  labelFont: 1,\n  labelFontSize: 1,\n  labelFontStyle: 1,\n  labelFontWeight: 1,\n  labelLimit: 1,\n  labelOffset: 1,\n  labelOpacity: 1,\n  labelOverlap: 1,\n  labelPadding: 1,\n  labelSeparation: 1,\n  legendX: 1,\n  legendY: 1,\n  offset: 1,\n  orient: 1,\n  padding: 1,\n  rowPadding: 1,\n  strokeColor: 1,\n  symbolDash: 1,\n  symbolDashOffset: 1,\n  symbolFillColor: 1,\n  symbolLimit: 1,\n  symbolOffset: 1,\n  symbolOpacity: 1,\n  symbolSize: 1,\n  symbolStrokeColor: 1,\n  symbolStrokeWidth: 1,\n  symbolType: 1,\n  tickCount: 1,\n  tickMinStep: 1,\n  title: 1,\n  titleAlign: 1,\n  titleAnchor: 1,\n  titleBaseline: 1,\n  titleColor: 1,\n  titleFont: 1,\n  titleFontSize: 1,\n  titleFontStyle: 1,\n  titleFontWeight: 1,\n  titleLimit: 1,\n  titleLineHeight: 1,\n  titleOpacity: 1,\n  titleOrient: 1,\n  titlePadding: 1,\n  type: 1,\n  values: 1,\n  zindex: 1\n};\n\nexport const LEGEND_PROPERTIES = keys(COMMON_LEGEND_PROPERTY_INDEX);\n","/**\n * Collection of all Vega-Lite Error Messages\n */\nimport {AggregateOp} from 'vega';\nimport {Aggregate} from '../aggregate';\nimport {\n  Channel,\n  ExtendedChannel,\n  FacetChannel,\n  GeoPositionChannel,\n  getSizeChannel,\n  PositionScaleChannel,\n  ScaleChannel\n} from '../channel';\nimport {HiddenCompositeAggregate, TypedFieldDef, Value} from '../channeldef';\nimport {SplitParentProperty} from '../compile/split';\nimport {CompositeMark} from '../compositemark';\nimport {ErrorBarCenter, ErrorBarExtent} from '../compositemark/errorbar';\nimport {DateTime, DateTimeExpr} from '../datetime';\nimport {Mark} from '../mark';\nimport {Projection} from '../projection';\nimport {ScaleType} from '../scale';\nimport {GenericSpec} from '../spec';\nimport {Type} from '../type';\nimport {stringify} from '../util';\nimport {VgSortField} from '../vega.schema';\n\nexport function invalidSpec(spec: GenericSpec<any, any, any, any>) {\n  return `Invalid specification ${JSON.stringify(\n    spec\n  )}. Make sure the specification includes at least one of the following properties: \"mark\", \"layer\", \"facet\", \"hconcat\", \"vconcat\", \"concat\", or \"repeat\".`;\n}\n\n// FIT\nexport const FIT_NON_SINGLE = 'Autosize \"fit\" only works for single views and layered views.';\n\nexport function containerSizeNonSingle(name: 'width' | 'height') {\n  const uName = name == 'width' ? 'Width' : 'Height';\n  return `${uName} \"container\" only works for single views and layered views.`;\n}\n\nexport function containerSizeNotCompatibleWithAutosize(name: 'width' | 'height') {\n  const uName = name == 'width' ? 'Width' : 'Height';\n  const fitDirection = name == 'width' ? 'x' : 'y';\n  return `${uName} \"container\" only works well with autosize \"fit\" or \"fit-${fitDirection}\".`;\n}\n\nexport function droppingFit(channel?: PositionScaleChannel) {\n  return channel\n    ? `Dropping \"fit-${channel}\" because spec has discrete ${getSizeChannel(channel)}.`\n    : `Dropping \"fit\" because spec has discrete size.`;\n}\n\n// VIEW SIZE\n\nexport function unknownField(channel: Channel) {\n  return `Unknown field for ${channel}. Cannot calculate view size.`;\n}\n\n// SELECTION\nexport function cannotProjectOnChannelWithoutField(channel: Channel) {\n  return `Cannot project a selection on encoding channel \"${channel}\", which has no field.`;\n}\n\nexport function cannotProjectAggregate(channel: Channel, aggregate: Aggregate | HiddenCompositeAggregate) {\n  return `Cannot project a selection on encoding channel \"${channel}\" as it uses an aggregate function (\"${aggregate}\").`;\n}\n\nexport function nearestNotSupportForContinuous(mark: string) {\n  return `The \"nearest\" transform is not supported for ${mark} marks.`;\n}\n\nexport function selectionNotSupported(mark: CompositeMark) {\n  return `Selection not supported for ${mark} yet.`;\n}\n\nexport function selectionNotFound(name: string) {\n  return `Cannot find a selection named \"${name}\".`;\n}\n\nexport const SCALE_BINDINGS_CONTINUOUS =\n  'Scale bindings are currently only supported for scales with unbinned, continuous domains.';\n\nexport const LEGEND_BINDINGS_MUST_HAVE_PROJECTION =\n  'Legend bindings are only supported for selections over an individual field or encoding channel.';\nexport function noSameUnitLookup(name: string) {\n  return (\n    `Cannot define and lookup the \"${name}\" selection in the same view. ` +\n    `Try moving the lookup into a second, layered view?`\n  );\n}\n\nexport const NEEDS_SAME_SELECTION = 'The same selection must be used to override scale domains in a layered view.';\n\nexport const INTERVAL_INITIALIZED_WITH_X_Y = 'Interval selections should be initialized using \"x\" and/or \"y\" keys.';\n\n// REPEAT\nexport function noSuchRepeatedValue(field: string) {\n  return `Unknown repeated value \"${field}\".`;\n}\n\nexport function columnsNotSupportByRowCol(type: 'facet' | 'repeat') {\n  return `The \"columns\" property cannot be used when \"${type}\" has nested row/column.`;\n}\n\n// CONCAT / REPEAT\nexport const CONCAT_CANNOT_SHARE_AXIS =\n  'Axes cannot be shared in concatenated or repeated views yet (https://github.com/vega/vega-lite/issues/2415).';\n\n// DATA\nexport function unrecognizedParse(p: string) {\n  return `Unrecognized parse \"${p}\".`;\n}\n\nexport function differentParse(field: string, local: string, ancestor: string) {\n  return `An ancestor parsed field \"${field}\" as ${ancestor} but a child wants to parse the field as ${local}.`;\n}\n\nexport const ADD_SAME_CHILD_TWICE = 'Attempt to add the same child twice.';\n\n// TRANSFORMS\nexport function invalidTransformIgnored(transform: any) {\n  return `Ignoring an invalid transform: ${stringify(transform)}.`;\n}\n\nexport const NO_FIELDS_NEEDS_AS =\n  'If \"from.fields\" is not specified, \"as\" has to be a string that specifies the key to be used for the data from the secondary source.';\n\n// ENCODING & FACET\n\nexport function customFormatTypeNotAllowed(channel: ExtendedChannel) {\n  return `Config.customFormatTypes is not true, thus custom format type and format for channel ${channel} are dropped.`;\n}\n\nexport function projectionOverridden(opt: {parentProjection: Projection; projection: Projection}) {\n  const {parentProjection, projection} = opt;\n  return `Layer's shared projection ${stringify(parentProjection)} is overridden by a child projection ${stringify(\n    projection\n  )}.`;\n}\n\nexport const REPLACE_ANGLE_WITH_THETA = 'Arc marks uses theta channel rather than angle, replacing angle with theta.';\n\nexport function primitiveChannelDef(\n  channel: ExtendedChannel,\n  type: 'string' | 'number' | 'boolean',\n  value: Exclude<Value, null>\n) {\n  return `Channel ${channel} is a ${type}. Converted to {value: ${stringify(value)}}.`;\n}\n\nexport function invalidFieldType(type: Type) {\n  return `Invalid field type \"${type}\".`;\n}\n\nexport function invalidFieldTypeForCountAggregate(type: Type, aggregate: Aggregate | string) {\n  return `Invalid field type \"${type}\" for aggregate: \"${aggregate}\", using \"quantitative\" instead.`;\n}\n\nexport function invalidAggregate(aggregate: AggregateOp | string) {\n  return `Invalid aggregation operator \"${aggregate}\".`;\n}\n\nexport function missingFieldType(channel: Channel, newType: Type) {\n  return `Missing type for channel \"${channel}\", using \"${newType}\" instead.`;\n}\nexport function droppingColor(type: 'encoding' | 'property', opt: {fill?: boolean; stroke?: boolean}) {\n  const {fill, stroke} = opt;\n  return `Dropping color ${type} as the plot also has ${\n    fill && stroke ? 'fill and stroke' : fill ? 'fill' : 'stroke'\n  }.`;\n}\n\nexport function emptyFieldDef(fieldDef: unknown, channel: ExtendedChannel) {\n  return `Dropping ${stringify(\n    fieldDef\n  )} from channel \"${channel}\" since it does not contain any data field, datum, value, or signal.`;\n}\nexport function latLongDeprecated(channel: Channel, type: Type, newChannel: GeoPositionChannel) {\n  return `${channel}-encoding with type ${type} is deprecated. Replacing with ${newChannel}-encoding.`;\n}\n\nexport const LINE_WITH_VARYING_SIZE =\n  'Line marks cannot encode size with a non-groupby field. You may want to use trail marks instead.';\n\nexport function incompatibleChannel(\n  channel: ExtendedChannel,\n  markOrFacet: Mark | 'facet' | CompositeMark,\n  when?: string\n) {\n  return `${channel} dropped as it is incompatible with \"${markOrFacet}\"${when ? ` when ${when}` : ''}.`;\n}\n\nexport function invalidEncodingChannel(channel: ExtendedChannel) {\n  return `${channel}-encoding is dropped as ${channel} is not a valid encoding channel.`;\n}\n\nexport function facetChannelShouldBeDiscrete(channel: FacetChannel) {\n  return `${channel} encoding should be discrete (ordinal / nominal / binned).`;\n}\n\nexport function facetChannelDropped(channels: FacetChannel[]) {\n  return `Facet encoding dropped as ${channels.join(' and ')} ${channels.length > 1 ? 'are' : 'is'} also specified.`;\n}\n\nexport function discreteChannelCannotEncode(channel: Channel, type: Type) {\n  return `Using discrete channel \"${channel}\" to encode \"${type}\" field can be misleading as it does not encode ${\n    type === 'ordinal' ? 'order' : 'magnitude'\n  }.`;\n}\n\n// MARK\n\nexport function rangeMarkAlignmentCannotBeExpression(align: 'align' | 'baseline') {\n  return `The ${align} for range marks cannot be an expression`;\n}\n\nexport function lineWithRange(hasX2: boolean, hasY2: boolean) {\n  const channels = hasX2 && hasY2 ? 'x2 and y2' : hasX2 ? 'x2' : 'y2';\n  return `Line mark is for continuous lines and thus cannot be used with ${channels}. We will use the rule mark (line segments) instead.`;\n}\n\nexport function orientOverridden(original: string, actual: string) {\n  return `Specified orient \"${original}\" overridden with \"${actual}\".`;\n}\n\n// SCALE\nexport const CANNOT_UNION_CUSTOM_DOMAIN_WITH_FIELD_DOMAIN =\n  'Custom domain scale cannot be unioned with default field-based domain.';\n\nexport const RANGE_STEP_DEPRECATED = `Scale's \"rangeStep\" is deprecated and will be removed in Vega-Lite 5.0. Please use \"width\"/\"height\": {\"step\": ...} instead. See https://vega.github.io/vega-lite/docs/size.html.`;\n\nexport function cannotUseScalePropertyWithNonColor(prop: string) {\n  return `Cannot use the scale property \"${prop}\" with non-color channel.`;\n}\n\nexport function unaggregateDomainHasNoEffectForRawField(fieldDef: TypedFieldDef<string>) {\n  return `Using unaggregated domain with raw field has no effect (${stringify(fieldDef)}).`;\n}\n\nexport function unaggregateDomainWithNonSharedDomainOp(aggregate: Aggregate | string) {\n  return `Unaggregated domain not applicable for \"${aggregate}\" since it produces values outside the origin domain of the source data.`;\n}\n\nexport function unaggregatedDomainWithLogScale(fieldDef: TypedFieldDef<string>) {\n  return `Unaggregated domain is currently unsupported for log scale (${stringify(fieldDef)}).`;\n}\n\nexport function cannotApplySizeToNonOrientedMark(mark: Mark) {\n  return `Cannot apply size to non-oriented mark \"${mark}\".`;\n}\n\nexport function scaleTypeNotWorkWithChannel(channel: Channel, scaleType: ScaleType, defaultScaleType: ScaleType) {\n  return `Channel \"${channel}\" does not work with \"${scaleType}\" scale. We are using \"${defaultScaleType}\" scale instead.`;\n}\n\nexport function scaleTypeNotWorkWithFieldDef(scaleType: ScaleType, defaultScaleType: ScaleType) {\n  return `FieldDef does not work with \"${scaleType}\" scale. We are using \"${defaultScaleType}\" scale instead.`;\n}\n\nexport function scalePropertyNotWorkWithScaleType(scaleType: ScaleType, propName: string, channel: Channel) {\n  return `${channel}-scale's \"${propName}\" is dropped as it does not work with ${scaleType} scale.`;\n}\n\nexport function scaleTypeNotWorkWithMark(mark: Mark, scaleType: ScaleType) {\n  return `Scale type \"${scaleType}\" does not work with mark \"${mark}\".`;\n}\n\nexport function stepDropped(channel: 'width' | 'height') {\n  return `The step for \"${channel}\" is dropped because the ${channel === 'width' ? 'x' : 'y'} is continuous.`;\n}\n\nexport function mergeConflictingProperty<T>(\n  property: string | number | symbol,\n  propertyOf: SplitParentProperty,\n  v1: T,\n  v2: T\n) {\n  return `Conflicting ${propertyOf.toString()} property \"${property.toString()}\" (${stringify(v1)} and ${stringify(\n    v2\n  )}). Using ${stringify(v1)}.`;\n}\n\nexport function mergeConflictingDomainProperty<T>(property: 'domains', propertyOf: SplitParentProperty, v1: T, v2: T) {\n  return `Conflicting ${propertyOf.toString()} property \"${property.toString()}\" (${stringify(v1)} and ${stringify(\n    v2\n  )}). Using the union of the two domains.`;\n}\n\nexport function independentScaleMeansIndependentGuide(channel: Channel) {\n  return `Setting the scale to be independent for \"${channel}\" means we also have to set the guide (axis or legend) to be independent.`;\n}\n\nexport function domainSortDropped(sort: VgSortField) {\n  return `Dropping sort property ${stringify(\n    sort\n  )} as unioned domains only support boolean or op \"count\", \"min\", and \"max\".`;\n}\n\nexport const MORE_THAN_ONE_SORT =\n  'Domains that should be unioned has conflicting sort properties. Sort will be set to true.';\n\nexport const FACETED_INDEPENDENT_DIFFERENT_SOURCES =\n  'Detected faceted independent scales that union domain of multiple fields from different data sources. We will use the first field. The result view size may be incorrect.';\n\nexport const FACETED_INDEPENDENT_SAME_FIELDS_DIFFERENT_SOURCES =\n  'Detected faceted independent scales that union domain of the same fields from different source. We will assume that this is the same field from a different fork of the same data source. However, if this is not the case, the result view size may be incorrect.';\n\nexport const FACETED_INDEPENDENT_SAME_SOURCE =\n  'Detected faceted independent scales that union domain of multiple fields from the same data source. We will use the first field. The result view size may be incorrect.';\n\n// AXIS\nexport const INVALID_CHANNEL_FOR_AXIS = 'Invalid channel for axis.';\n\n// STACK\nexport function cannotStackRangedMark(channel: Channel) {\n  return `Cannot stack \"${channel}\" if there is already \"${channel}2\".`;\n}\n\nexport function cannotStackNonLinearScale(scaleType: ScaleType) {\n  return `Cannot stack non-linear scale (${scaleType}).`;\n}\n\nexport function stackNonSummativeAggregate(aggregate: Aggregate | string) {\n  return `Stacking is applied even though the aggregate function is non-summative (\"${aggregate}\").`;\n}\n\n// TIMEUNIT\nexport function invalidTimeUnit(unitName: string, value: string | number) {\n  return `Invalid ${unitName}: ${stringify(value)}.`;\n}\n\nexport function droppedDay(d: DateTime | DateTimeExpr) {\n  return `Dropping day from datetime ${stringify(d)} as day cannot be combined with other units.`;\n}\n\nexport function errorBarCenterAndExtentAreNotNeeded(center: ErrorBarCenter, extent: ErrorBarExtent) {\n  return `${extent ? 'extent ' : ''}${extent && center ? 'and ' : ''}${center ? 'center ' : ''}${\n    extent && center ? 'are ' : 'is '\n  }not needed when data are aggregated.`;\n}\n\nexport function errorBarCenterIsUsedWithWrongExtent(\n  center: ErrorBarCenter,\n  extent: ErrorBarExtent,\n  mark: 'errorbar' | 'errorband'\n) {\n  return `${center} is not usually used with ${extent} for ${mark}.`;\n}\n\nexport function errorBarContinuousAxisHasCustomizedAggregate(\n  aggregate: Aggregate | string,\n  compositeMark: CompositeMark\n) {\n  return `Continuous axis should not have customized aggregation function ${aggregate}; ${compositeMark} already agregates the axis.`;\n}\n\nexport function errorBand1DNotSupport(property: 'interpolate' | 'tension') {\n  return `1D error band does not support ${property}.`;\n}\n\n// CHANNEL\nexport function channelRequiredForBinned(channel: Channel) {\n  return `Channel ${channel} is required for \"binned\" bin.`;\n}\n\nexport function channelShouldNotBeUsedForBinned(channel: ExtendedChannel) {\n  return `Channel ${channel} should not be used with \"binned\" bin.`;\n}\n\nexport function domainRequiredForThresholdScale(channel: ScaleChannel) {\n  return `Domain for ${channel} is required for threshold scale.`;\n}\n","/**\n * Vega-Lite's singleton logger utility.\n */\n\nimport {Debug, Error as ErrorLevel, Info, logger, LoggerInterface, Warn} from 'vega-util';\nexport * as message from './message';\n\n/**\n * Main (default) Vega Logger instance for Vega-Lite.\n */\nconst main = logger(Warn);\nlet current: LoggerInterface = main;\n\n/**\n * Logger tool for checking if the code throws correct warning.\n */\nexport class LocalLogger implements LoggerInterface {\n  public warns: any[] = [];\n  public infos: any[] = [];\n  public debugs: any[] = [];\n\n  #level: number = Warn;\n\n  public level(): number;\n  public level(_: number): this;\n  public level(_?: number) {\n    if (_) {\n      this.#level = _;\n      return this;\n    }\n    return this.#level;\n  }\n\n  public warn(...args: readonly any[]) {\n    if (this.#level >= Warn) this.warns.push(...args);\n    return this;\n  }\n\n  public info(...args: readonly any[]) {\n    if (this.#level >= Info) this.infos.push(...args);\n    return this;\n  }\n\n  public debug(...args: readonly any[]) {\n    if (this.#level >= Debug) this.debugs.push(...args);\n    return this;\n  }\n\n  public error(...args: readonly any[]): this {\n    if (this.#level >= ErrorLevel) throw Error(...args);\n    return this;\n  }\n}\n\nexport function wrap(f: (logger: LocalLogger) => void) {\n  return () => {\n    current = new LocalLogger();\n    f(current as LocalLogger);\n    reset();\n  };\n}\n\n/**\n * Set the singleton logger to be a custom logger.\n */\nexport function set(newLogger: LoggerInterface) {\n  current = newLogger;\n  return current;\n}\n\n/**\n * Reset the main logger to use the default Vega Logger.\n */\nexport function reset() {\n  current = main;\n  return current;\n}\n\nexport function error(...args: readonly any[]) {\n  current.error(...args);\n}\n\nexport function warn(...args: readonly any[]) {\n  current.warn(...args);\n}\n\nexport function info(...args: readonly any[]) {\n  current.info(...args);\n}\n\nexport function debug(...args: readonly any[]) {\n  current.debug(...args);\n}\n","import {keys} from './util';\n\n/**\n * Data type based on level of measurement\n */\nexport const Type = {\n  quantitative: 'quantitative',\n  ordinal: 'ordinal',\n  temporal: 'temporal',\n  nominal: 'nominal',\n  geojson: 'geojson'\n} as const;\n\nexport type Type = keyof typeof Type;\n\nexport function isType(t: any): t is Type {\n  return t in Type;\n}\n\nexport const QUANTITATIVE = Type.quantitative;\nexport const ORDINAL = Type.ordinal;\nexport const TEMPORAL = Type.temporal;\nexport const NOMINAL = Type.nominal;\n\nexport const GEOJSON = Type.geojson;\n\nexport type StandardType = 'quantitative' | 'ordinal' | 'temporal' | 'nominal';\n\nexport const TYPES = keys(Type);\n\n/**\n * Get full, lowercase type name for a given type.\n * @param  type\n * @return Full type name.\n */\nexport function getFullName(type: Type | string): Type | undefined {\n  if (type) {\n    type = type.toLowerCase();\n    switch (type) {\n      case 'q':\n      case QUANTITATIVE:\n        return 'quantitative';\n      case 't':\n      case TEMPORAL:\n        return 'temporal';\n      case 'o':\n      case ORDINAL:\n        return 'ordinal';\n      case 'n':\n      case NOMINAL:\n        return 'nominal';\n      case GEOJSON:\n        return 'geojson';\n    }\n  }\n  // If we get invalid input, return undefined type.\n  return undefined;\n}\n","import {\n  RangeEnum,\n  ScaleBins,\n  ScaleInterpolateEnum,\n  ScaleInterpolateParams,\n  SignalRef,\n  TimeInterval,\n  TimeIntervalStep\n} from 'vega';\nimport {isString, toSet} from 'vega-util';\nimport * as CHANNEL from './channel';\nimport {Channel, isColorChannel} from './channel';\nimport {DateTime} from './datetime';\nimport {ExprRef} from './expr';\nimport * as log from './log';\nimport {SelectionExtent} from './selection';\nimport {NOMINAL, ORDINAL, QUANTITATIVE, TEMPORAL, Type} from './type';\nimport {contains, Flag, keys} from './util';\n\nexport const ScaleType = {\n  // Continuous - Quantitative\n  LINEAR: 'linear',\n  LOG: 'log',\n  POW: 'pow',\n  SQRT: 'sqrt',\n  SYMLOG: 'symlog',\n\n  IDENTITY: 'identity',\n  SEQUENTIAL: 'sequential',\n\n  // Continuous - Time\n  TIME: 'time',\n  UTC: 'utc',\n\n  // Discretizing scales\n  QUANTILE: 'quantile',\n  QUANTIZE: 'quantize',\n  THRESHOLD: 'threshold',\n  BIN_ORDINAL: 'bin-ordinal',\n\n  // Discrete scales\n  ORDINAL: 'ordinal',\n  POINT: 'point',\n  BAND: 'band'\n} as const;\n\ntype ValueOf<T> = T[keyof T];\nexport type ScaleType = ValueOf<typeof ScaleType>;\n\n/**\n * Index for scale categories -- only scale of the same categories can be merged together.\n * Current implementation is trying to be conservative and avoid merging scale type that might not work together\n */\nexport const SCALE_CATEGORY_INDEX: Record<ScaleType, ScaleType | 'numeric' | 'ordinal-position' | 'discretizing'> = {\n  linear: 'numeric',\n  log: 'numeric',\n  pow: 'numeric',\n  sqrt: 'numeric',\n  symlog: 'numeric',\n  identity: 'numeric',\n  sequential: 'numeric',\n  time: 'time',\n  utc: 'time',\n  ordinal: 'ordinal',\n  'bin-ordinal': 'bin-ordinal', // TODO: should bin-ordinal support merging with other\n  point: 'ordinal-position',\n  band: 'ordinal-position',\n  quantile: 'discretizing',\n  quantize: 'discretizing',\n  threshold: 'discretizing'\n};\n\nexport const SCALE_TYPES = keys(SCALE_CATEGORY_INDEX) as ScaleType[];\n\n/**\n * Whether the two given scale types can be merged together.\n */\nexport function scaleCompatible(scaleType1: ScaleType, scaleType2: ScaleType) {\n  const scaleCategory1 = SCALE_CATEGORY_INDEX[scaleType1];\n  const scaleCategory2 = SCALE_CATEGORY_INDEX[scaleType2];\n  return (\n    scaleCategory1 === scaleCategory2 ||\n    (scaleCategory1 === 'ordinal-position' && scaleCategory2 === 'time') ||\n    (scaleCategory2 === 'ordinal-position' && scaleCategory1 === 'time')\n  );\n}\n\n/**\n * Index for scale precedence -- high score = higher priority for merging.\n */\nconst SCALE_PRECEDENCE_INDEX: Record<ScaleType, number> = {\n  // numeric\n  linear: 0,\n  log: 1,\n  pow: 1,\n  sqrt: 1,\n  symlog: 1,\n  identity: 1,\n  sequential: 1,\n  // time\n  time: 0,\n  utc: 0,\n  // ordinal-position -- these have higher precedence than continuous scales as they support more types of data\n  point: 10,\n  band: 11, // band has higher precedence as it is better for interaction\n  // non grouped types\n  ordinal: 0,\n  'bin-ordinal': 0,\n  quantile: 0,\n  quantize: 0,\n  threshold: 0\n};\n\n/**\n * Return scale categories -- only scale of the same categories can be merged together.\n */\nexport function scaleTypePrecedence(scaleType: ScaleType): number {\n  return SCALE_PRECEDENCE_INDEX[scaleType];\n}\n\nexport const CONTINUOUS_TO_CONTINUOUS_SCALES: ScaleType[] = ['linear', 'log', 'pow', 'sqrt', 'symlog', 'time', 'utc'];\nconst CONTINUOUS_TO_CONTINUOUS_INDEX = toSet(CONTINUOUS_TO_CONTINUOUS_SCALES);\n\nexport const QUANTITATIVE_SCALES: ScaleType[] = ['linear', 'log', 'pow', 'sqrt', 'symlog'];\n\nconst QUANTITATIVE_SCALES_INDEX = toSet(QUANTITATIVE_SCALES);\n\nexport function isQuantitative(type: ScaleType): type is 'linear' | 'log' | 'pow' | 'sqrt' | 'symlog' {\n  return type in QUANTITATIVE_SCALES_INDEX;\n}\n\nexport const CONTINUOUS_TO_DISCRETE_SCALES: ScaleType[] = ['quantile', 'quantize', 'threshold'];\nconst CONTINUOUS_TO_DISCRETE_INDEX = toSet(CONTINUOUS_TO_DISCRETE_SCALES);\n\nexport const CONTINUOUS_DOMAIN_SCALES: ScaleType[] = CONTINUOUS_TO_CONTINUOUS_SCALES.concat([\n  'quantile',\n  'quantize',\n  'threshold',\n  'sequential',\n  'identity'\n]);\nconst CONTINUOUS_DOMAIN_INDEX = toSet(CONTINUOUS_DOMAIN_SCALES);\n\nexport const DISCRETE_DOMAIN_SCALES: ScaleType[] = ['ordinal', 'bin-ordinal', 'point', 'band'];\nconst DISCRETE_DOMAIN_INDEX = toSet(DISCRETE_DOMAIN_SCALES);\n\nexport const TIME_SCALE_TYPES: ScaleType[] = ['time', 'utc'];\n\nexport function hasDiscreteDomain(type: ScaleType): type is 'ordinal' | 'bin-ordinal' | 'point' | 'band' {\n  return type in DISCRETE_DOMAIN_INDEX;\n}\n\nexport function hasContinuousDomain(\n  type: ScaleType\n): type is 'linear' | 'log' | 'pow' | 'sqrt' | 'symlog' | 'time' | 'utc' | 'quantile' | 'quantize' | 'threshold' {\n  return type in CONTINUOUS_DOMAIN_INDEX;\n}\n\nexport function isContinuousToContinuous(\n  type: ScaleType\n): type is 'linear' | 'log' | 'pow' | 'sqrt' | 'symlog' | 'time' | 'utc' {\n  return type in CONTINUOUS_TO_CONTINUOUS_INDEX;\n}\n\nexport function isContinuousToDiscrete(type: ScaleType): type is 'quantile' | 'quantize' | 'threshold' {\n  return type in CONTINUOUS_TO_DISCRETE_INDEX;\n}\n\nexport interface ScaleConfig<ES extends ExprRef | SignalRef> {\n  /**\n   * If true, rounds numeric output values to integers.\n   * This can be helpful for snapping to the pixel grid.\n   * (Only available for `x`, `y`, and `size` scales.)\n   */\n  round?: boolean | ES;\n\n  /**\n   * If true, values that exceed the data domain are clamped to either the minimum or maximum range value\n   */\n  clamp?: boolean | ES;\n\n  /**\n   * Default inner padding for `x` and `y` band-ordinal scales.\n   *\n   * __Default value:__\n   * - `barBandPaddingInner` for bar marks (`0.1` by default)\n   * - `rectBandPaddingInner` for rect and other marks (`0` by default)\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  bandPaddingInner?: number | ES;\n\n  /**\n   * Default outer padding for `x` and `y` band-ordinal scales.\n   *\n   * __Default value:__ `paddingInner/2` (which makes _width/height = number of unique values * step_)\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  bandPaddingOuter?: number | ES;\n\n  /**\n   * Default inner padding for `x` and `y` band-ordinal scales of `\"bar\"` marks.\n   *\n   * __Default value:__ `0.1`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  barBandPaddingInner?: number | ES;\n\n  /**\n   * Default inner padding for `x` and `y` band-ordinal scales of `\"rect\"` marks.\n   *\n   * __Default value:__ `0`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  rectBandPaddingInner?: number | ES;\n\n  /**\n   * Default padding for continuous scales.\n   *\n   * __Default:__ `5` for continuous x-scale of a vertical bar and continuous y-scale of a horizontal bar.; `0` otherwise.\n   *\n   * @minimum 0\n   */\n  continuousPadding?: number | ES;\n\n  /**\n   * Default outer padding for `x` and `y` point-ordinal scales.\n   *\n   * __Default value:__ `0.5` (which makes _width/height = number of unique values * step_)\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  pointPadding?: number | ES;\n\n  /**\n   * Use the source data range before aggregation as scale domain instead of aggregated data for aggregate axis.\n   *\n   * This is equivalent to setting `domain` to `\"unaggregate\"` for aggregated _quantitative_ fields by default.\n   *\n   * This property only works with aggregate functions that produce values within the raw data domain (`\"mean\"`, `\"average\"`, `\"median\"`, `\"q1\"`, `\"q3\"`, `\"min\"`, `\"max\"`). For other aggregations that produce values outside of the raw data domain (e.g. `\"count\"`, `\"sum\"`), this property is ignored.\n   *\n   * __Default value:__ `false`\n   */\n  useUnaggregatedDomain?: boolean;\n\n  // nice should depends on type (quantitative or temporal), so\n  // let's not make a config.\n\n  // Configs for Range\n\n  /**\n   * The default max value for mapping quantitative fields to bar's size/bandSize.\n   *\n   * If undefined (default), we will use the axis's size (width or height) - 1.\n   * @minimum 0\n   */\n  maxBandSize?: number;\n\n  /**\n   * The default min value for mapping quantitative fields to bar and tick's size/bandSize scale with zero=false.\n   *\n   * __Default value:__ `2`\n   *\n   * @minimum 0\n   */\n  minBandSize?: number;\n\n  /**\n   * The default max value for mapping quantitative fields to text's size/fontSize.\n   *\n   * __Default value:__ `40`\n   *\n   * @minimum 0\n   */\n  maxFontSize?: number;\n\n  /**\n   * The default min value for mapping quantitative fields to tick's size/fontSize scale with zero=false\n   *\n   * __Default value:__ `8`\n   *\n   * @minimum 0\n   */\n  minFontSize?: number;\n\n  /**\n   * Default minimum opacity for mapping a field to opacity.\n   *\n   * __Default value:__ `0.3`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  minOpacity?: number;\n\n  /**\n   * Default max opacity for mapping a field to opacity.\n   *\n   * __Default value:__ `0.8`\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  maxOpacity?: number;\n\n  /**\n   * Default minimum value for point size scale with zero=false.\n   *\n   * __Default value:__ `9`\n   *\n   * @minimum 0\n   */\n  minSize?: number;\n\n  /**\n   * Default max value for point size scale.\n   * @minimum 0\n   */\n  maxSize?: number;\n\n  /**\n   * Default minimum strokeWidth for the scale of strokeWidth for rule and line marks and of size for trail marks with zero=false.\n   *\n   * __Default value:__ `1`\n   *\n   * @minimum 0\n   */\n  minStrokeWidth?: number;\n\n  /**\n   * Default max strokeWidth for the scale of strokeWidth for rule and line marks and of size for trail marks.\n   *\n   * __Default value:__ `4`\n   *\n   * @minimum 0\n   */\n  maxStrokeWidth?: number;\n\n  /**\n   * Default range cardinality for [`quantile`](https://vega.github.io/vega-lite/docs/scale.html#quantile) scale.\n   *\n   * __Default value:__ `4`\n   *\n   * @minimum 0\n   */\n  quantileCount?: number;\n\n  /**\n   * Default range cardinality for [`quantize`](https://vega.github.io/vega-lite/docs/scale.html#quantize) scale.\n   *\n   * __Default value:__ `4`\n   *\n   * @minimum 0\n   */\n  quantizeCount?: number;\n\n  /**\n   * Reverse x-scale by default (useful for right-to-left charts).\n   */\n  xReverse?: boolean | ES;\n}\n\nexport const defaultScaleConfig: ScaleConfig<SignalRef> = {\n  pointPadding: 0.5,\n\n  barBandPaddingInner: 0.1,\n  rectBandPaddingInner: 0,\n\n  minBandSize: 2,\n\n  minFontSize: 8,\n  maxFontSize: 40,\n\n  minOpacity: 0.3,\n  maxOpacity: 0.8,\n\n  // FIXME: revise if these *can* become ratios of width/height step\n  minSize: 9, // Point size is area. For square point, 9 = 3 pixel ^ 2, not too small!\n\n  minStrokeWidth: 1,\n  maxStrokeWidth: 4,\n  quantileCount: 4,\n  quantizeCount: 4\n};\n\nexport interface SchemeParams {\n  /**\n   * A color scheme name for ordinal scales (e.g., `\"category10\"` or `\"blues\"`).\n   *\n   * For the full list of supported schemes, please refer to the [Vega Scheme](https://vega.github.io/vega/docs/schemes/#reference) reference.\n   */\n  name: string | SignalRef;\n\n  /**\n   * The extent of the color range to use. For example `[0.2, 1]` will rescale the color scheme such that color values in the range _[0, 0.2)_ are excluded from the scheme.\n   */\n  extent?: (number | SignalRef)[] | SignalRef;\n\n  /**\n   * The number of colors to use in the scheme. This can be useful for scale types such as `\"quantize\"`, which use the length of the scale range to determine the number of discrete bins for the scale domain.\n   */\n  count?: number | SignalRef;\n}\n\nexport type Domain =\n  | (null | string | number | boolean | DateTime | SignalRef)[]\n  | 'unaggregated'\n  | SelectionExtent\n  | SignalRef\n  | DomainUnionWith;\n\nexport type Scheme = string | SchemeParams;\n\nexport function isExtendedScheme(scheme: Scheme | SignalRef): scheme is SchemeParams {\n  return !isString(scheme) && !!scheme['name'];\n}\n\nexport function isSelectionDomain(domain: Domain): domain is SelectionExtent {\n  return domain?.['selection'];\n}\n\nexport interface DomainUnionWith {\n  /**\n   * Customized domain values to be union with the field's values.\n   *\n   * 1) `domain` for _quantitative_ fields can take one of the following forms:\n   *\n   * - a two-element array with minimum and maximum values.\n   * - an array with more than two entries, for [Piecewise  quantitative scales](https://vega.github.io/vega-lite/docs/scale.html#piecewise). (Alternatively, the `domainMid` property can be set for a diverging scale.)\n   * - a string value `\"unaggregated\"`, if the input field is aggregated, to indicate that the domain should include the raw data values prior to the aggregation.\n   *\n   * 2) `domain` for _temporal_ fields can be a two-element array minimum and maximum values, in the form of either timestamps or the [DateTime definition objects](https://vega.github.io/vega-lite/docs/types.html#datetime).\n   *\n   * 3) `domain` for _ordinal_ and _nominal_ fields can be an array that lists valid input values.\n   */\n  unionWith: number[] | string[] | boolean[] | DateTime[];\n}\n\nexport function isDomainUnionWith(domain: Domain): domain is DomainUnionWith {\n  return domain && domain['unionWith'];\n}\n\nexport interface Scale<ES extends ExprRef | SignalRef = ExprRef | SignalRef> {\n  /**\n   * The type of scale. Vega-Lite supports the following categories of scale types:\n   *\n   * 1) [**Continuous Scales**](https://vega.github.io/vega-lite/docs/scale.html#continuous) -- mapping continuous domains to continuous output ranges ([`\"linear\"`](https://vega.github.io/vega-lite/docs/scale.html#linear), [`\"pow\"`](https://vega.github.io/vega-lite/docs/scale.html#pow), [`\"sqrt\"`](https://vega.github.io/vega-lite/docs/scale.html#sqrt), [`\"symlog\"`](https://vega.github.io/vega-lite/docs/scale.html#symlog), [`\"log\"`](https://vega.github.io/vega-lite/docs/scale.html#log), [`\"time\"`](https://vega.github.io/vega-lite/docs/scale.html#time), [`\"utc\"`](https://vega.github.io/vega-lite/docs/scale.html#utc).\n   *\n   * 2) [**Discrete Scales**](https://vega.github.io/vega-lite/docs/scale.html#discrete) -- mapping discrete domains to discrete ([`\"ordinal\"`](https://vega.github.io/vega-lite/docs/scale.html#ordinal)) or continuous ([`\"band\"`](https://vega.github.io/vega-lite/docs/scale.html#band) and [`\"point\"`](https://vega.github.io/vega-lite/docs/scale.html#point)) output ranges.\n   *\n   * 3) [**Discretizing Scales**](https://vega.github.io/vega-lite/docs/scale.html#discretizing) -- mapping continuous domains to discrete output ranges [`\"bin-ordinal\"`](https://vega.github.io/vega-lite/docs/scale.html#bin-ordinal), [`\"quantile\"`](https://vega.github.io/vega-lite/docs/scale.html#quantile), [`\"quantize\"`](https://vega.github.io/vega-lite/docs/scale.html#quantize) and [`\"threshold\"`](https://vega.github.io/vega-lite/docs/scale.html#threshold).\n   *\n   * __Default value:__ please see the [scale type table](https://vega.github.io/vega-lite/docs/scale.html#type).\n   */\n  type?: ScaleType;\n\n  /**\n   * Customized domain values in the form of constant values or dynamic values driven by a selection.\n   *\n   * 1) Constant `domain` for _quantitative_ fields can take one of the following forms:\n   *\n   * - A two-element array with minimum and maximum values. To create a diverging scale, this two-element array can be combined with the `domainMid` property.\n   * - An array with more than two entries, for [Piecewise quantitative scales](https://vega.github.io/vega-lite/docs/scale.html#piecewise).\n   * - A string value `\"unaggregated\"`, if the input field is aggregated, to indicate that the domain should include the raw data values prior to the aggregation.\n   *\n   * 2) Constant `domain` for _temporal_ fields can be a two-element array with minimum and maximum values, in the form of either timestamps or the [DateTime definition objects](https://vega.github.io/vega-lite/docs/types.html#datetime).\n   *\n   * 3) Constant `domain` for _ordinal_ and _nominal_ fields can be an array that lists valid input values.\n   *\n   * 4) To combine (union) specified constant domain with the field's values, `domain` can be an object with a `unionWith` property that specify constant domain to be combined. For example, `domain: {unionWith: [0, 100]}` for a quantitative scale means that the scale domain always includes `[0, 100]`, but will include other values in the fields beyond `[0, 100]`.\n   *\n   * 5) Domain can also takes an object defining a field or encoding of a selection that [interactively determines](https://vega.github.io/vega-lite/docs/selection.html#scale-domains) the scale domain.\n   */\n  domain?:\n    | (null | string | number | boolean | DateTime | ES)[]\n    | 'unaggregated'\n    | SelectionExtent\n    | DomainUnionWith\n    | ES;\n\n  /**\n   * Inserts a single mid-point value into a two-element domain. The mid-point value must lie between the domain minimum and maximum values. This property can be useful for setting a midpoint for [diverging color scales](https://vega.github.io/vega-lite/docs/scale.html#piecewise). The domainMid property is only intended for use with scales supporting continuous, piecewise domains.\n   */\n  domainMid?: number | ES;\n\n  /**\n   * Sets the maximum value in the scale domain, overriding the `domain` property. This property is only intended for use with scales having continuous domains.\n   */\n  domainMax?: number | DateTime | ES;\n\n  /**\n   * Sets the minimum value in the scale domain, overriding the domain property. This property is only intended for use with scales having continuous domains.\n   */\n  domainMin?: number | DateTime | ES;\n\n  /**\n   * If true, reverses the order of the scale range.\n   * __Default value:__ `false`.\n   */\n  reverse?: boolean | ES;\n\n  /**\n   * The range of the scale. One of:\n   *\n   * - A string indicating a [pre-defined named scale range](https://vega.github.io/vega-lite/docs/scale.html#range-config) (e.g., example, `\"symbol\"`, or `\"diverging\"`).\n   *\n   * - For [continuous scales](https://vega.github.io/vega-lite/docs/scale.html#continuous), two-element array indicating  minimum and maximum values, or an array with more than two entries for specifying a [piecewise scale](https://vega.github.io/vega-lite/docs/scale.html#piecewise).\n   *\n   * - For [discrete](https://vega.github.io/vega-lite/docs/scale.html#discrete) and [discretizing](https://vega.github.io/vega-lite/docs/scale.html#discretizing) scales, an array of desired output values or an object with a `field` property representing the range values.  For example, if a field `color` contains CSS color names, we can set `range` to `{field: \"color\"}`.\n   *\n   * __Notes:__\n   *\n   * 1) For color scales you can also specify a color [`scheme`](https://vega.github.io/vega-lite/docs/scale.html#scheme) instead of `range`.\n   *\n   * 2) Any directly specified `range` for `x` and `y` channels will be ignored. Range can be customized via the view's corresponding [size](https://vega.github.io/vega-lite/docs/size.html) (`width` and `height`).\n   */\n  range?: RangeEnum | (number | string | number[] | ES)[] | {field: string};\n\n  /**\n   * Sets the maximum value in the scale range, overriding the `range` property or the default range. This property is only intended for use with scales having continuous ranges.\n   */\n  rangeMax?: number | string | ES;\n\n  /**\n   * Sets the minimum value in the scale range, overriding the `range` property or the default range. This property is only intended for use with scales having continuous ranges.\n   */\n  rangeMin?: number | string | ES;\n\n  // ordinal\n\n  /**\n   * A string indicating a color [scheme](https://vega.github.io/vega-lite/docs/scale.html#scheme) name (e.g., `\"category10\"` or `\"blues\"`) or a [scheme parameter object](https://vega.github.io/vega-lite/docs/scale.html#scheme-params).\n   *\n   * Discrete color schemes may be used with [discrete](https://vega.github.io/vega-lite/docs/scale.html#discrete) or [discretizing](https://vega.github.io/vega-lite/docs/scale.html#discretizing) scales. Continuous color schemes are intended for use with color scales.\n   *\n   * For the full list of supported schemes, please refer to the [Vega Scheme](https://vega.github.io/vega/docs/schemes/#reference) reference.\n   */\n  scheme?: string | SchemeParams | ES;\n\n  /**\n   * The alignment of the steps within the scale range.\n   *\n   * This value must lie in the range `[0,1]`. A value of `0.5` indicates that the steps should be centered within the range. A value of `0` or `1` may be used to shift the bands to one side, say to position them adjacent to an axis.\n   *\n   * __Default value:__ `0.5`\n   */\n  align?: number | ES;\n\n  /**\n   * Bin boundaries can be provided to scales as either an explicit array of bin boundaries or as a bin specification object. The legal values are:\n   * - An [array](../types/#Array) literal of bin boundary values. For example, `[0, 5, 10, 15, 20]`. The array must include both starting and ending boundaries. The previous example uses five values to indicate a total of four bin intervals: [0-5), [5-10), [10-15), [15-20]. Array literals may include signal references as elements.\n   * - A [bin specification object](https://vega.github.io/vega-lite/docs/scale.html#bins) that indicates the bin _step_ size, and optionally the _start_ and _stop_ boundaries.\n   * - An array of bin boundaries over the scale domain. If provided, axes and legends will use the bin boundaries to inform the choice of tick marks and text labels.\n   */\n  // TODO: add - A [signal reference](../types/#Signal) that resolves to either an array or bin specification object.\n  bins?: ScaleBins;\n\n  /**\n   * If `true`, rounds numeric output values to integers. This can be helpful for snapping to the pixel grid.\n   *\n   * __Default value:__ `false`.\n   */\n  round?: boolean | ES;\n\n  /**\n   * For _[continuous](https://vega.github.io/vega-lite/docs/scale.html#continuous)_ scales, expands the scale domain to accommodate the specified number of pixels on each of the scale range. The scale range must represent pixels for this parameter to function as intended. Padding adjustment is performed prior to all other adjustments, including the effects of the `zero`, `nice`, `domainMin`, and `domainMax` properties.\n   *\n   * For _[band](https://vega.github.io/vega-lite/docs/scale.html#band)_ scales, shortcut for setting `paddingInner` and `paddingOuter` to the same value.\n   *\n   * For _[point](https://vega.github.io/vega-lite/docs/scale.html#point)_ scales, alias for `paddingOuter`.\n   *\n   * __Default value:__ For _continuous_ scales, derived from the [scale config](https://vega.github.io/vega-lite/docs/scale.html#config)'s `continuousPadding`.\n   * For _band and point_ scales, see `paddingInner` and `paddingOuter`. By default, Vega-Lite sets padding such that _width/height = number of unique values * step_.\n   *\n   * @minimum 0\n   */\n  padding?: number | ES;\n\n  /**\n   * The inner padding (spacing) within each band step of band scales, as a fraction of the step size. This value must lie in the range [0,1].\n   *\n   * For point scale, this property is invalid as point scales do not have internal band widths (only step sizes between bands).\n   *\n   * __Default value:__ derived from the [scale config](https://vega.github.io/vega-lite/docs/scale.html#config)'s `bandPaddingInner`.\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  paddingInner?: number | ES;\n\n  /**\n   * The outer padding (spacing) at the ends of the range of band and point scales,\n   * as a fraction of the step size. This value must lie in the range [0,1].\n   *\n   * __Default value:__ derived from the [scale config](https://vega.github.io/vega-lite/docs/scale.html#config)'s `bandPaddingOuter` for band scales and `pointPadding` for point scales.\n   * By default, Vega-Lite sets outer padding such that _width/height = number of unique values * step_.\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  paddingOuter?: number | ES;\n\n  // typical\n  /**\n   * If `true`, values that exceed the data domain are clamped to either the minimum or maximum range value\n   *\n   * __Default value:__ derived from the [scale config](https://vega.github.io/vega-lite/docs/config.html#scale-config)'s `clamp` (`true` by default).\n   */\n  clamp?: boolean | ES;\n\n  /**\n   * Extending the domain so that it starts and ends on nice round values. This method typically modifies the scale’s domain, and may only extend the bounds to the nearest round value. Nicing is useful if the domain is computed from data and may be irregular. For example, for a domain of _[0.201479…, 0.996679…]_, a nice domain might be _[0.2, 1.0]_.\n   *\n   * For quantitative scales such as linear, `nice` can be either a boolean flag or a number. If `nice` is a number, it will represent a desired tick count. This allows greater control over the step size used to extend the bounds, guaranteeing that the returned ticks will exactly cover the domain.\n   *\n   * For temporal fields with time and utc scales, the `nice` value can be a string indicating the desired time interval. Legal values are `\"millisecond\"`, `\"second\"`, `\"minute\"`, `\"hour\"`, `\"day\"`, `\"week\"`, `\"month\"`, and `\"year\"`. Alternatively, `time` and `utc` scales can accept an object-valued interval specifier of the form `{\"interval\": \"month\", \"step\": 3}`, which includes a desired number of interval steps. Here, the domain would snap to quarter (Jan, Apr, Jul, Oct) boundaries.\n   *\n   * __Default value:__ `true` for unbinned _quantitative_ fields; `false` otherwise.\n   *\n   */\n  nice?: boolean | number | TimeInterval | TimeIntervalStep | ES;\n\n  /**\n   * The logarithm base of the `log` scale (default `10`).\n   */\n  base?: number | ES;\n\n  /**\n   * The exponent of the `pow` scale.\n   */\n  exponent?: number | ES;\n\n  /**\n   * A constant determining the slope of the symlog function around zero. Only used for `symlog` scales.\n   *\n   * __Default value:__ `1`\n   */\n  constant?: number | ES;\n\n  /**\n   * If `true`, ensures that a zero baseline value is included in the scale domain.\n   *\n   * __Default value:__ `true` for x and y channels if the quantitative field is not binned and no custom `domain` is provided; `false` otherwise.\n   *\n   * __Note:__ Log, time, and utc scales do not support `zero`.\n   */\n  zero?: boolean | ES;\n\n  /**\n   * The interpolation method for range values. By default, a general interpolator for numbers, dates, strings and colors (in HCL space) is used. For color ranges, this property allows interpolation in alternative color spaces. Legal values include `rgb`, `hsl`, `hsl-long`, `lab`, `hcl`, `hcl-long`, `cubehelix` and `cubehelix-long` ('-long' variants use longer paths in polar coordinate spaces). If object-valued, this property accepts an object with a string-valued _type_ property and an optional numeric _gamma_ property applicable to rgb and cubehelix interpolators. For more, see the [d3-interpolate documentation](https://github.com/d3/d3-interpolate).\n   *\n   * * __Default value:__ `hcl`\n   */\n  interpolate?: ScaleInterpolateEnum | ES | ScaleInterpolateParams;\n}\n\nconst SCALE_PROPERTY_INDEX: Flag<keyof Scale<any>> = {\n  type: 1,\n  domain: 1,\n  domainMax: 1,\n  domainMin: 1,\n  domainMid: 1,\n  align: 1,\n  range: 1,\n  rangeMax: 1,\n  rangeMin: 1,\n  scheme: 1,\n  bins: 1,\n  // Other properties\n  reverse: 1,\n  round: 1,\n  // quantitative / time\n  clamp: 1,\n  nice: 1,\n  // quantitative\n  base: 1,\n  exponent: 1,\n  constant: 1,\n  interpolate: 1,\n  zero: 1, // zero depends on domain\n  // band/point\n  padding: 1,\n  paddingInner: 1,\n  paddingOuter: 1\n};\n\nexport const SCALE_PROPERTIES = keys(SCALE_PROPERTY_INDEX);\n\nconst {\n  type,\n  domain,\n  range,\n  rangeMax,\n  rangeMin,\n  scheme,\n  ...NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTY_INDEX\n} = SCALE_PROPERTY_INDEX;\n\nexport const NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTIES = keys(NON_TYPE_DOMAIN_RANGE_VEGA_SCALE_PROPERTY_INDEX);\n\nexport function scaleTypeSupportProperty(scaleType: ScaleType, propName: keyof Scale): boolean {\n  switch (propName) {\n    case 'type':\n    case 'domain':\n    case 'reverse':\n    case 'range':\n      return true;\n    case 'scheme':\n    case 'interpolate':\n      return !contains(['point', 'band', 'identity'], scaleType);\n    case 'bins':\n      return !contains(['point', 'band', 'identity', 'ordinal'], scaleType);\n    case 'round':\n      return isContinuousToContinuous(scaleType) || scaleType === 'band' || scaleType === 'point';\n    case 'padding':\n    case 'rangeMin':\n    case 'rangeMax':\n      return isContinuousToContinuous(scaleType) || contains(['point', 'band'], scaleType);\n    case 'paddingOuter':\n    case 'align':\n      return contains(['point', 'band'], scaleType);\n    case 'paddingInner':\n      return scaleType === 'band';\n    case 'domainMax':\n    case 'domainMid':\n    case 'domainMin':\n    case 'clamp':\n      return isContinuousToContinuous(scaleType);\n    case 'nice':\n      return isContinuousToContinuous(scaleType) || scaleType === 'quantize' || scaleType === 'threshold';\n    case 'exponent':\n      return scaleType === 'pow';\n    case 'base':\n      return scaleType === 'log';\n    case 'constant':\n      return scaleType === 'symlog';\n    case 'zero':\n      return (\n        hasContinuousDomain(scaleType) &&\n        !contains(\n          [\n            'log', // log scale cannot have zero value\n            'time',\n            'utc', // zero is not meaningful for time\n            'threshold', // threshold requires custom domain so zero does not matter\n            'quantile' // quantile depends on distribution so zero does not matter\n          ],\n          scaleType\n        )\n      );\n  }\n}\n\n/**\n * Returns undefined if the input channel supports the input scale property name\n */\nexport function channelScalePropertyIncompatability(channel: Channel, propName: keyof Scale): string {\n  switch (propName) {\n    case 'interpolate':\n    case 'scheme':\n    case 'domainMid':\n      if (!isColorChannel(channel)) {\n        return log.message.cannotUseScalePropertyWithNonColor(channel);\n      }\n      return undefined;\n    case 'align':\n    case 'type':\n    case 'bins':\n    case 'domain':\n    case 'domainMax':\n    case 'domainMin':\n    case 'range':\n    case 'base':\n    case 'exponent':\n    case 'constant':\n    case 'nice':\n    case 'padding':\n    case 'paddingInner':\n    case 'paddingOuter':\n    case 'rangeMax':\n    case 'rangeMin':\n    case 'reverse':\n    case 'round':\n    case 'clamp':\n    case 'zero':\n      return undefined; // GOOD!\n  }\n}\n\nexport function scaleTypeSupportDataType(specifiedType: ScaleType, fieldDefType: Type): boolean {\n  if (contains([ORDINAL, NOMINAL], fieldDefType)) {\n    return specifiedType === undefined || hasDiscreteDomain(specifiedType);\n  } else if (fieldDefType === TEMPORAL) {\n    return contains([ScaleType.TIME, ScaleType.UTC, undefined], specifiedType);\n  } else if (fieldDefType === QUANTITATIVE) {\n    return contains(\n      [\n        ScaleType.LOG,\n        ScaleType.POW,\n        ScaleType.SQRT,\n        ScaleType.SYMLOG,\n        ScaleType.QUANTILE,\n        ScaleType.QUANTIZE,\n        ScaleType.THRESHOLD,\n        ScaleType.LINEAR,\n        undefined\n      ],\n      specifiedType\n    );\n  }\n\n  return true;\n}\n\nexport function channelSupportScaleType(channel: Channel, scaleType: ScaleType): boolean {\n  if (!CHANNEL.isScaleChannel(channel)) {\n    return false;\n  }\n  switch (channel) {\n    case CHANNEL.X:\n    case CHANNEL.Y:\n    case CHANNEL.THETA:\n    case CHANNEL.RADIUS:\n      return isContinuousToContinuous(scaleType) || contains(['band', 'point'], scaleType);\n    case CHANNEL.SIZE: // TODO: size and opacity can support ordinal with more modification\n    case CHANNEL.STROKEWIDTH:\n    case CHANNEL.OPACITY:\n    case CHANNEL.FILLOPACITY:\n    case CHANNEL.STROKEOPACITY:\n    case CHANNEL.ANGLE:\n      // Although it generally doesn't make sense to use band with size and opacity,\n      // it can also work since we use band: 0.5 to get midpoint.\n      return (\n        isContinuousToContinuous(scaleType) ||\n        isContinuousToDiscrete(scaleType) ||\n        contains(['band', 'point', 'ordinal'], scaleType)\n      );\n    case CHANNEL.COLOR:\n    case CHANNEL.FILL:\n    case CHANNEL.STROKE:\n      return scaleType !== 'band'; // band does not make sense with color\n    case CHANNEL.STROKEDASH:\n      return scaleType === 'ordinal' || isContinuousToDiscrete(scaleType);\n    case CHANNEL.SHAPE:\n      return scaleType === 'ordinal'; // shape = lookup only\n  }\n}\n","import {isArray} from 'datalib/src/util';\nimport {Flag} from 'vega-lite/build/src/util';\n\nexport {cmp, keys, duplicate, extend, isObject, isBoolean, toMap} from 'datalib/src/util';\n\nexport {isArray};\n\nexport interface Dict<T> {\n  [key: string]: T;\n}\n\nexport function contains(array: any[], item: any) {\n  return array.indexOf(item) !== -1;\n}\n\nexport function every<T>(arr: T[], f: (item: T, key: number) => boolean) {\n  for (let i = 0; i < arr.length; i++) {\n    if (!f(arr[i], i)) {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function forEach(obj: any, f: (item: any, key: number | string, i: number) => void, thisArg?: any) {\n  if (obj.forEach) {\n    obj.forEach.call(thisArg, f);\n  } else {\n    for (const k in obj) {\n      f.call(thisArg, obj[k], k, obj);\n    }\n  }\n}\n\nexport function some<T>(arr: T[], f: (item: T, key: number | string, i: number) => boolean) {\n  let i = 0;\n  for (let k = 0; k < arr.length; k++) {\n    if (f(arr[k], k, i++)) {\n      return true;\n    }\n  }\n  return false;\n}\n\nexport function nestedMap(array: any[], f: (item: any) => any): any[] {\n  return array.map((a) => {\n    if (isArray(a)) {\n      return nestedMap(a, f);\n    }\n    return f(a);\n  });\n}\n\n/** Returns the array without the elements in item */\nexport function without<T>(array: Array<T>, excludedItems: Array<T>) {\n  return array.filter(function (item) {\n    return !contains(excludedItems, item);\n  });\n}\n\nexport function flagKeys<S extends string>(f: Flag<S>): S[] {\n  return Object.keys(f) as S[];\n}\n\nexport type Diff<T extends string, U extends string> = ({[P in T]: P} & {[P in U]: never} & {[x: string]: never})[T];\n","var u = module.exports;\n\n// utility functions\n\nvar FNAME = '__name__';\n\nu.namedfunc = function(name, f) { return (f[FNAME] = name, f); };\n\nu.name = function(f) { return f==null ? null : f[FNAME]; };\n\nu.identity = function(x) { return x; };\n\nu.true = u.namedfunc('true', function() { return true; });\n\nu.false = u.namedfunc('false', function() { return false; });\n\nu.duplicate = function(obj) {\n  return JSON.parse(JSON.stringify(obj));\n};\n\nu.equal = function(a, b) {\n  return JSON.stringify(a) === JSON.stringify(b);\n};\n\nu.extend = function(obj) {\n  for (var x, name, i=1, len=arguments.length; i<len; ++i) {\n    x = arguments[i];\n    for (name in x) { obj[name] = x[name]; }\n  }\n  return obj;\n};\n\nu.length = function(x) {\n  return x != null && x.length != null ? x.length : null;\n};\n\nu.keys = function(x) {\n  var keys = [], k;\n  for (k in x) keys.push(k);\n  return keys;\n};\n\nu.vals = function(x) {\n  var vals = [], k;\n  for (k in x) vals.push(x[k]);\n  return vals;\n};\n\nu.toMap = function(list, f) {\n  return (f = u.$(f)) ?\n    list.reduce(function(obj, x) { return (obj[f(x)] = 1, obj); }, {}) :\n    list.reduce(function(obj, x) { return (obj[x] = 1, obj); }, {});\n};\n\nu.keystr = function(values) {\n  // use to ensure consistent key generation across modules\n  var n = values.length;\n  if (!n) return '';\n  for (var s=String(values[0]), i=1; i<n; ++i) {\n    s += '|' + String(values[i]);\n  }\n  return s;\n};\n\n// type checking functions\n\nvar toString = Object.prototype.toString;\n\nu.isObject = function(obj) {\n  return obj === Object(obj);\n};\n\nu.isFunction = function(obj) {\n  return toString.call(obj) === '[object Function]';\n};\n\nu.isString = function(obj) {\n  return typeof value === 'string' || toString.call(obj) === '[object String]';\n};\n\nu.isArray = Array.isArray || function(obj) {\n  return toString.call(obj) === '[object Array]';\n};\n\nu.isNumber = function(obj) {\n  return typeof obj === 'number' || toString.call(obj) === '[object Number]';\n};\n\nu.isBoolean = function(obj) {\n  return obj === true || obj === false || toString.call(obj) == '[object Boolean]';\n};\n\nu.isDate = function(obj) {\n  return toString.call(obj) === '[object Date]';\n};\n\nu.isValid = function(obj) {\n  return obj != null && obj === obj;\n};\n\nu.isBuffer = (typeof Buffer === 'function' && Buffer.isBuffer) || u.false;\n\n// type coercion functions\n\nu.number = function(s) {\n  return s == null || s === '' ? null : +s;\n};\n\nu.boolean = function(s) {\n  return s == null || s === '' ? null : s==='false' ? false : !!s;\n};\n\n// parse a date with optional d3.time-format format\nu.date = function(s, format) {\n  var d = format ? format : Date;\n  return s == null || s === '' ? null : d.parse(s);\n};\n\nu.array = function(x) {\n  return x != null ? (u.isArray(x) ? x : [x]) : [];\n};\n\nu.str = function(x) {\n  return u.isArray(x) ? '[' + x.map(u.str) + ']'\n    : u.isObject(x) || u.isString(x) ?\n      // Output valid JSON and JS source strings.\n      // See http://timelessrepo.com/json-isnt-a-javascript-subset\n      JSON.stringify(x).replace('\\u2028','\\\\u2028').replace('\\u2029', '\\\\u2029')\n    : x;\n};\n\n// data access functions\n\nvar field_re = /\\[(.*?)\\]|[^.\\[]+/g;\n\nu.field = function(f) {\n  return String(f).match(field_re).map(function(d) {\n    return d[0] !== '[' ? d :\n      d[1] !== \"'\" && d[1] !== '\"' ? d.slice(1, -1) :\n      d.slice(2, -2).replace(/\\\\([\"'])/g, '$1');\n  });\n};\n\nu.accessor = function(f) {\n  /* jshint evil: true */\n  return f==null || u.isFunction(f) ? f :\n    u.namedfunc(f, Function('x', 'return x[' + u.field(f).map(u.str).join('][') + '];'));\n};\n\n// short-cut for accessor\nu.$ = u.accessor;\n\nu.mutator = function(f) {\n  var s;\n  return u.isString(f) && (s=u.field(f)).length > 1 ?\n    function(x, v) {\n      for (var i=0; i<s.length-1; ++i) x = x[s[i]];\n      x[s[i]] = v;\n    } :\n    function(x, v) { x[f] = v; };\n};\n\n\nu.$func = function(name, op) {\n  return function(f) {\n    f = u.$(f) || u.identity;\n    var n = name + (u.name(f) ? '_'+u.name(f) : '');\n    return u.namedfunc(n, function(d) { return op(f(d)); });\n  };\n};\n\nu.$valid  = u.$func('valid', u.isValid);\nu.$length = u.$func('length', u.length);\n\nu.$in = function(f, values) {\n  f = u.$(f);\n  var map = u.isArray(values) ? u.toMap(values) : values;\n  return function(d) { return !!map[f(d)]; };\n};\n\n// comparison / sorting functions\n\nu.comparator = function(sort) {\n  var sign = [];\n  if (sort === undefined) sort = [];\n  sort = u.array(sort).map(function(f) {\n    var s = 1;\n    if      (f[0] === '-') { s = -1; f = f.slice(1); }\n    else if (f[0] === '+') { s = +1; f = f.slice(1); }\n    sign.push(s);\n    return u.accessor(f);\n  });\n  return function(a, b) {\n    var i, n, f, c;\n    for (i=0, n=sort.length; i<n; ++i) {\n      f = sort[i];\n      c = u.cmp(f(a), f(b));\n      if (c) return c * sign[i];\n    }\n    return 0;\n  };\n};\n\nu.cmp = function(a, b) {\n  return (a < b || a == null) && b != null ? -1 :\n    (a > b || b == null) && a != null ? 1 :\n    ((b = b instanceof Date ? +b : b),\n     (a = a instanceof Date ? +a : a)) !== a && b === b ? -1 :\n    b !== b && a === a ? 1 : 0;\n};\n\nu.numcmp = function(a, b) { return a - b; };\n\nu.stablesort = function(array, sortBy, keyFn) {\n  var indices = array.reduce(function(idx, v, i) {\n    return (idx[keyFn(v)] = i, idx);\n  }, {});\n\n  array.sort(function(a, b) {\n    var sa = sortBy(a),\n        sb = sortBy(b);\n    return sa < sb ? -1 : sa > sb ? 1\n         : (indices[keyFn(a)] - indices[keyFn(b)]);\n  });\n\n  return array;\n};\n\n// permutes an array using a Knuth shuffle\nu.permute = function(a) {\n  var m = a.length,\n      swap,\n      i;\n\n  while (m) {\n    i = Math.floor(Math.random() * m--);\n    swap = a[m];\n    a[m] = a[i];\n    a[i] = swap;\n  }\n};\n\n// string functions\n\nu.pad = function(s, length, pos, padchar) {\n  padchar = padchar || \" \";\n  var d = length - s.length;\n  if (d <= 0) return s;\n  switch (pos) {\n    case 'left':\n      return strrep(d, padchar) + s;\n    case 'middle':\n    case 'center':\n      return strrep(Math.floor(d/2), padchar) +\n         s + strrep(Math.ceil(d/2), padchar);\n    default:\n      return s + strrep(d, padchar);\n  }\n};\n\nfunction strrep(n, str) {\n  var s = \"\", i;\n  for (i=0; i<n; ++i) s += str;\n  return s;\n}\n\nu.truncate = function(s, length, pos, word, ellipsis) {\n  var len = s.length;\n  if (len <= length) return s;\n  ellipsis = ellipsis !== undefined ? String(ellipsis) : '\\u2026';\n  var l = Math.max(0, length - ellipsis.length);\n\n  switch (pos) {\n    case 'left':\n      return ellipsis + (word ? truncateOnWord(s,l,1) : s.slice(len-l));\n    case 'middle':\n    case 'center':\n      var l1 = Math.ceil(l/2), l2 = Math.floor(l/2);\n      return (word ? truncateOnWord(s,l1) : s.slice(0,l1)) +\n        ellipsis + (word ? truncateOnWord(s,l2,1) : s.slice(len-l2));\n    default:\n      return (word ? truncateOnWord(s,l) : s.slice(0,l)) + ellipsis;\n  }\n};\n\nfunction truncateOnWord(s, len, rev) {\n  var cnt = 0, tok = s.split(truncate_word_re);\n  if (rev) {\n    s = (tok = tok.reverse())\n      .filter(function(w) { cnt += w.length; return cnt <= len; })\n      .reverse();\n  } else {\n    s = tok.filter(function(w) { cnt += w.length; return cnt <= len; });\n  }\n  return s.length ? s.join('').trim() : tok[0].slice(0, len);\n}\n\nvar truncate_word_re = /([\\u0009\\u000A\\u000B\\u000C\\u000D\\u0020\\u00A0\\u1680\\u180E\\u2000\\u2001\\u2002\\u2003\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u202F\\u205F\\u2028\\u2029\\u3000\\uFEFF])/;\n","import {Axis, AXIS_PROPERTIES} from 'vega-lite/build/src/axis';\nimport {BinParams} from 'vega-lite/build/src/bin';\nimport {Legend, LEGEND_PROPERTIES} from 'vega-lite/build/src/legend';\nimport {Scale, SCALE_PROPERTIES} from 'vega-lite/build/src/scale';\nimport {EncodingSortField} from 'vega-lite/build/src/sort';\nimport {Flag} from 'vega-lite/build/src/util';\nimport {AutoCountQuery, FieldQuery, ValueQuery} from './query/encoding';\nimport {TransformQuery} from './query/transform';\nimport {Diff, flagKeys} from './util';\n\n/**\n * There are two types of `Property`'s.\n * One is just flat property names.\n * (Try to hover `FlatProp` to see all of them.)\n * Another is an object that describes a parent property (e.g., `scale`) and the child property (e.g., `type`)\n */\nexport type Property = FlatProp | EncodingNestedProp;\nexport type FlatProp = MarkProp | TransformProp | ViewProp | EncodingTopLevelProp;\n\nexport type MarkProp = 'mark' | 'stack'; // FIXME: determine how 'stack' works;\nexport type TransformProp = keyof TransformQuery;\nexport type ViewProp = 'width' | 'height' | 'background' | 'padding' | 'title';\nexport type EncodingTopLevelProp = Diff<keyof (FieldQuery & ValueQuery & AutoCountQuery), 'description'>; // Do not include description since description is simply a metadata\n\nexport type EncodingNestedProp = BinProp | SortProp | ScaleProp | AxisProp | LegendProp;\n\nexport type EncodingNestedChildProp =\n  | keyof BinParams\n  | keyof EncodingSortField<string>\n  | keyof Scale\n  | keyof Axis\n  | keyof Legend<any>;\n\n/**\n * An object that describes a parent property (e.g., `scale`) and the child property (e.g., `type`)\n */\nexport type BaseEncodingNestedProp<P, T> = {\n  parent: P;\n  child: keyof T;\n};\n\nexport type BinProp = BaseEncodingNestedProp<'bin', BinParams>;\nexport type SortProp = BaseEncodingNestedProp<'sort', EncodingSortField<string>>;\nexport type ScaleProp = BaseEncodingNestedProp<'scale', Scale>;\nexport type AxisProp = BaseEncodingNestedProp<'axis', Axis>;\nexport type LegendProp = BaseEncodingNestedProp<'legend', Legend<any>>;\n\nexport function isEncodingNestedProp(p: Property): p is EncodingNestedProp {\n  return !!p['parent'];\n}\n\nconst ENCODING_TOPLEVEL_PROP_INDEX: Flag<EncodingTopLevelProp> = {\n  channel: 1,\n  aggregate: 1,\n  autoCount: 1,\n  bin: 1,\n  timeUnit: 1,\n  hasFn: 1,\n  sort: 1,\n  stack: 1,\n  field: 1,\n  type: 1,\n  format: 1,\n  scale: 1,\n  axis: 1,\n  legend: 1,\n  value: 1,\n};\n\nexport const ENCODING_TOPLEVEL_PROPS = flagKeys(ENCODING_TOPLEVEL_PROP_INDEX);\n\nexport function isEncodingTopLevelProperty(p: Property): p is EncodingTopLevelProp {\n  return p.toString() in ENCODING_TOPLEVEL_PROP_INDEX;\n}\n\nexport type EncodingNestedPropParent = 'bin' | 'scale' | 'sort' | 'axis' | 'legend';\n\nconst ENCODING_NESTED_PROP_PARENT_INDEX: Flag<EncodingNestedPropParent> = {\n  bin: 1,\n  scale: 1,\n  sort: 1,\n  axis: 1,\n  legend: 1,\n};\n\nexport function isEncodingNestedParent(prop: string): prop is EncodingNestedPropParent {\n  return ENCODING_NESTED_PROP_PARENT_INDEX[prop as string];\n}\n\n// FIXME -- we should not have to manually specify these\nexport const BIN_CHILD_PROPS: (keyof BinParams)[] = ['maxbins', 'divide', 'extent', 'base', 'step', 'steps', 'minstep'];\nexport const SORT_CHILD_PROPS: (keyof EncodingSortField<string>)[] = ['field', 'op', 'order'];\n\nconst BIN_PROPS = BIN_CHILD_PROPS.map((c): BinProp => {\n  return {parent: 'bin', child: c};\n});\n\nexport const SORT_PROPS = SORT_CHILD_PROPS.map((c): SortProp => {\n  return {parent: 'sort', child: c};\n});\n\nexport const SCALE_PROPS = SCALE_PROPERTIES.map((c): ScaleProp => {\n  return {parent: 'scale', child: c};\n});\n\nconst AXIS_PROPS = AXIS_PROPERTIES.map((c): AxisProp => {\n  return {parent: 'axis', child: c};\n});\n\nconst LEGEND_PROPS = LEGEND_PROPERTIES.map((c): LegendProp => {\n  return {parent: 'legend', child: c};\n});\n\nexport const ENCODING_NESTED_PROPS = ([] as EncodingNestedProp[]).concat(\n  BIN_PROPS,\n  SORT_PROPS,\n  SCALE_PROPS,\n  AXIS_PROPS,\n  LEGEND_PROPS\n);\n\nexport const VIEW_PROPS: Property[] = ['width', 'height', 'background', 'padding', 'title'] as Property[];\n\nconst PROP_KEY_DELIMITER = '.';\n\nexport function toKey(p: Property): string {\n  if (isEncodingNestedProp(p)) {\n    return p.parent + PROP_KEY_DELIMITER + p.child;\n  }\n  return p;\n}\n\nexport function fromKey(k: string): Property {\n  const split = k.split(PROP_KEY_DELIMITER);\n  /* istanbul ignore else */\n  if (split.length === 1) {\n    return k as Property;\n  } else if (split.length === 2) {\n    return {\n      parent: split[0],\n      child: split[1],\n    } as EncodingNestedProp;\n  } else {\n    throw `Invalid property key with ${split.length} dots: ${k}`;\n  }\n}\n\nconst ENCODING_NESTED_PROP_INDEX = ENCODING_NESTED_PROPS.reduce((i, prop: EncodingNestedProp) => {\n  i[prop.parent] = i[prop.parent] || [];\n  i[prop.parent][prop.child] = prop;\n  return i;\n}, {});\n\n// FIXME consider using a more general method\nexport function getEncodingNestedProp(parent: EncodingTopLevelProp, child: EncodingNestedChildProp) {\n  return (ENCODING_NESTED_PROP_INDEX[parent] || {})[child];\n}\n\nexport function isEncodingProperty(p: Property): p is EncodingTopLevelProp | EncodingNestedProp {\n  return isEncodingTopLevelProperty(p) || isEncodingNestedProp(p);\n}\n\nexport const ALL_ENCODING_PROPS = ([] as Property[]).concat(ENCODING_TOPLEVEL_PROPS, ENCODING_NESTED_PROPS);\n\nexport const DEFAULT_PROP_PRECEDENCE: Property[] = (\n  [\n    'type', // type is a constraint for field\n    'field',\n\n    // Field Transform\n    'bin',\n    'timeUnit',\n    'aggregate',\n    'autoCount',\n\n    // Encoding\n    'channel',\n\n    // Mark\n    'mark',\n    'stack',\n\n    'scale',\n    'sort',\n    'axis',\n    'legend',\n  ] as Property[]\n).concat(BIN_PROPS, SCALE_PROPS, AXIS_PROPS, LEGEND_PROPS, SORT_PROPS);\n\nexport namespace Property {\n  export const MARK: 'mark' = 'mark';\n\n  export const TRANSFORM: 'transform' = 'transform';\n  // Layout\n  export const STACK: 'stack' = 'stack';\n\n  export const FORMAT: 'format' = 'format';\n\n  // TODO: sub parts of stack\n\n  // Encoding Properties\n  export const CHANNEL: 'channel' = 'channel';\n  export const AGGREGATE: 'aggregate' = 'aggregate';\n  export const AUTOCOUNT: 'autoCount' = 'autoCount';\n  export const BIN: 'bin' = 'bin';\n\n  export const HAS_FN: 'hasFn' = 'hasFn';\n  export const TIMEUNIT: 'timeUnit' = 'timeUnit';\n  export const FIELD: 'field' = 'field';\n  export const TYPE: 'type' = 'type';\n\n  export const SORT: 'sort' = 'sort';\n\n  export const SCALE: 'scale' = 'scale';\n  export const AXIS: 'axis' = 'axis';\n\n  export const LEGEND: 'legend' = 'legend';\n\n  export const WIDTH: 'width' = 'width';\n  export const HEIGHT: 'height' = 'height';\n  export const BACKGROUND: 'background' = 'background';\n  export const PADDING: 'padding' = 'padding';\n  export const TITLE: 'title' = 'title';\n}\n","import {Align, Color, Gradient, MarkConfig as VgMarkConfig, Orientation, SignalRef, TextBaseline} from 'vega';\nimport {toSet} from 'vega-util';\nimport {CompositeMark, CompositeMarkDef} from './compositemark';\nimport {ExprOrSignalRef, ExprRef} from './expr';\nimport {contains, Flag, keys} from './util';\nimport {MapExcludeValueRefAndReplaceSignalWith} from './vega.schema';\n\n/**\n * All types of primitive marks.\n */\nexport const Mark = {\n  arc: 'arc',\n  area: 'area',\n  bar: 'bar',\n  image: 'image',\n  line: 'line',\n  point: 'point',\n  rect: 'rect',\n  rule: 'rule',\n  text: 'text',\n  tick: 'tick',\n  trail: 'trail',\n  circle: 'circle',\n  square: 'square',\n  geoshape: 'geoshape'\n} as const;\n\nexport const ARC = Mark.arc;\nexport const AREA = Mark.area;\nexport const BAR = Mark.bar;\nexport const IMAGE = Mark.image;\nexport const LINE = Mark.line;\nexport const POINT = Mark.point;\nexport const RECT = Mark.rect;\nexport const RULE = Mark.rule;\nexport const TEXT = Mark.text;\nexport const TICK = Mark.tick;\nexport const TRAIL = Mark.trail;\nexport const CIRCLE = Mark.circle;\nexport const SQUARE = Mark.square;\nexport const GEOSHAPE = Mark.geoshape;\n\nexport type Mark = keyof typeof Mark;\n\nexport function isMark(m: string): m is Mark {\n  return m in Mark;\n}\n\nexport function isPathMark(m: Mark | CompositeMark): m is 'line' | 'area' | 'trail' {\n  return contains(['line', 'area', 'trail'], m);\n}\n\nexport function isRectBasedMark(m: Mark | CompositeMark): m is 'rect' | 'bar' | 'image' | 'arc' {\n  return contains(['rect', 'bar', 'image', 'arc' /* arc is rect/interval in polar coordinate */], m);\n}\n\nexport const PRIMITIVE_MARKS = keys(Mark);\n\nexport interface ColorMixins<ES extends ExprRef | SignalRef> {\n  /**\n   * Default color.\n   *\n   * __Default value:__ <span style=\"color: #4682b4;\">&#9632;</span> `\"#4682b4\"`\n   *\n   * __Note:__\n   * - This property cannot be used in a [style config](https://vega.github.io/vega-lite/docs/mark.html#style-config).\n   * - The `fill` and `stroke` properties have higher precedence than `color` and will override `color`.\n   */\n  color?: Color | Gradient | ES;\n}\n\nexport interface TooltipContent {\n  content: 'encoding' | 'data';\n}\n\n/** @hidden */\nexport type Hide = 'hide';\n\nexport interface VLOnlyMarkConfig<ES extends ExprRef | SignalRef> extends ColorMixins<ES> {\n  /**\n   * Whether the mark's color should be used as fill color instead of stroke color.\n   *\n   * __Default value:__ `false` for all `point`, `line`, and `rule` marks as well as `geoshape` marks for [`graticule`](https://vega.github.io/vega-lite/docs/data.html#graticule) data sources; otherwise, `true`.\n   *\n   * __Note:__ This property cannot be used in a [style config](https://vega.github.io/vega-lite/docs/mark.html#style-config).\n   *\n   */\n  filled?: boolean;\n\n  /**\n   * Defines how Vega-Lite should handle marks for invalid values (`null` and `NaN`).\n   * - If set to `\"filter\"` (default), all data items with null values will be skipped (for line, trail, and area marks) or filtered (for other marks).\n   * - If `null`, all data items are included. In this case, invalid values will be interpreted as zeroes.\n   */\n  invalid?: 'filter' | Hide | null;\n\n  /**\n   * For line and trail marks, this `order` property can be set to `null` or `false` to make the lines use the original order in the data sources.\n   */\n  order?: null | boolean;\n\n  /**\n   * Default relative band position for a time unit. If set to `0`, the marks will be positioned at the beginning of the time unit band step.\n   * If set to `0.5`, the marks will be positioned in the middle of the time unit band step.\n   */\n  timeUnitBandPosition?: number;\n\n  /**\n   * Default relative band size for a time unit. If set to `1`, the bandwidth of the marks will be equal to the time unit band step.\n   * If set to `0.5`, bandwidth of the marks will be half of the time unit band step.\n   */\n  timeUnitBand?: number;\n\n  /**\n   * The end angle of arc marks in radians. A value of 0 indicates up or “north”, increasing values proceed clockwise.\n   */\n  theta2?: number | ES; // In Vega, this is called endAngle\n\n  /**\n   * The secondary (inner) radius in pixels of arc marks.\n   *\n   * @minimum 0\n   * __Default value:__ `0`\n   */\n  radius2?: number | ES; // In Vega, this is called innerRadius\n}\n\nexport interface MarkConfig<ES extends ExprRef | SignalRef>\n  extends VLOnlyMarkConfig<ES>,\n    MapExcludeValueRefAndReplaceSignalWith<Omit<VgMarkConfig, 'tooltip' | 'fill' | 'stroke'>, ES> {\n  // ========== Overriding Vega ==========\n\n  /**\n   * The tooltip text string to show upon mouse hover or an object defining which fields should the tooltip be derived from.\n   *\n   * - If `tooltip` is `true` or `{\"content\": \"encoding\"}`, then all fields from `encoding` will be used.\n   * - If `tooltip` is `{\"content\": \"data\"}`, then all fields that appear in the highlighted data point will be used.\n   * - If set to `null` or `false`, then no tooltip will be used.\n   *\n   * See the [`tooltip`](https://vega.github.io/vega-lite/docs/tooltip.html) documentation for a detailed discussion about tooltip  in Vega-Lite.\n   *\n   * __Default value:__ `null`\n   */\n  tooltip?: number | string | boolean | TooltipContent | ES | null; // VL has a special object form for tooltip content\n\n  /**\n   * Default size for marks.\n   * - For `point`/`circle`/`square`, this represents the pixel area of the marks. Note that this value sets the area of the symbol; the side lengths will increase with the square root of this value.\n   * - For `bar`, this represents the band size of the bar, in pixels.\n   * - For `text`, this represents the font size, in pixels.\n   *\n   * __Default value:__\n   * - `30` for point, circle, square marks; width/height's `step`\n   * - `2` for bar marks with discrete dimensions;\n   * - `5` for bar marks with continuous dimensions;\n   * - `11` for text marks.\n   *\n   * @minimum 0\n   */\n  size?: number | ES; // size works beyond symbol marks in VL\n\n  /**\n   * X coordinates of the marks, or width of horizontal `\"bar\"` and `\"area\"` without specified `x2` or `width`.\n   *\n   * The `value` of this channel can be a number or a string `\"width\"` for the width of the plot.\n   */\n  x?: number | 'width' | ES; // Vega doesn't have 'width'\n\n  /**\n   * Y coordinates of the marks, or height of vertical `\"bar\"` and `\"area\"` without specified `y2` or `height`.\n   *\n   * The `value` of this channel can be a number or a string `\"height\"` for the height of the plot.\n   */\n  y?: number | 'height' | ES; // Vega doesn't have 'height'\n\n  /**\n   * X2 coordinates for ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   *\n   * The `value` of this channel can be a number or a string `\"width\"` for the width of the plot.\n   */\n  x2?: number | 'width' | ES; // Vega doesn't have 'width'\n\n  /**\n   * Y2 coordinates for ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   *\n   * The `value` of this channel can be a number or a string `\"height\"` for the height of the plot.\n   */\n  y2?: number | 'height' | ES; // Vega doesn't have 'height'\n\n  /**\n   * Default fill color. This property has higher precedence than `config.color`. Set to `null` to remove fill.\n   *\n   * __Default value:__ (None)\n   *\n   */\n  fill?: Color | Gradient | null | ES; // docs: Vega doesn't have config.color\n\n  /**\n   * Default stroke color. This property has higher precedence than `config.color`. Set to `null` to remove stroke.\n   *\n   * __Default value:__ (None)\n   *\n   */\n  stroke?: Color | Gradient | null | ES; // docs: Vega doesn't have config.color\n\n  /**\n   * The overall opacity (value between [0,1]).\n   *\n   * __Default value:__ `0.7` for non-aggregate plots with `point`, `tick`, `circle`, or `square` marks or layered `bar` charts and `1` otherwise.\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  opacity?: number | ES; // docs (different defaults)\n\n  /**\n   * The orientation of a non-stacked bar, tick, area, and line charts.\n   * The value is either horizontal (default) or vertical.\n   * - For bar, rule and tick, this determines whether the size of the bar and tick\n   * should be applied to x or y dimension.\n   * - For area, this property determines the orient property of the Vega output.\n   * - For line and trail marks, this property determines the sort order of the points in the line\n   * if `config.sortLineBy` is not specified.\n   * For stacked charts, this is always determined by the orientation of the stack;\n   * therefore explicitly specified value will be ignored.\n   */\n  orient?: Orientation; // Vega orient doesn't apply to bar/tick/line. Since some logic depends on this property, Vega-Lite does NOT allow signal for orient.\n\n  /**\n   * The horizontal alignment of the text or ranged marks (area, bar, image, rect, rule). One of `\"left\"`, `\"right\"`, `\"center\"`.\n   *\n   * __Note:__ Expression reference is *not* supported for range marks.\n   */\n  align?: Align | ES;\n\n  /**\n   * For text marks, the vertical text baseline. One of `\"alphabetic\"` (default), `\"top\"`, `\"middle\"`, `\"bottom\"`, `\"line-top\"`, `\"line-bottom\"`, or an expression reference that provides one of the valid values.\n   * The `\"line-top\"` and `\"line-bottom\"` values operate similarly to `\"top\"` and `\"bottom\"`,\n   * but are calculated relative to the `lineHeight` rather than `fontSize` alone.\n   *\n   * For range marks, the vertical alignment of the marks. One of `\"top\"`, `\"middle\"`, `\"bottom\"`.\n   *\n   * __Note:__ Expression reference is *not* supported for range marks.\n   *\n   */\n  baseline?: TextBaseline | ES;\n\n  /**\n   * - For arc marks, the arc length in radians if theta2 is not specified, otherwise the start arc angle. (A value of 0 indicates up or “north”, increasing values proceed clockwise.)\n   *\n   * - For text marks, polar coordinate angle in radians.\n   *\n   * @minimum 0\n   * @maximum 360\n   */\n  theta?: number | ES; // overriding VG\n\n  /**\n   *\n   * For arc mark, the primary (outer) radius in pixels.\n   *\n   * For text marks, polar coordinate radial offset, in pixels, of the text from the origin determined by the `x` and `y` properties.\n   *\n   * @minimum 0\n   *\n   * __Default value:__ `min(plot_width, plot_height)/2`\n   */\n  radius?: number | ES; // overriding VG\n\n  /**\n   * The inner radius in pixels of arc marks. `innerRadius` is an alias for `radius2`.\n   *\n   * @minimum 0\n   * __Default value:__ `0`\n   */\n  innerRadius?: number | ES;\n\n  /**\n   * The outer radius in pixels of arc marks. `outerRadius` is an alias for `radius`.\n   *\n   * @minimum 0\n   * __Default value:__ `0`\n   */\n  outerRadius?: number | ES;\n}\n\nexport interface RectBinSpacingMixins {\n  /**\n   * Offset between bars for binned field. The ideal value for this is either 0 (preferred by statisticians) or 1 (Vega-Lite default, D3 example style).\n   *\n   * __Default value:__ `1`\n   *\n   * @minimum 0\n   */\n  binSpacing?: number;\n}\n\nexport type AnyMark = CompositeMark | CompositeMarkDef | Mark | MarkDef;\n\nexport function isMarkDef(mark: string | GenericMarkDef<any>): mark is GenericMarkDef<any> {\n  return mark['type'];\n}\n\nconst PRIMITIVE_MARK_INDEX = toSet(PRIMITIVE_MARKS);\n\nexport function isPrimitiveMark(mark: AnyMark): mark is Mark {\n  const markType = isMarkDef(mark) ? mark.type : mark;\n  return markType in PRIMITIVE_MARK_INDEX;\n}\n\nexport const STROKE_CONFIG = [\n  'stroke',\n  'strokeWidth',\n  'strokeDash',\n  'strokeDashOffset',\n  'strokeOpacity',\n  'strokeJoin',\n  'strokeMiterLimit'\n] as const;\n\nexport const FILL_CONFIG = ['fill', 'fillOpacity'] as const;\n\nexport const FILL_STROKE_CONFIG = [...STROKE_CONFIG, ...FILL_CONFIG];\n\nconst VL_ONLY_MARK_CONFIG_INDEX: Flag<keyof VLOnlyMarkConfig<any>> = {\n  color: 1,\n  filled: 1,\n  invalid: 1,\n  order: 1,\n  radius2: 1,\n  theta2: 1,\n  timeUnitBand: 1,\n  timeUnitBandPosition: 1\n};\n\nexport const VL_ONLY_MARK_CONFIG_PROPERTIES = keys(VL_ONLY_MARK_CONFIG_INDEX);\n\nexport const VL_ONLY_MARK_SPECIFIC_CONFIG_PROPERTY_INDEX: {\n  [k in Mark]?: (keyof Required<MarkConfigMixins<any>>[k])[];\n} = {\n  area: ['line', 'point'],\n  bar: ['binSpacing', 'continuousBandSize', 'discreteBandSize'],\n  rect: ['binSpacing', 'continuousBandSize', 'discreteBandSize'],\n  line: ['point'],\n  tick: ['bandSize', 'thickness']\n};\n\nexport const defaultMarkConfig: MarkConfig<SignalRef> = {\n  color: '#4c78a8',\n  invalid: 'filter',\n  timeUnitBand: 1\n};\n\n// TODO: replace with MarkConfigMixins[Mark] once https://github.com/vega/ts-json-schema-generator/issues/344 is fixed\nexport type AnyMarkConfig<ES extends ExprRef | SignalRef> =\n  | MarkConfig<SignalRef>\n  | AreaConfig<ES>\n  | BarConfig<ES>\n  | RectConfig<ES>\n  | LineConfig<ES>\n  | TickConfig<ES>;\n\nexport interface MarkConfigMixins<ES extends ExprRef | SignalRef> {\n  /** Mark Config */\n  mark?: MarkConfig<ES>;\n\n  // MARK-SPECIFIC CONFIGS\n\n  /** Arc-specific Config */\n  arc?: RectConfig<ES>;\n\n  /** Area-Specific Config */\n  area?: AreaConfig<ES>;\n\n  /** Bar-Specific Config */\n  bar?: BarConfig<ES>;\n\n  /** Circle-Specific Config */\n  circle?: MarkConfig<ES>;\n\n  /** Image-specific Config */\n  image?: RectConfig<ES>;\n\n  /** Line-Specific Config */\n  line?: LineConfig<ES>;\n\n  /** Point-Specific Config */\n  point?: MarkConfig<ES>;\n\n  /** Rect-Specific Config */\n  rect?: RectConfig<ES>;\n\n  /** Rule-Specific Config */\n  rule?: MarkConfig<ES>;\n\n  /** Square-Specific Config */\n  square?: MarkConfig<ES>;\n\n  /** Text-Specific Config */\n  text?: MarkConfig<ES>;\n\n  /** Tick-Specific Config */\n  tick?: TickConfig<ES>;\n\n  /** Trail-Specific Config */\n  trail?: LineConfig<ES>;\n\n  /** Geoshape-Specific Config */\n  geoshape?: MarkConfig<ES>;\n}\n\nconst MARK_CONFIG_INDEX: Flag<keyof MarkConfigMixins<any>> = {\n  mark: 1,\n  arc: 1,\n  area: 1,\n  bar: 1,\n  circle: 1,\n  image: 1,\n  line: 1,\n  point: 1,\n  rect: 1,\n  rule: 1,\n  square: 1,\n  text: 1,\n  tick: 1,\n  trail: 1,\n  geoshape: 1\n};\n\nexport const MARK_CONFIGS = keys(MARK_CONFIG_INDEX);\n\nexport interface RectConfig<ES extends ExprRef | SignalRef> extends RectBinSpacingMixins, MarkConfig<ES> {\n  /**\n   * The default size of the bars on continuous scales.\n   *\n   * __Default value:__ `5`\n   *\n   * @minimum 0\n   */\n  continuousBandSize?: number;\n\n  /**\n   * The default size of the bars with discrete dimensions. If unspecified, the default size is  `step-2`, which provides 2 pixel offset between bars.\n   * @minimum 0\n   */\n  discreteBandSize?: number;\n}\n\nexport const BAR_CORNER_RADIUS_INDEX: Partial<Record<\n  Orientation,\n  ('cornerRadiusTopLeft' | 'cornerRadiusTopRight' | 'cornerRadiusBottomLeft' | 'cornerRadiusBottomRight')[]\n>> = {\n  horizontal: ['cornerRadiusTopRight', 'cornerRadiusBottomRight'],\n  vertical: ['cornerRadiusTopLeft', 'cornerRadiusTopRight']\n};\n\nexport interface BarCornerRadiusMixins<ES extends ExprOrSignalRef> {\n  /**\n   * - For vertical bars, top-left and top-right corner radius.\n   * - For horizontal bars, top-right and bottom-right corner radius.\n   */\n  cornerRadiusEnd?: number | ES;\n}\n\nexport type BarConfig<ES extends ExprRef | SignalRef> = RectConfig<ES> & BarCornerRadiusMixins<ES>;\n\nexport type OverlayMarkDef<ES extends ExprRef | SignalRef> = MarkConfig<ES> & MarkDefMixins<ES>;\n\nexport interface PointOverlayMixins<ES extends ExprRef | SignalRef> {\n  /**\n   * A flag for overlaying points on top of line or area marks, or an object defining the properties of the overlayed points.\n   *\n   * - If this property is `\"transparent\"`, transparent points will be used (for enhancing tooltips and selections).\n   *\n   * - If this property is an empty object (`{}`) or `true`, filled points with default properties will be used.\n   *\n   * - If this property is `false`, no points would be automatically added to line or area marks.\n   *\n   * __Default value:__ `false`.\n   */\n  point?: boolean | OverlayMarkDef<ES> | 'transparent';\n}\n\nexport interface LineConfig<ES extends ExprRef | SignalRef> extends MarkConfig<ES>, PointOverlayMixins<ES> {}\n\nexport interface LineOverlayMixins<ES extends ExprRef | SignalRef> {\n  /**\n   * A flag for overlaying line on top of area marks, or an object defining the properties of the overlayed lines.\n   *\n   * - If this value is an empty object (`{}`) or `true`, lines with default properties will be used.\n   *\n   * - If this value is `false`, no lines would be automatically added to area marks.\n   *\n   * __Default value:__ `false`.\n   */\n  line?: boolean | OverlayMarkDef<ES>;\n}\n\nexport interface AreaConfig<ES extends ExprRef | SignalRef>\n  extends MarkConfig<ES>,\n    PointOverlayMixins<ES>,\n    LineOverlayMixins<ES> {}\n\nexport interface TickThicknessMixins {\n  /**\n   * Thickness of the tick mark.\n   *\n   * __Default value:__  `1`\n   *\n   * @minimum 0\n   */\n  thickness?: number | SignalRef;\n}\n\nexport interface GenericMarkDef<M> {\n  /**\n   * The mark type. This could a primitive mark type\n   * (one of `\"bar\"`, `\"circle\"`, `\"square\"`, `\"tick\"`, `\"line\"`,\n   * `\"area\"`, `\"point\"`, `\"geoshape\"`, `\"rule\"`, and `\"text\"`)\n   * or a composite mark type (`\"boxplot\"`, `\"errorband\"`, `\"errorbar\"`).\n   */\n  type: M;\n}\n\nexport interface MarkDefMixins<ES extends ExprRef | SignalRef> {\n  /**\n   * A string or array of strings indicating the name of custom styles to apply to the mark. A style is a named collection of mark property defaults defined within the [style configuration](https://vega.github.io/vega-lite/docs/mark.html#style-config). If style is an array, later styles will override earlier styles. Any [mark properties](https://vega.github.io/vega-lite/docs/encoding.html#mark-prop) explicitly defined within the `encoding` will override a style default.\n   *\n   * __Default value:__ The mark's name. For example, a bar mark will have style `\"bar\"` by default.\n   * __Note:__ Any specified style will augment the default style. For example, a bar mark with `\"style\": \"foo\"` will receive from `config.style.bar` and `config.style.foo` (the specified style `\"foo\"` has higher precedence).\n   */\n  style?: string | string[];\n\n  /**\n   * Whether a mark be clipped to the enclosing group’s width and height.\n   */\n  clip?: boolean;\n\n  // Offset properties should not be a part of config\n\n  /**\n   * Offset for x-position.\n   */\n  xOffset?: number | ES;\n\n  /**\n   * Offset for y-position.\n   */\n  yOffset?: number | ES;\n\n  /**\n   * Offset for x2-position.\n   */\n  x2Offset?: number | ES;\n\n  /**\n   * Offset for y2-position.\n   */\n  y2Offset?: number | ES;\n\n  /**\n   * Offset for theta.\n   */\n  thetaOffset?: number | ES;\n\n  /**\n   * Offset for theta2.\n   */\n  theta2Offset?: number | ES;\n\n  /**\n   * Offset for radius.\n   */\n  radiusOffset?: number | ES;\n\n  /**\n   * Offset for radius2.\n   */\n  radius2Offset?: number | ES;\n}\n\n// Point/Line OverlayMixins are only for area, line, and trail but we don't want to declare multiple types of MarkDef\n\n// Point/Line OverlayMixins are only for area, line, and trail but we don't want to declare multiple types of MarkDef\nexport interface MarkDef<\n  M extends string | Mark = Mark,\n  ES extends ExprRef | SignalRef = ExprRef | SignalRef\n> extends GenericMarkDef<M>,\n    Omit<\n      MarkConfig<ES> &\n        AreaConfig<ES> &\n        BarConfig<ES> & // always extends RectConfig\n        LineConfig<ES> &\n        TickConfig<ES>,\n      'startAngle' | 'endAngle'\n    >,\n    MarkDefMixins<ES> {\n  // Omit startAngle/endAngle since we use theta/theta2 from Vega-Lite schema to avoid confusion\n  // We still support start/endAngle  only in config, just in case people use Vega config with Vega-Lite.\n\n  /**\n   * @hidden\n   */\n  startAngle?: number | ES;\n  /**\n   * @hidden\n   */\n  endAngle?: number | ES;\n}\n\nconst DEFAULT_RECT_BAND_SIZE = 5;\n\nexport const defaultBarConfig: RectConfig<SignalRef> = {\n  binSpacing: 1,\n  continuousBandSize: DEFAULT_RECT_BAND_SIZE,\n  timeUnitBandPosition: 0.5\n};\n\nexport const defaultRectConfig: RectConfig<SignalRef> = {\n  binSpacing: 0,\n  continuousBandSize: DEFAULT_RECT_BAND_SIZE,\n  timeUnitBandPosition: 0.5\n};\n\nexport interface TickConfig<ES extends ExprRef | SignalRef> extends MarkConfig<ES>, TickThicknessMixins {\n  /**\n   * The width of the ticks.\n   *\n   * __Default value:__  3/4 of step (width step for horizontal ticks and height step for vertical ticks).\n   * @minimum 0\n   */\n  bandSize?: number;\n}\n\nexport const defaultTickConfig: TickConfig<SignalRef> = {\n  thickness: 1\n};\n\nexport function getMarkType(m: string | GenericMarkDef<any>) {\n  return isMarkDef(m) ? m.type : m;\n}\n","import {Axis, AXIS_PROPERTIES} from 'vega-lite/build/src/axis';\nimport {BinParams} from 'vega-lite/build/src/bin';\nimport {ExtendedChannel, COLOR, COLUMN, ROW, SIZE, X, Y} from 'vega-lite/build/src/channel';\nimport {TypedFieldDef} from 'vega-lite/build/src/channeldef';\nimport {Legend, LEGEND_PROPERTIES} from 'vega-lite/build/src/legend';\nimport * as MARK from 'vega-lite/build/src/mark';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {Scale, ScaleType, SCALE_PROPERTIES} from 'vega-lite/build/src/scale';\nimport {EncodingSortField, SortOrder} from 'vega-lite/build/src/sort';\nimport {StackOffset} from 'vega-lite/build/src/stack';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from './config';\nimport {isEncodingNestedProp, Property} from './property';\nimport {Schema} from './schema';\nimport {extend, isArray} from './util';\n\nexport const SHORT_WILDCARD: SHORT_WILDCARD = '?';\nexport type SHORT_WILDCARD = '?';\n\nexport interface Wildcard<T> {\n  name?: string;\n\n  /**\n   * List of values to enumerate\n   */\n  enum?: T[];\n}\n\nexport type WildcardProperty<T> = T | Wildcard<T> | SHORT_WILDCARD;\n\nexport interface ExtendedWildcard<T> extends Wildcard<T> {\n  [prop: string]: any;\n}\n\nexport function isWildcard(prop: any): prop is Wildcard<any> | SHORT_WILDCARD {\n  return isShortWildcard(prop) || isWildcardDef(prop);\n}\n\nexport function isShortWildcard(prop: any): prop is SHORT_WILDCARD {\n  return prop === SHORT_WILDCARD;\n}\n\nexport function isWildcardDef(prop: any): prop is Wildcard<any> {\n  return prop !== undefined && prop != null && (!!prop.enum || !!prop.name) && !isArray(prop);\n}\n\nexport function initWildcard(\n  prop: SHORT_WILDCARD | ExtendedWildcard<any>,\n  defaultName: string,\n  defaultEnumValues: any[]\n): ExtendedWildcard<any> {\n  return extend(\n    {},\n    {\n      name: defaultName,\n      enum: defaultEnumValues,\n    },\n    prop === SHORT_WILDCARD ? {} : prop\n  );\n}\n\n/**\n * Initial short names from list of full camelCaseNames.\n * For each camelCaseNames, return unique short names based on initial (e.g., `ccn`)\n */\nfunction initNestedPropName(fullNames: string[]) {\n  const index = {};\n  const has = {};\n  for (const fullName of fullNames) {\n    const initialIndices = [0];\n    for (let i = 0; i < fullName.length; i++) {\n      if (fullName.charAt(i).toUpperCase() === fullName.charAt(i)) {\n        initialIndices.push(i);\n      }\n    }\n    let shortName = initialIndices\n      .map((i) => fullName.charAt(i))\n      .join('')\n      .toLowerCase();\n    if (!has[shortName]) {\n      index[fullName] = shortName;\n      has[shortName] = true;\n      continue;\n    }\n    // If duplicate, add last character and try again!\n    if (initialIndices[initialIndices.length - 1] !== fullName.length - 1) {\n      shortName = initialIndices\n        .concat([fullName.length - 1])\n        .map((i) => fullName.charAt(i))\n        .join('')\n        .toLowerCase();\n      if (!has[shortName]) {\n        index[fullName] = shortName;\n        has[shortName] = true;\n        continue;\n      }\n    }\n    for (let i = 1; !index[fullName]; i++) {\n      const shortNameWithNo = `${shortName}_${i}`;\n      if (!has[shortNameWithNo]) {\n        index[fullName] = shortNameWithNo;\n        has[shortNameWithNo] = true;\n        break;\n      }\n    }\n  }\n  return index;\n}\n\nexport const DEFAULT_NAME = {\n  mark: 'm',\n  channel: 'c',\n  aggregate: 'a',\n  autoCount: '#',\n  hasFn: 'h',\n  bin: 'b',\n  sort: 'so',\n  stack: 'st',\n  scale: 's',\n  format: 'f',\n  axis: 'ax',\n  legend: 'l',\n  value: 'v',\n\n  timeUnit: 'tu',\n  field: 'f',\n  type: 't',\n\n  binProps: {\n    maxbins: 'mb',\n    min: 'mi',\n    max: 'ma',\n    base: 'b',\n    step: 's',\n    steps: 'ss',\n    minstep: 'ms',\n    divide: 'd',\n  },\n  sortProps: {\n    field: 'f',\n    op: 'o',\n    order: 'or',\n  },\n  scaleProps: initNestedPropName(SCALE_PROPERTIES),\n  axisProps: initNestedPropName(AXIS_PROPERTIES),\n  legendProps: initNestedPropName(LEGEND_PROPERTIES),\n};\n\nexport function getDefaultName(prop: Property) {\n  if (isEncodingNestedProp(prop)) {\n    return `${DEFAULT_NAME[prop.parent]}-${DEFAULT_NAME[`${prop.parent}Props`][prop.child]}`;\n  }\n  if (DEFAULT_NAME[prop]) {\n    return DEFAULT_NAME[prop];\n  }\n  /* istanbul ignore next */\n  throw new Error(`Default name undefined for ${prop}`);\n}\n\n/**\n * Generic index for default enum (values to enumerate) of a particular definition type.\n */\nexport type DefEnumIndex<T> = {[P in keyof T]-?: T[P][]};\n\nconst DEFAULT_BOOLEAN_ENUM = [false, true];\n\nexport type EnumIndex = {\n  mark: Mark[];\n  channel: ExtendedChannel[];\n  autoCount: boolean[];\n  hasFn: boolean[];\n} & DefEnumIndex<TypedFieldDef<string>> & {\n    sort: (EncodingSortField<string> | SortOrder)[];\n    stack: StackOffset[];\n    format: string[];\n    scale: boolean[];\n    axis: boolean[];\n    legend: boolean[];\n    value: any[];\n\n    binProps: Partial<DefEnumIndex<BinParams>>;\n    sortProps: Partial<DefEnumIndex<EncodingSortField<string>>>;\n    scaleProps: Partial<DefEnumIndex<Scale>>;\n    axisProps: Partial<DefEnumIndex<Axis>>;\n    legendProps: Partial<DefEnumIndex<Legend<any>>>;\n  };\n\nconst DEFAULT_BIN_PROPS_ENUM: DefEnumIndex<BinParams> = {\n  maxbins: [5, 10, 20],\n  extent: [undefined],\n  base: [10],\n  step: [undefined],\n  steps: [undefined],\n  minstep: [undefined],\n  divide: [[5, 2]],\n  binned: [false],\n  anchor: [undefined],\n  nice: [true],\n};\n\nconst DEFAULT_SORT_PROPS: DefEnumIndex<EncodingSortField<string>> = {\n  field: [undefined], // This should be never call and instead read from the schema\n  op: ['min', 'mean'],\n  order: ['ascending', 'descending'],\n};\n\nconst DEFAULT_SCALE_PROPS_ENUM: DefEnumIndex<Scale> = {\n  align: [undefined],\n  type: [undefined, ScaleType.LOG],\n  domain: [undefined],\n  domainMax: [undefined],\n  domainMid: [undefined],\n  domainMin: [undefined],\n  base: [undefined],\n  exponent: [1, 2],\n  constant: [undefined],\n\n  bins: [undefined],\n\n  clamp: DEFAULT_BOOLEAN_ENUM,\n  nice: DEFAULT_BOOLEAN_ENUM,\n  reverse: DEFAULT_BOOLEAN_ENUM,\n  round: DEFAULT_BOOLEAN_ENUM,\n  zero: DEFAULT_BOOLEAN_ENUM,\n\n  padding: [undefined],\n  paddingInner: [undefined],\n  paddingOuter: [undefined],\n\n  interpolate: [undefined],\n\n  range: [undefined],\n  rangeMax: [undefined],\n  rangeMin: [undefined],\n  scheme: [undefined],\n};\n\nconst DEFAULT_AXIS_PROPS_ENUM: DefEnumIndex<Axis> = {\n  aria: [undefined],\n  description: [undefined],\n  zindex: [1, 0],\n  offset: [undefined],\n  orient: [undefined],\n  values: [undefined],\n\n  bandPosition: [undefined],\n  encoding: [undefined],\n\n  domain: DEFAULT_BOOLEAN_ENUM,\n  domainCap: [undefined],\n  domainColor: [undefined],\n  domainDash: [undefined],\n  domainDashOffset: [undefined],\n  domainOpacity: [undefined],\n  domainWidth: [undefined],\n\n  formatType: [undefined],\n\n  grid: DEFAULT_BOOLEAN_ENUM,\n  gridCap: [undefined],\n  gridColor: [undefined],\n  gridDash: [undefined],\n  gridDashOffset: [undefined],\n  gridOpacity: [undefined],\n  gridWidth: [undefined],\n\n  format: [undefined],\n  labels: DEFAULT_BOOLEAN_ENUM,\n  labelAlign: [undefined],\n  labelAngle: [undefined],\n  labelBaseline: [undefined],\n  labelColor: [undefined],\n  labelExpr: [undefined],\n  labelFlushOffset: [undefined],\n  labelFont: [undefined],\n  labelFontSize: [undefined],\n  labelFontStyle: [undefined],\n  labelFontWeight: [undefined],\n  labelLimit: [undefined],\n  labelLineHeight: [undefined],\n  labelOffset: [undefined],\n  labelOpacity: [undefined],\n  labelSeparation: [undefined],\n  labelOverlap: [undefined],\n  labelPadding: [undefined],\n  labelBound: [undefined],\n  labelFlush: [undefined],\n\n  maxExtent: [undefined],\n  minExtent: [undefined],\n  position: [undefined],\n\n  style: [undefined],\n\n  ticks: DEFAULT_BOOLEAN_ENUM,\n  tickBand: [undefined],\n  tickCap: [undefined],\n  tickColor: [undefined],\n  tickCount: [undefined],\n  tickDash: [undefined],\n  tickExtra: [undefined],\n  tickDashOffset: [undefined],\n  tickMinStep: [undefined],\n  tickOffset: [undefined],\n  tickOpacity: [undefined],\n  tickRound: [undefined],\n  tickSize: [undefined],\n  tickWidth: [undefined],\n\n  title: [undefined],\n  titleAlign: [undefined],\n  titleAnchor: [undefined],\n  titleAngle: [undefined],\n  titleBaseline: [undefined],\n  titleColor: [undefined],\n  titleFont: [undefined],\n  titleFontSize: [undefined],\n  titleFontStyle: [undefined],\n  titleFontWeight: [undefined],\n  titleLimit: [undefined],\n  titleLineHeight: [undefined],\n  titleOpacity: [undefined],\n  titlePadding: [undefined],\n  titleX: [undefined],\n  titleY: [undefined],\n\n  translate: [undefined],\n};\n\nconst DEFAULT_LEGEND_PROPS_ENUM: DefEnumIndex<Legend<any>> = {\n  aria: [undefined],\n  description: [undefined],\n  orient: ['left', 'right'],\n  format: [undefined],\n  type: [undefined],\n  values: [undefined],\n  zindex: [undefined],\n\n  clipHeight: [undefined],\n  columnPadding: [undefined],\n  columns: [undefined],\n  cornerRadius: [undefined],\n  direction: [undefined],\n  encoding: [undefined],\n  fillColor: [undefined],\n  formatType: [undefined],\n  gridAlign: [undefined],\n  offset: [undefined],\n  padding: [undefined],\n  rowPadding: [undefined],\n  strokeColor: [undefined],\n\n  labelAlign: [undefined],\n  labelBaseline: [undefined],\n  labelColor: [undefined],\n  labelExpr: [undefined],\n  labelFont: [undefined],\n  labelFontSize: [undefined],\n  labelFontStyle: [undefined],\n  labelFontWeight: [undefined],\n  labelLimit: [undefined],\n  labelOffset: [undefined],\n  labelOpacity: [undefined],\n  labelOverlap: [undefined],\n  labelPadding: [undefined],\n  labelSeparation: [undefined],\n\n  legendX: [undefined],\n  legendY: [undefined],\n\n  gradientLength: [undefined],\n  gradientOpacity: [undefined],\n  gradientStrokeColor: [undefined],\n  gradientStrokeWidth: [undefined],\n  gradientThickness: [undefined],\n\n  symbolDash: [undefined],\n  symbolDashOffset: [undefined],\n  symbolFillColor: [undefined],\n  symbolLimit: [undefined],\n  symbolOffset: [undefined],\n  symbolOpacity: [undefined],\n  symbolSize: [undefined],\n  symbolStrokeColor: [undefined],\n  symbolStrokeWidth: [undefined],\n  symbolType: [undefined],\n\n  tickCount: [undefined],\n  tickMinStep: [undefined],\n\n  title: [undefined],\n  titleAnchor: [undefined],\n  titleAlign: [undefined],\n  titleBaseline: [undefined],\n  titleColor: [undefined],\n  titleFont: [undefined],\n  titleFontSize: [undefined],\n  titleFontStyle: [undefined],\n  titleFontWeight: [undefined],\n  titleLimit: [undefined],\n  titleLineHeight: [undefined],\n  titleOpacity: [undefined],\n  titleOrient: [undefined],\n  titlePadding: [undefined],\n};\n\n// Use FullEnumIndex to make sure we have all properties specified here!\nexport const DEFAULT_ENUM_INDEX: EnumIndex = {\n  mark: [MARK.POINT, MARK.BAR, MARK.LINE, MARK.AREA, MARK.RECT, MARK.TICK, MARK.TEXT],\n  channel: [X, Y, ROW, COLUMN, SIZE, COLOR], // TODO: TEXT\n  band: [undefined],\n\n  aggregate: [undefined, 'mean'],\n  autoCount: DEFAULT_BOOLEAN_ENUM,\n  bin: DEFAULT_BOOLEAN_ENUM,\n  hasFn: DEFAULT_BOOLEAN_ENUM,\n  timeUnit: [undefined, 'year', 'month', 'minutes', 'seconds'],\n\n  field: [undefined], // This is not used as field should be read from schema\n  type: [TYPE.NOMINAL, TYPE.ORDINAL, TYPE.QUANTITATIVE, TYPE.TEMPORAL],\n\n  sort: ['ascending', 'descending'],\n  stack: ['zero', 'normalize', 'center', null],\n  value: [undefined],\n\n  format: [undefined],\n  title: [undefined],\n  scale: [true],\n  axis: DEFAULT_BOOLEAN_ENUM,\n  legend: DEFAULT_BOOLEAN_ENUM,\n\n  binProps: DEFAULT_BIN_PROPS_ENUM,\n  sortProps: DEFAULT_SORT_PROPS,\n  scaleProps: DEFAULT_SCALE_PROPS_ENUM,\n  axisProps: DEFAULT_AXIS_PROPS_ENUM,\n  legendProps: DEFAULT_LEGEND_PROPS_ENUM,\n};\n\n// TODO: rename this to getDefaultEnum\nexport function getDefaultEnumValues(prop: Property, schema: Schema, opt: QueryConfig): any[] {\n  if (prop === 'field' || (isEncodingNestedProp(prop) && prop.parent === 'sort' && prop.child === 'field')) {\n    // For field, by default enumerate all fields\n    return schema.fieldNames();\n  }\n\n  let val;\n  if (isEncodingNestedProp(prop)) {\n    val = opt.enum[`${prop.parent}Props`][prop.child];\n  } else {\n    val = opt.enum[prop];\n  }\n\n  if (val !== undefined) {\n    return val;\n  }\n\n  /* istanbul ignore next */\n  throw new Error(`No default enumValues for ${JSON.stringify(prop)}`);\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {Channel, ExtendedChannel} from 'vega-lite/build/src/channel';\nimport {Config} from 'vega-lite/build/src/config';\nimport {DEFAULT_PROP_PRECEDENCE, toKey} from './property';\nimport {DEFAULT_ENUM_INDEX, EnumIndex} from './wildcard';\n\n// We name this QueryConfig to avoid confusion with Vega-Lite's Config\nexport interface QueryConfig {\n  verbose?: boolean;\n\n  defaultSpecConfig?: Config;\n\n  propertyPrecedence?: string[];\n\n  enum?: Partial<EnumIndex>;\n\n  /** Default ratio for number fields to be considered ordinal */\n  numberNominalProportion?: number;\n\n  /** Default cutoff for not applying the numberOrdinalProportion inference */\n  numberNominalLimit?: number;\n\n  // SPECIAL MODE\n  /**\n   * Allow automatically adding a special count (autoCount) field for plots\n   * that contain only discrete fields. In such cases, adding count make the\n   * output plots way more meaningful.\n   */\n  autoAddCount?: boolean;\n\n  // CONSTRAINTS\n  constraintManuallySpecifiedValue?: boolean;\n  // Spec Constraints\n\n  hasAppropriateGraphicTypeForMark?: boolean;\n  omitAggregate?: boolean;\n  omitAggregatePlotWithDimensionOnlyOnFacet?: boolean;\n  omitAggregatePlotWithoutDimension?: boolean;\n  omitBarLineAreaWithOcclusion?: boolean;\n  omitBarTickWithSize?: boolean;\n  omitMultipleNonPositionalChannels?: boolean;\n  omitRaw?: boolean;\n  omitRawContinuousFieldForAggregatePlot?: boolean;\n  omitRawWithXYBothOrdinalScaleOrBin?: boolean;\n  omitRepeatedField?: boolean;\n  omitNonPositionalOrFacetOverPositionalChannels?: boolean;\n  omitTableWithOcclusionIfAutoAddCount?: boolean;\n  omitVerticalDotPlot?: boolean;\n  omitInvalidStackSpec?: boolean;\n  omitNonSumStack?: boolean;\n\n  preferredBinAxis?: Channel;\n  preferredTemporalAxis?: Channel;\n  preferredOrdinalAxis?: Channel;\n  preferredNominalAxis?: Channel;\n  preferredFacet?: ExtendedChannel;\n\n  // Field Encoding Constraints\n  minCardinalityForBin?: number;\n  maxCardinalityForCategoricalColor?: number;\n  maxCardinalityForFacet?: number;\n  maxCardinalityForShape?: number;\n  timeUnitShouldHaveVariation?: boolean;\n  typeMatchesSchemaType?: boolean;\n\n  // STYLIZE\n  stylize?: boolean;\n  smallRangeStepForHighCardinalityOrFacet?: {maxCardinality: number; rangeStep: number};\n  nominalColorScaleForHighCardinality?: {maxCardinality: number; palette: string};\n  xAxisOnTopForHighYCardinalityWithoutColumn?: {maxCardinality: number};\n\n  // EFFECTIVENESS PREFERENCE\n  maxGoodCardinalityForColor?: number; // FIXME: revise\n  maxGoodCardinalityForFacet?: number; // FIXME: revise\n  // HIGH CARDINALITY STRINGS\n  minPercentUniqueForKey?: number;\n  minCardinalityForKey?: number;\n}\n\nexport const DEFAULT_QUERY_CONFIG: QueryConfig = {\n  verbose: false,\n  defaultSpecConfig: {\n    line: {point: true},\n    scale: {useUnaggregatedDomain: true},\n  },\n  propertyPrecedence: DEFAULT_PROP_PRECEDENCE.map(toKey),\n  enum: DEFAULT_ENUM_INDEX,\n\n  numberNominalProportion: 0.05,\n  numberNominalLimit: 40,\n\n  // CONSTRAINTS\n  constraintManuallySpecifiedValue: false,\n  // Spec Constraints -- See description inside src/constraints/spec.ts\n  autoAddCount: false,\n\n  hasAppropriateGraphicTypeForMark: true,\n  omitAggregate: false,\n  omitAggregatePlotWithDimensionOnlyOnFacet: true,\n  omitAggregatePlotWithoutDimension: false,\n  omitBarLineAreaWithOcclusion: true,\n  omitBarTickWithSize: true,\n  omitMultipleNonPositionalChannels: true,\n  omitRaw: false,\n  omitRawContinuousFieldForAggregatePlot: true,\n  omitRepeatedField: true,\n  omitNonPositionalOrFacetOverPositionalChannels: true,\n  omitTableWithOcclusionIfAutoAddCount: true,\n  omitVerticalDotPlot: false,\n  omitInvalidStackSpec: true,\n  omitNonSumStack: true,\n\n  preferredBinAxis: CHANNEL.X,\n  preferredTemporalAxis: CHANNEL.X,\n  preferredOrdinalAxis: CHANNEL.Y, // ordinal on y makes it easier to read.\n  preferredNominalAxis: CHANNEL.Y, // nominal on y makes it easier to read.\n  preferredFacet: CHANNEL.ROW, // row make it easier to scroll than column\n\n  // Field Encoding Constraints -- See description inside src/constraint/field.ts\n  minCardinalityForBin: 15,\n  maxCardinalityForCategoricalColor: 20,\n  maxCardinalityForFacet: 20,\n  maxCardinalityForShape: 6,\n  timeUnitShouldHaveVariation: true,\n  typeMatchesSchemaType: true,\n\n  // STYLIZE\n  stylize: true,\n  smallRangeStepForHighCardinalityOrFacet: {maxCardinality: 10, rangeStep: 12},\n  nominalColorScaleForHighCardinality: {maxCardinality: 10, palette: 'category20'},\n  xAxisOnTopForHighYCardinalityWithoutColumn: {maxCardinality: 30},\n\n  // RANKING PREFERENCE\n  maxGoodCardinalityForFacet: 5, // FIXME: revise\n  maxGoodCardinalityForColor: 7, // FIXME: revise\n\n  // HIGH CARDINALITY STRINGS\n  minPercentUniqueForKey: 0.8,\n  minCardinalityForKey: 50,\n};\n\nexport function extendConfig(opt: QueryConfig) {\n  return {\n    ...DEFAULT_QUERY_CONFIG,\n    ...opt,\n    enum: extendEnumIndex(opt.enum),\n  };\n}\n\nfunction extendEnumIndex(enumIndex: Partial<EnumIndex>) {\n  const enumOpt: EnumIndex = {\n    ...DEFAULT_ENUM_INDEX,\n    ...enumIndex,\n    binProps: extendNestedEnumIndex(enumIndex, 'bin'),\n    scaleProps: extendNestedEnumIndex(enumIndex, 'scale'),\n    axisProps: extendNestedEnumIndex(enumIndex, 'axis'),\n    legendProps: extendNestedEnumIndex(enumIndex, 'legend'),\n  };\n  return enumOpt;\n}\n\nfunction extendNestedEnumIndex(enumIndex: Partial<EnumIndex>, prop: 'bin' | 'scale' | 'axis' | 'legend') {\n  return {\n    ...DEFAULT_ENUM_INDEX[`${prop}Props`],\n    ...enumIndex[`${prop}Props`],\n  };\n}\n","import {AggregateOp} from 'vega';\nimport {isString, toSet} from 'vega-util';\nimport {contains, Flag, keys} from './util';\n\nconst AGGREGATE_OP_INDEX: Flag<AggregateOp> = {\n  argmax: 1,\n  argmin: 1,\n  average: 1,\n  count: 1,\n  distinct: 1,\n  product: 1,\n  max: 1,\n  mean: 1,\n  median: 1,\n  min: 1,\n  missing: 1,\n  q1: 1,\n  q3: 1,\n  ci0: 1,\n  ci1: 1,\n  stderr: 1,\n  stdev: 1,\n  stdevp: 1,\n  sum: 1,\n  valid: 1,\n  values: 1,\n  variance: 1,\n  variancep: 1\n};\n\nexport const MULTIDOMAIN_SORT_OP_INDEX = {\n  count: 1,\n  min: 1,\n  max: 1\n};\n\nexport interface ArgminDef {\n  argmin: string;\n}\n\nexport interface ArgmaxDef {\n  argmax: string;\n}\n\nexport type NonArgAggregateOp = Exclude<AggregateOp, 'argmin' | 'argmax'>;\n\nexport type Aggregate = NonArgAggregateOp | ArgmaxDef | ArgminDef;\n\nexport function isArgminDef(a: Aggregate | string): a is ArgminDef {\n  return !!a && !!a['argmin'];\n}\n\nexport function isArgmaxDef(a: Aggregate | string): a is ArgmaxDef {\n  return !!a && !!a['argmax'];\n}\n\nexport const AGGREGATE_OPS = keys(AGGREGATE_OP_INDEX);\n\nexport function isAggregateOp(a: string | ArgminDef | ArgmaxDef): a is AggregateOp {\n  return isString(a) && !!AGGREGATE_OP_INDEX[a];\n}\n\nexport const COUNTING_OPS: NonArgAggregateOp[] = ['count', 'valid', 'missing', 'distinct'];\n\nexport function isCountingAggregateOp(aggregate?: string | Aggregate): boolean {\n  return isString(aggregate) && contains(COUNTING_OPS, aggregate);\n}\n\nexport function isMinMaxOp(aggregate?: Aggregate | string): boolean {\n  return isString(aggregate) && contains(['min', 'max'], aggregate);\n}\n\n/** Additive-based aggregation operations. These can be applied to stack. */\nexport const SUM_OPS: NonArgAggregateOp[] = ['count', 'sum', 'distinct', 'valid', 'missing'];\n\n/**\n * Aggregation operators that always produce values within the range [domainMin, domainMax].\n */\nexport const SHARED_DOMAIN_OPS: AggregateOp[] = ['mean', 'average', 'median', 'q1', 'q3', 'min', 'max'];\n\nexport const SHARED_DOMAIN_OP_INDEX = toSet(SHARED_DOMAIN_OPS);\n","import {isBoolean, isObject} from 'vega-util';\nimport {\n  COLOR,\n  COLUMN,\n  ExtendedChannel,\n  FILL,\n  FILLOPACITY,\n  OPACITY,\n  ROW,\n  SHAPE,\n  SIZE,\n  STROKE,\n  STROKEDASH,\n  STROKEOPACITY,\n  STROKEWIDTH\n} from './channel';\nimport {normalizeBin} from './channeldef';\nimport {SelectionExtent} from './selection';\nimport {entries, keys, varName} from './util';\n\nexport interface BaseBin {\n  /**\n   * The number base to use for automatic bin determination (default is base 10).\n   *\n   * __Default value:__ `10`\n   *\n   */\n  base?: number;\n  /**\n   * An exact step size to use between bins.\n   *\n   * __Note:__ If provided, options such as maxbins will be ignored.\n   */\n  step?: number;\n  /**\n   * An array of allowable step sizes to choose from.\n   * @minItems 1\n   */\n  steps?: number[];\n  /**\n   * A minimum allowable step size (particularly useful for integer values).\n   */\n  minstep?: number;\n  /**\n   * Scale factors indicating allowable subdivisions. The default value is [5, 2], which indicates that for base 10 numbers (the default base), the method may consider dividing bin sizes by 5 and/or 2. For example, for an initial step size of 10, the method can check if bin sizes of 2 (= 10/5), 5 (= 10/2), or 1 (= 10/(5*2)) might also satisfy the given constraints.\n   *\n   * __Default value:__ `[5, 2]`\n   *\n   * @minItems 1\n   */\n  divide?: [number, number];\n  /**\n   * Maximum number of bins.\n   *\n   * __Default value:__ `6` for `row`, `column` and `shape` channels; `10` for other channels\n   *\n   * @minimum 2\n   */\n  maxbins?: number;\n  /**\n   * A value in the binned domain at which to anchor the bins, shifting the bin boundaries if necessary to ensure that a boundary aligns with the anchor value.\n   *\n   * __Default value:__ the minimum bin extent value\n   */\n  anchor?: number;\n  /**\n   * If true, attempts to make the bin boundaries use human-friendly boundaries, such as multiples of ten.\n   *\n   * __Default value:__ `true`\n   */\n  nice?: boolean;\n}\n\n/**\n * Binning properties or boolean flag for determining whether to bin data or not.\n */\nexport interface BinParams extends BaseBin {\n  /**\n   * A two-element (`[min, max]`) array indicating the range of desired bin values.\n   */\n  extent?: BinExtent; // VgBinTransform uses a different extent so we need to pull this out.\n\n  /**\n   * When set to `true`, Vega-Lite treats the input data as already binned.\n   */\n  binned?: boolean;\n}\n\nexport type Bin = boolean | BinParams | 'binned' | null;\n\nexport type BinExtent = [number, number] | SelectionExtent;\n\n/**\n * Create a key for the bin configuration. Not for prebinned bin.\n */\nexport function binToString(bin: BinParams | true) {\n  if (isBoolean(bin)) {\n    bin = normalizeBin(bin, undefined);\n  }\n  return (\n    'bin' +\n    keys(bin)\n      .map(p => (isSelectionExtent(bin[p]) ? varName(`_${p}_${entries(bin[p])}`) : varName(`_${p}_${bin[p]}`)))\n      .join('')\n  );\n}\n\n/**\n * Vega-Lite should bin the data.\n */\nexport function isBinning(bin: BinParams | boolean | 'binned'): bin is BinParams | true {\n  return bin === true || (isBinParams(bin) && !bin.binned);\n}\n\n/**\n * The data is already binned and so Vega-Lite should not bin it again.\n */\nexport function isBinned(bin: BinParams | boolean | 'binned'): bin is 'binned' | BinParams {\n  return bin === 'binned' || (isBinParams(bin) && bin.binned === true);\n}\n\nexport function isBinParams(bin: BinParams | boolean | 'binned'): bin is BinParams {\n  return isObject(bin);\n}\n\nexport function isSelectionExtent(extent: BinExtent): extent is SelectionExtent {\n  return extent?.['selection'];\n}\n\nexport function autoMaxBins(channel?: ExtendedChannel): number {\n  switch (channel) {\n    case ROW:\n    case COLUMN:\n    case SIZE:\n    case COLOR:\n    case FILL:\n    case STROKE:\n    case STROKEWIDTH:\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    // Facets and Size shouldn't have too many bins\n    // We choose 6 like shape to simplify the rule [falls through]\n    case SHAPE:\n      return 6; // Vega's \"shape\" has 6 distinct values\n    case STROKEDASH:\n      return 4; // We only provide 5 different stroke dash values (but 4 is more effective)\n    default:\n      return 10;\n  }\n}\n","import {Gradient, SignalRef, Text} from 'vega';\nimport {isArray, isBoolean, isNumber, isString} from 'vega-util';\nimport {Aggregate, isAggregateOp, isArgmaxDef, isArgminDef, isCountingAggregateOp} from './aggregate';\nimport {Axis} from './axis';\nimport {autoMaxBins, Bin, BinParams, binToString, isBinned, isBinning} from './bin';\nimport {\n  ANGLE,\n  Channel,\n  COLOR,\n  COLUMN,\n  DESCRIPTION,\n  DETAIL,\n  ExtendedChannel,\n  FACET,\n  FILL,\n  FILLOPACITY,\n  HREF,\n  isScaleChannel,\n  isSecondaryRangeChannel,\n  isXorY,\n  KEY,\n  LATITUDE,\n  LATITUDE2,\n  LONGITUDE,\n  LONGITUDE2,\n  OPACITY,\n  ORDER,\n  RADIUS,\n  RADIUS2,\n  ROW,\n  SHAPE,\n  SIZE,\n  STROKE,\n  STROKEDASH,\n  STROKEOPACITY,\n  STROKEWIDTH,\n  TEXT,\n  THETA,\n  THETA2,\n  TOOLTIP,\n  URL,\n  X,\n  X2,\n  Y,\n  Y2\n} from './channel';\nimport {getMarkConfig} from './compile/common';\nimport {isCustomFormatType} from './compile/format';\nimport {CompositeAggregate} from './compositemark';\nimport {Config} from './config';\nimport {DateTime, dateTimeToExpr, isDateTime} from './datetime';\nimport {Encoding} from './encoding';\nimport {ExprRef, isExprRef} from './expr';\nimport {FormatMixins, Guide, GuideEncodingConditionalValueDef, TitleMixins} from './guide';\nimport {ImputeParams} from './impute';\nimport {Legend} from './legend';\nimport * as log from './log';\nimport {LogicalComposition} from './logical';\nimport {isRectBasedMark, Mark, MarkDef} from './mark';\nimport {Predicate} from './predicate';\nimport {Scale, SCALE_CATEGORY_INDEX} from './scale';\nimport {isSortByChannel, Sort, SortOrder} from './sort';\nimport {isFacetFieldDef} from './spec/facet';\nimport {StackOffset, StackProperties} from './stack';\nimport {\n  getTimeUnitParts,\n  isLocalSingleTimeUnit,\n  normalizeTimeUnit,\n  TimeUnit,\n  TimeUnitParams,\n  timeUnitToString\n} from './timeunit';\nimport {AggregatedFieldDef, WindowFieldDef} from './transform';\nimport {getFullName, QUANTITATIVE, StandardType, Type} from './type';\nimport {\n  contains,\n  flatAccessWithDatum,\n  getFirstDefined,\n  internalField,\n  omit,\n  removePathFromField,\n  replacePathInField,\n  titleCase\n} from './util';\nimport {isSignalRef} from './vega.schema';\n\nexport type PrimitiveValue = number | string | boolean | null;\n\nexport type Value<ES extends ExprRef | SignalRef = ExprRef | SignalRef> =\n  | PrimitiveValue\n  | number[]\n  | Gradient\n  | Text\n  | ES;\n\n/**\n * Definition object for a constant value (primitive value or gradient definition) of an encoding channel.\n */\nexport interface ValueDef<V extends Value = Value> {\n  /**\n   * A constant value in visual domain (e.g., `\"red\"` / `\"#0099ff\"` / [gradient definition](https://vega.github.io/vega-lite/docs/types.html#gradient) for color, values between `0` to `1` for opacity).\n   */\n  value: V;\n}\n\nexport type PositionValueDef = ValueDef<number | 'width' | 'height' | ExprRef | SignalRef>;\nexport type NumericValueDef = ValueDef<number | ExprRef | SignalRef>;\n\n/**\n * A ValueDef with Condition<ValueDef | FieldDef> where either the condition or the value are optional.\n * {\n *   condition: {field: ...} | {value: ...},\n *   value: ...,\n * }\n */\n\n/**\n * @minProperties 1\n */\nexport type ValueDefWithCondition<F extends FieldDef<any> | DatumDef<any>, V extends Value = Value> = Partial<\n  ValueDef<V | ExprRef | SignalRef>\n> & {\n  /**\n   * A field definition or one or more value definition(s) with a selection predicate.\n   */\n  condition?:\n    | Conditional<F>\n    | Conditional<ValueDef<V | ExprRef | SignalRef>>\n    | Conditional<ValueDef<V | ExprRef | SignalRef>>[];\n};\n\nexport type StringValueDefWithCondition<F extends Field, T extends Type = StandardType> = ValueDefWithCondition<\n  MarkPropFieldOrDatumDef<F, T>,\n  string | null\n>;\nexport type TypeForShape = 'nominal' | 'ordinal' | 'geojson';\n\nexport type Conditional<CD extends FieldDef<any> | DatumDef | ValueDef<any> | ExprRef | SignalRef> =\n  | ConditionalPredicate<CD>\n  | ConditionalSelection<CD>;\n\nexport type ConditionalPredicate<CD extends FieldDef<any> | DatumDef | ValueDef<any> | ExprRef | SignalRef> = {\n  /**\n   * Predicate for triggering the condition\n   */\n  test: LogicalComposition<Predicate>;\n} & CD;\n\nexport type ConditionalSelection<CD extends FieldDef<any> | DatumDef | ValueDef<any> | ExprRef | SignalRef> = {\n  /**\n   * A [selection name](https://vega.github.io/vega-lite/docs/selection.html), or a series of [composed selections](https://vega.github.io/vega-lite/docs/selection.html#compose).\n   */\n  selection: LogicalComposition<string>;\n} & CD;\n\nexport function isConditionalSelection<T>(c: Conditional<T>): c is ConditionalSelection<T> {\n  return c['selection'];\n}\n\nexport interface ConditionValueDefMixins<V extends Value = Value> {\n  /**\n   * One or more value definition(s) with [a selection or a test predicate](https://vega.github.io/vega-lite/docs/condition.html).\n   *\n   * __Note:__ A field definition's `condition` property can only contain [conditional value definitions](https://vega.github.io/vega-lite/docs/condition.html#value)\n   * since Vega-Lite only allows at most one encoded field per encoding channel.\n   */\n  condition?: Conditional<ValueDef<V>> | Conditional<ValueDef<V>>[];\n}\n\n/**\n * A FieldDef with Condition<ValueDef>\n * {\n *   condition: {value: ...},\n *   field: ...,\n *   ...\n * }\n */\n\nexport type FieldOrDatumDefWithCondition<F extends FieldDef<any, any> | DatumDef<any>, V extends Value = Value> = F &\n  ConditionValueDefMixins<V | ExprRef | SignalRef>;\n\nexport type MarkPropDef<F extends Field, V extends Value, T extends Type = StandardType> =\n  | FieldOrDatumDefWithCondition<MarkPropFieldDef<F, T>, V>\n  | FieldOrDatumDefWithCondition<DatumDef<F>, V>\n  | ValueDefWithCondition<MarkPropFieldOrDatumDef<F, T>, V>;\n\nexport type ColorDef<F extends Field> = MarkPropDef<F, Gradient | string | null>;\nexport type NumericMarkPropDef<F extends Field> = MarkPropDef<F, number>;\n\nexport type NumericArrayMarkPropDef<F extends Field> = MarkPropDef<F, number[]>;\n\nexport type ShapeDef<F extends Field> = MarkPropDef<F, string | null, TypeForShape>;\n\nexport type StringFieldDefWithCondition<F extends Field> = FieldOrDatumDefWithCondition<StringFieldDef<F>, string>;\nexport type TextDef<F extends Field> =\n  | FieldOrDatumDefWithCondition<StringFieldDef<F>, Text>\n  | FieldOrDatumDefWithCondition<StringDatumDef<F>, Text>\n  | ValueDefWithCondition<StringFieldDef<F>, Text>;\n\n/**\n * A ValueDef with optional Condition<ValueDef | FieldDef>\n * {\n *   condition: {field: ...} | {value: ...},\n *   value: ...,\n * }\n */\n\n/**\n * Reference to a repeated value.\n */\nexport interface RepeatRef {\n  repeat: 'row' | 'column' | 'repeat' | 'layer';\n}\n\nexport type FieldName = string;\nexport type Field = FieldName | RepeatRef;\n\nexport function isRepeatRef(field: Field | any): field is RepeatRef {\n  return field && !isString(field) && 'repeat' in field;\n}\n\n/** @@hidden */\nexport type HiddenCompositeAggregate = CompositeAggregate;\n\nexport interface FieldDefBase<F, B extends Bin = Bin> extends BandMixins {\n  /**\n   * __Required.__ A string defining the name of the field from which to pull a data value\n   * or an object defining iterated values from the [`repeat`](https://vega.github.io/vega-lite/docs/repeat.html) operator.\n   *\n   * __See also:__ [`field`](https://vega.github.io/vega-lite/docs/field.html) documentation.\n   *\n   * __Notes:__\n   * 1)  Dots (`.`) and brackets (`[` and `]`) can be used to access nested objects (e.g., `\"field\": \"foo.bar\"` and `\"field\": \"foo['bar']\"`).\n   * If field names contain dots or brackets but are not nested, you can use `\\\\` to escape dots and brackets (e.g., `\"a\\\\.b\"` and `\"a\\\\[0\\\\]\"`).\n   * See more details about escaping in the [field documentation](https://vega.github.io/vega-lite/docs/field.html).\n   * 2) `field` is not required if `aggregate` is `count`.\n   */\n  field?: F;\n\n  // function\n\n  /**\n   * Time unit (e.g., `year`, `yearmonth`, `month`, `hours`) for a temporal field.\n   * or [a temporal field that gets casted as ordinal](https://vega.github.io/vega-lite/docs/type.html#cast).\n   *\n   * __Default value:__ `undefined` (None)\n   *\n   * __See also:__ [`timeUnit`](https://vega.github.io/vega-lite/docs/timeunit.html) documentation.\n   */\n  timeUnit?: TimeUnit | TimeUnitParams;\n\n  /**\n   * Aggregation function for the field\n   * (e.g., `\"mean\"`, `\"sum\"`, `\"median\"`, `\"min\"`, `\"max\"`, `\"count\"`).\n   *\n   * __Default value:__ `undefined` (None)\n   *\n   * __See also:__ [`aggregate`](https://vega.github.io/vega-lite/docs/aggregate.html) documentation.\n   */\n  aggregate?: Aggregate | HiddenCompositeAggregate;\n\n  /**\n   * A flag for binning a `quantitative` field, [an object defining binning parameters](https://vega.github.io/vega-lite/docs/bin.html#params), or indicating that the data for `x` or `y` channel are binned before they are imported into Vega-Lite (`\"binned\"`).\n   *\n   * - If `true`, default [binning parameters](https://vega.github.io/vega-lite/docs/bin.html) will be applied.\n   *\n   * - If `\"binned\"`, this indicates that the data for the `x` (or `y`) channel are already binned. You can map the bin-start field to `x` (or `y`) and the bin-end field to `x2` (or `y2`). The scale and axis will be formatted similar to binning in Vega-Lite.  To adjust the axis ticks based on the bin step, you can also set the axis's [`tickMinStep`](https://vega.github.io/vega-lite/docs/axis.html#ticks) property.\n   *\n   * __Default value:__ `false`\n   *\n   * __See also:__ [`bin`](https://vega.github.io/vega-lite/docs/bin.html) documentation.\n   */\n  bin?: B;\n}\n\nexport function toFieldDefBase(fieldDef: FieldDef<string>): FieldDefBase<string> {\n  const {field, timeUnit, bin, aggregate} = fieldDef;\n  return {\n    ...(timeUnit ? {timeUnit} : {}),\n    ...(bin ? {bin} : {}),\n    ...(aggregate ? {aggregate} : {}),\n    field\n  };\n}\n\nexport interface TypeMixins<T extends Type> {\n  /**\n   * The type of measurement (`\"quantitative\"`, `\"temporal\"`, `\"ordinal\"`, or `\"nominal\"`) for the encoded field or constant value (`datum`).\n   * It can also be a `\"geojson\"` type for encoding ['geoshape'](https://vega.github.io/vega-lite/docs/geoshape.html).\n   *\n   * Vega-Lite automatically infers data types in many cases as discussed below. However, type is required for a field if:\n   * (1) the field is not nominal and the field encoding has no specified `aggregate` (except `argmin` and `argmax`), `bin`, scale type, custom `sort` order, nor `timeUnit`\n   * or (2) if you wish to use an ordinal scale for a field with `bin` or `timeUnit`.\n   *\n   * __Default value:__\n   *\n   * 1) For a data `field`, `\"nominal\"` is the default data type unless the field encoding has `aggregate`, `channel`, `bin`, scale type, `sort`, or `timeUnit` that satisfies the following criteria:\n   * - `\"quantitative\"` is the default type if (1) the encoded field contains `bin` or `aggregate` except `\"argmin\"` and `\"argmax\"`, (2) the encoding channel is `latitude` or `longitude` channel or (3) if the specified scale type is [a quantitative scale](https://vega.github.io/vega-lite/docs/scale.html#type).\n   * - `\"temporal\"` is the default type if (1) the encoded field contains `timeUnit` or (2) the specified scale type is a time or utc scale\n   * - `ordinal\"\"` is the default type if (1) the encoded field contains a [custom `sort` order](https://vega.github.io/vega-lite/docs/sort.html#specifying-custom-sort-order), (2) the specified scale type is an ordinal/point/band scale, or (3) the encoding channel is `order`.\n   *\n   * 2) For a constant value in data domain (`datum`):\n   * - `\"quantitative\"` if the datum is a number\n   * - `\"nominal\"` if the datum is a string\n   * - `\"temporal\"` if the datum is [a date time object](https://vega.github.io/vega-lite/docs/datetime.html)\n   *\n   * __Note:__\n   * - Data `type` describes the semantics of the data rather than the primitive data types (number, string, etc.). The same primitive data type can have different types of measurement. For example, numeric data can represent quantitative, ordinal, or nominal data.\n   * - Data values for a temporal field can be either a date-time string (e.g., `\"2015-03-07 12:32:17\"`, `\"17:01\"`, `\"2015-03-16\"`. `\"2015\"`) or a timestamp number (e.g., `1552199579097`).\n   * - When using with [`bin`](https://vega.github.io/vega-lite/docs/bin.html), the `type` property can be either `\"quantitative\"` (for using a linear bin scale) or [`\"ordinal\"` (for using an ordinal bin scale)](https://vega.github.io/vega-lite/docs/type.html#cast-bin).\n   * - When using with [`timeUnit`](https://vega.github.io/vega-lite/docs/timeunit.html), the `type` property can be either `\"temporal\"` (default, for using a temporal scale) or [`\"ordinal\"` (for using an ordinal scale)](https://vega.github.io/vega-lite/docs/type.html#cast-bin).\n   * - When using with [`aggregate`](https://vega.github.io/vega-lite/docs/aggregate.html), the `type` property refers to the post-aggregation data type. For example, we can calculate count `distinct` of a categorical field `\"cat\"` using `{\"aggregate\": \"distinct\", \"field\": \"cat\"}`. The `\"type\"` of the aggregate output is `\"quantitative\"`.\n   * - Secondary channels (e.g., `x2`, `y2`, `xError`, `yError`) do not have `type` as they must have exactly the same type as their primary channels (e.g., `x`, `y`).\n   *\n   * __See also:__ [`type`](https://vega.github.io/vega-lite/docs/type.html) documentation.\n   */\n  type?: T;\n}\n\n/**\n *  Definition object for a data field, its type and transformation of an encoding channel.\n */\nexport type TypedFieldDef<\n  F extends Field,\n  T extends Type = any,\n  B extends Bin = boolean | BinParams | 'binned' | null // This is equivalent to Bin but we use the full form so the docs has detailed types\n> = FieldDefBase<F, B> & TitleMixins & TypeMixins<T>;\n\nexport interface SortableFieldDef<\n  F extends Field,\n  T extends Type = StandardType,\n  B extends Bin = boolean | BinParams | null\n> extends TypedFieldDef<F, T, B> {\n  /**\n   * Sort order for the encoded field.\n   *\n   * For continuous fields (quantitative or temporal), `sort` can be either `\"ascending\"` or `\"descending\"`.\n   *\n   * For discrete fields, `sort` can be one of the following:\n   * - `\"ascending\"` or `\"descending\"` -- for sorting by the values' natural order in JavaScript.\n   * - [A string indicating an encoding channel name to sort by](https://vega.github.io/vega-lite/docs/sort.html#sort-by-encoding) (e.g., `\"x\"` or `\"y\"`) with an optional minus prefix for descending sort (e.g., `\"-x\"` to sort by x-field, descending). This channel string is short-form of [a sort-by-encoding definition](https://vega.github.io/vega-lite/docs/sort.html#sort-by-encoding). For example, `\"sort\": \"-x\"` is equivalent to `\"sort\": {\"encoding\": \"x\", \"order\": \"descending\"}`.\n   * - [A sort field definition](https://vega.github.io/vega-lite/docs/sort.html#sort-field) for sorting by another field.\n   * - [An array specifying the field values in preferred order](https://vega.github.io/vega-lite/docs/sort.html#sort-array). In this case, the sort order will obey the values in the array, followed by any unspecified values in their original order. For discrete time field, values in the sort array can be [date-time definition objects](types#datetime). In addition, for time units `\"month\"` and `\"day\"`, the values can be the month or day names (case insensitive) or their 3-letter initials (e.g., `\"Mon\"`, `\"Tue\"`).\n   * - `null` indicating no sort.\n   *\n   * __Default value:__ `\"ascending\"`\n   *\n   * __Note:__ `null` and sorting by another channel is not supported for `row` and `column`.\n   *\n   * __See also:__ [`sort`](https://vega.github.io/vega-lite/docs/sort.html) documentation.\n   */\n  sort?: Sort<F>;\n}\n\nexport function isSortableFieldDef<F extends Field>(fieldDef: FieldDef<F>): fieldDef is SortableFieldDef<F> {\n  return 'sort' in fieldDef;\n}\n\nexport type ScaleFieldDef<\n  F extends Field,\n  T extends Type = StandardType,\n  B extends Bin = boolean | BinParams | null\n> = SortableFieldDef<F, T, B> & ScaleMixins;\n\nexport interface ScaleMixins {\n  /**\n   * An object defining properties of the channel's scale, which is the function that transforms values in the data domain (numbers, dates, strings, etc) to visual values (pixels, colors, sizes) of the encoding channels.\n   *\n   * If `null`, the scale will be [disabled and the data value will be directly encoded](https://vega.github.io/vega-lite/docs/scale.html#disable).\n   *\n   * __Default value:__ If undefined, default [scale properties](https://vega.github.io/vega-lite/docs/scale.html) are applied.\n   *\n   * __See also:__ [`scale`](https://vega.github.io/vega-lite/docs/scale.html) documentation.\n   */\n  scale?: Scale | null;\n}\n\nexport interface DatumDef<\n  F extends Field = string,\n  V extends PrimitiveValue | DateTime | ExprRef | SignalRef = PrimitiveValue | DateTime | ExprRef | SignalRef\n> extends Partial<TypeMixins<Type>>,\n    BandMixins {\n  /**\n   * A constant value in data domain.\n   */\n  datum?: F extends RepeatRef ? V | RepeatRef : V;\n  // only apply Repeatref if field (F) can be RepeatRef\n  // FIXME(https://github.com/microsoft/TypeScript/issues/37586):\n  // `F extends RepeatRef` probably should be `RepeatRef extends F` but there is likely a bug in TS.\n}\n\nexport type StringDatumDef<F extends Field = string> = DatumDef<F> & FormatMixins;\n\nexport type ScaleDatumDef<F extends Field = string> = ScaleMixins & DatumDef<F>;\n\n/**\n * A field definition of a secondary channel that shares a scale with another primary channel. For example, `x2`, `xError` and `xError2` share the same scale with `x`.\n */\nexport type SecondaryFieldDef<F extends Field> = FieldDefBase<F, null> & TitleMixins; // x2/y2 shouldn't have bin, but we keep bin property for simplicity of the codebase.\n\nexport type Position2Def<F extends Field> = SecondaryFieldDef<F> | DatumDef<F> | PositionValueDef;\n\nexport type SecondaryChannelDef<F extends Field> = Encoding<F>['x2' | 'y2'];\n\n/**\n * Field Def without scale (and without bin: \"binned\" support).\n */\nexport type FieldDefWithoutScale<F extends Field, T extends Type = StandardType> = TypedFieldDef<F, T>;\n\nexport type LatLongFieldDef<F extends Field> = FieldDefBase<F, null> &\n  TitleMixins &\n  Partial<TypeMixins<'quantitative'>>; // Lat long shouldn't have bin, but we keep bin property for simplicity of the codebase.\n\nexport type LatLongDef<F extends Field> = LatLongFieldDef<F> | DatumDef<F> | NumericValueDef;\n\nexport type PositionFieldDefBase<F extends Field> = ScaleFieldDef<\n  F,\n  StandardType,\n  boolean | BinParams | 'binned' | null // This is equivalent to Bin but we use the full form so the docs has detailed types\n> &\n  PositionBaseMixins;\n\nexport type PositionDatumDefBase<F extends Field> = ScaleDatumDef<F> & PositionBaseMixins;\n\nexport interface PositionBaseMixins {\n  /**\n   * Type of stacking offset if the field should be stacked.\n   * `stack` is only applicable for `x`, `y`, `theta`, and `radius` channels with continuous domains.\n   * For example, `stack` of `y` can be used to customize stacking for a vertical bar chart.\n   *\n   * `stack` can be one of the following values:\n   * - `\"zero\"` or `true`: stacking with baseline offset at zero value of the scale (for creating typical stacked [bar](https://vega.github.io/vega-lite/docs/stack.html#bar) and [area](https://vega.github.io/vega-lite/docs/stack.html#area) chart).\n   * - `\"normalize\"` - stacking with normalized domain (for creating [normalized stacked bar and area charts](https://vega.github.io/vega-lite/docs/stack.html#normalized). <br/>\n   * -`\"center\"` - stacking with center baseline (for [streamgraph](https://vega.github.io/vega-lite/docs/stack.html#streamgraph)).\n   * - `null` or `false` - No-stacking. This will produce layered [bar](https://vega.github.io/vega-lite/docs/stack.html#layered-bar-chart) and area chart.\n   *\n   * __Default value:__ `zero` for plots with all of the following conditions are true:\n   * (1) the mark is `bar`, `area`, or `arc`;\n   * (2) the stacked measure channel (x or y) has a linear scale;\n   * (3) At least one of non-position channels mapped to an unaggregated field that is different from x and y. Otherwise, `null` by default.\n   *\n   * __See also:__ [`stack`](https://vega.github.io/vega-lite/docs/stack.html) documentation.\n   */\n  stack?: StackOffset | null | boolean;\n}\n\nexport interface BandMixins {\n  /**\n   * For rect-based marks (`rect`, `bar`, and `image`), mark size relative to bandwidth of [band scales](https://vega.github.io/vega-lite/docs/scale.html#band), bins or time units. If set to `1`, the mark size is set to the bandwidth, the bin interval, or the time unit interval. If set to `0.5`, the mark size is half of the bandwidth or the time unit interval.\n   *\n   * For other marks, relative position on a band of a stacked, binned, time unit or band scale. If set to `0`, the marks will be positioned at the beginning of the band. If set to `0.5`, the marks will be positioned in the middle of the band.\n   *\n   * @minimum 0\n   * @maximum 1\n   */\n  band?: number;\n}\n\nexport type PositionFieldDef<F extends Field> = PositionFieldDefBase<F> & PositionMixins;\n\nexport type PositionDatumDef<F extends Field> = PositionDatumDefBase<F> & PositionMixins;\n\nexport type PositionDef<F extends Field> = PositionFieldDef<F> | PositionDatumDef<F> | PositionValueDef;\n\nexport interface PositionMixins {\n  /**\n   * An object defining properties of axis's gridlines, ticks and labels.\n   * If `null`, the axis for the encoding channel will be removed.\n   *\n   * __Default value:__ If undefined, default [axis properties](https://vega.github.io/vega-lite/docs/axis.html) are applied.\n   *\n   * __See also:__ [`axis`](https://vega.github.io/vega-lite/docs/axis.html) documentation.\n   */\n  axis?: Axis<ExprRef | SignalRef> | null;\n\n  /**\n   * An object defining the properties of the Impute Operation to be applied.\n   * The field value of the other positional channel is taken as `key` of the `Impute` Operation.\n   * The field of the `color` channel if specified is used as `groupby` of the `Impute` Operation.\n   *\n   * __See also:__ [`impute`](https://vega.github.io/vega-lite/docs/impute.html) documentation.\n   */\n  impute?: ImputeParams | null;\n}\n\nexport type PolarDef<F extends Field> = PositionFieldDefBase<F> | PositionDatumDefBase<F> | PositionValueDef;\n\nexport function getBand({\n  channel,\n  fieldDef,\n  fieldDef2,\n  markDef: mark,\n  stack,\n  config,\n  isMidPoint\n}: {\n  isMidPoint?: boolean;\n  channel: Channel;\n  fieldDef: FieldDef<string> | DatumDef;\n  fieldDef2?: SecondaryChannelDef<string>;\n  stack: StackProperties;\n  markDef: MarkDef<Mark, SignalRef>;\n  config: Config<SignalRef>;\n}): number {\n  if (isFieldOrDatumDef(fieldDef) && fieldDef.band !== undefined) {\n    return fieldDef.band;\n  }\n  if (isFieldDef(fieldDef)) {\n    const {timeUnit, bin} = fieldDef;\n\n    if (timeUnit && !fieldDef2) {\n      if (isMidPoint) {\n        return getMarkConfig('timeUnitBandPosition', mark, config);\n      } else {\n        return isRectBasedMark(mark.type) ? getMarkConfig('timeUnitBand', mark, config) : 0;\n      }\n    } else if (isBinning(bin)) {\n      return isRectBasedMark(mark.type) && !isMidPoint ? 1 : 0.5;\n    }\n  }\n  if (stack?.fieldChannel === channel && isMidPoint) {\n    return 0.5;\n  }\n  return undefined;\n}\n\nexport function hasBand(\n  channel: Channel,\n  fieldDef: FieldDef<string>,\n  fieldDef2: SecondaryChannelDef<string>,\n  stack: StackProperties,\n  markDef: MarkDef<Mark, SignalRef>,\n  config: Config<SignalRef>\n): boolean {\n  if (isBinning(fieldDef.bin) || (fieldDef.timeUnit && isTypedFieldDef(fieldDef) && fieldDef.type === 'temporal')) {\n    return !!getBand({channel, fieldDef, fieldDef2, stack, markDef, config});\n  }\n  return false;\n}\n\n/**\n * Field definition of a mark property, which can contain a legend.\n */\nexport type MarkPropFieldDef<F extends Field, T extends Type = Type> = ScaleFieldDef<F, T, boolean | BinParams | null> &\n  LegendMixins;\n\nexport type MarkPropDatumDef<F extends Field> = LegendMixins & ScaleDatumDef<F>;\n\nexport type MarkPropFieldOrDatumDef<F extends Field, T extends Type = Type> =\n  | MarkPropFieldDef<F, T>\n  | MarkPropDatumDef<F>;\n\nexport interface LegendMixins {\n  /**\n   * An object defining properties of the legend.\n   * If `null`, the legend for the encoding channel will be removed.\n   *\n   * __Default value:__ If undefined, default [legend properties](https://vega.github.io/vega-lite/docs/legend.html) are applied.\n   *\n   * __See also:__ [`legend`](https://vega.github.io/vega-lite/docs/legend.html) documentation.\n   */\n  legend?: Legend<ExprRef | SignalRef> | null;\n}\n\n// Detail\n\n// Order Path have no scale\n\nexport interface OrderFieldDef<F extends Field> extends FieldDefWithoutScale<F> {\n  /**\n   * The sort order. One of `\"ascending\"` (default) or `\"descending\"`.\n   */\n  sort?: SortOrder;\n}\n\nexport type OrderValueDef = ConditionValueDefMixins<number> & NumericValueDef;\n\nexport interface StringFieldDef<F extends Field> extends FieldDefWithoutScale<F, StandardType>, FormatMixins {}\n\nexport type FieldDef<F extends Field, T extends Type = any> = SecondaryFieldDef<F> | TypedFieldDef<F, T>;\nexport type ChannelDef<F extends Field = string> = Encoding<F>[keyof Encoding<F>];\n\nexport function isConditionalDef<CD extends ChannelDef<any> | GuideEncodingConditionalValueDef | ExprRef | SignalRef>(\n  channelDef: CD\n): channelDef is CD & {condition: Conditional<any>} {\n  return !!channelDef && 'condition' in channelDef;\n}\n\n/**\n * Return if a channelDef is a ConditionalValueDef with ConditionFieldDef\n */\nexport function hasConditionalFieldDef<F extends Field>(\n  channelDef: Partial<ChannelDef<F>>\n): channelDef is {condition: Conditional<TypedFieldDef<F>>} {\n  const condition = channelDef && channelDef['condition'];\n  return !!condition && !isArray(condition) && isFieldDef(condition);\n}\n\nexport function hasConditionalFieldOrDatumDef<F extends Field>(\n  channelDef: ChannelDef<F>\n): channelDef is {condition: Conditional<TypedFieldDef<F>>} {\n  const condition = channelDef && channelDef['condition'];\n  return !!condition && !isArray(condition) && isFieldOrDatumDef(condition);\n}\n\nexport function hasConditionalValueDef<F extends Field>(\n  channelDef: ChannelDef<F>\n): channelDef is ValueDef<any> & {condition: Conditional<ValueDef<any>> | Conditional<ValueDef<any>>[]} {\n  const condition = channelDef && channelDef['condition'];\n  return !!condition && (isArray(condition) || isValueDef(condition));\n}\n\nexport function isFieldDef<F extends Field>(\n  channelDef: Partial<ChannelDef<F>> | FieldDefBase<F> | DatumDef<F, any>\n): channelDef is FieldDefBase<F> | TypedFieldDef<F> | SecondaryFieldDef<F> {\n  // TODO: we can't use field in channelDef here as it's somehow failing runtime test\n  return !!channelDef && (!!channelDef['field'] || channelDef['aggregate'] === 'count');\n}\n\nexport function channelDefType<F extends Field>(channelDef: ChannelDef<F>): Type | undefined {\n  return channelDef && channelDef['type'];\n}\n\nexport function isDatumDef<F extends Field>(\n  channelDef: Partial<ChannelDef<F>> | FieldDefBase<F> | DatumDef<F, any>\n): channelDef is DatumDef<F, any> {\n  return !!channelDef && 'datum' in channelDef;\n}\n\nexport function isContinuousFieldOrDatumDef<F extends Field>(\n  cd: ChannelDef<F>\n): cd is TypedFieldDef<F> | DatumDef<F, number> {\n  // TODO: make datum support DateTime object\n  return (isTypedFieldDef(cd) && isContinuous(cd)) || isNumericDataDef(cd);\n}\n\nexport function isQuantitativeFieldOrDatumDef<F extends Field>(cd: ChannelDef<F>) {\n  // TODO: make datum support DateTime object\n  return channelDefType(cd) === 'quantitative' || isNumericDataDef(cd);\n}\n\nexport function isNumericDataDef<F extends Field>(cd: ChannelDef<F>): cd is DatumDef<F, number> {\n  return isDatumDef(cd) && isNumber(cd.datum);\n}\n\nexport function isFieldOrDatumDef<F extends Field>(\n  channelDef: Partial<ChannelDef<F>>\n): channelDef is FieldDef<F, any> | DatumDef<F> {\n  return isFieldDef(channelDef) || isDatumDef(channelDef);\n}\n\nexport function isTypedFieldDef<F extends Field>(channelDef: ChannelDef<F>): channelDef is TypedFieldDef<F> {\n  return !!channelDef && ('field' in channelDef || channelDef['aggregate'] === 'count') && 'type' in channelDef;\n}\n\nexport function isValueDef<F extends Field>(channelDef: Partial<ChannelDef<F>>): channelDef is ValueDef<any> {\n  return channelDef && 'value' in channelDef && 'value' in channelDef;\n}\n\nexport function isScaleFieldDef<F extends Field>(channelDef: ChannelDef<F>): channelDef is ScaleFieldDef<F> {\n  return !!channelDef && ('scale' in channelDef || 'sort' in channelDef);\n}\n\nexport function isPositionFieldOrDatumDef<F extends Field>(\n  channelDef: ChannelDef<F>\n): channelDef is PositionFieldDef<F> | PositionDatumDef<F> {\n  return channelDef && ('axis' in channelDef || 'stack' in channelDef || 'impute' in channelDef);\n}\n\nexport function isMarkPropFieldOrDatumDef<F extends Field>(\n  channelDef: ChannelDef<F>\n): channelDef is MarkPropFieldDef<F, any> | MarkPropDatumDef<F> {\n  return !!channelDef && 'legend' in channelDef;\n}\n\nexport function isStringFieldOrDatumDef<F extends Field>(\n  channelDef: ChannelDef<F>\n): channelDef is StringFieldDef<F> | StringDatumDef<F> {\n  return !!channelDef && ('format' in channelDef || 'formatType' in channelDef);\n}\n\nexport function toStringFieldDef<F extends Field>(fieldDef: FieldDef<F>): StringFieldDef<F> {\n  // omit properties that don't exist in string field defs\n  return omit(fieldDef, ['legend', 'axis', 'header', 'scale'] as any[]);\n}\n\nexport interface FieldRefOption {\n  /** Exclude bin, aggregate, timeUnit */\n  nofn?: boolean;\n  /** Wrap the field with datum, parent, or datum.datum (e.g., datum['...'] for Vega Expression */\n  expr?: 'datum' | 'parent' | 'datum.datum';\n  /** Prepend fn with custom function prefix */\n  prefix?: string;\n  /** Append suffix to the field ref for bin (default='start') */\n  binSuffix?: 'end' | 'range' | 'mid';\n  /** Append suffix to the field ref (general) */\n  suffix?: string;\n  /**\n   * Use the field name for `as` in a transform.\n   * We will not escape nested accesses because Vega transform outputs cannot be nested.\n   */\n  forAs?: boolean;\n}\n\nfunction isOpFieldDef(\n  fieldDef: FieldDefBase<string> | WindowFieldDef | AggregatedFieldDef\n): fieldDef is WindowFieldDef | AggregatedFieldDef {\n  return 'op' in fieldDef;\n}\n\n/**\n * Get a Vega field reference from a Vega-Lite field def.\n */\nexport function vgField(\n  fieldDef: FieldDefBase<string> | WindowFieldDef | AggregatedFieldDef,\n  opt: FieldRefOption = {}\n): string {\n  let field = fieldDef.field;\n  const prefix = opt.prefix;\n  let suffix = opt.suffix;\n\n  let argAccessor = ''; // for accessing argmin/argmax field at the end without getting escaped\n\n  if (isCount(fieldDef)) {\n    field = internalField('count');\n  } else {\n    let fn: string;\n\n    if (!opt.nofn) {\n      if (isOpFieldDef(fieldDef)) {\n        fn = fieldDef.op;\n      } else {\n        const {bin, aggregate, timeUnit} = fieldDef;\n        if (isBinning(bin)) {\n          fn = binToString(bin);\n          suffix = (opt.binSuffix ?? '') + (opt.suffix ?? '');\n        } else if (aggregate) {\n          if (isArgmaxDef(aggregate)) {\n            argAccessor = `[\"${field}\"]`;\n            field = `argmax_${aggregate.argmax}`;\n          } else if (isArgminDef(aggregate)) {\n            argAccessor = `[\"${field}\"]`;\n            field = `argmin_${aggregate.argmin}`;\n          } else {\n            fn = String(aggregate);\n          }\n        } else if (timeUnit) {\n          fn = timeUnitToString(timeUnit);\n          suffix = ((!contains(['range', 'mid'], opt.binSuffix) && opt.binSuffix) || '') + (opt.suffix ?? '');\n        }\n      }\n    }\n\n    if (fn) {\n      field = field ? `${fn}_${field}` : fn;\n    }\n  }\n\n  if (suffix) {\n    field = `${field}_${suffix}`;\n  }\n\n  if (prefix) {\n    field = `${prefix}_${field}`;\n  }\n\n  if (opt.forAs) {\n    return removePathFromField(field);\n  } else if (opt.expr) {\n    // Expression to access flattened field. No need to escape dots.\n    return flatAccessWithDatum(field, opt.expr) + argAccessor;\n  } else {\n    // We flattened all fields so paths should have become dot.\n    return replacePathInField(field) + argAccessor;\n  }\n}\n\nexport function isDiscrete(def: TypedFieldDef<Field> | DatumDef<any, any>) {\n  switch (def.type) {\n    case 'nominal':\n    case 'ordinal':\n    case 'geojson':\n      return true;\n    case 'quantitative':\n      return isFieldDef(def) && !!def.bin;\n    case 'temporal':\n      return false;\n  }\n  throw new Error(log.message.invalidFieldType(def.type));\n}\n\nexport function isContinuous(fieldDef: TypedFieldDef<Field>) {\n  return !isDiscrete(fieldDef);\n}\n\nexport function isCount(fieldDef: FieldDefBase<Field>) {\n  return fieldDef.aggregate === 'count';\n}\n\nexport type FieldTitleFormatter = (fieldDef: FieldDefBase<string>, config: Config) => string;\n\nexport function verbalTitleFormatter(fieldDef: FieldDefBase<string>, config: Config) {\n  const {field, bin, timeUnit, aggregate} = fieldDef;\n  if (aggregate === 'count') {\n    return config.countTitle;\n  } else if (isBinning(bin)) {\n    return `${field} (binned)`;\n  } else if (timeUnit) {\n    const unit = normalizeTimeUnit(timeUnit)?.unit;\n    if (unit) {\n      return `${field} (${getTimeUnitParts(unit).join('-')})`;\n    }\n  } else if (aggregate) {\n    if (isArgmaxDef(aggregate)) {\n      return `${field} for max ${aggregate.argmax}`;\n    } else if (isArgminDef(aggregate)) {\n      return `${field} for min ${aggregate.argmin}`;\n    } else {\n      return `${titleCase(aggregate)} of ${field}`;\n    }\n  }\n  return field;\n}\n\nexport function functionalTitleFormatter(fieldDef: FieldDefBase<string>) {\n  const {aggregate, bin, timeUnit, field} = fieldDef;\n  if (isArgmaxDef(aggregate)) {\n    return `${field} for argmax(${aggregate.argmax})`;\n  } else if (isArgminDef(aggregate)) {\n    return `${field} for argmin(${aggregate.argmin})`;\n  }\n\n  const timeUnitParams = normalizeTimeUnit(timeUnit);\n\n  const fn = aggregate || timeUnitParams?.unit || (timeUnitParams?.maxbins && 'timeunit') || (isBinning(bin) && 'bin');\n  if (fn) {\n    return fn.toUpperCase() + '(' + field + ')';\n  } else {\n    return field;\n  }\n}\n\nexport const defaultTitleFormatter: FieldTitleFormatter = (fieldDef: FieldDefBase<string>, config: Config) => {\n  switch (config.fieldTitle) {\n    case 'plain':\n      return fieldDef.field;\n    case 'functional':\n      return functionalTitleFormatter(fieldDef);\n    default:\n      return verbalTitleFormatter(fieldDef, config);\n  }\n};\n\nlet titleFormatter = defaultTitleFormatter;\n\nexport function setTitleFormatter(formatter: FieldTitleFormatter) {\n  titleFormatter = formatter;\n}\n\nexport function resetTitleFormatter() {\n  setTitleFormatter(defaultTitleFormatter);\n}\n\nexport function title(\n  fieldOrDatumDef: TypedFieldDef<string> | SecondaryFieldDef<string> | DatumDef,\n  config: Config,\n  {allowDisabling, includeDefault = true}: {allowDisabling: boolean; includeDefault?: boolean}\n) {\n  const guideTitle = getGuide(fieldOrDatumDef)?.title;\n\n  if (!isFieldDef(fieldOrDatumDef)) {\n    return guideTitle;\n  }\n  const fieldDef = fieldOrDatumDef;\n\n  const def = includeDefault ? defaultTitle(fieldDef, config) : undefined;\n\n  if (allowDisabling) {\n    return getFirstDefined(guideTitle, fieldDef.title, def);\n  } else {\n    return guideTitle ?? fieldDef.title ?? def;\n  }\n}\n\nexport function getGuide(fieldDef: TypedFieldDef<string> | SecondaryFieldDef<string> | DatumDef): Guide {\n  if (isPositionFieldOrDatumDef(fieldDef) && fieldDef.axis) {\n    return fieldDef.axis;\n  } else if (isMarkPropFieldOrDatumDef(fieldDef) && fieldDef.legend) {\n    return fieldDef.legend;\n  } else if (isFacetFieldDef(fieldDef) && fieldDef.header) {\n    return fieldDef.header;\n  }\n  return undefined;\n}\n\nexport function defaultTitle(fieldDef: FieldDefBase<string>, config: Config) {\n  return titleFormatter(fieldDef, config);\n}\n\nexport function getFormatMixins(fieldDef: TypedFieldDef<string> | DatumDef) {\n  if (isStringFieldOrDatumDef(fieldDef)) {\n    const {format, formatType} = fieldDef;\n    return {format, formatType};\n  } else {\n    const guide = getGuide(fieldDef) ?? {};\n    const {format, formatType} = guide;\n    return {format, formatType};\n  }\n}\n\nexport function defaultType<T extends TypedFieldDef<Field>>(fieldDef: T, channel: ExtendedChannel): Type {\n  switch (channel) {\n    case 'latitude':\n    case 'longitude':\n      return 'quantitative';\n\n    case 'row':\n    case 'column':\n    case 'facet':\n    case 'shape':\n    case 'strokeDash':\n      return 'nominal';\n\n    case 'order':\n      return 'ordinal';\n  }\n\n  if (isSortableFieldDef(fieldDef) && isArray(fieldDef.sort)) {\n    return 'ordinal';\n  }\n\n  const {aggregate, bin, timeUnit} = fieldDef;\n  if (timeUnit) {\n    return 'temporal';\n  }\n\n  if (bin || (aggregate && !isArgmaxDef(aggregate) && !isArgminDef(aggregate))) {\n    return 'quantitative';\n  }\n\n  if (isScaleFieldDef(fieldDef) && fieldDef.scale?.type) {\n    switch (SCALE_CATEGORY_INDEX[fieldDef.scale.type]) {\n      case 'numeric':\n      case 'discretizing':\n        return 'quantitative';\n      case 'time':\n        return 'temporal';\n    }\n  }\n\n  return 'nominal';\n}\n\n/**\n * Returns the fieldDef -- either from the outer channelDef or from the condition of channelDef.\n * @param channelDef\n */\n\nexport function getFieldDef<F extends Field>(channelDef: ChannelDef<F>): FieldDef<F> {\n  if (isFieldDef(channelDef)) {\n    return channelDef;\n  } else if (hasConditionalFieldDef(channelDef)) {\n    return channelDef.condition;\n  }\n  return undefined;\n}\n\nexport function getFieldOrDatumDef<F extends Field = string, CD extends ChannelDef<F> = ChannelDef<F>>(\n  channelDef: CD\n): FieldDef<F> | DatumDef<F> {\n  if (isFieldOrDatumDef<F>(channelDef)) {\n    return channelDef;\n  } else if (hasConditionalFieldOrDatumDef(channelDef)) {\n    return channelDef.condition;\n  }\n  return undefined;\n}\n\n/**\n * Convert type to full, lowercase type, or augment the fieldDef with a default type if missing.\n */\nexport function initChannelDef(\n  channelDef: ChannelDef<string>,\n  channel: ExtendedChannel,\n  config: Config,\n  opt: {compositeMark?: boolean} = {}\n): ChannelDef<string> {\n  if (isString(channelDef) || isNumber(channelDef) || isBoolean(channelDef)) {\n    const primitiveType = isString(channelDef) ? 'string' : isNumber(channelDef) ? 'number' : 'boolean';\n    log.warn(log.message.primitiveChannelDef(channel, primitiveType, channelDef));\n    return {value: channelDef} as ValueDef<any>;\n  }\n\n  // If a fieldDef contains a field, we need type.\n  if (isFieldOrDatumDef(channelDef)) {\n    return initFieldOrDatumDef(channelDef, channel, config, opt);\n  } else if (hasConditionalFieldOrDatumDef(channelDef)) {\n    return {\n      ...channelDef,\n      // Need to cast as normalizeFieldDef normally return FieldDef, but here we know that it is definitely Condition<FieldDef>\n      condition: initFieldOrDatumDef(channelDef.condition, channel, config, opt) as Conditional<TypedFieldDef<string>>\n    };\n  }\n  return channelDef;\n}\n\nexport function initFieldOrDatumDef(\n  fd: FieldDef<string, any> | DatumDef,\n  channel: ExtendedChannel,\n  config: Config,\n  opt: {compositeMark?: boolean}\n): FieldDef<string, any> | DatumDef {\n  if (isStringFieldOrDatumDef(fd)) {\n    const {format, formatType, ...rest} = fd;\n    if (isCustomFormatType(formatType) && !config.customFormatTypes) {\n      log.warn(log.message.customFormatTypeNotAllowed(channel));\n      return initFieldOrDatumDef(rest, channel, config, opt);\n    }\n  } else {\n    const guideType = isPositionFieldOrDatumDef(fd)\n      ? 'axis'\n      : isMarkPropFieldOrDatumDef(fd)\n      ? 'legend'\n      : isFacetFieldDef(fd)\n      ? 'header'\n      : null;\n    if (guideType && fd[guideType]) {\n      const {format, formatType, ...newGuide} = fd[guideType];\n      if (isCustomFormatType(formatType) && !config.customFormatTypes) {\n        log.warn(log.message.customFormatTypeNotAllowed(channel));\n        return initFieldOrDatumDef({...fd, [guideType]: newGuide}, channel, config, opt);\n      }\n    }\n  }\n\n  if (isFieldDef(fd)) {\n    return initFieldDef(fd, channel, opt);\n  }\n  return initDatumDef(fd);\n}\n\nfunction initDatumDef(datumDef: DatumDef): DatumDef {\n  let type = datumDef['type'];\n  if (type) {\n    return datumDef;\n  }\n  const {datum} = datumDef;\n  type = isNumber(datum) ? 'quantitative' : isString(datum) ? 'nominal' : isDateTime(datum) ? 'temporal' : undefined;\n\n  return {...datumDef, type};\n}\n\nexport function initFieldDef(\n  fd: FieldDef<string, any>,\n  channel: ExtendedChannel,\n  {compositeMark = false}: {compositeMark?: boolean} = {}\n) {\n  const {aggregate, timeUnit, bin, field} = fd;\n  const fieldDef = {...fd};\n\n  // Drop invalid aggregate\n  if (!compositeMark && aggregate && !isAggregateOp(aggregate) && !isArgmaxDef(aggregate) && !isArgminDef(aggregate)) {\n    log.warn(log.message.invalidAggregate(aggregate));\n    delete fieldDef.aggregate;\n  }\n\n  // Normalize Time Unit\n  if (timeUnit) {\n    fieldDef.timeUnit = normalizeTimeUnit(timeUnit);\n  }\n\n  if (field) {\n    fieldDef.field = `${field}`;\n  }\n\n  // Normalize bin\n  if (isBinning(bin)) {\n    fieldDef.bin = normalizeBin(bin, channel);\n  }\n\n  if (isBinned(bin) && !isXorY(channel)) {\n    log.warn(log.message.channelShouldNotBeUsedForBinned(channel));\n  }\n\n  // Normalize Type\n  if (isTypedFieldDef(fieldDef)) {\n    const {type} = fieldDef;\n    const fullType = getFullName(type);\n    if (type !== fullType) {\n      // convert short type to full type\n      fieldDef.type = fullType;\n    }\n    if (type !== 'quantitative') {\n      if (isCountingAggregateOp(aggregate)) {\n        log.warn(log.message.invalidFieldTypeForCountAggregate(type, aggregate));\n        fieldDef.type = 'quantitative';\n      }\n    }\n  } else if (!isSecondaryRangeChannel(channel)) {\n    // If type is empty / invalid, then augment with default type\n    const newType = defaultType(fieldDef as TypedFieldDef<any>, channel);\n    fieldDef['type'] = newType;\n  }\n\n  if (isTypedFieldDef(fieldDef)) {\n    const {compatible, warning} = channelCompatibility(fieldDef, channel) || {};\n    if (compatible === false) {\n      log.warn(warning);\n    }\n  }\n\n  if (isSortableFieldDef(fieldDef) && isString(fieldDef.sort)) {\n    const {sort} = fieldDef;\n    if (isSortByChannel(sort)) {\n      return {\n        ...fieldDef,\n        sort: {encoding: sort}\n      };\n    }\n    const sub = sort.substr(1);\n    if (sort.charAt(0) === '-' && isSortByChannel(sub)) {\n      return {\n        ...fieldDef,\n        sort: {encoding: sub, order: 'descending'}\n      };\n    }\n  }\n\n  if (isFacetFieldDef(fieldDef)) {\n    const {header} = fieldDef;\n    const {orient, ...rest} = header;\n    if (orient) {\n      return {\n        ...fieldDef,\n        header: {\n          ...rest,\n          labelOrient: header.labelOrient || orient,\n          titleOrient: header.titleOrient || orient\n        }\n      };\n    }\n  }\n\n  return fieldDef;\n}\n\nexport function normalizeBin(bin: BinParams | boolean | 'binned', channel?: ExtendedChannel) {\n  if (isBoolean(bin)) {\n    return {maxbins: autoMaxBins(channel)};\n  } else if (bin === 'binned') {\n    return {\n      binned: true\n    };\n  } else if (!bin.maxbins && !bin.step) {\n    return {...bin, maxbins: autoMaxBins(channel)};\n  } else {\n    return bin;\n  }\n}\n\nconst COMPATIBLE = {compatible: true};\nexport function channelCompatibility(\n  fieldDef: TypedFieldDef<Field>,\n  channel: ExtendedChannel\n): {compatible: boolean; warning?: string} {\n  const type = fieldDef.type;\n\n  if (type === 'geojson' && channel !== 'shape') {\n    return {\n      compatible: false,\n      warning: `Channel ${channel} should not be used with a geojson data.`\n    };\n  }\n\n  switch (channel) {\n    case ROW:\n    case COLUMN:\n    case FACET:\n      if (isContinuous(fieldDef)) {\n        return {\n          compatible: false,\n          warning: log.message.facetChannelShouldBeDiscrete(channel)\n        };\n      }\n      return COMPATIBLE;\n\n    case X:\n    case Y:\n    case COLOR:\n    case FILL:\n    case STROKE:\n    case TEXT:\n    case DETAIL:\n    case KEY:\n    case TOOLTIP:\n    case HREF:\n    case URL:\n    case ANGLE:\n    case THETA:\n    case RADIUS:\n    case DESCRIPTION:\n      return COMPATIBLE;\n\n    case LONGITUDE:\n    case LONGITUDE2:\n    case LATITUDE:\n    case LATITUDE2:\n      if (type !== QUANTITATIVE) {\n        return {\n          compatible: false,\n          warning: `Channel ${channel} should be used with a quantitative field only, not ${fieldDef.type} field.`\n        };\n      }\n      return COMPATIBLE;\n\n    case OPACITY:\n    case FILLOPACITY:\n    case STROKEOPACITY:\n    case STROKEWIDTH:\n    case SIZE:\n    case THETA2:\n    case RADIUS2:\n    case X2:\n    case Y2:\n      if (type === 'nominal' && !fieldDef['sort']) {\n        return {\n          compatible: false,\n          warning: `Channel ${channel} should not be used with an unsorted discrete field.`\n        };\n      }\n      return COMPATIBLE;\n\n    case STROKEDASH:\n      if (!contains(['ordinal', 'nominal'], fieldDef.type)) {\n        return {\n          compatible: false,\n          warning: 'StrokeDash channel should be used with only discrete data.'\n        };\n      }\n      return COMPATIBLE;\n\n    case SHAPE:\n      if (!contains(['ordinal', 'nominal', 'geojson'], fieldDef.type)) {\n        return {\n          compatible: false,\n          warning: 'Shape channel should be used with only either discrete or geojson data.'\n        };\n      }\n      return COMPATIBLE;\n\n    case ORDER:\n      if (fieldDef.type === 'nominal' && !('sort' in fieldDef)) {\n        return {\n          compatible: false,\n          warning: `Channel order is inappropriate for nominal field, which has no inherent order.`\n        };\n      }\n      return COMPATIBLE;\n  }\n}\n\n/**\n * Check if the field def uses a time format or does not use any format but is temporal\n * (this does not cover field defs that are temporal but use a number format).\n */\nexport function isFieldOrDatumDefForTimeFormat(fieldOrDatumDef: FieldDef<string> | DatumDef): boolean {\n  const {formatType} = getFormatMixins(fieldOrDatumDef);\n  return formatType === 'time' || (!formatType && isTimeFieldDef(fieldOrDatumDef));\n}\n\n/**\n * Check if field def has type `temporal`. If you want to also cover field defs that use a time format, use `isTimeFormatFieldDef`.\n */\nexport function isTimeFieldDef(def: FieldDef<any> | DatumDef): boolean {\n  return def && (def['type'] === 'temporal' || (isFieldDef(def) && !!def.timeUnit));\n}\n\n/**\n * Getting a value associated with a fielddef.\n * Convert the value to Vega expression if applicable (for datetime object, or string if the field def is temporal or has timeUnit)\n */\nexport function valueExpr(\n  v: number | string | boolean | DateTime | ExprRef | SignalRef | number[],\n  {\n    timeUnit,\n    type,\n    wrapTime,\n    undefinedIfExprNotRequired\n  }: {\n    timeUnit: TimeUnit | TimeUnitParams;\n    type?: Type;\n    wrapTime?: boolean;\n    undefinedIfExprNotRequired?: boolean;\n  }\n): string {\n  const unit = timeUnit && normalizeTimeUnit(timeUnit)?.unit;\n  let isTime = unit || type === 'temporal';\n\n  let expr;\n  if (isExprRef(v)) {\n    expr = v.expr;\n  } else if (isSignalRef(v)) {\n    expr = v.signal;\n  } else if (isDateTime(v)) {\n    isTime = true;\n    expr = dateTimeToExpr(v);\n  } else if (isString(v) || isNumber(v)) {\n    if (isTime) {\n      expr = `datetime(${JSON.stringify(v)})`;\n\n      if (isLocalSingleTimeUnit(unit)) {\n        // for single timeUnit, we will use dateTimeToExpr to convert number/string to match the timeUnit\n        if ((isNumber(v) && v < 10000) || (isString(v) && isNaN(Date.parse(v)))) {\n          expr = dateTimeToExpr({[unit]: v});\n        }\n      }\n    }\n  }\n  if (expr) {\n    return wrapTime && isTime ? `time(${expr})` : expr;\n  }\n  // number or boolean or normal string\n  return undefinedIfExprNotRequired ? undefined : JSON.stringify(v);\n}\n\n/**\n * Standardize value array -- convert each value to Vega expression if applicable\n */\nexport function valueArray(\n  fieldOrDatumDef: TypedFieldDef<string> | DatumDef,\n  values: (number | string | boolean | DateTime)[]\n) {\n  const {type} = fieldOrDatumDef;\n  return values.map(v => {\n    const expr = valueExpr(v, {\n      timeUnit: isFieldDef(fieldOrDatumDef) ? fieldOrDatumDef.timeUnit : undefined,\n      type,\n      undefinedIfExprNotRequired: true\n    });\n    // return signal for the expression if we need an expression\n    if (expr !== undefined) {\n      return {signal: expr};\n    }\n    // otherwise just return the original value\n    return v;\n  });\n}\n\n/**\n * Checks whether a fieldDef for a particular channel requires a computed bin range.\n */\nexport function binRequiresRange(fieldDef: FieldDef<string>, channel: Channel): boolean {\n  if (!isBinning(fieldDef.bin)) {\n    console.warn('Only call this method for binned field defs.');\n    return false;\n  }\n\n  // We need the range only when the user explicitly forces a binned field to be use discrete scale. In this case, bin range is used in axis and legend labels.\n  // We could check whether the axis or legend exists (not disabled) but that seems overkill.\n  return isScaleChannel(channel) && contains(['ordinal', 'nominal'], (fieldDef as ScaleFieldDef<string>).type);\n}\n","// DateTime definition object\n\nimport {isNumber, isObject} from 'vega-util';\nimport * as log from './log';\nimport {TIMEUNIT_PARTS} from './timeunit';\nimport {duplicate, isNumeric, keys} from './util';\n\n/**\n * @minimum 1\n * @maximum 12\n * @TJS-type integer\n */\nexport type Month = number;\n\n/**\n * @minimum 1\n * @maximum 7\n */\nexport type Day = number;\n\n/**\n * Object for defining datetime in Vega-Lite Filter.\n * If both month and quarter are provided, month has higher precedence.\n * `day` cannot be combined with other date.\n * We accept string for month and day names.\n */\nexport interface DateTime {\n  /**\n   * Integer value representing the year.\n   * @TJS-type integer\n   */\n  year?: number;\n\n  /**\n   * Integer value representing the quarter of the year (from 1-4).\n   * @minimum 1\n   * @maximum 4\n   * @TJS-type integer\n   */\n  quarter?: number;\n\n  /**\n   * One of:\n   * (1) integer value representing the month from `1`-`12`. `1` represents January;\n   * (2) case-insensitive month name (e.g., `\"January\"`);\n   * (3) case-insensitive, 3-character short month name (e.g., `\"Jan\"`).\n   */\n  month?: Month | string;\n\n  /**\n   * Integer value representing the date (day of the month) from 1-31.\n   * @minimum 1\n   * @maximum 31\n   * @TJS-type integer\n   */\n  date?: number;\n\n  /**\n   * Value representing the day of a week. This can be one of:\n   * (1) integer value -- `1` represents Monday;\n   * (2) case-insensitive day name (e.g., `\"Monday\"`);\n   * (3) case-insensitive, 3-character short day name (e.g., `\"Mon\"`).\n   *\n   * **Warning:** A DateTime definition object with `day`** should not be combined with `year`, `quarter`, `month`, or `date`.\n   */\n  day?: Day | string;\n\n  /**\n   * Integer value representing the hour of a day from 0-23.\n   * @minimum 0\n   * @maximum 24\n   * @TJS-type integer\n   */\n  hours?: number;\n\n  /**\n   * Integer value representing the minute segment of time from 0-59.\n   * @minimum 0\n   * @maximum 60\n   * @TJS-type integer\n   */\n  minutes?: number;\n\n  /**\n   * Integer value representing the second segment (0-59) of a time value\n   * @minimum 0\n   * @maximum 60\n   * @TJS-type integer\n   */\n  seconds?: number;\n\n  /**\n   * Integer value representing the millisecond segment of time.\n   * @minimum 0\n   * @maximum 1000\n   * @TJS-type integer\n   */\n  milliseconds?: number;\n\n  /**\n   * A boolean flag indicating if date time is in utc time. If false, the date time is in local time\n   */\n  utc?: boolean;\n}\n\n/**\n * Internal Object for defining datetime expressions.\n * This is an expression version of DateTime.\n * If both month and quarter are provided, month has higher precedence.\n * `day` cannot be combined with other date.\n */\nexport interface DateTimeExpr {\n  year?: string;\n  quarter?: string;\n  month?: string;\n  date?: string;\n  day?: string;\n  hours?: string;\n  minutes?: string;\n  seconds?: string;\n  milliseconds?: string;\n  utc?: boolean;\n}\n\nexport function isDateTime(o: any): o is DateTime {\n  if (o && isObject(o)) {\n    for (const part of TIMEUNIT_PARTS) {\n      if (part in o) {\n        return true;\n      }\n    }\n  }\n  return false;\n}\n\nexport const MONTHS = [\n  'january',\n  'february',\n  'march',\n  'april',\n  'may',\n  'june',\n  'july',\n  'august',\n  'september',\n  'october',\n  'november',\n  'december'\n];\nexport const SHORT_MONTHS = MONTHS.map(m => m.substr(0, 3));\n\nexport const DAYS = ['sunday', 'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday'];\nexport const SHORT_DAYS = DAYS.map(d => d.substr(0, 3));\n\nfunction normalizeQuarter(q: number | string): number {\n  if (isNumeric(q)) {\n    q = +q;\n  }\n\n  if (isNumber(q)) {\n    if (q > 4) {\n      log.warn(log.message.invalidTimeUnit('quarter', q));\n    }\n    // We accept 1-based quarter, so need to readjust to 0-based quarter\n    return q - 1;\n  } else {\n    // Invalid quarter\n    throw new Error(log.message.invalidTimeUnit('quarter', q));\n  }\n}\n\nfunction normalizeMonth(m: string | number): number {\n  if (isNumeric(m)) {\n    m = +m;\n  }\n\n  if (isNumber(m)) {\n    // We accept 1-based month, so need to readjust to 0-based month\n    return m - 1;\n  } else {\n    const lowerM = m.toLowerCase();\n    const monthIndex = MONTHS.indexOf(lowerM);\n    if (monthIndex !== -1) {\n      return monthIndex; // 0 for january, ...\n    }\n    const shortM = lowerM.substr(0, 3);\n    const shortMonthIndex = SHORT_MONTHS.indexOf(shortM);\n    if (shortMonthIndex !== -1) {\n      return shortMonthIndex;\n    }\n\n    // Invalid month\n    throw new Error(log.message.invalidTimeUnit('month', m));\n  }\n}\n\nfunction normalizeDay(d: string | number): number {\n  if (isNumeric(d)) {\n    d = +d;\n  }\n\n  if (isNumber(d)) {\n    // mod so that this can be both 0-based where 0 = sunday\n    // and 1-based where 7=sunday\n    return d % 7;\n  } else {\n    const lowerD = d.toLowerCase();\n    const dayIndex = DAYS.indexOf(lowerD);\n    if (dayIndex !== -1) {\n      return dayIndex; // 0 for january, ...\n    }\n    const shortD = lowerD.substr(0, 3);\n    const shortDayIndex = SHORT_DAYS.indexOf(shortD);\n    if (shortDayIndex !== -1) {\n      return shortDayIndex;\n    }\n    // Invalid day\n    throw new Error(log.message.invalidTimeUnit('day', d));\n  }\n}\n\n/**\n * @param d the date.\n * @param normalize whether to normalize quarter, month, day. This should probably be true if d is a DateTime.\n * @returns array of date time parts [year, month, day, hours, minutes, seconds, milliseconds]\n */\nfunction dateTimeParts(d: DateTime | DateTimeExpr, normalize: boolean) {\n  const parts: (string | number)[] = [];\n\n  if (normalize && d.day !== undefined) {\n    if (keys(d).length > 1) {\n      log.warn(log.message.droppedDay(d));\n      d = duplicate(d);\n      delete d.day;\n    }\n  }\n\n  if (d.year !== undefined) {\n    parts.push(d.year);\n  } else {\n    // Just like Vega's timeunit transform, set default year to 2012, so domain conversion will be compatible with Vega\n    // Note: 2012 is a leap year (and so the date February 29 is respected) that begins on a Sunday (and so days of the week will order properly at the beginning of the year).\n    parts.push(2012);\n  }\n\n  if (d.month !== undefined) {\n    const month = normalize ? normalizeMonth(d.month) : d.month;\n    parts.push(month);\n  } else if (d.quarter !== undefined) {\n    const quarter = normalize ? normalizeQuarter(d.quarter) : d.quarter;\n    parts.push(isNumber(quarter) ? quarter * 3 : quarter + '*3');\n  } else {\n    parts.push(0); // months start at zero in JS\n  }\n\n  if (d.date !== undefined) {\n    parts.push(d.date);\n  } else if (d.day !== undefined) {\n    // HACK: Day only works as a standalone unit\n    // This is only correct because we always set year to 2006 for day\n    const day = normalize ? normalizeDay(d.day) : d.day;\n    parts.push(isNumber(day) ? day + 1 : day + '+1');\n  } else {\n    parts.push(1); // Date starts at 1 in JS\n  }\n\n  // Note: can't use TimeUnit enum here as importing it will create\n  // circular dependency problem!\n  for (const timeUnit of ['hours', 'minutes', 'seconds', 'milliseconds'] as const) {\n    const unit = d[timeUnit];\n    parts.push(typeof unit === 'undefined' ? 0 : unit);\n  }\n\n  return parts;\n}\n\n/**\n * Return Vega expression for a date time.\n *\n * @param d the date time.\n * @returns the Vega expression.\n */\nexport function dateTimeToExpr(d: DateTime) {\n  const parts: (string | number)[] = dateTimeParts(d, true);\n\n  const string = parts.join(', ');\n\n  if (d.utc) {\n    return `utc(${string})`;\n  } else {\n    return `datetime(${string})`;\n  }\n}\n\n/**\n * Return Vega expression for a date time expression.\n *\n * @param d the internal date time object with expression.\n * @returns the Vega expression.\n */\nexport function dateTimeExprToExpr(d: DateTimeExpr) {\n  const parts: (string | number)[] = dateTimeParts(d, false);\n\n  const string = parts.join(', ');\n\n  if (d.utc) {\n    return `utc(${string})`;\n  } else {\n    return `datetime(${string})`;\n  }\n}\n\n/**\n * @param d the date time.\n * @returns the timestamp.\n */\nexport function dateTimeToTimestamp(d: DateTime) {\n  const parts: (string | number)[] = dateTimeParts(d, true);\n\n  if (d.utc) {\n    return +new Date(Date.UTC(...(parts as [any, any])));\n  } else {\n    return +new Date(...(parts as [any]));\n  }\n}\n","import stringify from 'fast-json-stable-stringify';\nimport {isObject, isString} from 'vega-util';\nimport {DateTimeExpr, dateTimeExprToExpr} from './datetime';\nimport {accessPathWithDatum, keys, varName} from './util';\n\n/** Time Unit that only corresponds to only one part of Date objects. */\nexport const LOCAL_SINGLE_TIMEUNIT_INDEX = {\n  year: 1,\n  quarter: 1,\n  month: 1,\n  week: 1,\n  day: 1,\n  dayofyear: 1,\n  date: 1,\n  hours: 1,\n  minutes: 1,\n  seconds: 1,\n  milliseconds: 1\n} as const;\n\nexport type LocalSingleTimeUnit = keyof typeof LOCAL_SINGLE_TIMEUNIT_INDEX;\n\nexport const TIMEUNIT_PARTS = keys(LOCAL_SINGLE_TIMEUNIT_INDEX);\n\nexport function isLocalSingleTimeUnit(timeUnit: string): timeUnit is LocalSingleTimeUnit {\n  return !!LOCAL_SINGLE_TIMEUNIT_INDEX[timeUnit];\n}\n\nexport const UTC_SINGLE_TIMEUNIT_INDEX = {\n  utcyear: 1,\n  utcquarter: 1,\n  utcmonth: 1,\n  utcweek: 1,\n  utcday: 1,\n  utcdayofyear: 1,\n  utcdate: 1,\n  utchours: 1,\n  utcminutes: 1,\n  utcseconds: 1,\n  utcmilliseconds: 1\n} as const;\n\nexport type UtcSingleTimeUnit = keyof typeof UTC_SINGLE_TIMEUNIT_INDEX;\n\nexport type SingleTimeUnit = LocalSingleTimeUnit | UtcSingleTimeUnit;\n\nexport const LOCAL_MULTI_TIMEUNIT_INDEX = {\n  yearquarter: 1,\n  yearquartermonth: 1,\n\n  yearmonth: 1,\n  yearmonthdate: 1,\n  yearmonthdatehours: 1,\n  yearmonthdatehoursminutes: 1,\n  yearmonthdatehoursminutesseconds: 1,\n\n  yearweek: 1,\n  yearweekday: 1,\n  yearweekdayhours: 1,\n  yearweekdayhoursminutes: 1,\n  yearweekdayhoursminutesseconds: 1,\n\n  yeardayofyear: 1,\n\n  quartermonth: 1,\n\n  monthdate: 1,\n  monthdatehours: 1,\n  monthdatehoursminutes: 1,\n  monthdatehoursminutesseconds: 1,\n\n  weekday: 1,\n  weeksdayhours: 1,\n  weekdayhoursminutes: 1,\n  weekdayhoursminutesseconds: 1,\n\n  dayhours: 1,\n  dayhoursminutes: 1,\n  dayhoursminutesseconds: 1,\n\n  hoursminutes: 1,\n  hoursminutesseconds: 1,\n\n  minutesseconds: 1,\n\n  secondsmilliseconds: 1\n} as const;\n\nexport type LocalMultiTimeUnit = keyof typeof LOCAL_MULTI_TIMEUNIT_INDEX;\n\nexport const UTC_MULTI_TIMEUNIT_INDEX = {\n  utcyearquarter: 1,\n  utcyearquartermonth: 1,\n\n  utcyearmonth: 1,\n  utcyearmonthdate: 1,\n  utcyearmonthdatehours: 1,\n  utcyearmonthdatehoursminutes: 1,\n  utcyearmonthdatehoursminutesseconds: 1,\n\n  utcyearweek: 1,\n  utcyearweekday: 1,\n  utcyearweekdayhours: 1,\n  utcyearweekdayhoursminutes: 1,\n  utcyearweekdayhoursminutesseconds: 1,\n\n  utcyeardayofyear: 1,\n\n  utcquartermonth: 1,\n\n  utcmonthdate: 1,\n  utcmonthdatehours: 1,\n  utcmonthdatehoursminutes: 1,\n  utcmonthdatehoursminutesseconds: 1,\n\n  utcweekday: 1,\n  utcweeksdayhours: 1,\n  utcweekdayhoursminutes: 1,\n  utcweekdayhoursminutesseconds: 1,\n\n  utcdayhours: 1,\n  utcdayhoursminutes: 1,\n  utcdayhoursminutesseconds: 1,\n\n  utchoursminutes: 1,\n  utchoursminutesseconds: 1,\n\n  utcminutesseconds: 1,\n\n  utcsecondsmilliseconds: 1\n} as const;\n\nexport type UtcMultiTimeUnit = keyof typeof UTC_MULTI_TIMEUNIT_INDEX;\n\nexport type MultiTimeUnit = LocalMultiTimeUnit | UtcMultiTimeUnit;\n\nexport type LocalTimeUnit = LocalSingleTimeUnit | LocalMultiTimeUnit;\nexport type UtcTimeUnit = UtcSingleTimeUnit | UtcMultiTimeUnit;\n\nexport function isUTCTimeUnit(t: string): t is UtcTimeUnit {\n  return t.startsWith('utc');\n}\n\nexport function getLocalTimeUnit(t: UtcTimeUnit): LocalTimeUnit {\n  return t.substr(3) as LocalTimeUnit;\n}\n\nexport type TimeUnit = SingleTimeUnit | MultiTimeUnit;\n\nexport type TimeUnitFormat =\n  | 'year'\n  | 'year-month'\n  | 'year-month-date'\n  | 'quarter'\n  | 'month'\n  | 'date'\n  | 'week'\n  | 'day'\n  | 'hours'\n  | 'hours-minutes'\n  | 'minutes'\n  | 'seconds'\n  | 'milliseconds';\n\nexport interface TimeUnitParams {\n  /**\n   * Defines how date-time values should be binned.\n   */\n  unit?: TimeUnit;\n\n  /**\n   * If no `unit` is specified, maxbins is used to infer time units.\n   */\n  maxbins?: number;\n\n  /**\n   * The number of steps between bins, in terms of the least\n   * significant unit provided.\n   */\n  step?: number;\n\n  /**\n   * True to use UTC timezone. Equivalent to using a `utc` prefixed `TimeUnit`.\n   */\n  utc?: boolean;\n}\n\n// matches vega time unit format specifier\nexport type TimeFormatConfig = Partial<Record<TimeUnitFormat, string>>;\n\n// In order of increasing specificity\nexport const VEGALITE_TIMEFORMAT: TimeFormatConfig = {\n  'year-month': '%b %Y ',\n  'year-month-date': '%b %d, %Y '\n};\n\nexport function getTimeUnitParts(timeUnit: TimeUnit) {\n  const parts: LocalSingleTimeUnit[] = [];\n\n  for (const part of TIMEUNIT_PARTS) {\n    if (containsTimeUnit(timeUnit, part)) {\n      parts.push(part);\n    }\n  }\n\n  return parts;\n}\n\n/** Returns true if fullTimeUnit contains the timeUnit, false otherwise. */\nexport function containsTimeUnit(fullTimeUnit: TimeUnit, timeUnit: TimeUnit) {\n  const index = fullTimeUnit.indexOf(timeUnit);\n\n  if (index < 0) {\n    return false;\n  }\n\n  // exclude milliseconds\n  if (index > 0 && timeUnit === 'seconds' && fullTimeUnit.charAt(index - 1) === 'i') {\n    return false;\n  }\n\n  // exclude dayofyear\n  if (fullTimeUnit.length > index + 3 && timeUnit === 'day' && fullTimeUnit.charAt(index + 3) === 'o') {\n    return false;\n  }\n  if (index > 0 && timeUnit === 'year' && fullTimeUnit.charAt(index - 1) === 'f') {\n    return false;\n  }\n\n  return true;\n}\n\n/**\n * Returns Vega expression for a given timeUnit and fieldRef\n */\nexport function fieldExpr(fullTimeUnit: TimeUnit, field: string, {end}: {end: boolean} = {end: false}): string {\n  const fieldRef = accessPathWithDatum(field);\n\n  const utc = isUTCTimeUnit(fullTimeUnit) ? 'utc' : '';\n\n  function func(timeUnit: TimeUnit) {\n    if (timeUnit === 'quarter') {\n      // quarter starting at 0 (0,3,6,9).\n      return `(${utc}quarter(${fieldRef})-1)`;\n    } else {\n      return `${utc}${timeUnit}(${fieldRef})`;\n    }\n  }\n\n  let lastTimeUnit: TimeUnit;\n\n  const dateExpr: DateTimeExpr = {};\n\n  for (const part of TIMEUNIT_PARTS) {\n    if (containsTimeUnit(fullTimeUnit, part)) {\n      dateExpr[part] = func(part);\n      lastTimeUnit = part;\n    }\n  }\n\n  if (end) {\n    dateExpr[lastTimeUnit] += '+1';\n  }\n\n  return dateTimeExprToExpr(dateExpr);\n}\n\nexport function timeUnitSpecifierExpression(timeUnit: TimeUnit) {\n  if (!timeUnit) {\n    return undefined;\n  }\n\n  const timeUnitParts = getTimeUnitParts(timeUnit);\n  return `timeUnitSpecifier(${stringify(timeUnitParts)}, ${stringify(VEGALITE_TIMEFORMAT)})`;\n}\n\n/**\n * Returns the signal expression used for axis labels for a time unit.\n */\nexport function formatExpression(timeUnit: TimeUnit, field: string, isUTCScale: boolean): string {\n  if (!timeUnit) {\n    return undefined;\n  }\n\n  const expr = timeUnitSpecifierExpression(timeUnit);\n\n  // We only use utcFormat for utc scale\n  // For utc time units, the data is already converted as a part of timeUnit transform.\n  // Thus, utc time units should use timeFormat to avoid shifting the time twice.\n  const utc = isUTCScale || isUTCTimeUnit(timeUnit);\n\n  return `${utc ? 'utc' : 'time'}Format(${field}, ${expr})`;\n}\n\nexport function normalizeTimeUnit(timeUnit: TimeUnit | TimeUnitParams): TimeUnitParams {\n  if (!timeUnit) {\n    return undefined;\n  }\n\n  let params: TimeUnitParams;\n  if (isString(timeUnit)) {\n    params = {\n      unit: timeUnit\n    };\n  } else if (isObject(timeUnit)) {\n    params = {\n      ...timeUnit,\n      ...(timeUnit.unit ? {unit: timeUnit.unit} : {})\n    };\n  }\n\n  if (isUTCTimeUnit(params.unit)) {\n    params.utc = true;\n    params.unit = getLocalTimeUnit(params.unit);\n  }\n\n  return params;\n}\n\nexport function timeUnitToString(tu: TimeUnit | TimeUnitParams) {\n  const {utc, ...rest} = normalizeTimeUnit(tu);\n\n  if (rest.unit) {\n    return (\n      (utc ? 'utc' : '') +\n      keys(rest)\n        .map(p => varName(`${p === 'unit' ? '' : `_${p}_`}${rest[p]}`))\n        .join('')\n    );\n  } else {\n    // when maxbins is specified instead of units\n    return (\n      (utc ? 'utc' : '') +\n      'timeunit' +\n      keys(rest)\n        .map(p => varName(`_${p}_${rest[p]}`))\n        .join('')\n    );\n  }\n}\n","import {isBinning} from '../../bin';\nimport {Channel, isColorChannel, isScaleChannel, rangeType} from '../../channel';\nimport {DatumDef, isFieldDef, isPositionFieldOrDatumDef, ScaleDatumDef, TypedFieldDef} from '../../channeldef';\nimport * as log from '../../log';\nimport {Mark} from '../../mark';\nimport {channelSupportScaleType, Scale, ScaleType, scaleTypeSupportDataType} from '../../scale';\nimport {normalizeTimeUnit} from '../../timeunit';\nimport * as util from '../../util';\nimport {POLAR_POSITION_SCALE_CHANNEL_INDEX, POSITION_SCALE_CHANNEL_INDEX} from './../../channel';\n\nexport type RangeType = 'continuous' | 'discrete' | 'flexible' | undefined;\n\n/**\n * Determine if there is a specified scale type and if it is appropriate,\n * or determine default type if type is unspecified or inappropriate.\n */\n// NOTE: CompassQL uses this method.\nexport function scaleType(\n  specifiedScale: Scale,\n  channel: Channel,\n  fieldDef: TypedFieldDef<string> | DatumDef,\n  mark: Mark\n): ScaleType {\n  const defaultScaleType = defaultType(channel, fieldDef, mark);\n  const {type} = specifiedScale;\n\n  if (!isScaleChannel(channel)) {\n    // There is no scale for these channels\n    return null;\n  }\n  if (type !== undefined) {\n    // Check if explicitly specified scale type is supported by the channel\n    if (!channelSupportScaleType(channel, type)) {\n      log.warn(log.message.scaleTypeNotWorkWithChannel(channel, type, defaultScaleType));\n      return defaultScaleType;\n    }\n\n    // Check if explicitly specified scale type is supported by the data type\n    if (isFieldDef(fieldDef) && !scaleTypeSupportDataType(type, fieldDef.type)) {\n      log.warn(log.message.scaleTypeNotWorkWithFieldDef(type, defaultScaleType));\n      return defaultScaleType;\n    }\n\n    return type;\n  }\n\n  return defaultScaleType;\n}\n\n/**\n * Determine appropriate default scale type.\n */\n// NOTE: Voyager uses this method.\nfunction defaultType(channel: Channel, fieldDef: TypedFieldDef<string> | ScaleDatumDef, mark: Mark): ScaleType {\n  switch (fieldDef.type) {\n    case 'nominal':\n    case 'ordinal':\n      if (isColorChannel(channel) || rangeType(channel) === 'discrete') {\n        if (channel === 'shape' && fieldDef.type === 'ordinal') {\n          log.warn(log.message.discreteChannelCannotEncode(channel, 'ordinal'));\n        }\n        return 'ordinal';\n      }\n\n      if (channel in POSITION_SCALE_CHANNEL_INDEX) {\n        if (util.contains(['rect', 'bar', 'image', 'rule'], mark)) {\n          // The rect/bar mark should fit into a band.\n          // For rule, using band scale to make rule align with axis ticks better https://github.com/vega/vega-lite/issues/3429\n          return 'band';\n        }\n      } else if (mark === 'arc' && channel in POLAR_POSITION_SCALE_CHANNEL_INDEX) {\n        return 'band';\n      }\n\n      if (fieldDef.band !== undefined || (isPositionFieldOrDatumDef(fieldDef) && fieldDef.axis?.tickBand)) {\n        return 'band';\n      }\n      // Otherwise, use ordinal point scale so we can easily get center positions of the marks.\n      return 'point';\n\n    case 'temporal':\n      if (isColorChannel(channel)) {\n        return 'time';\n      } else if (rangeType(channel) === 'discrete') {\n        log.warn(log.message.discreteChannelCannotEncode(channel, 'temporal'));\n        // TODO: consider using quantize (equivalent to binning) once we have it\n        return 'ordinal';\n      } else if (isFieldDef(fieldDef) && fieldDef.timeUnit && normalizeTimeUnit(fieldDef.timeUnit).utc) {\n        return 'utc';\n      }\n      return 'time';\n\n    case 'quantitative':\n      if (isColorChannel(channel)) {\n        if (isFieldDef(fieldDef) && isBinning(fieldDef.bin)) {\n          return 'bin-ordinal';\n        }\n\n        return 'linear';\n      } else if (rangeType(channel) === 'discrete') {\n        log.warn(log.message.discreteChannelCannotEncode(channel, 'quantitative'));\n        // TODO: consider using quantize (equivalent to binning) once we have it\n        return 'ordinal';\n      }\n\n      return 'linear';\n\n    case 'geojson':\n      return undefined;\n  }\n\n  /* istanbul ignore next: should never reach this */\n  throw new Error(log.message.invalidFieldType(fieldDef.type));\n}\n","import * as TYPE from 'vega-lite/build/src/type';\nimport {Type} from 'vega-lite/build/src/type';\n\nexport namespace ExpandedType {\n  export const QUANTITATIVE = TYPE.QUANTITATIVE;\n  export const ORDINAL = TYPE.ORDINAL;\n  export const TEMPORAL = TYPE.TEMPORAL;\n  export const NOMINAL = TYPE.NOMINAL;\n  export const KEY: 'key' = 'key';\n}\n\nexport type ExpandedType = Type | typeof ExpandedType.KEY;\n\nexport function isDiscrete(fieldType: any) {\n  return fieldType === TYPE.ORDINAL || fieldType === TYPE.NOMINAL || fieldType === ExpandedType.KEY;\n}\n","import {Dict, keys} from './util';\nimport {Property, toKey} from './property';\n\nexport interface PropIndexReader<T> {\n  has(p: Property): boolean;\n  get(p: Property): T;\n}\n\n/**\n * Dictionary that takes property as a key.\n */\nexport class PropIndex<T> implements PropIndexReader<T> {\n  private index: Dict<T>;\n\n  constructor(i: Dict<T> = null) {\n    this.index = i ? {...i} : {};\n  }\n\n  public has(p: Property) {\n    return toKey(p) in this.index;\n  }\n\n  public get(p: Property) {\n    return this.index[toKey(p)];\n  }\n\n  public set(p: Property, value: T) {\n    this.index[toKey(p)] = value;\n    return this;\n  }\n\n  public setByKey(key: string, value: T) {\n    this.index[key] = value;\n  }\n\n  public map<U>(f: (t: T) => U): PropIndex<U> {\n    const i = new PropIndex<U>();\n    for (const k in this.index) {\n      i.index[k] = f(this.index[k]);\n    }\n    return i;\n  }\n\n  public size() {\n    return keys(this.index).length;\n  }\n\n  public duplicate(): PropIndex<T> {\n    return new PropIndex<T>(this.index);\n  }\n}\n","import {AggregateOp} from 'vega';\nimport {array, isArray} from 'vega-util';\nimport {isArgmaxDef, isArgminDef} from './aggregate';\nimport {isBinned, isBinning} from './bin';\nimport {\n  ANGLE,\n  CHANNELS,\n  COLOR,\n  DESCRIPTION,\n  DETAIL,\n  FILL,\n  FILLOPACITY,\n  HREF,\n  isChannel,\n  isNonPositionScaleChannel,\n  isSecondaryRangeChannel,\n  isXorY,\n  KEY,\n  LATITUDE,\n  LATITUDE2,\n  LONGITUDE,\n  LONGITUDE2,\n  OPACITY,\n  ORDER,\n  RADIUS,\n  RADIUS2,\n  SHAPE,\n  SIZE,\n  STROKE,\n  STROKEDASH,\n  STROKEOPACITY,\n  STROKEWIDTH,\n  supportMark,\n  TEXT,\n  THETA,\n  THETA2,\n  TOOLTIP,\n  URL,\n  X,\n  X2,\n  Y,\n  Y2,\n  Channel\n} from './channel';\nimport {\n  binRequiresRange,\n  ChannelDef,\n  ColorDef,\n  Field,\n  FieldDef,\n  FieldDefWithoutScale,\n  getFieldDef,\n  getGuide,\n  hasConditionalFieldDef,\n  initChannelDef,\n  initFieldDef,\n  isConditionalDef,\n  isDatumDef,\n  isFieldDef,\n  isTypedFieldDef,\n  isValueDef,\n  LatLongDef,\n  NumericArrayMarkPropDef,\n  NumericMarkPropDef,\n  OrderFieldDef,\n  OrderValueDef,\n  PolarDef,\n  Position2Def,\n  PositionDef,\n  SecondaryFieldDef,\n  ShapeDef,\n  StringFieldDef,\n  StringFieldDefWithCondition,\n  StringValueDefWithCondition,\n  TextDef,\n  title,\n  TypedFieldDef,\n  vgField\n} from './channeldef';\nimport {Config} from './config';\nimport * as log from './log';\nimport {Mark} from './mark';\nimport {EncodingFacetMapping} from './spec/facet';\nimport {AggregatedFieldDef, BinTransform, TimeUnitTransform} from './transform';\nimport {QUANTITATIVE, TEMPORAL} from './type';\nimport {keys, some} from './util';\nimport {isSignalRef} from './vega.schema';\n\nexport interface Encoding<F extends Field> {\n  /**\n   * X coordinates of the marks, or width of horizontal `\"bar\"` and `\"area\"` without specified `x2` or `width`.\n   *\n   * The `value` of this channel can be a number or a string `\"width\"` for the width of the plot.\n   */\n  x?: PositionDef<F>;\n\n  /**\n   * Y coordinates of the marks, or height of vertical `\"bar\"` and `\"area\"` without specified `y2` or `height`.\n   *\n   * The `value` of this channel can be a number or a string `\"height\"` for the height of the plot.\n   */\n  y?: PositionDef<F>;\n\n  /**\n   * X2 coordinates for ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   *\n   * The `value` of this channel can be a number or a string `\"width\"` for the width of the plot.\n   */\n  // TODO: Ham need to add default behavior\n  // `x2` cannot have type as it should have the same type as `x`\n  x2?: Position2Def<F>;\n\n  /**\n   * Y2 coordinates for ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   *\n   * The `value` of this channel can be a number or a string `\"height\"` for the height of the plot.\n   */\n  // TODO: Ham need to add default behavior\n  // `y2` cannot have type as it should have the same type as `y`\n  y2?: Position2Def<F>;\n\n  /**\n   * Longitude position of geographically projected marks.\n   */\n  longitude?: LatLongDef<F>;\n\n  /**\n   * Latitude position of geographically projected marks.\n   */\n  latitude?: LatLongDef<F>;\n\n  /**\n   * Longitude-2 position for geographically projected ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   */\n  // `longitude2` cannot have type as it should have the same type as `longitude`\n  longitude2?: Position2Def<F>;\n\n  /**\n   * Latitude-2 position for geographically projected ranged `\"area\"`, `\"bar\"`, `\"rect\"`, and  `\"rule\"`.\n   */\n  // `latitude2` cannot have type as it should have the same type as `latitude`\n  latitude2?: Position2Def<F>;\n\n  /**\n   * - For arc marks, the arc length in radians if theta2 is not specified, otherwise the start arc angle. (A value of 0 indicates up or “north”, increasing values proceed clockwise.)\n   *\n   * - For text marks, polar coordinate angle in radians.\n   */\n  theta?: PolarDef<F>;\n\n  /**\n   * The end angle of arc marks in radians. A value of 0 indicates up or “north”, increasing values proceed clockwise.\n   */\n  theta2?: Position2Def<F>;\n\n  /**\n   * The outer radius in pixels of arc marks.\n   */\n\n  radius?: PolarDef<F>;\n\n  /**\n   * The inner radius in pixels of arc marks.\n   */\n  radius2?: Position2Def<F>;\n\n  /**\n   * Color of the marks – either fill or stroke color based on  the `filled` property of mark definition.\n   * By default, `color` represents fill color for `\"area\"`, `\"bar\"`, `\"tick\"`,\n   * `\"text\"`, `\"trail\"`, `\"circle\"`, and `\"square\"` / stroke color for `\"line\"` and `\"point\"`.\n   *\n   * __Default value:__ If undefined, the default color depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `color` property.\n   *\n   * _Note:_\n   * 1) For fine-grained control over both fill and stroke colors of the marks, please use the `fill` and `stroke` channels. The `fill` or `stroke` encodings have higher precedence than `color`, thus may override the `color` encoding if conflicting encodings are specified.\n   * 2) See the scale documentation for more information about customizing [color scheme](https://vega.github.io/vega-lite/docs/scale.html#scheme).\n   */\n  color?: ColorDef<F>;\n\n  /**\n   * Fill color of the marks.\n   * __Default value:__ If undefined, the default color depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `color` property.\n   *\n   * _Note:_ The `fill` encoding has higher precedence than `color`, thus may override the `color` encoding if conflicting encodings are specified.\n   */\n  fill?: ColorDef<F>;\n\n  /**\n   * Stroke color of the marks.\n   * __Default value:__ If undefined, the default color depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `color` property.\n   *\n   * _Note:_ The `stroke` encoding has higher precedence than `color`, thus may override the `color` encoding if conflicting encodings are specified.\n   */\n\n  stroke?: ColorDef<F>;\n\n  /**\n   * Opacity of the marks.\n   *\n   * __Default value:__ If undefined, the default opacity depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `opacity` property.\n   */\n  opacity?: NumericMarkPropDef<F>;\n\n  /**\n   * Fill opacity of the marks.\n   *\n   * __Default value:__ If undefined, the default opacity depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `fillOpacity` property.\n   */\n  fillOpacity?: NumericMarkPropDef<F>;\n\n  /**\n   * Stroke opacity of the marks.\n   *\n   * __Default value:__ If undefined, the default opacity depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `strokeOpacity` property.\n   */\n  strokeOpacity?: NumericMarkPropDef<F>;\n\n  /**\n   * Stroke width of the marks.\n   *\n   * __Default value:__ If undefined, the default stroke width depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#mark-config)'s `strokeWidth` property.\n   */\n  strokeWidth?: NumericMarkPropDef<F>;\n\n  /**\n   * Stroke dash of the marks.\n   *\n   * __Default value:__ `[1,0]` (No dash).\n   */\n  strokeDash?: NumericArrayMarkPropDef<F>;\n\n  /**\n   * Size of the mark.\n   * - For `\"point\"`, `\"square\"` and `\"circle\"`, – the symbol size, or pixel area of the mark.\n   * - For `\"bar\"` and `\"tick\"` – the bar and tick's size.\n   * - For `\"text\"` – the text's font size.\n   * - Size is unsupported for `\"line\"`, `\"area\"`, and `\"rect\"`. (Use `\"trail\"` instead of line with varying size)\n   */\n  size?: NumericMarkPropDef<F>;\n\n  /**\n   * Rotation angle of point and text marks.\n   */\n  angle?: NumericMarkPropDef<F>;\n\n  /**\n   * Shape of the mark.\n   *\n   * 1. For `point` marks the supported values include:\n   *   - plotting shapes: `\"circle\"`, `\"square\"`, `\"cross\"`, `\"diamond\"`, `\"triangle-up\"`, `\"triangle-down\"`, `\"triangle-right\"`, or `\"triangle-left\"`.\n   *   - the line symbol `\"stroke\"`\n   *   - centered directional shapes `\"arrow\"`, `\"wedge\"`, or `\"triangle\"`\n   *   - a custom [SVG path string](https://developer.mozilla.org/en-US/docs/Web/SVG/Tutorial/Paths) (For correct sizing, custom shape paths should be defined within a square bounding box with coordinates ranging from -1 to 1 along both the x and y dimensions.)\n   *\n   * 2. For `geoshape` marks it should be a field definition of the geojson data\n   *\n   * __Default value:__ If undefined, the default shape depends on [mark config](https://vega.github.io/vega-lite/docs/config.html#point-config)'s `shape` property. (`\"circle\"` if unset.)\n   */\n  shape?: ShapeDef<F>;\n  /**\n   * Additional levels of detail for grouping data in aggregate views and\n   * in line, trail, and area marks without mapping data to a specific visual channel.\n   */\n  detail?: FieldDefWithoutScale<F> | FieldDefWithoutScale<F>[];\n\n  /**\n   * A data field to use as a unique key for data binding. When a visualization’s data is updated, the key value will be used to match data elements to existing mark instances. Use a key channel to enable object constancy for transitions over dynamic data.\n   */\n  key?: FieldDefWithoutScale<F>;\n\n  /**\n   * Text of the `text` mark.\n   */\n  text?: TextDef<F>;\n\n  /**\n   * The tooltip text to show upon mouse hover. Specifying `tooltip` encoding overrides [the `tooltip` property in the mark definition](https://vega.github.io/vega-lite/docs/mark.html#mark-def).\n   *\n   * See the [`tooltip`](https://vega.github.io/vega-lite/docs/tooltip.html) documentation for a detailed discussion about tooltip in Vega-Lite.\n   */\n  tooltip?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F> | StringFieldDef<F>[] | null;\n\n  /**\n   * A URL to load upon mouse click.\n   */\n  href?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F>;\n\n  /**\n   * The URL of an image mark.\n   */\n  url?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F>;\n\n  /**\n   * A text description of this mark for ARIA accessibility (SVG output only). For SVG output the `\"aria-label\"` attribute will be set to this description.\n   */\n  description?: StringFieldDefWithCondition<F> | StringValueDefWithCondition<F>;\n\n  /**\n   * Order of the marks.\n   * - For stacked marks, this `order` channel encodes [stack order](https://vega.github.io/vega-lite/docs/stack.html#order).\n   * - For line and trail marks, this `order` channel encodes order of data points in the lines. This can be useful for creating [a connected scatterplot](https://vega.github.io/vega-lite/examples/connected_scatterplot.html). Setting `order` to `{\"value\": null}` makes the line marks use the original order in the data sources.\n   * - Otherwise, this `order` channel encodes layer order of the marks.\n   *\n   * __Note__: In aggregate plots, `order` field should be `aggregate`d to avoid creating additional aggregation grouping.\n   */\n  order?: OrderFieldDef<F> | OrderFieldDef<F>[] | OrderValueDef;\n}\n\nexport interface EncodingWithFacet<F extends Field> extends Encoding<F>, EncodingFacetMapping<F> {}\n\nexport function channelHasField<F extends Field>(\n  encoding: EncodingWithFacet<F>,\n  channel: keyof EncodingWithFacet<F>\n): boolean {\n  const channelDef = encoding && encoding[channel];\n  if (channelDef) {\n    if (isArray(channelDef)) {\n      return some(channelDef, fieldDef => !!fieldDef.field);\n    } else {\n      return isFieldDef(channelDef) || hasConditionalFieldDef<Field>(channelDef);\n    }\n  }\n  return false;\n}\n\nexport function isAggregate(encoding: EncodingWithFacet<any>) {\n  return some(CHANNELS, channel => {\n    if (channelHasField(encoding, channel)) {\n      const channelDef = encoding[channel];\n      if (isArray(channelDef)) {\n        return some(channelDef, fieldDef => !!fieldDef.aggregate);\n      } else {\n        const fieldDef = getFieldDef(channelDef);\n        return fieldDef && !!fieldDef.aggregate;\n      }\n    }\n    return false;\n  });\n}\n\nexport function extractTransformsFromEncoding(oldEncoding: Encoding<any>, config: Config) {\n  const groupby: string[] = [];\n  const bins: BinTransform[] = [];\n  const timeUnits: TimeUnitTransform[] = [];\n  const aggregate: AggregatedFieldDef[] = [];\n  const encoding: Encoding<string> = {};\n\n  forEach(oldEncoding, (channelDef, channel) => {\n    // Extract potential embedded transformations along with remaining properties\n    if (isFieldDef(channelDef)) {\n      const {field, aggregate: aggOp, bin, timeUnit, ...remaining} = channelDef;\n      if (aggOp || timeUnit || bin) {\n        const guide = getGuide(channelDef);\n        const isTitleDefined = guide && guide.title;\n        let newField = vgField(channelDef, {forAs: true});\n        const newFieldDef: FieldDef<string> = {\n          // Only add title if it doesn't exist\n          ...(isTitleDefined ? [] : {title: title(channelDef, config, {allowDisabling: true})}),\n          ...remaining,\n          // Always overwrite field\n          field: newField\n        };\n\n        if (aggOp) {\n          let op: AggregateOp;\n\n          if (isArgmaxDef(aggOp)) {\n            op = 'argmax';\n            newField = vgField({op: 'argmax', field: aggOp.argmax}, {forAs: true});\n            newFieldDef.field = `${newField}.${field}`;\n          } else if (isArgminDef(aggOp)) {\n            op = 'argmin';\n            newField = vgField({op: 'argmin', field: aggOp.argmin}, {forAs: true});\n            newFieldDef.field = `${newField}.${field}`;\n          } else if (aggOp !== 'boxplot' && aggOp !== 'errorbar' && aggOp !== 'errorband') {\n            op = aggOp;\n          }\n\n          if (op) {\n            const aggregateEntry: AggregatedFieldDef = {\n              op,\n              as: newField\n            };\n            if (field) {\n              aggregateEntry.field = field;\n            }\n            aggregate.push(aggregateEntry);\n          }\n        } else {\n          groupby.push(newField);\n          if (isTypedFieldDef(channelDef) && isBinning(bin)) {\n            bins.push({bin, field, as: newField});\n            // Add additional groupbys for range and end of bins\n            groupby.push(vgField(channelDef, {binSuffix: 'end'}));\n            if (binRequiresRange(channelDef, channel)) {\n              groupby.push(vgField(channelDef, {binSuffix: 'range'}));\n            }\n            // Create accompanying 'x2' or 'y2' field if channel is 'x' or 'y' respectively\n            if (isXorY(channel)) {\n              const secondaryChannel: SecondaryFieldDef<string> = {\n                field: newField + '_end'\n              };\n              encoding[channel + '2'] = secondaryChannel;\n            }\n            newFieldDef.bin = 'binned';\n            if (!isSecondaryRangeChannel(channel)) {\n              newFieldDef['type'] = QUANTITATIVE;\n            }\n          } else if (timeUnit) {\n            timeUnits.push({\n              timeUnit,\n              field,\n              as: newField\n            });\n\n            // define the format type for later compilation\n            const formatType = isTypedFieldDef(channelDef) && channelDef.type !== TEMPORAL && 'time';\n            if (formatType) {\n              if (channel === TEXT || channel === TOOLTIP) {\n                newFieldDef['formatType'] = formatType;\n              } else if (isNonPositionScaleChannel(channel)) {\n                newFieldDef['legend'] = {\n                  formatType,\n                  ...newFieldDef['legend']\n                };\n              } else if (isXorY(channel)) {\n                newFieldDef['axis'] = {\n                  formatType,\n                  ...newFieldDef['axis']\n                };\n              }\n            }\n          }\n        }\n\n        // now the field should refer to post-transformed field instead\n        encoding[channel as any] = newFieldDef;\n      } else {\n        groupby.push(field);\n        encoding[channel as any] = oldEncoding[channel];\n      }\n    } else {\n      // For value def / signal ref / datum def, just copy\n      encoding[channel as any] = oldEncoding[channel];\n    }\n  });\n\n  return {\n    bins,\n    timeUnits,\n    aggregate,\n    groupby,\n    encoding\n  };\n}\n\nexport function markChannelCompatible(encoding: Encoding<string>, channel: Channel, mark: Mark) {\n  const markSupported = supportMark(channel, mark);\n  if (!markSupported) {\n    return false;\n  } else if (markSupported === 'binned') {\n    const primaryFieldDef = encoding[channel === X2 ? X : Y];\n\n    // circle, point, square and tick only support x2/y2 when their corresponding x/y fieldDef\n    // has \"binned\" data and thus need x2/y2 to specify the bin-end field.\n    if (isFieldDef(primaryFieldDef) && isFieldDef(encoding[channel]) && isBinned(primaryFieldDef.bin)) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n  return true;\n}\n\nexport function initEncoding(\n  encoding: Encoding<string>,\n  mark: Mark,\n  filled: boolean,\n  config: Config\n): Encoding<string> {\n  return keys(encoding).reduce((normalizedEncoding: Encoding<string>, channel: Channel) => {\n    if (!isChannel(channel)) {\n      // Drop invalid channel\n      log.warn(log.message.invalidEncodingChannel(channel));\n      return normalizedEncoding;\n    }\n\n    const channelDef = encoding[channel];\n    if (channel === 'angle' && mark === 'arc' && !encoding.theta) {\n      log.warn(log.message.REPLACE_ANGLE_WITH_THETA);\n      channel = THETA;\n    }\n\n    if (!markChannelCompatible(encoding, channel, mark)) {\n      // Drop unsupported channel\n      log.warn(log.message.incompatibleChannel(channel, mark));\n      return normalizedEncoding;\n    }\n\n    // Drop line's size if the field is aggregated.\n    if (channel === SIZE && mark === 'line') {\n      const fieldDef = getFieldDef(encoding[channel]);\n      if (fieldDef?.aggregate) {\n        log.warn(log.message.LINE_WITH_VARYING_SIZE);\n        return normalizedEncoding;\n      }\n    }\n    // Drop color if either fill or stroke is specified\n\n    if (channel === COLOR && (filled ? 'fill' in encoding : 'stroke' in encoding)) {\n      log.warn(log.message.droppingColor('encoding', {fill: 'fill' in encoding, stroke: 'stroke' in encoding}));\n      return normalizedEncoding;\n    }\n\n    if (\n      channel === DETAIL ||\n      (channel === ORDER && !isArray(channelDef) && !isValueDef(channelDef)) ||\n      (channel === TOOLTIP && isArray(channelDef))\n    ) {\n      if (channelDef) {\n        // Array of fieldDefs for detail channel (or production rule)\n        (normalizedEncoding[channel] as any) = array(channelDef).reduce(\n          (defs: FieldDef<string>[], fieldDef: FieldDef<string>) => {\n            if (!isFieldDef(fieldDef)) {\n              log.warn(log.message.emptyFieldDef(fieldDef, channel));\n            } else {\n              defs.push(initFieldDef(fieldDef, channel));\n            }\n            return defs;\n          },\n          []\n        );\n      }\n    } else {\n      if (channel === TOOLTIP && channelDef === null) {\n        // Preserve null so we can use it to disable tooltip\n        normalizedEncoding[channel] = null;\n      } else if (\n        !isFieldDef(channelDef) &&\n        !isDatumDef(channelDef) &&\n        !isValueDef(channelDef) &&\n        !isConditionalDef(channelDef) &&\n        !isSignalRef(channelDef)\n      ) {\n        log.warn(log.message.emptyFieldDef(channelDef, channel));\n        return normalizedEncoding;\n      }\n\n      normalizedEncoding[channel as any] = initChannelDef(channelDef as ChannelDef, channel, config);\n    }\n    return normalizedEncoding;\n  }, {});\n}\n\n/**\n * For composite marks, we have to call initChannelDef during init so we can infer types earlier.\n */\nexport function normalizeEncoding(encoding: Encoding<string>, config: Config): Encoding<string> {\n  const normalizedEncoding: Encoding<string> = {};\n\n  for (const channel of keys(encoding)) {\n    const newChannelDef = initChannelDef(encoding[channel], channel, config, {compositeMark: true});\n    normalizedEncoding[channel as any] = newChannelDef;\n  }\n\n  return normalizedEncoding;\n}\n\nexport function fieldDefs<F extends Field>(encoding: EncodingWithFacet<F>): FieldDef<F>[] {\n  const arr: FieldDef<F>[] = [];\n  for (const channel of keys(encoding)) {\n    if (channelHasField(encoding, channel)) {\n      const channelDef = encoding[channel];\n      const channelDefArray = array(channelDef);\n      for (const def of channelDefArray) {\n        if (isFieldDef(def)) {\n          arr.push(def);\n        } else if (hasConditionalFieldDef<F>(def)) {\n          arr.push(def.condition);\n        }\n      }\n    }\n  }\n  return arr;\n}\n\nexport function forEach<U extends Record<any, any>>(\n  mapping: U,\n  f: (cd: ChannelDef, c: keyof U) => void,\n  thisArg?: any\n) {\n  if (!mapping) {\n    return;\n  }\n\n  for (const channel of keys(mapping)) {\n    const el = mapping[channel];\n    if (isArray(el)) {\n      for (const channelDef of el as unknown[]) {\n        f.call(thisArg, channelDef, channel);\n      }\n    } else {\n      f.call(thisArg, el, channel);\n    }\n  }\n}\n\nexport function reduce<T, U extends Record<any, any>>(\n  mapping: U,\n  f: (acc: any, fd: TypedFieldDef<string>, c: keyof U) => U,\n  init: T,\n  thisArg?: any\n) {\n  if (!mapping) {\n    return init;\n  }\n\n  return keys(mapping).reduce((r, channel) => {\n    const map = mapping[channel];\n    if (isArray(map)) {\n      return map.reduce((r1: T, channelDef: ChannelDef) => {\n        return f.call(thisArg, r1, channelDef, channel);\n      }, r);\n    } else {\n      return f.call(thisArg, r, map, channel);\n    }\n  }, init);\n}\n\n/**\n * Returns list of path grouping fields for the given encoding\n */\nexport function pathGroupingFields(mark: Mark, encoding: Encoding<string>): string[] {\n  return keys(encoding).reduce((details, channel) => {\n    switch (channel) {\n      // x, y, x2, y2, lat, long, lat1, long2, order, tooltip, href, aria label, cursor should not cause lines to group\n      case X:\n      case Y:\n      case HREF:\n      case DESCRIPTION:\n      case URL:\n      case X2:\n      case Y2:\n      case THETA:\n      case THETA2:\n      case RADIUS:\n      case RADIUS2:\n      // falls through\n\n      case LATITUDE:\n      case LONGITUDE:\n      case LATITUDE2:\n      case LONGITUDE2:\n      // TODO: case 'cursor':\n\n      // text, shape, shouldn't be a part of line/trail/area [falls through]\n      case TEXT:\n      case SHAPE:\n      case ANGLE:\n      // falls through\n\n      // tooltip fields should not be added to group by [falls through]\n      case TOOLTIP:\n        return details;\n\n      case ORDER:\n        // order should not group line / trail\n        if (mark === 'line' || mark === 'trail') {\n          return details;\n        }\n      // but order should group area for stacking (falls through)\n\n      case DETAIL:\n      case KEY: {\n        const channelDef = encoding[channel];\n        if (isArray(channelDef) || isFieldDef(channelDef)) {\n          for (const fieldDef of array(channelDef)) {\n            if (!fieldDef.aggregate) {\n              details.push(vgField(fieldDef, {}));\n            }\n          }\n        }\n        return details;\n      }\n\n      case SIZE:\n        if (mark === 'trail') {\n          // For trail, size should not group trail lines.\n          return details;\n        }\n      // For line, size should group lines.\n\n      // falls through\n      case COLOR:\n      case FILL:\n      case STROKE:\n      case OPACITY:\n      case FILLOPACITY:\n      case STROKEOPACITY:\n      case STROKEDASH:\n      case STROKEWIDTH: {\n        // TODO strokeDashOffset:\n        // falls through\n\n        const fieldDef = getFieldDef<string>(encoding[channel]);\n        if (fieldDef && !fieldDef.aggregate) {\n          details.push(vgField(fieldDef, {}));\n        }\n        return details;\n      }\n    }\n  }, []);\n}\n","import {array, isBoolean} from 'vega-util';\nimport {SUM_OPS} from './aggregate';\nimport {getSecondaryRangeChannel, NonPositionChannel, NONPOSITION_CHANNELS} from './channel';\nimport {\n  channelDefType,\n  FieldName,\n  getFieldDef,\n  isFieldDef,\n  isFieldOrDatumDef,\n  PositionDatumDef,\n  PositionFieldDef,\n  TypedFieldDef,\n  vgField\n} from './channeldef';\nimport {channelHasField, Encoding, isAggregate} from './encoding';\nimport * as log from './log';\nimport {\n  ARC,\n  AREA,\n  BAR,\n  CIRCLE,\n  isMarkDef,\n  isPathMark,\n  LINE,\n  Mark,\n  MarkDef,\n  POINT,\n  RULE,\n  SQUARE,\n  TEXT,\n  TICK\n} from './mark';\nimport {ScaleType} from './scale';\nimport {contains} from './util';\n\nconst STACK_OFFSET_INDEX = {\n  zero: 1,\n  center: 1,\n  normalize: 1\n} as const;\n\nexport type StackOffset = keyof typeof STACK_OFFSET_INDEX;\n\nexport function isStackOffset(s: string): s is StackOffset {\n  return s in STACK_OFFSET_INDEX;\n}\n\nexport interface StackProperties {\n  /** Dimension axis of the stack. */\n  groupbyChannel?: 'x' | 'y' | 'theta' | 'radius';\n\n  /** Field for groupbyChannel. */\n  groupbyField?: FieldName;\n\n  /** Measure axis of the stack. */\n  fieldChannel: 'x' | 'y' | 'theta' | 'radius';\n\n  /** Stack-by fields e.g., color, detail */\n  stackBy: {\n    fieldDef: TypedFieldDef<string>;\n    channel: NonPositionChannel;\n  }[];\n\n  /**\n   * See `stack` property of Position Field Def.\n   */\n  offset: StackOffset;\n\n  /**\n   * Whether this stack will produce impute transform\n   */\n  impute: boolean;\n}\n\nexport const STACKABLE_MARKS = new Set<Mark>([ARC, BAR, AREA, RULE, POINT, CIRCLE, SQUARE, LINE, TEXT, TICK]);\nexport const STACK_BY_DEFAULT_MARKS = new Set<Mark>([BAR, AREA, ARC]);\n\nfunction potentialStackedChannel(\n  encoding: Encoding<string>,\n  x: 'x' | 'theta'\n): 'x' | 'y' | 'theta' | 'radius' | undefined {\n  const y = x === 'x' ? 'y' : 'radius';\n\n  const xDef = encoding[x];\n  const yDef = encoding[y];\n\n  if (isFieldDef(xDef) && isFieldDef(yDef)) {\n    if (channelDefType(xDef) === 'quantitative' && channelDefType(yDef) === 'quantitative') {\n      if (xDef.stack) {\n        return x;\n      } else if (yDef.stack) {\n        return y;\n      }\n      const xAggregate = isFieldDef(xDef) && !!xDef.aggregate;\n      const yAggregate = isFieldDef(yDef) && !!yDef.aggregate;\n      // if there is no explicit stacking, only apply stack if there is only one aggregate for x or y\n      if (xAggregate !== yAggregate) {\n        return xAggregate ? x : y;\n      } else {\n        const xScale = xDef.scale?.type;\n        const yScale = yDef.scale?.type;\n\n        if (xScale && xScale !== 'linear') {\n          return y;\n        } else if (yScale && yScale !== 'linear') {\n          return x;\n        }\n      }\n    } else if (channelDefType(xDef) === 'quantitative') {\n      return x;\n    } else if (channelDefType(yDef) === 'quantitative') {\n      return y;\n    }\n  } else if (channelDefType(xDef) === 'quantitative') {\n    return x;\n  } else if (channelDefType(yDef) === 'quantitative') {\n    return y;\n  }\n  return undefined;\n}\n\nfunction getDimensionChannel(channel: 'x' | 'y' | 'theta' | 'radius') {\n  switch (channel) {\n    case 'x':\n      return 'y';\n    case 'y':\n      return 'x';\n    case 'theta':\n      return 'radius';\n    case 'radius':\n      return 'theta';\n  }\n}\n\n// Note: CompassQL uses this method and only pass in required properties of each argument object.\n// If required properties change, make sure to update CompassQL.\nexport function stack(\n  m: Mark | MarkDef,\n  encoding: Encoding<string>,\n  opt: {\n    disallowNonLinearStack?: boolean; // This option is for CompassQL\n  } = {}\n): StackProperties {\n  const mark = isMarkDef(m) ? m.type : m;\n  // Should have stackable mark\n  if (!STACKABLE_MARKS.has(mark)) {\n    return null;\n  }\n\n  // Run potential stacked twice, one for Cartesian and another for Polar,\n  // so text marks can be stacked in any of the coordinates.\n\n  // Note: The logic here is not perfectly correct.  If we want to support stacked dot plots where each dot is a pie chart with label, we have to change the stack logic here to separate Cartesian stacking for polar stacking.\n  // However, since we probably never want to do that, let's just note the limitation here.\n  const fieldChannel = potentialStackedChannel(encoding, 'x') || potentialStackedChannel(encoding, 'theta');\n\n  if (!fieldChannel) {\n    return null;\n  }\n\n  const stackedFieldDef = encoding[fieldChannel] as PositionFieldDef<string> | PositionDatumDef<string>;\n  const stackedField = isFieldDef(stackedFieldDef) ? vgField(stackedFieldDef, {}) : undefined;\n\n  let dimensionChannel: 'x' | 'y' | 'theta' | 'radius' = getDimensionChannel(fieldChannel);\n  let dimensionDef = encoding[dimensionChannel];\n\n  let dimensionField = isFieldDef(dimensionDef) ? vgField(dimensionDef, {}) : undefined;\n\n  // avoid grouping by the stacked field\n  if (dimensionField === stackedField) {\n    dimensionField = undefined;\n    dimensionDef = undefined;\n    dimensionChannel = undefined;\n  }\n\n  // Should have grouping level of detail that is different from the dimension field\n  const stackBy = NONPOSITION_CHANNELS.reduce((sc, channel) => {\n    // Ignore tooltip in stackBy (https://github.com/vega/vega-lite/issues/4001)\n    if (channel !== 'tooltip' && channelHasField(encoding, channel)) {\n      const channelDef = encoding[channel];\n      for (const cDef of array(channelDef)) {\n        const fieldDef = getFieldDef(cDef);\n        if (fieldDef.aggregate) {\n          continue;\n        }\n\n        // Check whether the channel's field is identical to x/y's field or if the channel is a repeat\n        const f = vgField(fieldDef, {});\n        if (\n          // if fielddef is a repeat, just include it in the stack by\n          !f ||\n          // otherwise, the field must be different from x and y fields.\n          f !== dimensionField\n        ) {\n          sc.push({channel, fieldDef});\n        }\n      }\n    }\n    return sc;\n  }, []);\n\n  // Automatically determine offset\n  let offset: StackOffset;\n  if (stackedFieldDef.stack !== undefined) {\n    if (isBoolean(stackedFieldDef.stack)) {\n      offset = stackedFieldDef.stack ? 'zero' : null;\n    } else {\n      offset = stackedFieldDef.stack;\n    }\n  } else if (stackBy.length > 0 && STACK_BY_DEFAULT_MARKS.has(mark)) {\n    // Bar and Area with sum ops are automatically stacked by default\n    offset = 'zero';\n  }\n\n  if (!offset || !isStackOffset(offset)) {\n    return null;\n  }\n\n  if (isAggregate(encoding) && stackBy.length === 0) {\n    return null;\n  }\n\n  // warn when stacking non-linear\n  if (stackedFieldDef.scale && stackedFieldDef.scale.type && stackedFieldDef.scale.type !== ScaleType.LINEAR) {\n    if (opt.disallowNonLinearStack) {\n      return null;\n    } else {\n      log.warn(log.message.cannotStackNonLinearScale(stackedFieldDef.scale.type));\n    }\n  }\n\n  // Check if it is a ranged mark\n  if (isFieldOrDatumDef(encoding[getSecondaryRangeChannel(fieldChannel)])) {\n    if (stackedFieldDef.stack !== undefined) {\n      log.warn(log.message.cannotStackRangedMark(fieldChannel));\n    }\n    return null;\n  }\n\n  // Warn if stacking non-summative aggregate\n  if (isFieldDef(stackedFieldDef) && stackedFieldDef.aggregate && !contains(SUM_OPS, stackedFieldDef.aggregate)) {\n    log.warn(log.message.stackNonSummativeAggregate(stackedFieldDef.aggregate));\n  }\n\n  return {\n    groupbyChannel: dimensionDef ? dimensionChannel : undefined,\n    groupbyField: dimensionField,\n    fieldChannel,\n    impute: stackedFieldDef.impute === null ? false : isPathMark(mark),\n    stackBy,\n    offset\n  };\n}\n","import {toMap} from 'datalib/src/util';\nimport {ExtendedChannel} from 'vega-lite/build/src/channel';\nimport {Config} from 'vega-lite/build/src/config';\nimport {Data} from 'vega-lite/build/src/data';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {FacetedUnitSpec, TopLevel} from 'vega-lite/build/src/spec';\nimport {Step} from 'vega-lite/build/src/spec/base';\nimport {stack, StackOffset, StackProperties} from 'vega-lite/build/src/stack';\nimport {TitleParams} from 'vega-lite/build/src/title';\nimport {ALL_ENCODING_PROPS, getEncodingNestedProp, isEncodingTopLevelProperty, Property, toKey} from '../property';\nimport {contains, extend, isObject, keys, some, without} from '../util';\nimport {isWildcard, WildcardProperty, Wildcard} from '../wildcard';\nimport {EncodingQuery, isDisabledAutoCountQuery, isEnabledAutoCountQuery, isFieldQuery, toEncoding} from './encoding';\nimport {TransformQuery} from './transform';\n\n/**\n * A \"query\" version of a [Vega-Lite](https://github.com/vega/vega-lite)'s `UnitSpec` (single view specification).\n * This interface and most of  its children have `Query` suffixes to hint that their instanced are queries that\n * can contain wildcards to describe a collection of specifications.\n */\nexport interface SpecQuery {\n  data?: Data;\n\n  // TODO: support mark definition object\n  mark: WildcardProperty<Mark>;\n  transform?: TransformQuery[];\n\n  /**\n   * Array of encoding query mappings.\n   * Note: Vega-Lite's `encoding` is an object whose keys are unique encoding channels.\n   * However, for CompassQL, the `channel` property of encoding query mappings can be wildcards.\n   * Thus the `encoding` object in Vega-Lite is flatten as the `encodings` array in CompassQL.\n   */\n  encodings: EncodingQuery[];\n\n  /**\n   * The width of the resulting encodings.\n   * __NOTE:__ Does not support wildcards.\n   */\n  width?: number | 'container' | Step | Wildcard<Step>;\n\n  /**\n   * The height of the resulting encodings.\n   * __NOTE:__ Does not support wildcards.\n   */\n  height?: number | 'container' | Step | Wildcard<Step>;\n\n  /**\n   * CSS color property to use as the background of visualization.\n   * __NOTE:__ Does not support wildcards.\n   */\n  background?: string;\n\n  /**\n   * The default visualization padding, in pixels, from the edge of the\n   * visualization canvas to the data rectangle. If a number, specifies\n   * padding for all sides. If an object, the value should have the\n   * format {\"left\": 5, \"top\": 5, \"right\": 5, \"bottom\": 5}\n   * to specify padding for each side of the visualization.\n   *\n   * __NOTE:__ Does not support wildcards.\n   */\n  padding?: number | Object;\n\n  /**\n   * Title for the plot.\n   * __NOTE:__ Does not support wildcards.\n   */\n  title?: string | TitleParams<any>;\n\n  // TODO: make config query (not important at all, only for the sake of completeness.)\n  /**\n   * Vega-Lite Configuration\n   */\n  config?: Config;\n}\n\n/**\n * Convert a Vega-Lite's ExtendedUnitSpec into a CompassQL's SpecQuery\n * @param {ExtendedUnitSpec} spec\n * @returns\n */\nexport function fromSpec(spec: TopLevel<FacetedUnitSpec>): SpecQuery {\n  return extend(\n    spec.data ? {data: spec.data} : {},\n    spec.transform ? {transform: spec.transform} : {},\n    spec.width ? {width: spec.width} : {},\n    spec.height ? {height: spec.height} : {},\n    spec.background ? {background: spec.background} : {},\n    spec.padding ? {padding: spec.padding} : {},\n    spec.title ? {title: spec.title} : {},\n    {\n      mark: spec.mark,\n      encodings: keys(spec.encoding).map((channel: ExtendedChannel) => {\n        const encQ: EncodingQuery = {channel: channel};\n        const channelDef = spec.encoding[channel];\n\n        for (const prop in channelDef) {\n          if (isEncodingTopLevelProperty(prop as Property) && channelDef[prop] !== undefined) {\n            // Currently bin, scale, axis, legend only support boolean, but not null.\n            // Therefore convert null to false.\n            if (contains(['bin', 'scale', 'axis', 'legend'], prop) && channelDef[prop] === null) {\n              encQ[prop] = false;\n            } else {\n              encQ[prop] = channelDef[prop];\n            }\n          }\n        }\n\n        if (isFieldQuery(encQ) && encQ.aggregate === 'count' && !encQ.field) {\n          encQ.field = '*';\n        }\n\n        return encQ;\n      }),\n    },\n    spec.config ? {config: spec.config} : {}\n  );\n}\n\nexport function isAggregate(specQ: SpecQuery) {\n  return some(specQ.encodings, (encQ: EncodingQuery) => {\n    return (isFieldQuery(encQ) && !isWildcard(encQ.aggregate) && !!encQ.aggregate) || isEnabledAutoCountQuery(encQ);\n  });\n}\n\n/**\n * @return The Vega-Lite `StackProperties` object that describes the stack\n * configuration of `specQ`. Returns `null` if this is not stackable.\n */\nexport function getVlStack(specQ: SpecQuery): StackProperties {\n  if (!hasRequiredStackProperties(specQ)) {\n    return null;\n  }\n\n  const encoding = toEncoding(specQ.encodings, {schema: null, wildcardMode: 'null'});\n  const mark = specQ.mark as Mark;\n\n  return stack(mark, encoding, {disallowNonLinearStack: true});\n}\n\n/**\n * @return The `StackOffset` specified in `specQ`, `undefined` if none\n * is specified.\n */\nexport function getStackOffset(specQ: SpecQuery): StackOffset {\n  for (const encQ of specQ.encodings) {\n    if (encQ[Property.STACK] !== undefined && !isWildcard(encQ[Property.STACK])) {\n      return encQ[Property.STACK];\n    }\n  }\n  return undefined;\n}\n\n/**\n * @return The `ExtendedChannel` in which `stack` is specified in `specQ`, or\n * `null` if none is specified.\n */\nexport function getStackChannel(specQ: SpecQuery): ExtendedChannel {\n  for (const encQ of specQ.encodings) {\n    if (encQ[Property.STACK] !== undefined && !isWildcard(encQ.channel)) {\n      return encQ.channel;\n    }\n  }\n  return null;\n}\n\n/**\n * Returns true iff the given SpecQuery has the properties defined\n * to be a potential Stack spec.\n * @param specQ The SpecQuery in question.\n */\nexport function hasRequiredStackProperties(specQ: SpecQuery) {\n  // TODO(haldenl): make this leaner, a lot of encQ properties aren't required for stack.\n  // TODO(haldenl): check mark, then encodings\n  if (isWildcard(specQ.mark)) {\n    return false;\n  }\n\n  const requiredEncodingProps = [\n    Property.STACK,\n    Property.CHANNEL,\n    Property.MARK,\n    Property.FIELD,\n    Property.AGGREGATE,\n    Property.AUTOCOUNT,\n    Property.SCALE,\n    getEncodingNestedProp('scale', 'type'),\n    Property.TYPE,\n  ];\n  const exclude = toMap(without(ALL_ENCODING_PROPS, requiredEncodingProps));\n\n  const encodings = specQ.encodings.filter((encQ) => !isDisabledAutoCountQuery(encQ));\n  for (const encQ of encodings) {\n    if (objectContainsWildcard(encQ, {exclude: exclude})) {\n      return false;\n    }\n  }\n  return true;\n}\n\n/**\n * Returns true iff the given object does not contain a nested wildcard.\n * @param obj The object in question.\n * @param opt With optional `exclude` property, which defines properties to\n * ignore when testing for wildcards.\n */\n// TODO(haldenl): rename to objectHasWildcard, rename prop to obj\nfunction objectContainsWildcard(obj: any, opt: {exclude?: {[key: string]: 1}} = {}) {\n  if (!isObject(obj)) {\n    return false;\n  }\n\n  for (const childProp in obj) {\n    if (obj.hasOwnProperty(childProp)) {\n      const wildcard = isWildcard(obj[childProp]);\n      if ((wildcard && (!opt.exclude || !opt.exclude[childProp])) || objectContainsWildcard(obj[childProp], opt)) {\n        return true;\n      }\n    }\n  }\n  return false;\n}\n\n/**\n * Returns true iff the given `specQ` contains a wildcard.\n * @param specQ The `SpecQuery` in question.\n * @param opt With optional `exclude` property, which defines properties to\n * ignore when testing for wildcards.\n */\nexport function hasWildcard(specQ: SpecQuery, opt: {exclude?: Property[]} = {}) {\n  const exclude = opt.exclude ? toMap(opt.exclude.map(toKey)) : {};\n  if (isWildcard(specQ.mark) && !exclude['mark']) {\n    return true;\n  }\n\n  for (const encQ of specQ.encodings) {\n    if (objectContainsWildcard(encQ, exclude)) {\n      return true;\n    }\n  }\n  return false;\n}\n","import {isString} from 'datalib/src/util';\nimport {isAggregateOp} from 'vega-lite/build/src/aggregate';\nimport {Channel, isChannel} from 'vega-lite/build/src/channel';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {FacetedUnitSpec} from 'vega-lite/build/src/spec';\nimport {StackProperties} from 'vega-lite/build/src/stack';\nimport {isUTCTimeUnit, isLocalSingleTimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {getFullName} from 'vega-lite/build/src/type';\nimport {\n  DEFAULT_PROP_PRECEDENCE,\n  EncodingNestedChildProp,\n  getEncodingNestedProp,\n  isEncodingNestedParent,\n  Property,\n  SORT_PROPS,\n  VIEW_PROPS,\n} from '../property';\nimport {PropIndex} from '../propindex';\nimport {Dict, isArray, isBoolean, keys} from '../util';\nimport {isShortWildcard, isWildcard, SHORT_WILDCARD} from '../wildcard';\nimport {\n  EncodingQuery,\n  FieldQuery,\n  FieldQueryBase,\n  isAutoCountQuery,\n  isDisabledAutoCountQuery,\n  isEnabledAutoCountQuery,\n  isFieldQuery,\n  isValueQuery,\n} from './encoding';\nimport {fromSpec, getVlStack, SpecQuery} from './spec';\n\nexport type Replacer = (s: string) => string;\n\nexport function getReplacerIndex(replaceIndex: PropIndex<Dict<string>>): PropIndex<Replacer> {\n  return replaceIndex.map((r) => getReplacer(r));\n}\n\nexport function getReplacer(replace: Dict<string>): Replacer {\n  return (s: string) => {\n    if (replace[s] !== undefined) {\n      return replace[s];\n    }\n    return s;\n  };\n}\n\nexport function value(v: any, replacer: Replacer): any {\n  if (isWildcard(v)) {\n    // Return the enum array if it's a full wildcard, or just return SHORT_WILDCARD for short ones.\n    if (!isShortWildcard(v) && v.enum) {\n      return SHORT_WILDCARD + JSON.stringify(v.enum);\n    } else {\n      return SHORT_WILDCARD;\n    }\n  }\n  if (replacer) {\n    return replacer(v);\n  }\n  return v;\n}\n\nexport function replace(v: any, replacer: Replacer): any {\n  if (replacer) {\n    return replacer(v);\n  }\n  return v;\n}\n\nexport const REPLACE_NONE = new PropIndex<Replacer>();\n\nexport const INCLUDE_ALL: PropIndex<boolean> =\n  // FIXME: remove manual TRANSFORM concat once we really support enumerating transform.\n  []\n    .concat(DEFAULT_PROP_PRECEDENCE, SORT_PROPS, [Property.TRANSFORM, Property.STACK], VIEW_PROPS)\n    .reduce((pi, prop: Property) => pi.set(prop, true), new PropIndex<boolean>());\n\nexport function vlSpec(\n  vlspec: FacetedUnitSpec,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replace: PropIndex<Replacer> = REPLACE_NONE\n) {\n  const specQ = fromSpec(vlspec);\n  return spec(specQ, include, replace);\n}\n\nexport const PROPERTY_SUPPORTED_CHANNELS = {\n  axis: {x: true, y: true, row: true, column: true},\n  legend: {color: true, opacity: true, size: true, shape: true},\n  scale: {x: true, y: true, color: true, opacity: true, row: true, column: true, size: true, shape: true},\n  sort: {x: true, y: true, path: true, order: true},\n  stack: {x: true, y: true},\n};\n\n/**\n * Returns a shorthand for a spec query\n * @param specQ a spec query\n * @param include Dict Set listing property types (key) to be included in the shorthand\n * @param replace Dictionary of replace function for values of a particular property type (key)\n */\nexport function spec(\n  specQ: SpecQuery,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replace: PropIndex<Replacer> = REPLACE_NONE\n): string {\n  const parts: string[] = [];\n\n  if (include.get(Property.MARK)) {\n    parts.push(value(specQ.mark, replace.get(Property.MARK)));\n  }\n\n  if (specQ.transform && specQ.transform.length > 0) {\n    parts.push(`transform:${JSON.stringify(specQ.transform)}`);\n  }\n\n  let stack: StackProperties;\n  if (include.get(Property.STACK)) {\n    stack = getVlStack(specQ);\n  }\n\n  if (specQ.encodings) {\n    const encodings = specQ.encodings\n      .reduce((encQs, encQ) => {\n        // Exclude encoding mapping with autoCount=false as they are basically disabled.\n        if (!isDisabledAutoCountQuery(encQ)) {\n          let str;\n          if (!!stack && encQ.channel === stack.fieldChannel) {\n            str = encoding({...encQ, stack: stack.offset}, include, replace);\n          } else {\n            str = encoding(encQ, include, replace);\n          }\n          if (str) {\n            // only add if the shorthand isn't an empty string.\n            encQs.push(str);\n          }\n        }\n        return encQs;\n      }, [])\n      .sort() // sort at the end to ignore order\n      .join('|');\n\n    if (encodings) {\n      parts.push(encodings);\n    }\n  }\n\n  for (const viewProp of VIEW_PROPS) {\n    const propString = viewProp.toString();\n    if (include.get(viewProp) && !!specQ[propString]) {\n      const value = specQ[propString];\n      parts.push(`${propString}=${JSON.stringify(value)}`);\n    }\n  }\n\n  return parts.join('|');\n}\n\n/**\n * Returns a shorthand for an encoding query\n * @param encQ an encoding query\n * @param include Dict Set listing property types (key) to be included in the shorthand\n * @param replace Dictionary of replace function for values of a particular property type (key)\n */\nexport function encoding(\n  encQ: EncodingQuery,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replace: PropIndex<Replacer> = REPLACE_NONE\n): string {\n  const parts = [];\n  if (include.get(Property.CHANNEL)) {\n    parts.push(value(encQ.channel, replace.get(Property.CHANNEL)));\n  }\n\n  if (isFieldQuery(encQ)) {\n    const fieldDefStr = fieldDef(encQ, include, replace);\n\n    if (fieldDefStr) {\n      parts.push(fieldDefStr);\n    }\n  } else if (isValueQuery(encQ)) {\n    parts.push(encQ.value);\n  } else if (isAutoCountQuery(encQ)) {\n    parts.push('autocount()');\n  }\n\n  return parts.join(':');\n}\n\n/**\n * Returns a field definition shorthand for an encoding query\n * @param encQ an encoding query\n * @param include Dict Set listing property types (key) to be included in the shorthand\n * @param replace Dictionary of replace function for values of a particular property type (key)\n */\nexport function fieldDef(\n  encQ: EncodingQuery,\n  include: PropIndex<boolean> = INCLUDE_ALL,\n  replacer: PropIndex<Replacer> = REPLACE_NONE\n): string {\n  if (include.get(Property.AGGREGATE) && isDisabledAutoCountQuery(encQ)) {\n    return '-';\n  }\n\n  const fn = func(encQ, include, replacer);\n  const props = fieldDefProps(encQ, include, replacer);\n\n  let fieldAndParams;\n  if (isFieldQuery(encQ)) {\n    // field\n    fieldAndParams = include.get('field') ? value(encQ.field, replacer.get('field')) : '...';\n    // type\n    if (include.get(Property.TYPE)) {\n      if (isWildcard(encQ.type)) {\n        fieldAndParams += `,${value(encQ.type, replacer.get(Property.TYPE))}`;\n      } else {\n        const typeShort = `${encQ.type || TYPE.QUANTITATIVE}`.substr(0, 1);\n        fieldAndParams += `,${value(typeShort, replacer.get(Property.TYPE))}`;\n      }\n    }\n    // encoding properties\n    fieldAndParams += props\n      .map((p) => {\n        const val = p.value instanceof Array ? `[${p.value}]` : p.value;\n        return `,${p.key}=${val}`;\n      })\n      .join('');\n  } else if (isAutoCountQuery(encQ)) {\n    fieldAndParams = '*,q';\n  }\n\n  if (!fieldAndParams) {\n    return null;\n  }\n  if (fn) {\n    const fnPrefix = isString(fn) ? fn : SHORT_WILDCARD + (keys(fn).length > 0 ? JSON.stringify(fn) : '');\n\n    return `${fnPrefix}(${fieldAndParams})`;\n  }\n  return fieldAndParams;\n}\n\n/**\n * Return function part of\n */\nfunction func(fieldQ: FieldQuery, include: PropIndex<boolean>, replacer: PropIndex<Replacer>): string | Object {\n  if (include.get(Property.AGGREGATE) && fieldQ.aggregate && !isWildcard(fieldQ.aggregate)) {\n    return replace(fieldQ.aggregate, replacer.get(Property.AGGREGATE));\n  } else if (include.get(Property.AGGREGATE) && isEnabledAutoCountQuery(fieldQ)) {\n    // autoCount is considered a part of aggregate\n    return replace('count', replacer.get(Property.AGGREGATE));\n  } else if (include.get(Property.TIMEUNIT) && fieldQ.timeUnit && !isWildcard(fieldQ.timeUnit)) {\n    return replace(fieldQ.timeUnit, replacer.get(Property.TIMEUNIT));\n  } else if (include.get(Property.BIN) && fieldQ.bin && !isWildcard(fieldQ.bin)) {\n    return 'bin';\n  } else {\n    let fn: any = null;\n    for (const prop of [Property.AGGREGATE, Property.AUTOCOUNT, Property.TIMEUNIT, Property.BIN]) {\n      const val = fieldQ[prop];\n      if (include.get(prop) && fieldQ[prop] && isWildcard(val)) {\n        // assign fnEnumIndex[prop] = array of enum values or just \"?\" if it is SHORT_WILDCARD\n        fn = fn || {};\n        fn[prop] = isShortWildcard(val) ? val : val.enum;\n      }\n    }\n    if (fn && fieldQ.hasFn) {\n      fn.hasFn = true;\n    }\n    return fn;\n  }\n}\n\n/**\n * Return key-value of parameters of field defs\n */\nfunction fieldDefProps(fieldQ: FieldQuery, include: PropIndex<boolean>, replacer: PropIndex<Replacer>) {\n  /** Encoding properties e.g., Scale, Axis, Legend */\n  const props: {key: string; value: boolean | Object}[] = [];\n\n  // Parameters of function such as bin will be just top-level properties\n  if (!isBoolean(fieldQ.bin) && !isShortWildcard(fieldQ.bin)) {\n    const bin = fieldQ.bin;\n    for (const child in bin) {\n      const prop = getEncodingNestedProp('bin', child as EncodingNestedChildProp);\n      if (prop && include.get(prop) && bin[child] !== undefined) {\n        props.push({\n          key: child,\n          value: value(bin[child], replacer.get(prop)),\n        });\n      }\n    }\n    // Sort to make sure that parameter are ordered consistently\n    props.sort((a, b) => a.key.localeCompare(b.key));\n  }\n\n  for (const parent of [Property.SCALE, Property.SORT, Property.STACK, Property.AXIS, Property.LEGEND]) {\n    if (!isWildcard(fieldQ.channel) && !PROPERTY_SUPPORTED_CHANNELS[parent][fieldQ.channel as Channel]) {\n      continue;\n    }\n\n    if (include.get(parent) && fieldQ[parent] !== undefined) {\n      const parentValue = fieldQ[parent];\n      if (isBoolean(parentValue) || parentValue === null) {\n        // `scale`, `axis`, `legend` can be false/null.\n        props.push({\n          key: `${parent}`,\n          value: parentValue || false, // return true or false (false if null)\n        });\n      } else if (isString(parentValue)) {\n        // `sort` can be a string (ascending/descending).\n        props.push({\n          key: `${parent}`,\n          value: replace(JSON.stringify(parentValue), replacer.get(parent)),\n        });\n      } else {\n        const nestedPropChildren = [];\n        for (const child in parentValue) {\n          const nestedProp = getEncodingNestedProp(parent, child as EncodingNestedChildProp);\n          if (nestedProp && include.get(nestedProp) && parentValue[child] !== undefined) {\n            nestedPropChildren.push({\n              key: child,\n              value: value(parentValue[child], replacer.get(nestedProp)),\n            });\n          }\n        }\n\n        if (nestedPropChildren.length > 0) {\n          const nestedPropObject = nestedPropChildren\n            .sort((a, b) => a.key.localeCompare(b.key))\n            .reduce((o, item) => {\n              o[item.key] = item.value;\n              return o;\n            }, {});\n\n          // Sort to make sure that parameter are ordered consistently\n          props.push({\n            key: `${parent}`,\n            value: JSON.stringify(nestedPropObject),\n          });\n        }\n      }\n    }\n  }\n  return props;\n}\n\nexport function parse(shorthand: string): SpecQuery {\n  // TODO(https://github.com/uwdata/compassql/issues/259):\n  // Do not split directly, but use an upgraded version of `getClosingBraceIndex()`\n  const splitShorthand = shorthand.split('|');\n\n  const specQ: SpecQuery = {\n    mark: splitShorthand[0] as Mark,\n    encodings: [] as EncodingQuery[],\n  };\n\n  for (let i = 1; i < splitShorthand.length; i++) {\n    const part = splitShorthand[i];\n    const splitPart = splitWithTail(part, ':', 1);\n    const splitPartKey = splitPart[0];\n    const splitPartValue = splitPart[1];\n\n    if (isChannel(splitPartKey) || splitPartKey === '?') {\n      const encQ = shorthandParser.encoding(splitPartKey, splitPartValue);\n      specQ.encodings.push(encQ);\n      continue;\n    }\n\n    if (splitPartKey === 'transform') {\n      specQ.transform = JSON.parse(splitPartValue);\n      continue;\n    }\n  }\n\n  return specQ;\n}\n\n/**\n * Split a string n times into substrings with the specified delimiter and return them as an array.\n * @param str The string to be split\n * @param delim The delimiter string used to separate the string\n * @param number The value used to determine how many times the string is split\n */\nexport function splitWithTail(str: string, delim: string, count: number): string[] {\n  const result = [];\n  let lastIndex = 0;\n\n  for (let i = 0; i < count; i++) {\n    const indexOfDelim = str.indexOf(delim, lastIndex);\n\n    if (indexOfDelim !== -1) {\n      result.push(str.substring(lastIndex, indexOfDelim));\n      lastIndex = indexOfDelim + 1;\n    } else {\n      break;\n    }\n  }\n\n  result.push(str.substr(lastIndex));\n\n  // If the specified count is greater than the number of delimiters that exist in the string,\n  // an empty string will be pushed count minus number of delimiter occurence times.\n  if (result.length !== count + 1) {\n    while (result.length !== count + 1) {\n      result.push('');\n    }\n  }\n\n  return result;\n}\n\nexport namespace shorthandParser {\n  export function encoding(channel: Channel | SHORT_WILDCARD, fieldDefShorthand: string): EncodingQuery {\n    const encQMixins =\n      fieldDefShorthand.indexOf('(') !== -1\n        ? fn(fieldDefShorthand)\n        : rawFieldDef(splitWithTail(fieldDefShorthand, ',', 2));\n    return {\n      channel,\n      ...encQMixins,\n    };\n  }\n\n  export function rawFieldDef(fieldDefPart: string[]): FieldQueryBase {\n    const fieldQ: FieldQueryBase = {};\n    fieldQ.field = fieldDefPart[0];\n    fieldQ.type = getFullName(fieldDefPart[1].toUpperCase()) || '?';\n\n    const partParams = fieldDefPart[2];\n    let closingBraceIndex = 0;\n    let i = 0;\n\n    while (i < partParams.length) {\n      const propEqualSignIndex = partParams.indexOf('=', i);\n      let parsedValue;\n      if (propEqualSignIndex !== -1) {\n        const prop = partParams.substring(i, propEqualSignIndex);\n        if (partParams[i + prop.length + 1] === '{') {\n          const openingBraceIndex = i + prop.length + 1;\n          closingBraceIndex = getClosingIndex(openingBraceIndex, partParams, '}');\n          const value = partParams.substring(openingBraceIndex, closingBraceIndex + 1);\n          parsedValue = JSON.parse(value);\n\n          // index after next comma\n          i = closingBraceIndex + 2;\n        } else if (partParams[i + prop.length + 1] === '[') {\n          // find closing square bracket\n          const openingBracketIndex = i + prop.length + 1;\n          const closingBracketIndex = getClosingIndex(openingBracketIndex, partParams, ']');\n          const value = partParams.substring(openingBracketIndex, closingBracketIndex + 1);\n          parsedValue = JSON.parse(value);\n\n          // index after next comma\n          i = closingBracketIndex + 2;\n        } else {\n          const propIndex = i;\n          // Substring until the next comma (or end of the string)\n          let nextCommaIndex = partParams.indexOf(',', i + prop.length);\n          if (nextCommaIndex === -1) {\n            nextCommaIndex = partParams.length;\n          }\n          // index after next comma\n          i = nextCommaIndex + 1;\n\n          parsedValue = JSON.parse(partParams.substring(propIndex + prop.length + 1, nextCommaIndex));\n        }\n\n        if (isEncodingNestedParent(prop)) {\n          fieldQ[prop] = parsedValue;\n        } else {\n          // prop is a property of the aggregation function such as bin\n          fieldQ.bin = fieldQ.bin || {};\n          fieldQ.bin[prop] = parsedValue;\n        }\n      } else {\n        // something is wrong with the format of the partParams\n        // exits loop if don't have then infintie loop\n        break;\n      }\n    }\n    return fieldQ;\n  }\n\n  export function getClosingIndex(openingBraceIndex: number, str: string, closingChar: string): number {\n    for (let i = openingBraceIndex; i < str.length; i++) {\n      if (str[i] === closingChar) {\n        return i;\n      }\n    }\n  }\n\n  export function fn(fieldDefShorthand: string): FieldQueryBase {\n    const fieldQ: FieldQueryBase = {};\n    // Aggregate, Bin, TimeUnit as wildcard case\n    if (fieldDefShorthand[0] === '?') {\n      const closingBraceIndex = getClosingIndex(1, fieldDefShorthand, '}');\n\n      const fnEnumIndex = JSON.parse(fieldDefShorthand.substring(1, closingBraceIndex + 1));\n\n      for (const encodingProperty in fnEnumIndex) {\n        if (isArray(fnEnumIndex[encodingProperty])) {\n          fieldQ[encodingProperty] = {enum: fnEnumIndex[encodingProperty]};\n        } else {\n          // Definitely a `SHORT_WILDCARD`\n          fieldQ[encodingProperty] = fnEnumIndex[encodingProperty];\n        }\n      }\n\n      return {\n        ...fieldQ,\n        ...rawFieldDef(\n          splitWithTail(fieldDefShorthand.substring(closingBraceIndex + 2, fieldDefShorthand.length - 1), ',', 2)\n        ),\n      };\n    } else {\n      const func = fieldDefShorthand.substring(0, fieldDefShorthand.indexOf('('));\n      const insideFn = fieldDefShorthand.substring(func.length + 1, fieldDefShorthand.length - 1);\n      const insideFnParts = splitWithTail(insideFn, ',', 2);\n\n      if (isAggregateOp(func)) {\n        return {\n          aggregate: func,\n          ...rawFieldDef(insideFnParts),\n        };\n      } else if (isUTCTimeUnit(func) || isLocalSingleTimeUnit(func)) {\n        return {\n          timeUnit: func,\n          ...rawFieldDef(insideFnParts),\n        };\n      } else if (func === 'bin') {\n        return {\n          bin: {},\n          ...rawFieldDef(insideFnParts),\n        };\n      }\n    }\n  }\n}\n","import {isObject} from 'datalib/src/util';\nimport {AggregateOp} from 'vega';\nimport {Axis} from 'vega-lite/build/src/axis';\nimport {BinParams} from 'vega-lite/build/src/bin';\nimport {ExtendedChannel} from 'vega-lite/build/src/channel';\nimport * as vlChannelDef from 'vega-lite/build/src/channeldef';\nimport {ValueDef} from 'vega-lite/build/src/channeldef';\nimport {scaleType as compileScaleType} from 'vega-lite/build/src/compile/scale/type';\nimport {Encoding} from 'vega-lite/build/src/encoding';\nimport {Legend} from 'vega-lite/build/src/legend';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {Scale} from 'vega-lite/build/src/scale';\nimport {EncodingSortField, SortOrder} from 'vega-lite/build/src/sort';\nimport {StackOffset} from 'vega-lite/build/src/stack';\nimport {TimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {Type as VLType} from 'vega-lite/build/src/type';\nimport {FlatProp, isEncodingNestedParent, Property} from '../property';\nimport {Schema} from '../schema';\nimport {isWildcard, SHORT_WILDCARD, Wildcard, WildcardProperty} from '../wildcard';\nimport {ExpandedType} from './expandedtype';\nimport {PROPERTY_SUPPORTED_CHANNELS} from './shorthand';\n\nexport type EncodingQuery = FieldQuery | ValueQuery | AutoCountQuery;\n\nexport interface EncodingQueryBase {\n  channel: WildcardProperty<ExtendedChannel>;\n\n  description?: string;\n}\n\nexport interface ValueQuery extends EncodingQueryBase {\n  value: WildcardProperty<boolean | number | string>;\n}\n\nexport function isValueQuery(encQ: EncodingQuery): encQ is ValueQuery {\n  return encQ !== null && encQ !== undefined && encQ['value'] !== undefined;\n}\n\nexport function isFieldQuery(encQ: EncodingQuery): encQ is FieldQuery {\n  return encQ !== null && encQ !== undefined && (encQ['field'] || encQ['aggregate'] === 'count');\n}\n\nexport function isAutoCountQuery(encQ: EncodingQuery): encQ is AutoCountQuery {\n  return encQ !== null && encQ !== undefined && 'autoCount' in encQ;\n}\n\nexport function isDisabledAutoCountQuery(encQ: EncodingQuery) {\n  return isAutoCountQuery(encQ) && encQ.autoCount === false;\n}\n\nexport function isEnabledAutoCountQuery(encQ: EncodingQuery) {\n  return isAutoCountQuery(encQ) && encQ.autoCount === true;\n}\n\n/**\n * A special encoding query that gets added internally if the `config.autoCount` flag is on. See SpecQueryModel.build for its generation.\n *\n * __Note:__ this type of query should not be specified by users.\n */\nexport interface AutoCountQuery extends EncodingQueryBase {\n  /**\n   * A count function that gets added internally if the config.autoCount flag in on.\n   * This allows us to add one extra encoding mapping if needed when the query produces\n   * plot that only have discrete fields.\n   * In such cases, adding count make the output plots way more meaningful.\n   */\n  autoCount: WildcardProperty<boolean>;\n  type: 'quantitative';\n}\n\nexport interface FieldQueryBase {\n  // FieldDef\n  aggregate?: WildcardProperty<AggregateOp>;\n  timeUnit?: WildcardProperty<TimeUnit>;\n\n  /**\n   * Special flag for enforcing that the field should have a fuction (one of timeUnit, bin, or aggregate).\n   *\n   * For example, if you enumerate both bin and aggregate then you need `undefined` for both.\n   *\n   * ```\n   * {aggregate: {enum: [undefined, 'mean', 'sum']}, bin: {enum: [false, true]}}\n   * ```\n   *\n   * This would enumerate a fieldDef with \"mean\", \"sum\", bin:true, and no function at all.\n   * If you want only \"mean\", \"sum\", bin:true, then use `hasFn: true`\n   *\n   * ```\n   * {aggregate: {enum: [undefined, 'mean', 'sum']}, bin: {enum: [false, true]}, hasFn: true}\n   * ```\n   */\n  hasFn?: boolean;\n\n  bin?: boolean | BinQuery | SHORT_WILDCARD;\n  scale?: boolean | ScaleQuery | SHORT_WILDCARD;\n\n  sort?: SortOrder | EncodingSortField<string>;\n  stack?: StackOffset | SHORT_WILDCARD;\n\n  field?: WildcardProperty<string>;\n  type?: WildcardProperty<ExpandedType>;\n\n  axis?: boolean | AxisQuery | SHORT_WILDCARD;\n  legend?: boolean | LegendQuery | SHORT_WILDCARD;\n\n  format?: string;\n}\n\nexport type FieldQuery = EncodingQueryBase & FieldQueryBase;\n\n// Using Mapped Type from TS2.1 to declare query for an object without nested property\n// https://www.typescriptlang.org/docs/handbook/release-notes/typescript-2-1.html#mapped-types\nexport type FlatQuery<T> = {[P in keyof T]: WildcardProperty<T[P]>};\n\nexport type FlatQueryWithEnableFlag<T> = (Wildcard<boolean> | {}) & FlatQuery<T>;\n\nexport type BinQuery = FlatQueryWithEnableFlag<BinParams>;\nexport type ScaleQuery = FlatQueryWithEnableFlag<Scale>;\nexport type AxisQuery = FlatQueryWithEnableFlag<Axis>;\nexport type LegendQuery = FlatQueryWithEnableFlag<Legend<any>>;\n\nconst DEFAULT_PROPS = [\n  Property.AGGREGATE,\n  Property.BIN,\n  Property.TIMEUNIT,\n  Property.FIELD,\n  Property.TYPE,\n  Property.SCALE,\n  Property.SORT,\n  Property.AXIS,\n  Property.LEGEND,\n  Property.STACK,\n  Property.FORMAT,\n];\n\nexport interface ConversionParams {\n  schema?: Schema;\n  props?: FlatProp[];\n  wildcardMode?: 'skip' | 'null';\n}\n\nexport function toEncoding(encQs: EncodingQuery[], params: ConversionParams): Encoding<string> {\n  const {wildcardMode = 'skip'} = params;\n  const encoding: Encoding<string> = {};\n\n  for (const encQ of encQs) {\n    if (isDisabledAutoCountQuery(encQ)) {\n      continue; // Do not include this in the output.\n    }\n\n    const {channel} = encQ;\n\n    // if channel is a wildcard, return null\n    if (isWildcard(channel)) {\n      throw new Error('Cannot convert wildcard channel to a fixed channel');\n    }\n    const channelDef = isValueQuery(encQ) ? toValueDef(encQ) : toFieldDef(encQ, params);\n\n    if (channelDef === null) {\n      if (params.wildcardMode === 'null') {\n        // contains invalid property (e.g., wildcard, thus cannot return a proper spec.)\n        return null;\n      }\n      continue;\n    }\n    // Otherwise, we can set the channelDef\n    encoding[channel] = channelDef;\n  }\n  return encoding;\n}\n\nexport function toValueDef(valueQ: ValueQuery): ValueDef {\n  const {value} = valueQ;\n  if (isWildcard(value)) {\n    return null;\n  }\n  return {value};\n}\n\nexport function toFieldDef(\n  encQ: FieldQuery | AutoCountQuery,\n  params: ConversionParams = {}\n): vlChannelDef.TypedFieldDef<string> {\n  const {props = DEFAULT_PROPS, schema, wildcardMode = 'skip'} = params;\n\n  if (isFieldQuery(encQ)) {\n    const fieldDef = {} as vlChannelDef.TypedFieldDef<string>;\n    for (const prop of props) {\n      let encodingProperty = encQ[prop];\n      if (isWildcard(encodingProperty)) {\n        if (wildcardMode === 'skip') continue;\n        return null;\n      }\n\n      if (encodingProperty !== undefined) {\n        // if the channel supports this prop\n        const isSupportedByChannel =\n          !PROPERTY_SUPPORTED_CHANNELS[prop] || PROPERTY_SUPPORTED_CHANNELS[prop][encQ.channel as ExtendedChannel];\n        if (!isSupportedByChannel) {\n          continue;\n        }\n\n        if (isEncodingNestedParent(prop) && isObject(encodingProperty)) {\n          encodingProperty = {...encodingProperty}; // Make a shallow copy first\n          for (const childProp in encodingProperty) {\n            // ensure nested properties are not wildcard before assigning to field def\n            if (isWildcard(encodingProperty[childProp])) {\n              if (wildcardMode === 'null') {\n                return null;\n              }\n              delete encodingProperty[childProp]; // skip\n            }\n          }\n        }\n\n        if (prop === 'bin' && encodingProperty === false) {\n          continue;\n        } else if (prop === 'type' && encodingProperty === 'key') {\n          fieldDef.type = 'nominal';\n        } else {\n          fieldDef[prop] = encodingProperty;\n        }\n      }\n\n      if (prop === Property.SCALE && schema && encQ.type === TYPE.ORDINAL) {\n        const scale = encQ.scale;\n        const {ordinalDomain} = schema.fieldSchema(encQ.field as string);\n\n        if (scale !== null && ordinalDomain) {\n          fieldDef[Property.SCALE] = {\n            domain: ordinalDomain,\n            // explicitly specfied domain property should override ordinalDomain\n            ...(isObject(scale) ? scale : {}),\n          };\n        }\n      }\n    }\n    return fieldDef;\n  } else {\n    if (encQ.autoCount === false) {\n      throw new Error(`Cannot convert {autoCount: false} into a field def`);\n    } else {\n      return {\n        aggregate: 'count',\n        field: '*',\n        type: 'quantitative',\n      };\n    }\n  }\n}\n\n/**\n * Is a field query continuous field?\n * This method is applicable only for fieldQuery without wildcard\n */\nexport function isContinuous(encQ: EncodingQuery) {\n  if (isFieldQuery(encQ)) {\n    return vlChannelDef.isContinuous(toFieldDef(encQ, {props: ['bin', 'timeUnit', 'field', 'type']}));\n  }\n  return isAutoCountQuery(encQ);\n}\n\nexport function isMeasure(encQ: EncodingQuery) {\n  if (isFieldQuery(encQ)) {\n    return !isDimension(encQ) && encQ.type !== 'temporal';\n  }\n  return isAutoCountQuery(encQ);\n}\n\n/**\n * Is a field query discrete field?\n * This method is applicable only for fieldQuery without wildcard\n */\nexport function isDimension(encQ: EncodingQuery) {\n  if (isFieldQuery(encQ)) {\n    const props: FlatProp[] = encQ['field'] ? ['field', 'bin', 'timeUnit', 'type'] : ['bin', 'timeUnit', 'type'];\n    const fieldDef = toFieldDef(encQ, {props: props});\n    return vlChannelDef.isDiscrete(fieldDef) || !!fieldDef.timeUnit;\n  }\n  return false;\n}\n\n/**\n *  Returns the true scale type of an encoding.\n *  @returns {ScaleType} If the scale type was not specified, it is inferred from the encoding's TYPE.\n *  @returns {undefined} If the scale type was not specified and Type (or TimeUnit if applicable) is a Wildcard, there is no clear scale type\n */\n\nexport function scaleType(fieldQ: FieldQuery) {\n  const scale: ScaleQuery = fieldQ.scale === true || fieldQ.scale === SHORT_WILDCARD ? {} : fieldQ.scale || {};\n\n  const {type, channel, timeUnit, bin} = fieldQ;\n\n  // HACK: All of markType, and scaleConfig only affect\n  // sub-type of ordinal to quantitative scales (point or band)\n  // Currently, most of scaleType usage in CompassQL doesn't care about this subtle difference.\n  // Thus, instead of making this method requiring the global mark,\n  // we will just call it with mark = undefined .\n  // Thus, currently, we will always get a point scale unless a CompassQuery specifies band.\n  const markType: Mark = undefined;\n\n  if (isWildcard(scale.type) || isWildcard(type) || isWildcard(channel) || isWildcard(bin)) {\n    return undefined;\n  }\n\n  if (channel === 'row' || channel === 'column' || channel === 'facet') {\n    return undefined;\n  }\n\n  // If scale type is specified, then use scale.type\n  if (scale.type) {\n    return scale.type;\n  }\n\n  // if type is fixed and it's not temporal, we can ignore time unit.\n  if (type === 'temporal' && isWildcard(timeUnit)) {\n    return undefined;\n  }\n\n  // if type is fixed and it's not quantitative, we can ignore bin\n  if (type === 'quantitative' && isWildcard(bin)) {\n    return undefined;\n  }\n\n  const vegaLiteType: VLType = type === ExpandedType.KEY ? 'nominal' : type;\n\n  const fieldDef = {\n    type: vegaLiteType,\n    timeUnit: timeUnit as TimeUnit,\n    bin: bin as BinParams,\n  };\n  return compileScaleType({type: scale.type}, channel, fieldDef, markType);\n}\n","(function (global, factory) {\n  typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n  typeof define === 'function' && define.amd ? define('d3-time', ['exports'], factory) :\n  factory((global.d3_time = {}));\n}(this, function (exports) { 'use strict';\n\n  var t0 = new Date;\n  var t1 = new Date;\n  function newInterval(floori, offseti, count, field) {\n\n    function interval(date) {\n      return floori(date = new Date(+date)), date;\n    }\n\n    interval.floor = interval;\n\n    interval.round = function(date) {\n      var d0 = new Date(+date),\n          d1 = new Date(date - 1);\n      floori(d0), floori(d1), offseti(d1, 1);\n      return date - d0 < d1 - date ? d0 : d1;\n    };\n\n    interval.ceil = function(date) {\n      return floori(date = new Date(date - 1)), offseti(date, 1), date;\n    };\n\n    interval.offset = function(date, step) {\n      return offseti(date = new Date(+date), step == null ? 1 : Math.floor(step)), date;\n    };\n\n    interval.range = function(start, stop, step) {\n      var range = [];\n      start = new Date(start - 1);\n      stop = new Date(+stop);\n      step = step == null ? 1 : Math.floor(step);\n      if (!(start < stop) || !(step > 0)) return range; // also handles Invalid Date\n      offseti(start, 1), floori(start);\n      if (start < stop) range.push(new Date(+start));\n      while (offseti(start, step), floori(start), start < stop) range.push(new Date(+start));\n      return range;\n    };\n\n    interval.filter = function(test) {\n      return newInterval(function(date) {\n        while (floori(date), !test(date)) date.setTime(date - 1);\n      }, function(date, step) {\n        while (--step >= 0) while (offseti(date, 1), !test(date));\n      });\n    };\n\n    if (count) {\n      interval.count = function(start, end) {\n        t0.setTime(+start), t1.setTime(+end);\n        floori(t0), floori(t1);\n        return Math.floor(count(t0, t1));\n      };\n\n      interval.every = function(step) {\n        step = Math.floor(step);\n        return !isFinite(step) || !(step > 0) ? null\n            : !(step > 1) ? interval\n            : interval.filter(field\n                ? function(d) { return field(d) % step === 0; }\n                : function(d) { return interval.count(0, d) % step === 0; });\n      };\n    }\n\n    return interval;\n  };\n\n  var millisecond = newInterval(function() {\n    // noop\n  }, function(date, step) {\n    date.setTime(+date + step);\n  }, function(start, end) {\n    return end - start;\n  });\n\n  // An optimized implementation for this simple case.\n  millisecond.every = function(k) {\n    k = Math.floor(k);\n    if (!isFinite(k) || !(k > 0)) return null;\n    if (!(k > 1)) return millisecond;\n    return newInterval(function(date) {\n      date.setTime(Math.floor(date / k) * k);\n    }, function(date, step) {\n      date.setTime(+date + step * k);\n    }, function(start, end) {\n      return (end - start) / k;\n    });\n  };\n\n  var second = newInterval(function(date) {\n    date.setMilliseconds(0);\n  }, function(date, step) {\n    date.setTime(+date + step * 1e3);\n  }, function(start, end) {\n    return (end - start) / 1e3;\n  }, function(date) {\n    return date.getSeconds();\n  });\n\n  var minute = newInterval(function(date) {\n    date.setSeconds(0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 6e4);\n  }, function(start, end) {\n    return (end - start) / 6e4;\n  }, function(date) {\n    return date.getMinutes();\n  });\n\n  var hour = newInterval(function(date) {\n    date.setMinutes(0, 0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 36e5);\n  }, function(start, end) {\n    return (end - start) / 36e5;\n  }, function(date) {\n    return date.getHours();\n  });\n\n  var day = newInterval(function(date) {\n    date.setHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setDate(date.getDate() + step);\n  }, function(start, end) {\n    return (end - start - (end.getTimezoneOffset() - start.getTimezoneOffset()) * 6e4) / 864e5;\n  }, function(date) {\n    return date.getDate() - 1;\n  });\n\n  function weekday(i) {\n    return newInterval(function(date) {\n      date.setHours(0, 0, 0, 0);\n      date.setDate(date.getDate() - (date.getDay() + 7 - i) % 7);\n    }, function(date, step) {\n      date.setDate(date.getDate() + step * 7);\n    }, function(start, end) {\n      return (end - start - (end.getTimezoneOffset() - start.getTimezoneOffset()) * 6e4) / 6048e5;\n    });\n  }\n\n  var sunday = weekday(0);\n  var monday = weekday(1);\n  var tuesday = weekday(2);\n  var wednesday = weekday(3);\n  var thursday = weekday(4);\n  var friday = weekday(5);\n  var saturday = weekday(6);\n\n  var month = newInterval(function(date) {\n    date.setHours(0, 0, 0, 0);\n    date.setDate(1);\n  }, function(date, step) {\n    date.setMonth(date.getMonth() + step);\n  }, function(start, end) {\n    return end.getMonth() - start.getMonth() + (end.getFullYear() - start.getFullYear()) * 12;\n  }, function(date) {\n    return date.getMonth();\n  });\n\n  var year = newInterval(function(date) {\n    date.setHours(0, 0, 0, 0);\n    date.setMonth(0, 1);\n  }, function(date, step) {\n    date.setFullYear(date.getFullYear() + step);\n  }, function(start, end) {\n    return end.getFullYear() - start.getFullYear();\n  }, function(date) {\n    return date.getFullYear();\n  });\n\n  var utcSecond = newInterval(function(date) {\n    date.setUTCMilliseconds(0);\n  }, function(date, step) {\n    date.setTime(+date + step * 1e3);\n  }, function(start, end) {\n    return (end - start) / 1e3;\n  }, function(date) {\n    return date.getUTCSeconds();\n  });\n\n  var utcMinute = newInterval(function(date) {\n    date.setUTCSeconds(0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 6e4);\n  }, function(start, end) {\n    return (end - start) / 6e4;\n  }, function(date) {\n    return date.getUTCMinutes();\n  });\n\n  var utcHour = newInterval(function(date) {\n    date.setUTCMinutes(0, 0, 0);\n  }, function(date, step) {\n    date.setTime(+date + step * 36e5);\n  }, function(start, end) {\n    return (end - start) / 36e5;\n  }, function(date) {\n    return date.getUTCHours();\n  });\n\n  var utcDay = newInterval(function(date) {\n    date.setUTCHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setUTCDate(date.getUTCDate() + step);\n  }, function(start, end) {\n    return (end - start) / 864e5;\n  }, function(date) {\n    return date.getUTCDate() - 1;\n  });\n\n  function utcWeekday(i) {\n    return newInterval(function(date) {\n      date.setUTCHours(0, 0, 0, 0);\n      date.setUTCDate(date.getUTCDate() - (date.getUTCDay() + 7 - i) % 7);\n    }, function(date, step) {\n      date.setUTCDate(date.getUTCDate() + step * 7);\n    }, function(start, end) {\n      return (end - start) / 6048e5;\n    });\n  }\n\n  var utcSunday = utcWeekday(0);\n  var utcMonday = utcWeekday(1);\n  var utcTuesday = utcWeekday(2);\n  var utcWednesday = utcWeekday(3);\n  var utcThursday = utcWeekday(4);\n  var utcFriday = utcWeekday(5);\n  var utcSaturday = utcWeekday(6);\n\n  var utcMonth = newInterval(function(date) {\n    date.setUTCHours(0, 0, 0, 0);\n    date.setUTCDate(1);\n  }, function(date, step) {\n    date.setUTCMonth(date.getUTCMonth() + step);\n  }, function(start, end) {\n    return end.getUTCMonth() - start.getUTCMonth() + (end.getUTCFullYear() - start.getUTCFullYear()) * 12;\n  }, function(date) {\n    return date.getUTCMonth();\n  });\n\n  var utcYear = newInterval(function(date) {\n    date.setUTCHours(0, 0, 0, 0);\n    date.setUTCMonth(0, 1);\n  }, function(date, step) {\n    date.setUTCFullYear(date.getUTCFullYear() + step);\n  }, function(start, end) {\n    return end.getUTCFullYear() - start.getUTCFullYear();\n  }, function(date) {\n    return date.getUTCFullYear();\n  });\n\n  var milliseconds = millisecond.range;\n  var seconds = second.range;\n  var minutes = minute.range;\n  var hours = hour.range;\n  var days = day.range;\n  var sundays = sunday.range;\n  var mondays = monday.range;\n  var tuesdays = tuesday.range;\n  var wednesdays = wednesday.range;\n  var thursdays = thursday.range;\n  var fridays = friday.range;\n  var saturdays = saturday.range;\n  var weeks = sunday.range;\n  var months = month.range;\n  var years = year.range;\n\n  var utcMillisecond = millisecond;\n  var utcMilliseconds = milliseconds;\n  var utcSeconds = utcSecond.range;\n  var utcMinutes = utcMinute.range;\n  var utcHours = utcHour.range;\n  var utcDays = utcDay.range;\n  var utcSundays = utcSunday.range;\n  var utcMondays = utcMonday.range;\n  var utcTuesdays = utcTuesday.range;\n  var utcWednesdays = utcWednesday.range;\n  var utcThursdays = utcThursday.range;\n  var utcFridays = utcFriday.range;\n  var utcSaturdays = utcSaturday.range;\n  var utcWeeks = utcSunday.range;\n  var utcMonths = utcMonth.range;\n  var utcYears = utcYear.range;\n\n  var version = \"0.1.1\";\n\n  exports.version = version;\n  exports.milliseconds = milliseconds;\n  exports.seconds = seconds;\n  exports.minutes = minutes;\n  exports.hours = hours;\n  exports.days = days;\n  exports.sundays = sundays;\n  exports.mondays = mondays;\n  exports.tuesdays = tuesdays;\n  exports.wednesdays = wednesdays;\n  exports.thursdays = thursdays;\n  exports.fridays = fridays;\n  exports.saturdays = saturdays;\n  exports.weeks = weeks;\n  exports.months = months;\n  exports.years = years;\n  exports.utcMillisecond = utcMillisecond;\n  exports.utcMilliseconds = utcMilliseconds;\n  exports.utcSeconds = utcSeconds;\n  exports.utcMinutes = utcMinutes;\n  exports.utcHours = utcHours;\n  exports.utcDays = utcDays;\n  exports.utcSundays = utcSundays;\n  exports.utcMondays = utcMondays;\n  exports.utcTuesdays = utcTuesdays;\n  exports.utcWednesdays = utcWednesdays;\n  exports.utcThursdays = utcThursdays;\n  exports.utcFridays = utcFridays;\n  exports.utcSaturdays = utcSaturdays;\n  exports.utcWeeks = utcWeeks;\n  exports.utcMonths = utcMonths;\n  exports.utcYears = utcYears;\n  exports.millisecond = millisecond;\n  exports.second = second;\n  exports.minute = minute;\n  exports.hour = hour;\n  exports.day = day;\n  exports.sunday = sunday;\n  exports.monday = monday;\n  exports.tuesday = tuesday;\n  exports.wednesday = wednesday;\n  exports.thursday = thursday;\n  exports.friday = friday;\n  exports.saturday = saturday;\n  exports.week = sunday;\n  exports.month = month;\n  exports.year = year;\n  exports.utcSecond = utcSecond;\n  exports.utcMinute = utcMinute;\n  exports.utcHour = utcHour;\n  exports.utcDay = utcDay;\n  exports.utcSunday = utcSunday;\n  exports.utcMonday = utcMonday;\n  exports.utcTuesday = utcTuesday;\n  exports.utcWednesday = utcWednesday;\n  exports.utcThursday = utcThursday;\n  exports.utcFriday = utcFriday;\n  exports.utcSaturday = utcSaturday;\n  exports.utcWeek = utcSunday;\n  exports.utcMonth = utcMonth;\n  exports.utcYear = utcYear;\n  exports.interval = newInterval;\n\n}));","var d3_time = require('d3-time');\n\nvar tempDate = new Date(),\n    baseDate = new Date(2000, 0, 1),\n    utcBaseDate = new Date(Date.UTC(2000, 0, 1));\n\nfunction date(d) {\n  return (tempDate.setTime(+d), tempDate);\n}\n\n// create a time unit entry\nfunction entry(type, date, unit, step, min, max) {\n  var e = {\n    type: type,\n    date: date,\n    unit: unit\n  };\n  if (step) {\n    e.step = step;\n  } else {\n    e.minstep = 1;\n  }\n  if (min != null) e.min = min;\n  if (max != null) e.max = max;\n  return e;\n}\n\nfunction create(type, unit, base, step, min, max) {\n  return entry(type,\n    function(d) { return unit.offset(base, d); },\n    function(d) { return unit.count(base, d); },\n    step, min, max);\n}\n\nvar locale = [\n  create('second', d3_time.second, baseDate),\n  create('minute', d3_time.minute, baseDate),\n  create('hour',   d3_time.hour,   baseDate),\n  create('day',    d3_time.day,    baseDate, [1, 7]),\n  create('month',  d3_time.month,  baseDate, [1, 3, 6]),\n  create('year',   d3_time.year,   new Date(baseDate).setFullYear(0)),\n\n  // periodic units\n  entry('seconds',\n    function(d) { return new Date(1970, 0, 1, 0, 0, d); },\n    function(d) { return date(d).getSeconds(); },\n    null, 0, 59\n  ),\n  entry('minutes',\n    function(d) { return new Date(1970, 0, 1, 0, d); },\n    function(d) { return date(d).getMinutes(); },\n    null, 0, 59\n  ),\n  entry('hours',\n    function(d) { return new Date(1970, 0, 1, d); },\n    function(d) { return date(d).getHours(); },\n    null, 0, 23\n  ),\n  entry('weekdays',\n    function(d) { return new Date(1970, 0, 4+d); },\n    function(d) { return date(d).getDay(); },\n    [1], 0, 6\n  ),\n  entry('dates',\n    function(d) { return new Date(1970, 0, d); },\n    function(d) { return date(d).getDate(); },\n    [1], 1, 31\n  ),\n  entry('months',\n    function(d) { return new Date(1970, d % 12, 1); },\n    function(d) { return date(d).getMonth(); },\n    [1], 0, 11\n  )\n];\n\nvar utc = [\n  create('second', d3_time.utcSecond, utcBaseDate),\n  create('minute', d3_time.utcMinute, utcBaseDate),\n  create('hour',   d3_time.utcHour,   utcBaseDate),\n  create('day',    d3_time.utcDay,    utcBaseDate, [1, 7]),\n  create('month',  d3_time.utcMonth,  utcBaseDate, [1, 3, 6]),\n  create('year',   d3_time.utcYear,   new Date(utcBaseDate).setUTCFullYear(0)),\n\n  // periodic units\n  entry('seconds',\n    function(d) { return new Date(Date.UTC(1970, 0, 1, 0, 0, d)); },\n    function(d) { return date(d).getUTCSeconds(); },\n    null, 0, 59\n  ),\n  entry('minutes',\n    function(d) { return new Date(Date.UTC(1970, 0, 1, 0, d)); },\n    function(d) { return date(d).getUTCMinutes(); },\n    null, 0, 59\n  ),\n  entry('hours',\n    function(d) { return new Date(Date.UTC(1970, 0, 1, d)); },\n    function(d) { return date(d).getUTCHours(); },\n    null, 0, 23\n  ),\n  entry('weekdays',\n    function(d) { return new Date(Date.UTC(1970, 0, 4+d)); },\n    function(d) { return date(d).getUTCDay(); },\n    [1], 0, 6\n  ),\n  entry('dates',\n    function(d) { return new Date(Date.UTC(1970, 0, d)); },\n    function(d) { return date(d).getUTCDate(); },\n    [1], 1, 31\n  ),\n  entry('months',\n    function(d) { return new Date(Date.UTC(1970, d % 12, 1)); },\n    function(d) { return date(d).getUTCMonth(); },\n    [1], 0, 11\n  )\n];\n\nvar STEPS = [\n  [31536e6, 5],  // 1-year\n  [7776e6, 4],   // 3-month\n  [2592e6, 4],   // 1-month\n  [12096e5, 3],  // 2-week\n  [6048e5, 3],   // 1-week\n  [1728e5, 3],   // 2-day\n  [864e5, 3],    // 1-day\n  [432e5, 2],    // 12-hour\n  [216e5, 2],    // 6-hour\n  [108e5, 2],    // 3-hour\n  [36e5, 2],     // 1-hour\n  [18e5, 1],     // 30-minute\n  [9e5, 1],      // 15-minute\n  [3e5, 1],      // 5-minute\n  [6e4, 1],      // 1-minute\n  [3e4, 0],      // 30-second\n  [15e3, 0],     // 15-second\n  [5e3, 0],      // 5-second\n  [1e3, 0]       // 1-second\n];\n\nfunction find(units, span, minb, maxb) {\n  var step = STEPS[0], i, n, bins;\n\n  for (i=1, n=STEPS.length; i<n; ++i) {\n    step = STEPS[i];\n    if (span > step[0]) {\n      bins = span / step[0];\n      if (bins > maxb) {\n        return units[STEPS[i-1][1]];\n      }\n      if (bins >= minb) {\n        return units[step[1]];\n      }\n    }\n  }\n  return units[STEPS[n-1][1]];\n}\n\nfunction toUnitMap(units) {\n  var map = {}, i, n;\n  for (i=0, n=units.length; i<n; ++i) {\n    map[units[i].type] = units[i];\n  }\n  map.find = function(span, minb, maxb) {\n    return find(units, span, minb, maxb);\n  };\n  return map;\n}\n\nmodule.exports = toUnitMap(locale);\nmodule.exports.utc = toUnitMap(utc);","var util = require('../util'),\n    time = require('../time'),\n    EPSILON = 1e-14;\n\nfunction bins(opt) {\n  if (!opt) { throw Error(\"Missing binning options.\"); }\n\n  // determine range\n  var maxb = opt.maxbins || 15,\n      base = opt.base || 10,\n      logb = Math.log(base),\n      div = opt.div || [5, 2],\n      min = opt.min,\n      max = opt.max,\n      span = max - min,\n      step, level, minstep, precision, v, i, eps;\n\n  if (opt.step) {\n    // if step size is explicitly given, use that\n    step = opt.step;\n  } else if (opt.steps) {\n    // if provided, limit choice to acceptable step sizes\n    step = opt.steps[Math.min(\n      opt.steps.length - 1,\n      bisect(opt.steps, span/maxb, 0, opt.steps.length)\n    )];\n  } else {\n    // else use span to determine step size\n    level = Math.ceil(Math.log(maxb) / logb);\n    minstep = opt.minstep || 0;\n    step = Math.max(\n      minstep,\n      Math.pow(base, Math.round(Math.log(span) / logb) - level)\n    );\n\n    // increase step size if too many bins\n    while (Math.ceil(span/step) > maxb) { step *= base; }\n\n    // decrease step size if allowed\n    for (i=0; i<div.length; ++i) {\n      v = step / div[i];\n      if (v >= minstep && span / v <= maxb) step = v;\n    }\n  }\n\n  // update precision, min and max\n  v = Math.log(step);\n  precision = v >= 0 ? 0 : ~~(-v / logb) + 1;\n  eps = Math.pow(base, -precision - 1);\n  min = Math.min(min, Math.floor(min / step + eps) * step);\n  max = Math.ceil(max / step) * step;\n\n  return {\n    start: min,\n    stop:  max,\n    step:  step,\n    unit:  {precision: precision},\n    value: value,\n    index: index\n  };\n}\n\nfunction bisect(a, x, lo, hi) {\n  while (lo < hi) {\n    var mid = lo + hi >>> 1;\n    if (util.cmp(a[mid], x) < 0) { lo = mid + 1; }\n    else { hi = mid; }\n  }\n  return lo;\n}\n\nfunction value(v) {\n  return this.start + this.step * Math.floor((EPSILON + (v - this.start)) / this.step);\n}\n\n\nfunction index(v) {\n  return Math.floor((v - this.start) / this.step + EPSILON);\n}\n\nfunction date_value(v) {\n  return this.unit.date(value.call(this, v));\n}\n\nfunction date_index(v) {\n  return index.call(this, this.unit.unit(v));\n}\n\nbins.date = function(opt) {\n  if (!opt) { throw Error(\"Missing date binning options.\"); }\n\n  // find time step, then bin\n  var units = opt.utc ? time.utc : time,\n      dmin = opt.min,\n      dmax = opt.max,\n      maxb = opt.maxbins || 20,\n      minb = opt.minbins || 4,\n      span = (+dmax) - (+dmin),\n      unit = opt.unit ? units[opt.unit] : units.find(span, minb, maxb),\n      spec = bins({\n        min:     unit.min != null ? unit.min : unit.unit(dmin),\n        max:     unit.max != null ? unit.max : unit.unit(dmax),\n        maxbins: maxb,\n        minstep: unit.minstep,\n        steps:   unit.step\n      });\n\n  spec.unit = unit;\n  spec.index = date_index;\n  if (!opt.raw) spec.value = date_value;\n  return spec;\n};\n\nmodule.exports = bins;\n","var util = require('../util');\n\nvar TYPES = '__types__';\n\nvar PARSERS = {\n  boolean: util.boolean,\n  integer: util.number,\n  number:  util.number,\n  date:    util.date,\n  string:  function(x) { return x == null || x === '' ? null : x + ''; }\n};\n\nvar TESTS = {\n  boolean: function(x) { return x==='true' || x==='false' || util.isBoolean(x); },\n  integer: function(x) { return TESTS.number(x) && (x=+x) === ~~x; },\n  number: function(x) { return !isNaN(+x) && !util.isDate(x); },\n  date: function(x) { return !isNaN(Date.parse(x)); }\n};\n\nfunction annotation(data, types) {\n  if (!types) return data && data[TYPES] || null;\n  data[TYPES] = types;\n}\n\nfunction fieldNames(datum) {\n  return util.keys(datum);\n}\n\nfunction bracket(fieldName) {\n  return '[' + fieldName + ']';\n}\n\nfunction type(values, f) {\n  values = util.array(values);\n  f = util.$(f);\n  var v, i, n;\n\n  // if data array has type annotations, use them\n  if (values[TYPES]) {\n    v = f(values[TYPES]);\n    if (util.isString(v)) return v;\n  }\n\n  for (i=0, n=values.length; !util.isValid(v) && i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n  }\n\n  return util.isDate(v) ? 'date' :\n    util.isNumber(v)    ? 'number' :\n    util.isBoolean(v)   ? 'boolean' :\n    util.isString(v)    ? 'string' : null;\n}\n\nfunction typeAll(data, fields) {\n  if (!data.length) return;\n  var get = fields ? util.identity : (fields = fieldNames(data[0]), bracket);\n  return fields.reduce(function(types, f) {\n    return (types[f] = type(data, get(f)), types);\n  }, {});\n}\n\nfunction infer(values, f, ignore) {\n  values = util.array(values);\n  f = util.$(f);\n  var i, j, v;\n\n  // types to test for, in precedence order\n  var types = ['boolean', 'integer', 'number', 'date'];\n\n  for (i=0; i<values.length; ++i) {\n    // get next value to test\n    v = f ? f(values[i]) : values[i];\n    // test value against remaining types\n    for (j=0; j<types.length; ++j) {\n      if ((!ignore || !ignore.test(v)) && util.isValid(v) && !TESTS[types[j]](v)) {\n        types.splice(j, 1);\n        j -= 1;\n      }\n    }\n    // if no types left, return 'string'\n    if (types.length === 0) return 'string';\n  }\n\n  return types[0];\n}\n\nfunction inferAll(data, fields, ignore) {\n  var get = fields ? util.identity : (fields = fieldNames(data[0]), bracket);\n  return fields.reduce(function(types, f) {\n    types[f] = infer(data, get(f), ignore);\n    return types;\n  }, {});\n}\n\ntype.annotation = annotation;\ntype.all = typeAll;\ntype.infer = infer;\ntype.inferAll = inferAll;\ntype.parsers = PARSERS;\nmodule.exports = type;\n","var util = require('./util'),\n    gen = module.exports;\n\ngen.repeat = function(val, n) {\n  var a = Array(n), i;\n  for (i=0; i<n; ++i) a[i] = val;\n  return a;\n};\n\ngen.zeros = function(n) {\n  return gen.repeat(0, n);\n};\n\ngen.range = function(start, stop, step) {\n  if (arguments.length < 3) {\n    step = 1;\n    if (arguments.length < 2) {\n      stop = start;\n      start = 0;\n    }\n  }\n  if ((stop - start) / step == Infinity) throw new Error('Infinite range');\n  var range = [], i = -1, j;\n  if (step < 0) while ((j = start + step * ++i) > stop) range.push(j);\n  else while ((j = start + step * ++i) < stop) range.push(j);\n  return range;\n};\n\ngen.random = {};\n\ngen.random.uniform = function(min, max) {\n  if (max === undefined) {\n    max = min === undefined ? 1 : min;\n    min = 0;\n  }\n  var d = max - min;\n  var f = function() {\n    return min + d * Math.random();\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  f.pdf = function(x) {\n    return (x >= min && x <= max) ? 1/d : 0;\n  };\n  f.cdf = function(x) {\n    return x < min ? 0 : x > max ? 1 : (x - min) / d;\n  };\n  f.icdf = function(p) {\n    return (p >= 0 && p <= 1) ? min + p*d : NaN;\n  };\n  return f;\n};\n\ngen.random.integer = function(a, b) {\n  if (b === undefined) {\n    b = a;\n    a = 0;\n  }\n  var d = b - a;\n  var f = function() {\n    return a + Math.floor(d * Math.random());\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  f.pdf = function(x) {\n    return (x === Math.floor(x) && x >= a && x < b) ? 1/d : 0;\n  };\n  f.cdf = function(x) {\n    var v = Math.floor(x);\n    return v < a ? 0 : v >= b ? 1 : (v - a + 1) / d;\n  };\n  f.icdf = function(p) {\n    return (p >= 0 && p <= 1) ? a - 1 + Math.floor(p*d) : NaN;\n  };\n  return f;\n};\n\ngen.random.normal = function(mean, stdev) {\n  mean = mean || 0;\n  stdev = stdev || 1;\n  var next;\n  var f = function() {\n    var x = 0, y = 0, rds, c;\n    if (next !== undefined) {\n      x = next;\n      next = undefined;\n      return x;\n    }\n    do {\n      x = Math.random()*2-1;\n      y = Math.random()*2-1;\n      rds = x*x + y*y;\n    } while (rds === 0 || rds > 1);\n    c = Math.sqrt(-2*Math.log(rds)/rds); // Box-Muller transform\n    next = mean + y*c*stdev;\n    return mean + x*c*stdev;\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  f.pdf = function(x) {\n    var exp = Math.exp(Math.pow(x-mean, 2) / (-2 * Math.pow(stdev, 2)));\n    return (1 / (stdev * Math.sqrt(2*Math.PI))) * exp;\n  };\n  f.cdf = function(x) {\n    // Approximation from West (2009)\n    // Better Approximations to Cumulative Normal Functions\n    var cd,\n        z = (x - mean) / stdev,\n        Z = Math.abs(z);\n    if (Z > 37) {\n      cd = 0;\n    } else {\n      var sum, exp = Math.exp(-Z*Z/2);\n      if (Z < 7.07106781186547) {\n        sum = 3.52624965998911e-02 * Z + 0.700383064443688;\n        sum = sum * Z + 6.37396220353165;\n        sum = sum * Z + 33.912866078383;\n        sum = sum * Z + 112.079291497871;\n        sum = sum * Z + 221.213596169931;\n        sum = sum * Z + 220.206867912376;\n        cd = exp * sum;\n        sum = 8.83883476483184e-02 * Z + 1.75566716318264;\n        sum = sum * Z + 16.064177579207;\n        sum = sum * Z + 86.7807322029461;\n        sum = sum * Z + 296.564248779674;\n        sum = sum * Z + 637.333633378831;\n        sum = sum * Z + 793.826512519948;\n        sum = sum * Z + 440.413735824752;\n        cd = cd / sum;\n      } else {\n        sum = Z + 0.65;\n        sum = Z + 4 / sum;\n        sum = Z + 3 / sum;\n        sum = Z + 2 / sum;\n        sum = Z + 1 / sum;\n        cd = exp / sum / 2.506628274631;\n      }\n    }\n    return z > 0 ? 1 - cd : cd;\n  };\n  f.icdf = function(p) {\n    // Approximation of Probit function using inverse error function.\n    if (p <= 0 || p >= 1) return NaN;\n    var x = 2*p - 1,\n        v = (8 * (Math.PI - 3)) / (3 * Math.PI * (4-Math.PI)),\n        a = (2 / (Math.PI*v)) + (Math.log(1 - Math.pow(x,2)) / 2),\n        b = Math.log(1 - (x*x)) / v,\n        s = (x > 0 ? 1 : -1) * Math.sqrt(Math.sqrt((a*a) - b) - a);\n    return mean + stdev * Math.SQRT2 * s;\n  };\n  return f;\n};\n\ngen.random.bootstrap = function(domain, smooth) {\n  // Generates a bootstrap sample from a set of observations.\n  // Smooth bootstrapping adds random zero-centered noise to the samples.\n  var val = domain.filter(util.isValid),\n      len = val.length,\n      err = smooth ? gen.random.normal(0, smooth) : null;\n  var f = function() {\n    return val[~~(Math.random()*len)] + (err ? err() : 0);\n  };\n  f.samples = function(n) {\n    return gen.zeros(n).map(f);\n  };\n  return f;\n};","var util = require('./util');\nvar type = require('./import/type');\nvar gen = require('./generate');\n\nvar stats = module.exports;\n\n// Collect unique values.\n// Output: an array of unique values, in first-observed order\nstats.unique = function(values, f, results) {\n  f = util.$(f);\n  results = results || [];\n  var u = {}, v, i, n;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (v in u) continue;\n    u[v] = 1;\n    results.push(v);\n  }\n  return results;\n};\n\n// Return the length of the input array.\nstats.count = function(values) {\n  return values && values.length || 0;\n};\n\n// Count the number of non-null, non-undefined, non-NaN values.\nstats.count.valid = function(values, f) {\n  f = util.$(f);\n  var v, i, n, valid = 0;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) valid += 1;\n  }\n  return valid;\n};\n\n// Count the number of null or undefined values.\nstats.count.missing = function(values, f) {\n  f = util.$(f);\n  var v, i, n, count = 0;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (v == null) count += 1;\n  }\n  return count;\n};\n\n// Count the number of distinct values.\n// Null, undefined and NaN are each considered distinct values.\nstats.count.distinct = function(values, f) {\n  f = util.$(f);\n  var u = {}, v, i, n, count = 0;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (v in u) continue;\n    u[v] = 1;\n    count += 1;\n  }\n  return count;\n};\n\n// Construct a map from distinct values to occurrence counts.\nstats.count.map = function(values, f) {\n  f = util.$(f);\n  var map = {}, v, i, n;\n  for (i=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    map[v] = (v in map) ? map[v] + 1 : 1;\n  }\n  return map;\n};\n\n// Compute the median of an array of numbers.\nstats.median = function(values, f) {\n  if (f) values = values.map(util.$(f));\n  values = values.filter(util.isValid).sort(util.cmp);\n  return stats.quantile(values, 0.5);\n};\n\n// Computes the quartile boundaries of an array of numbers.\nstats.quartile = function(values, f) {\n  if (f) values = values.map(util.$(f));\n  values = values.filter(util.isValid).sort(util.cmp);\n  var q = stats.quantile;\n  return [q(values, 0.25), q(values, 0.50), q(values, 0.75)];\n};\n\n// Compute the quantile of a sorted array of numbers.\n// Adapted from the D3.js implementation.\nstats.quantile = function(values, f, p) {\n  if (p === undefined) { p = f; f = util.identity; }\n  f = util.$(f);\n  var H = (values.length - 1) * p + 1,\n      h = Math.floor(H),\n      v = +f(values[h - 1]),\n      e = H - h;\n  return e ? v + e * (f(values[h]) - v) : v;\n};\n\n// Compute the sum of an array of numbers.\nstats.sum = function(values, f) {\n  f = util.$(f);\n  for (var sum=0, i=0, n=values.length, v; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) sum += v;\n  }\n  return sum;\n};\n\n// Compute the mean (average) of an array of numbers.\nstats.mean = function(values, f) {\n  f = util.$(f);\n  var mean = 0, delta, i, n, c, v;\n  for (i=0, c=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      delta = v - mean;\n      mean = mean + delta / (++c);\n    }\n  }\n  return mean;\n};\n\n// Compute the geometric mean of an array of numbers.\nstats.mean.geometric = function(values, f) {\n  f = util.$(f);\n  var mean = 1, c, n, v, i;\n  for (i=0, c=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      if (v <= 0) {\n        throw Error(\"Geometric mean only defined for positive values.\");\n      }\n      mean *= v;\n      ++c;\n    }\n  }\n  mean = c > 0 ? Math.pow(mean, 1/c) : 0;\n  return mean;\n};\n\n// Compute the harmonic mean of an array of numbers.\nstats.mean.harmonic = function(values, f) {\n  f = util.$(f);\n  var mean = 0, c, n, v, i;\n  for (i=0, c=0, n=values.length; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      mean += 1/v;\n      ++c;\n    }\n  }\n  return c / mean;\n};\n\n// Compute the sample variance of an array of numbers.\nstats.variance = function(values, f) {\n  f = util.$(f);\n  if (!util.isArray(values) || values.length < 2) return 0;\n  var mean = 0, M2 = 0, delta, i, c, v;\n  for (i=0, c=0; i<values.length; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      delta = v - mean;\n      mean = mean + delta / (++c);\n      M2 = M2 + delta * (v - mean);\n    }\n  }\n  M2 = M2 / (c - 1);\n  return M2;\n};\n\n// Compute the sample standard deviation of an array of numbers.\nstats.stdev = function(values, f) {\n  return Math.sqrt(stats.variance(values, f));\n};\n\n// Compute the Pearson mode skewness ((median-mean)/stdev) of an array of numbers.\nstats.modeskew = function(values, f) {\n  var avg = stats.mean(values, f),\n      med = stats.median(values, f),\n      std = stats.stdev(values, f);\n  return std === 0 ? 0 : (avg - med) / std;\n};\n\n// Find the minimum value in an array.\nstats.min = function(values, f) {\n  return stats.extent(values, f)[0];\n};\n\n// Find the maximum value in an array.\nstats.max = function(values, f) {\n  return stats.extent(values, f)[1];\n};\n\n// Find the minimum and maximum of an array of values.\nstats.extent = function(values, f) {\n  f = util.$(f);\n  var a, b, v, i, n = values.length;\n  for (i=0; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) { a = b = v; break; }\n  }\n  for (; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      if (v < a) a = v;\n      if (v > b) b = v;\n    }\n  }\n  return [a, b];\n};\n\n// Find the integer indices of the minimum and maximum values.\nstats.extent.index = function(values, f) {\n  f = util.$(f);\n  var x = -1, y = -1, a, b, v, i, n = values.length;\n  for (i=0; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) { a = b = v; x = y = i; break; }\n  }\n  for (; i<n; ++i) {\n    v = f ? f(values[i]) : values[i];\n    if (util.isValid(v)) {\n      if (v < a) { a = v; x = i; }\n      if (v > b) { b = v; y = i; }\n    }\n  }\n  return [x, y];\n};\n\n// Compute the dot product of two arrays of numbers.\nstats.dot = function(values, a, b) {\n  var sum = 0, i, v;\n  if (!b) {\n    if (values.length !== a.length) {\n      throw Error('Array lengths must match.');\n    }\n    for (i=0; i<values.length; ++i) {\n      v = values[i] * a[i];\n      if (v === v) sum += v;\n    }\n  } else {\n    a = util.$(a);\n    b = util.$(b);\n    for (i=0; i<values.length; ++i) {\n      v = a(values[i]) * b(values[i]);\n      if (v === v) sum += v;\n    }\n  }\n  return sum;\n};\n\n// Compute the vector distance between two arrays of numbers.\n// Default is Euclidean (exp=2) distance, configurable via exp argument.\nstats.dist = function(values, a, b, exp) {\n  var f = util.isFunction(b) || util.isString(b),\n      X = values,\n      Y = f ? values : a,\n      e = f ? exp : b,\n      L2 = e === 2 || e == null,\n      n = values.length, s = 0, d, i;\n  if (f) {\n    a = util.$(a);\n    b = util.$(b);\n  }\n  for (i=0; i<n; ++i) {\n    d = f ? (a(X[i])-b(Y[i])) : (X[i]-Y[i]);\n    s += L2 ? d*d : Math.pow(Math.abs(d), e);\n  }\n  return L2 ? Math.sqrt(s) : Math.pow(s, 1/e);\n};\n\n// Compute the Cohen's d effect size between two arrays of numbers.\nstats.cohensd = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      x1 = stats.mean(X),\n      x2 = stats.mean(Y),\n      n1 = stats.count.valid(X),\n      n2 = stats.count.valid(Y);\n\n  if ((n1+n2-2) <= 0) {\n    // if both arrays are size 1, or one is empty, there's no effect size\n    return 0;\n  }\n  // pool standard deviation\n  var s1 = stats.variance(X),\n      s2 = stats.variance(Y),\n      s = Math.sqrt((((n1-1)*s1) + ((n2-1)*s2)) / (n1+n2-2));\n  // if there is no variance, there's no effect size\n  return s===0 ? 0 : (x1 - x2) / s;\n};\n\n// Computes the covariance between two arrays of numbers\nstats.covariance = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n = X.length,\n      xm = stats.mean(X),\n      ym = stats.mean(Y),\n      sum = 0, c = 0, i, x, y, vx, vy;\n\n  if (n !== Y.length) {\n    throw Error('Input lengths must match.');\n  }\n\n  for (i=0; i<n; ++i) {\n    x = X[i]; vx = util.isValid(x);\n    y = Y[i]; vy = util.isValid(y);\n    if (vx && vy) {\n      sum += (x-xm) * (y-ym);\n      ++c;\n    } else if (vx || vy) {\n      throw Error('Valid values must align.');\n    }\n  }\n  return sum / (c-1);\n};\n\n// Compute ascending rank scores for an array of values.\n// Ties are assigned their collective mean rank.\nstats.rank = function(values, f) {\n  f = util.$(f) || util.identity;\n  var a = values.map(function(v, i) {\n      return {idx: i, val: f(v)};\n    })\n    .sort(util.comparator('val'));\n\n  var n = values.length,\n      r = Array(n),\n      tie = -1, p = {}, i, v, mu;\n\n  for (i=0; i<n; ++i) {\n    v = a[i].val;\n    if (tie < 0 && p === v) {\n      tie = i - 1;\n    } else if (tie > -1 && p !== v) {\n      mu = 1 + (i-1 + tie) / 2;\n      for (; tie<i; ++tie) r[a[tie].idx] = mu;\n      tie = -1;\n    }\n    r[a[i].idx] = i + 1;\n    p = v;\n  }\n\n  if (tie > -1) {\n    mu = 1 + (n-1 + tie) / 2;\n    for (; tie<n; ++tie) r[a[tie].idx] = mu;\n  }\n\n  return r;\n};\n\n// Compute the sample Pearson product-moment correlation of two arrays of numbers.\nstats.cor = function(values, a, b) {\n  var fn = b;\n  b = fn ? values.map(util.$(b)) : a;\n  a = fn ? values.map(util.$(a)) : values;\n\n  var dot = stats.dot(a, b),\n      mua = stats.mean(a),\n      mub = stats.mean(b),\n      sda = stats.stdev(a),\n      sdb = stats.stdev(b),\n      n = values.length;\n\n  return (dot - n*mua*mub) / ((n-1) * sda * sdb);\n};\n\n// Compute the Spearman rank correlation of two arrays of values.\nstats.cor.rank = function(values, a, b) {\n  var ra = b ? stats.rank(values, a) : stats.rank(values),\n      rb = b ? stats.rank(values, b) : stats.rank(a),\n      n = values.length, i, s, d;\n\n  for (i=0, s=0; i<n; ++i) {\n    d = ra[i] - rb[i];\n    s += d * d;\n  }\n\n  return 1 - 6*s / (n * (n*n-1));\n};\n\n// Compute the distance correlation of two arrays of numbers.\n// http://en.wikipedia.org/wiki/Distance_correlation\nstats.cor.dist = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a;\n\n  var A = stats.dist.mat(X),\n      B = stats.dist.mat(Y),\n      n = A.length,\n      i, aa, bb, ab;\n\n  for (i=0, aa=0, bb=0, ab=0; i<n; ++i) {\n    aa += A[i]*A[i];\n    bb += B[i]*B[i];\n    ab += A[i]*B[i];\n  }\n\n  return Math.sqrt(ab / Math.sqrt(aa*bb));\n};\n\n// Simple linear regression.\n// Returns a \"fit\" object with slope (m), intercept (b),\n// r value (R), and sum-squared residual error (rss).\nstats.linearRegression = function(values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n = X.length,\n      xy = stats.covariance(X, Y), // will throw err if valid vals don't align\n      sx = stats.stdev(X),\n      sy = stats.stdev(Y),\n      slope = xy / (sx*sx),\n      icept = stats.mean(Y) - slope * stats.mean(X),\n      fit = {slope: slope, intercept: icept, R: xy / (sx*sy), rss: 0},\n      res, i;\n\n  for (i=0; i<n; ++i) {\n    if (util.isValid(X[i]) && util.isValid(Y[i])) {\n      res = (slope*X[i] + icept) - Y[i];\n      fit.rss += res * res;\n    }\n  }\n\n  return fit;\n};\n\n// Namespace for bootstrap\nstats.bootstrap = {};\n\n// Construct a bootstrapped confidence interval at a given percentile level\n// Arguments are an array, an optional n (defaults to 1000),\n//  an optional alpha (defaults to 0.05), and an optional smoothing parameter\nstats.bootstrap.ci = function(values, a, b, c, d) {\n  var X, N, alpha, smooth, bs, means, i;\n  if (util.isFunction(a) || util.isString(a)) {\n    X = values.map(util.$(a));\n    N = b;\n    alpha = c;\n    smooth = d;\n  } else {\n    X = values;\n    N = a;\n    alpha = b;\n    smooth = c;\n  }\n  N = N ? +N : 1000;\n  alpha = alpha || 0.05;\n\n  bs = gen.random.bootstrap(X, smooth);\n  for (i=0, means = Array(N); i<N; ++i) {\n    means[i] = stats.mean(bs.samples(X.length));\n  }\n  means.sort(util.numcmp);\n  return [\n    stats.quantile(means, alpha/2),\n    stats.quantile(means, 1-(alpha/2))\n  ];\n};\n\n// Namespace for z-tests\nstats.z = {};\n\n// Construct a z-confidence interval at a given significance level\n// Arguments are an array and an optional alpha (defaults to 0.05).\nstats.z.ci = function(values, a, b) {\n  var X = values, alpha = a;\n  if (util.isFunction(a) || util.isString(a)) {\n    X = values.map(util.$(a));\n    alpha = b;\n  }\n  alpha = alpha || 0.05;\n\n  var z = alpha===0.05 ? 1.96 : gen.random.normal(0, 1).icdf(1-(alpha/2)),\n      mu = stats.mean(X),\n      SE = stats.stdev(X) / Math.sqrt(stats.count.valid(X));\n  return [mu - (z*SE), mu + (z*SE)];\n};\n\n// Perform a z-test of means. Returns the p-value.\n// If a single array is provided, performs a one-sample location test.\n// If two arrays or a table and two accessors are provided, performs\n// a two-sample location test. A paired test is performed if specified\n// by the options hash.\n// The options hash format is: {paired: boolean, nullh: number}.\n// http://en.wikipedia.org/wiki/Z-test\n// http://en.wikipedia.org/wiki/Paired_difference_test\nstats.z.test = function(values, a, b, opt) {\n  if (util.isFunction(b) || util.isString(b)) { // table and accessors\n    return (opt && opt.paired ? ztestP : ztest2)(opt, values, a, b);\n  } else if (util.isArray(a)) { // two arrays\n    return (b && b.paired ? ztestP : ztest2)(b, values, a);\n  } else if (util.isFunction(a) || util.isString(a)) {\n    return ztest1(b, values, a); // table and accessor\n  } else {\n    return ztest1(a, values); // one array\n  }\n};\n\n// Perform a z-test of means. Returns the p-value.\n// Assuming we have a list of values, and a null hypothesis. If no null\n// hypothesis, assume our null hypothesis is mu=0.\nfunction ztest1(opt, X, f) {\n  var nullH = opt && opt.nullh || 0,\n      gaussian = gen.random.normal(0, 1),\n      mu = stats.mean(X,f),\n      SE = stats.stdev(X,f) / Math.sqrt(stats.count.valid(X,f));\n\n  if (SE===0) {\n    // Test not well defined when standard error is 0.\n    return (mu - nullH) === 0 ? 1 : 0;\n  }\n  // Two-sided, so twice the one-sided cdf.\n  var z = (mu - nullH) / SE;\n  return 2 * gaussian.cdf(-Math.abs(z));\n}\n\n// Perform a two sample paired z-test of means. Returns the p-value.\nfunction ztestP(opt, values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n1 = stats.count(X),\n      n2 = stats.count(Y),\n      diffs = Array(), i;\n\n  if (n1 !== n2) {\n    throw Error('Array lengths must match.');\n  }\n  for (i=0; i<n1; ++i) {\n    // Only valid differences should contribute to the test statistic\n    if (util.isValid(X[i]) && util.isValid(Y[i])) {\n      diffs.push(X[i] - Y[i]);\n    }\n  }\n  return stats.z.test(diffs, opt && opt.nullh || 0);\n}\n\n// Perform a two sample z-test of means. Returns the p-value.\nfunction ztest2(opt, values, a, b) {\n  var X = b ? values.map(util.$(a)) : values,\n      Y = b ? values.map(util.$(b)) : a,\n      n1 = stats.count.valid(X),\n      n2 = stats.count.valid(Y),\n      gaussian = gen.random.normal(0, 1),\n      meanDiff = stats.mean(X) - stats.mean(Y) - (opt && opt.nullh || 0),\n      SE = Math.sqrt(stats.variance(X)/n1 + stats.variance(Y)/n2);\n\n  if (SE===0) {\n    // Not well defined when pooled standard error is 0.\n    return meanDiff===0 ? 1 : 0;\n  }\n  // Two-tailed, so twice the one-sided cdf.\n  var z = meanDiff / SE;\n  return 2 * gaussian.cdf(-Math.abs(z));\n}\n\n// Construct a mean-centered distance matrix for an array of numbers.\nstats.dist.mat = function(X) {\n  var n = X.length,\n      m = n*n,\n      A = Array(m),\n      R = gen.zeros(n),\n      M = 0, v, i, j;\n\n  for (i=0; i<n; ++i) {\n    A[i*n+i] = 0;\n    for (j=i+1; j<n; ++j) {\n      A[i*n+j] = (v = Math.abs(X[i] - X[j]));\n      A[j*n+i] = v;\n      R[i] += v;\n      R[j] += v;\n    }\n  }\n\n  for (i=0; i<n; ++i) {\n    M += R[i];\n    R[i] /= n;\n  }\n  M /= m;\n\n  for (i=0; i<n; ++i) {\n    for (j=i; j<n; ++j) {\n      A[i*n+j] += M - R[i] - R[j];\n      A[j*n+i] = A[i*n+j];\n    }\n  }\n\n  return A;\n};\n\n// Compute the Shannon entropy (log base 2) of an array of counts.\nstats.entropy = function(counts, f) {\n  f = util.$(f);\n  var i, p, s = 0, H = 0, n = counts.length;\n  for (i=0; i<n; ++i) {\n    s += (f ? f(counts[i]) : counts[i]);\n  }\n  if (s === 0) return 0;\n  for (i=0; i<n; ++i) {\n    p = (f ? f(counts[i]) : counts[i]) / s;\n    if (p) H += p * Math.log(p);\n  }\n  return -H / Math.LN2;\n};\n\n// Compute the mutual information between two discrete variables.\n// Returns an array of the form [MI, MI_distance]\n// MI_distance is defined as 1 - I(a,b) / H(a,b).\n// http://en.wikipedia.org/wiki/Mutual_information\nstats.mutual = function(values, a, b, counts) {\n  var x = counts ? values.map(util.$(a)) : values,\n      y = counts ? values.map(util.$(b)) : a,\n      z = counts ? values.map(util.$(counts)) : b;\n\n  var px = {},\n      py = {},\n      n = z.length,\n      s = 0, I = 0, H = 0, p, t, i;\n\n  for (i=0; i<n; ++i) {\n    px[x[i]] = 0;\n    py[y[i]] = 0;\n  }\n\n  for (i=0; i<n; ++i) {\n    px[x[i]] += z[i];\n    py[y[i]] += z[i];\n    s += z[i];\n  }\n\n  t = 1 / (s * Math.LN2);\n  for (i=0; i<n; ++i) {\n    if (z[i] === 0) continue;\n    p = (s * z[i]) / (px[x[i]] * py[y[i]]);\n    I += z[i] * t * Math.log(p);\n    H += z[i] * t * Math.log(z[i]/s);\n  }\n\n  return [I, 1 + I/H];\n};\n\n// Compute the mutual information between two discrete variables.\nstats.mutual.info = function(values, a, b, counts) {\n  return stats.mutual(values, a, b, counts)[0];\n};\n\n// Compute the mutual information distance between two discrete variables.\n// MI_distance is defined as 1 - I(a,b) / H(a,b).\nstats.mutual.dist = function(values, a, b, counts) {\n  return stats.mutual(values, a, b, counts)[1];\n};\n\n// Compute a profile of summary statistics for a variable.\nstats.profile = function(values, f) {\n  var mean = 0,\n      valid = 0,\n      missing = 0,\n      distinct = 0,\n      min = null,\n      max = null,\n      M2 = 0,\n      vals = [],\n      u = {}, delta, sd, i, v, x;\n\n  // compute summary stats\n  for (i=0; i<values.length; ++i) {\n    v = f ? f(values[i]) : values[i];\n\n    // update unique values\n    u[v] = (v in u) ? u[v] + 1 : (distinct += 1, 1);\n\n    if (v == null) {\n      ++missing;\n    } else if (util.isValid(v)) {\n      // update stats\n      x = (typeof v === 'string') ? v.length : v;\n      if (min===null || x < min) min = x;\n      if (max===null || x > max) max = x;\n      delta = x - mean;\n      mean = mean + delta / (++valid);\n      M2 = M2 + delta * (x - mean);\n      vals.push(x);\n    }\n  }\n  M2 = M2 / (valid - 1);\n  sd = Math.sqrt(M2);\n\n  // sort values for median and iqr\n  vals.sort(util.cmp);\n\n  return {\n    type:     type(values, f),\n    unique:   u,\n    count:    values.length,\n    valid:    valid,\n    missing:  missing,\n    distinct: distinct,\n    min:      min,\n    max:      max,\n    mean:     mean,\n    stdev:    sd,\n    median:   (v = stats.quantile(vals, 0.5)),\n    q1:       stats.quantile(vals, 0.25),\n    q3:       stats.quantile(vals, 0.75),\n    modeskew: sd === 0 ? 0 : (mean - v) / sd\n  };\n};\n\n// Compute profiles for all variables in a data set.\nstats.summary = function(data, fields) {\n  fields = fields || util.keys(data[0]);\n  var s = fields.map(function(f) {\n    var p = stats.profile(data, util.$(f));\n    return (p.field = f, p);\n  });\n  return (s.__summary__ = true, s);\n};\n","var t0 = new Date,\n    t1 = new Date;\n\nexport default function newInterval(floori, offseti, count, field) {\n\n  function interval(date) {\n    return floori(date = arguments.length === 0 ? new Date : new Date(+date)), date;\n  }\n\n  interval.floor = function(date) {\n    return floori(date = new Date(+date)), date;\n  };\n\n  interval.ceil = function(date) {\n    return floori(date = new Date(date - 1)), offseti(date, 1), floori(date), date;\n  };\n\n  interval.round = function(date) {\n    var d0 = interval(date),\n        d1 = interval.ceil(date);\n    return date - d0 < d1 - date ? d0 : d1;\n  };\n\n  interval.offset = function(date, step) {\n    return offseti(date = new Date(+date), step == null ? 1 : Math.floor(step)), date;\n  };\n\n  interval.range = function(start, stop, step) {\n    var range = [], previous;\n    start = interval.ceil(start);\n    step = step == null ? 1 : Math.floor(step);\n    if (!(start < stop) || !(step > 0)) return range; // also handles Invalid Date\n    do range.push(previous = new Date(+start)), offseti(start, step), floori(start);\n    while (previous < start && start < stop);\n    return range;\n  };\n\n  interval.filter = function(test) {\n    return newInterval(function(date) {\n      if (date >= date) while (floori(date), !test(date)) date.setTime(date - 1);\n    }, function(date, step) {\n      if (date >= date) {\n        if (step < 0) while (++step <= 0) {\n          while (offseti(date, -1), !test(date)) {} // eslint-disable-line no-empty\n        } else while (--step >= 0) {\n          while (offseti(date, +1), !test(date)) {} // eslint-disable-line no-empty\n        }\n      }\n    });\n  };\n\n  if (count) {\n    interval.count = function(start, end) {\n      t0.setTime(+start), t1.setTime(+end);\n      floori(t0), floori(t1);\n      return Math.floor(count(t0, t1));\n    };\n\n    interval.every = function(step) {\n      step = Math.floor(step);\n      return !isFinite(step) || !(step > 0) ? null\n          : !(step > 1) ? interval\n          : interval.filter(field\n              ? function(d) { return field(d) % step === 0; }\n              : function(d) { return interval.count(0, d) % step === 0; });\n    };\n  }\n\n  return interval;\n}\n","import interval from \"./interval.js\";\n\nvar millisecond = interval(function() {\n  // noop\n}, function(date, step) {\n  date.setTime(+date + step);\n}, function(start, end) {\n  return end - start;\n});\n\n// An optimized implementation for this simple case.\nmillisecond.every = function(k) {\n  k = Math.floor(k);\n  if (!isFinite(k) || !(k > 0)) return null;\n  if (!(k > 1)) return millisecond;\n  return interval(function(date) {\n    date.setTime(Math.floor(date / k) * k);\n  }, function(date, step) {\n    date.setTime(+date + step * k);\n  }, function(start, end) {\n    return (end - start) / k;\n  });\n};\n\nexport default millisecond;\nexport var milliseconds = millisecond.range;\n","export var durationSecond = 1e3;\nexport var durationMinute = 6e4;\nexport var durationHour = 36e5;\nexport var durationDay = 864e5;\nexport var durationWeek = 6048e5;\n","import interval from \"./interval.js\";\nimport {durationSecond} from \"./duration.js\";\n\nvar second = interval(function(date) {\n  date.setTime(date - date.getMilliseconds());\n}, function(date, step) {\n  date.setTime(+date + step * durationSecond);\n}, function(start, end) {\n  return (end - start) / durationSecond;\n}, function(date) {\n  return date.getUTCSeconds();\n});\n\nexport default second;\nexport var seconds = second.range;\n","import interval from \"./interval.js\";\nimport {durationMinute, durationSecond} from \"./duration.js\";\n\nvar minute = interval(function(date) {\n  date.setTime(date - date.getMilliseconds() - date.getSeconds() * durationSecond);\n}, function(date, step) {\n  date.setTime(+date + step * durationMinute);\n}, function(start, end) {\n  return (end - start) / durationMinute;\n}, function(date) {\n  return date.getMinutes();\n});\n\nexport default minute;\nexport var minutes = minute.range;\n","import interval from \"./interval.js\";\nimport {durationHour, durationMinute, durationSecond} from \"./duration.js\";\n\nvar hour = interval(function(date) {\n  date.setTime(date - date.getMilliseconds() - date.getSeconds() * durationSecond - date.getMinutes() * durationMinute);\n}, function(date, step) {\n  date.setTime(+date + step * durationHour);\n}, function(start, end) {\n  return (end - start) / durationHour;\n}, function(date) {\n  return date.getHours();\n});\n\nexport default hour;\nexport var hours = hour.range;\n","import interval from \"./interval.js\";\nimport {durationDay, durationMinute} from \"./duration.js\";\n\nvar day = interval(\n  date => date.setHours(0, 0, 0, 0),\n  (date, step) => date.setDate(date.getDate() + step),\n  (start, end) => (end - start - (end.getTimezoneOffset() - start.getTimezoneOffset()) * durationMinute) / durationDay,\n  date => date.getDate() - 1\n);\n\nexport default day;\nexport var days = day.range;\n","import interval from \"./interval.js\";\nimport {durationMinute, durationWeek} from \"./duration.js\";\n\nfunction weekday(i) {\n  return interval(function(date) {\n    date.setDate(date.getDate() - (date.getDay() + 7 - i) % 7);\n    date.setHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setDate(date.getDate() + step * 7);\n  }, function(start, end) {\n    return (end - start - (end.getTimezoneOffset() - start.getTimezoneOffset()) * durationMinute) / durationWeek;\n  });\n}\n\nexport var sunday = weekday(0);\nexport var monday = weekday(1);\nexport var tuesday = weekday(2);\nexport var wednesday = weekday(3);\nexport var thursday = weekday(4);\nexport var friday = weekday(5);\nexport var saturday = weekday(6);\n\nexport var sundays = sunday.range;\nexport var mondays = monday.range;\nexport var tuesdays = tuesday.range;\nexport var wednesdays = wednesday.range;\nexport var thursdays = thursday.range;\nexport var fridays = friday.range;\nexport var saturdays = saturday.range;\n","import interval from \"./interval.js\";\n\nvar month = interval(function(date) {\n  date.setDate(1);\n  date.setHours(0, 0, 0, 0);\n}, function(date, step) {\n  date.setMonth(date.getMonth() + step);\n}, function(start, end) {\n  return end.getMonth() - start.getMonth() + (end.getFullYear() - start.getFullYear()) * 12;\n}, function(date) {\n  return date.getMonth();\n});\n\nexport default month;\nexport var months = month.range;\n","import interval from \"./interval.js\";\n\nvar year = interval(function(date) {\n  date.setMonth(0, 1);\n  date.setHours(0, 0, 0, 0);\n}, function(date, step) {\n  date.setFullYear(date.getFullYear() + step);\n}, function(start, end) {\n  return end.getFullYear() - start.getFullYear();\n}, function(date) {\n  return date.getFullYear();\n});\n\n// An optimized implementation for this simple case.\nyear.every = function(k) {\n  return !isFinite(k = Math.floor(k)) || !(k > 0) ? null : interval(function(date) {\n    date.setFullYear(Math.floor(date.getFullYear() / k) * k);\n    date.setMonth(0, 1);\n    date.setHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setFullYear(date.getFullYear() + step * k);\n  });\n};\n\nexport default year;\nexport var years = year.range;\n","import interval from \"./interval.js\";\nimport {durationMinute} from \"./duration.js\";\n\nvar utcMinute = interval(function(date) {\n  date.setUTCSeconds(0, 0);\n}, function(date, step) {\n  date.setTime(+date + step * durationMinute);\n}, function(start, end) {\n  return (end - start) / durationMinute;\n}, function(date) {\n  return date.getUTCMinutes();\n});\n\nexport default utcMinute;\nexport var utcMinutes = utcMinute.range;\n","import interval from \"./interval.js\";\nimport {durationHour} from \"./duration.js\";\n\nvar utcHour = interval(function(date) {\n  date.setUTCMinutes(0, 0, 0);\n}, function(date, step) {\n  date.setTime(+date + step * durationHour);\n}, function(start, end) {\n  return (end - start) / durationHour;\n}, function(date) {\n  return date.getUTCHours();\n});\n\nexport default utcHour;\nexport var utcHours = utcHour.range;\n","import interval from \"./interval.js\";\nimport {durationDay} from \"./duration.js\";\n\nvar utcDay = interval(function(date) {\n  date.setUTCHours(0, 0, 0, 0);\n}, function(date, step) {\n  date.setUTCDate(date.getUTCDate() + step);\n}, function(start, end) {\n  return (end - start) / durationDay;\n}, function(date) {\n  return date.getUTCDate() - 1;\n});\n\nexport default utcDay;\nexport var utcDays = utcDay.range;\n","import interval from \"./interval.js\";\nimport {durationWeek} from \"./duration.js\";\n\nfunction utcWeekday(i) {\n  return interval(function(date) {\n    date.setUTCDate(date.getUTCDate() - (date.getUTCDay() + 7 - i) % 7);\n    date.setUTCHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setUTCDate(date.getUTCDate() + step * 7);\n  }, function(start, end) {\n    return (end - start) / durationWeek;\n  });\n}\n\nexport var utcSunday = utcWeekday(0);\nexport var utcMonday = utcWeekday(1);\nexport var utcTuesday = utcWeekday(2);\nexport var utcWednesday = utcWeekday(3);\nexport var utcThursday = utcWeekday(4);\nexport var utcFriday = utcWeekday(5);\nexport var utcSaturday = utcWeekday(6);\n\nexport var utcSundays = utcSunday.range;\nexport var utcMondays = utcMonday.range;\nexport var utcTuesdays = utcTuesday.range;\nexport var utcWednesdays = utcWednesday.range;\nexport var utcThursdays = utcThursday.range;\nexport var utcFridays = utcFriday.range;\nexport var utcSaturdays = utcSaturday.range;\n","import interval from \"./interval.js\";\n\nvar utcMonth = interval(function(date) {\n  date.setUTCDate(1);\n  date.setUTCHours(0, 0, 0, 0);\n}, function(date, step) {\n  date.setUTCMonth(date.getUTCMonth() + step);\n}, function(start, end) {\n  return end.getUTCMonth() - start.getUTCMonth() + (end.getUTCFullYear() - start.getUTCFullYear()) * 12;\n}, function(date) {\n  return date.getUTCMonth();\n});\n\nexport default utcMonth;\nexport var utcMonths = utcMonth.range;\n","import interval from \"./interval.js\";\n\nvar utcYear = interval(function(date) {\n  date.setUTCMonth(0, 1);\n  date.setUTCHours(0, 0, 0, 0);\n}, function(date, step) {\n  date.setUTCFullYear(date.getUTCFullYear() + step);\n}, function(start, end) {\n  return end.getUTCFullYear() - start.getUTCFullYear();\n}, function(date) {\n  return date.getUTCFullYear();\n});\n\n// An optimized implementation for this simple case.\nutcYear.every = function(k) {\n  return !isFinite(k = Math.floor(k)) || !(k > 0) ? null : interval(function(date) {\n    date.setUTCFullYear(Math.floor(date.getUTCFullYear() / k) * k);\n    date.setUTCMonth(0, 1);\n    date.setUTCHours(0, 0, 0, 0);\n  }, function(date, step) {\n    date.setUTCFullYear(date.getUTCFullYear() + step * k);\n  });\n};\n\nexport default utcYear;\nexport var utcYears = utcYear.range;\n","import { array, error, hasOwnProperty, extend, peek, toSet, constant, zero, one, span } from 'vega-util';\nimport { timeDay, timeWeek, utcDay, utcWeek, timeYear, timeMonth, timeHour, timeMinute, timeSecond, timeMillisecond, utcYear, utcMonth, utcHour, utcMinute, utcSecond, utcMillisecond } from 'd3-time';\nimport { bisector, tickStep } from 'd3-array';\n\nconst YEAR = 'year';\nconst QUARTER = 'quarter';\nconst MONTH = 'month';\nconst WEEK = 'week';\nconst DATE = 'date';\nconst DAY = 'day';\nconst DAYOFYEAR = 'dayofyear';\nconst HOURS = 'hours';\nconst MINUTES = 'minutes';\nconst SECONDS = 'seconds';\nconst MILLISECONDS = 'milliseconds';\nconst TIME_UNITS = [YEAR, QUARTER, MONTH, WEEK, DATE, DAY, DAYOFYEAR, HOURS, MINUTES, SECONDS, MILLISECONDS];\nconst UNITS = TIME_UNITS.reduce((o, u, i) => (o[u] = 1 + i, o), {});\nfunction timeUnits(units) {\n  const u = array(units).slice(),\n        m = {}; // check validity\n\n  if (!u.length) error('Missing time unit.');\n  u.forEach(unit => {\n    if (hasOwnProperty(UNITS, unit)) {\n      m[unit] = 1;\n    } else {\n      error(\"Invalid time unit: \".concat(unit, \".\"));\n    }\n  });\n  const numTypes = (m[WEEK] || m[DAY] ? 1 : 0) + (m[QUARTER] || m[MONTH] || m[DATE] ? 1 : 0) + (m[DAYOFYEAR] ? 1 : 0);\n\n  if (numTypes > 1) {\n    error(\"Incompatible time units: \".concat(units));\n  } // ensure proper sort order\n\n\n  u.sort((a, b) => UNITS[a] - UNITS[b]);\n  return u;\n}\nconst defaultSpecifiers = {\n  [YEAR]: '%Y ',\n  [QUARTER]: 'Q%q ',\n  [MONTH]: '%b ',\n  [DATE]: '%d ',\n  [WEEK]: 'W%U ',\n  [DAY]: '%a ',\n  [DAYOFYEAR]: '%j ',\n  [HOURS]: '%H:00',\n  [MINUTES]: '00:%M',\n  [SECONDS]: ':%S',\n  [MILLISECONDS]: '.%L',\n  [\"\".concat(YEAR, \"-\").concat(MONTH)]: '%Y-%m ',\n  [\"\".concat(YEAR, \"-\").concat(MONTH, \"-\").concat(DATE)]: '%Y-%m-%d ',\n  [\"\".concat(HOURS, \"-\").concat(MINUTES)]: '%H:%M'\n};\nfunction timeUnitSpecifier(units, specifiers) {\n  const s = extend({}, defaultSpecifiers, specifiers),\n        u = timeUnits(units),\n        n = u.length;\n  let fmt = '',\n      start = 0,\n      end,\n      key;\n\n  for (start = 0; start < n;) {\n    for (end = u.length; end > start; --end) {\n      key = u.slice(start, end).join('-');\n\n      if (s[key] != null) {\n        fmt += s[key];\n        start = end;\n        break;\n      }\n    }\n  }\n\n  return fmt.trim();\n}\n\nconst t0 = new Date();\n\nfunction localYear(y) {\n  t0.setFullYear(y);\n  t0.setMonth(0);\n  t0.setDate(1);\n  t0.setHours(0, 0, 0, 0);\n  return t0;\n}\n\nfunction dayofyear(d) {\n  return localDayOfYear(new Date(d));\n}\nfunction week(d) {\n  return localWeekNum(new Date(d));\n}\nfunction localDayOfYear(d) {\n  return timeDay.count(localYear(d.getFullYear()) - 1, d);\n}\nfunction localWeekNum(d) {\n  return timeWeek.count(localYear(d.getFullYear()) - 1, d);\n}\nfunction localFirst(y) {\n  return localYear(y).getDay();\n}\nfunction localDate(y, m, d, H, M, S, L) {\n  if (0 <= y && y < 100) {\n    const date = new Date(-1, m, d, H, M, S, L);\n    date.setFullYear(y);\n    return date;\n  }\n\n  return new Date(y, m, d, H, M, S, L);\n}\nfunction utcdayofyear(d) {\n  return utcDayOfYear(new Date(d));\n}\nfunction utcweek(d) {\n  return utcWeekNum(new Date(d));\n}\nfunction utcDayOfYear(d) {\n  const y = Date.UTC(d.getUTCFullYear(), 0, 1);\n  return utcDay.count(y - 1, d);\n}\nfunction utcWeekNum(d) {\n  const y = Date.UTC(d.getUTCFullYear(), 0, 1);\n  return utcWeek.count(y - 1, d);\n}\nfunction utcFirst(y) {\n  t0.setTime(Date.UTC(y, 0, 1));\n  return t0.getUTCDay();\n}\nfunction utcDate(y, m, d, H, M, S, L) {\n  if (0 <= y && y < 100) {\n    const date = new Date(Date.UTC(-1, m, d, H, M, S, L));\n    date.setUTCFullYear(d.y);\n    return date;\n  }\n\n  return new Date(Date.UTC(y, m, d, H, M, S, L));\n}\n\nfunction floor(units, step, get, inv, newDate) {\n  const s = step || 1,\n        b = peek(units),\n        _ = (unit, p, key) => {\n    key = key || unit;\n    return getUnit(get[key], inv[key], unit === b && s, p);\n  };\n\n  const t = new Date(),\n        u = toSet(units),\n        y = u[YEAR] ? _(YEAR) : constant(2012),\n        m = u[MONTH] ? _(MONTH) : u[QUARTER] ? _(QUARTER) : zero,\n        d = u[WEEK] && u[DAY] ? _(DAY, 1, WEEK + DAY) : u[WEEK] ? _(WEEK, 1) : u[DAY] ? _(DAY, 1) : u[DATE] ? _(DATE, 1) : u[DAYOFYEAR] ? _(DAYOFYEAR, 1) : one,\n        H = u[HOURS] ? _(HOURS) : zero,\n        M = u[MINUTES] ? _(MINUTES) : zero,\n        S = u[SECONDS] ? _(SECONDS) : zero,\n        L = u[MILLISECONDS] ? _(MILLISECONDS) : zero;\n  return function (v) {\n    t.setTime(+v);\n    const year = y(t);\n    return newDate(year, m(t), d(t, year), H(t), M(t), S(t), L(t));\n  };\n}\n\nfunction getUnit(f, inv, step, phase) {\n  const u = step <= 1 ? f : phase ? (d, y) => phase + step * Math.floor((f(d, y) - phase) / step) : (d, y) => step * Math.floor(f(d, y) / step);\n  return inv ? (d, y) => inv(u(d, y), y) : u;\n} // returns the day of the year based on week number, day of week,\n// and the day of the week for the first day of the year\n\n\nfunction weekday(week, day, firstDay) {\n  return day + week * 7 - (firstDay + 6) % 7;\n} // -- LOCAL TIME --\n\n\nconst localGet = {\n  [YEAR]: d => d.getFullYear(),\n  [QUARTER]: d => Math.floor(d.getMonth() / 3),\n  [MONTH]: d => d.getMonth(),\n  [DATE]: d => d.getDate(),\n  [HOURS]: d => d.getHours(),\n  [MINUTES]: d => d.getMinutes(),\n  [SECONDS]: d => d.getSeconds(),\n  [MILLISECONDS]: d => d.getMilliseconds(),\n  [DAYOFYEAR]: d => localDayOfYear(d),\n  [WEEK]: d => localWeekNum(d),\n  [WEEK + DAY]: (d, y) => weekday(localWeekNum(d), d.getDay(), localFirst(y)),\n  [DAY]: (d, y) => weekday(1, d.getDay(), localFirst(y))\n};\nconst localInv = {\n  [QUARTER]: q => 3 * q,\n  [WEEK]: (w, y) => weekday(w, 0, localFirst(y))\n};\nfunction timeFloor(units, step) {\n  return floor(units, step || 1, localGet, localInv, localDate);\n} // -- UTC TIME --\n\nconst utcGet = {\n  [YEAR]: d => d.getUTCFullYear(),\n  [QUARTER]: d => Math.floor(d.getUTCMonth() / 3),\n  [MONTH]: d => d.getUTCMonth(),\n  [DATE]: d => d.getUTCDate(),\n  [HOURS]: d => d.getUTCHours(),\n  [MINUTES]: d => d.getUTCMinutes(),\n  [SECONDS]: d => d.getUTCSeconds(),\n  [MILLISECONDS]: d => d.getUTCMilliseconds(),\n  [DAYOFYEAR]: d => utcDayOfYear(d),\n  [WEEK]: d => utcWeekNum(d),\n  [DAY]: (d, y) => weekday(1, d.getUTCDay(), utcFirst(y)),\n  [WEEK + DAY]: (d, y) => weekday(utcWeekNum(d), d.getUTCDay(), utcFirst(y))\n};\nconst utcInv = {\n  [QUARTER]: q => 3 * q,\n  [WEEK]: (w, y) => weekday(w, 0, utcFirst(y))\n};\nfunction utcFloor(units, step) {\n  return floor(units, step || 1, utcGet, utcInv, utcDate);\n}\n\nconst timeIntervals = {\n  [YEAR]: timeYear,\n  [QUARTER]: timeMonth.every(3),\n  [MONTH]: timeMonth,\n  [WEEK]: timeWeek,\n  [DATE]: timeDay,\n  [DAY]: timeDay,\n  [DAYOFYEAR]: timeDay,\n  [HOURS]: timeHour,\n  [MINUTES]: timeMinute,\n  [SECONDS]: timeSecond,\n  [MILLISECONDS]: timeMillisecond\n};\nconst utcIntervals = {\n  [YEAR]: utcYear,\n  [QUARTER]: utcMonth.every(3),\n  [MONTH]: utcMonth,\n  [WEEK]: utcWeek,\n  [DATE]: utcDay,\n  [DAY]: utcDay,\n  [DAYOFYEAR]: utcDay,\n  [HOURS]: utcHour,\n  [MINUTES]: utcMinute,\n  [SECONDS]: utcSecond,\n  [MILLISECONDS]: utcMillisecond\n};\nfunction timeInterval(unit) {\n  return timeIntervals[unit];\n}\nfunction utcInterval(unit) {\n  return utcIntervals[unit];\n}\n\nfunction offset(ival, date, step) {\n  return ival ? ival.offset(date, step) : undefined;\n}\n\nfunction timeOffset(unit, date, step) {\n  return offset(timeInterval(unit), date, step);\n}\nfunction utcOffset(unit, date, step) {\n  return offset(utcInterval(unit), date, step);\n}\n\nfunction sequence(ival, start, stop, step) {\n  return ival ? ival.range(start, stop, step) : undefined;\n}\n\nfunction timeSequence(unit, start, stop, step) {\n  return sequence(timeInterval(unit), start, stop, step);\n}\nfunction utcSequence(unit, start, stop, step) {\n  return sequence(utcInterval(unit), start, stop, step);\n}\n\nconst durationSecond = 1000,\n      durationMinute = durationSecond * 60,\n      durationHour = durationMinute * 60,\n      durationDay = durationHour * 24,\n      durationWeek = durationDay * 7,\n      durationMonth = durationDay * 30,\n      durationYear = durationDay * 365;\nconst Milli = [YEAR, MONTH, DATE, HOURS, MINUTES, SECONDS, MILLISECONDS],\n      Seconds = Milli.slice(0, -1),\n      Minutes = Seconds.slice(0, -1),\n      Hours = Minutes.slice(0, -1),\n      Day = Hours.slice(0, -1),\n      Week = [YEAR, WEEK],\n      Month = [YEAR, MONTH],\n      Year = [YEAR];\nconst intervals = [[Seconds, 1, durationSecond], [Seconds, 5, 5 * durationSecond], [Seconds, 15, 15 * durationSecond], [Seconds, 30, 30 * durationSecond], [Minutes, 1, durationMinute], [Minutes, 5, 5 * durationMinute], [Minutes, 15, 15 * durationMinute], [Minutes, 30, 30 * durationMinute], [Hours, 1, durationHour], [Hours, 3, 3 * durationHour], [Hours, 6, 6 * durationHour], [Hours, 12, 12 * durationHour], [Day, 1, durationDay], [Week, 1, durationWeek], [Month, 1, durationMonth], [Month, 3, 3 * durationMonth], [Year, 1, durationYear]];\nfunction bin (opt) {\n  const ext = opt.extent,\n        max = opt.maxbins || 40,\n        target = Math.abs(span(ext)) / max;\n  let i = bisector(i => i[2]).right(intervals, target),\n      units,\n      step;\n\n  if (i === intervals.length) {\n    units = Year, step = tickStep(ext[0] / durationYear, ext[1] / durationYear, max);\n  } else if (i) {\n    i = intervals[target / intervals[i - 1][2] < intervals[i][2] / target ? i - 1 : i];\n    units = i[0];\n    step = i[1];\n  } else {\n    units = Milli;\n    step = Math.max(tickStep(ext[0], ext[1], max), 1);\n  }\n\n  return {\n    units,\n    step\n  };\n}\n\nexport { DATE, DAY, DAYOFYEAR, HOURS, MILLISECONDS, MINUTES, MONTH, QUARTER, SECONDS, TIME_UNITS, WEEK, YEAR, dayofyear, bin as timeBin, timeFloor, timeInterval, timeOffset, timeSequence, timeUnitSpecifier, timeUnits, utcFloor, utcInterval, utcOffset, utcSequence, utcdayofyear, utcweek, week };\n","import dlBin_ from 'datalib/src/bins/bins';\nimport {inferAll} from 'datalib/src/import/type';\nimport {summary} from 'datalib/src/stats';\nimport {autoMaxBins} from 'vega-lite/build/src/bin';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {\n  SingleTimeUnit,\n  LocalSingleTimeUnit,\n  isUTCTimeUnit,\n  containsTimeUnit,\n  TimeUnit,\n  TIMEUNIT_PARTS,\n} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport * as vegaTime from 'vega-time';\nimport {DEFAULT_QUERY_CONFIG, QueryConfig} from './config';\nimport {BinQuery, EncodingQuery, FieldQuery, isAutoCountQuery} from './query/encoding';\nimport {ExpandedType} from './query/expandedtype';\nimport {cmp, duplicate, extend, keys} from './util';\n\nconst dlBin = dlBin_;\n\n/**\n * Table Schema Field Descriptor interface\n * see: https://specs.frictionlessdata.io/table-schema/\n */\nexport interface TableSchemaFieldDescriptor {\n  /* name of field **/\n  name: string;\n\n  /* A nicer human readable label or title for the field **/\n  title?: string;\n\n  /* number, integer, string, datetime  */\n  type: PrimitiveType;\n\n  /* A string specifying a format */\n  format?: string;\n\n  /* A description for the field */\n  description?: string;\n}\n\n/**\n * Field Schema\n */\nexport interface FieldSchema extends TableSchemaFieldDescriptor {\n  vlType?: ExpandedType;\n\n  index?: number;\n  // Need to keep original index for re-exporting TableSchema\n  originalIndex?: number;\n\n  stats: DLFieldProfile;\n  binStats?: {[maxbins: string]: DLFieldProfile};\n  timeStats?: {[timeUnit: string]: DLFieldProfile};\n\n  // array of valid input values (fields)\n  ordinalDomain?: string[];\n}\n\n/**\n * Table Schema\n * see: https://specs.frictionlessdata.io/table-schema/\n */\nexport interface TableSchema<F extends TableSchemaFieldDescriptor> {\n  fields: F[];\n  missingValues?: string[];\n  primaryKey?: string | string[];\n  foreignKeys?: object[];\n}\n\n/**\n * Build a Schema object.\n *\n * @param data - a set of raw data in the same format that Vega-Lite / Vega takes\n * Basically, it's an array in the form of:\n *\n * [\n *   {a: 1, b:2},\n *   {a: 2, b:3},\n *   ...\n * ]\n *\n * @return a Schema object\n */\nexport function build(\n  data: any,\n  opt: QueryConfig = {},\n  tableSchema: TableSchema<TableSchemaFieldDescriptor> = {fields: []}\n): Schema {\n  opt = extend({}, DEFAULT_QUERY_CONFIG, opt);\n\n  // create profiles for each variable\n  const summaries: DLFieldProfile[] = summary(data);\n  const types = inferAll(data); // inferAll does stronger type inference than summary\n\n  const tableSchemaFieldIndex = tableSchema.fields.reduce((m, field: TableSchemaFieldDescriptor) => {\n    m[field.name] = field;\n    return m;\n  }, {});\n\n  const fieldSchemas: FieldSchema[] = summaries.map(function (fieldProfile, index) {\n    const name: string = fieldProfile.field;\n    // In Table schema, 'date' doesn't include time so use 'datetime'\n    const type: PrimitiveType = types[name] === 'date' ? PrimitiveType.DATETIME : (types[name] as any);\n    const distinct: number = fieldProfile.distinct;\n    let vlType: ExpandedType;\n\n    if (type === PrimitiveType.NUMBER) {\n      vlType = TYPE.QUANTITATIVE;\n    } else if (type === PrimitiveType.INTEGER) {\n      // use ordinal or nominal when cardinality of integer type is relatively low and the distinct values are less than an amount specified in options\n      if (distinct < opt.numberNominalLimit && distinct / fieldProfile.count < opt.numberNominalProportion) {\n        vlType = TYPE.NOMINAL;\n      } else {\n        vlType = TYPE.QUANTITATIVE;\n      }\n    } else if (type === PrimitiveType.DATETIME) {\n      vlType = TYPE.TEMPORAL;\n      // need to get correct min/max of date data because datalib's summary method does not\n      // calculate this correctly for date types.\n      fieldProfile.min = new Date(data[0][name]);\n      fieldProfile.max = new Date(data[0][name]);\n      for (const dataEntry of data) {\n        const time = new Date(dataEntry[name]).getTime();\n        if (time < (fieldProfile.min as Date).getTime()) {\n          fieldProfile.min = new Date(time);\n        }\n        if (time > (fieldProfile.max as Date).getTime()) {\n          fieldProfile.max = new Date(time);\n        }\n      }\n    } else {\n      vlType = TYPE.NOMINAL;\n    }\n\n    if (\n      vlType === TYPE.NOMINAL &&\n      distinct / fieldProfile.count > opt.minPercentUniqueForKey &&\n      fieldProfile.count > opt.minCardinalityForKey\n    ) {\n      vlType = ExpandedType.KEY;\n    }\n\n    let fieldSchema = {\n      name: name,\n      // Need to keep original index for re-exporting TableSchema\n      originalIndex: index,\n      vlType: vlType,\n      type: type,\n      stats: fieldProfile,\n      timeStats: {} as {[timeUnit: string]: DLFieldProfile},\n      binStats: {} as {[key: string]: DLFieldProfile},\n    };\n\n    // extend field schema with table schema field - if present\n    const orgFieldSchema = tableSchemaFieldIndex[fieldSchema.name];\n    fieldSchema = extend(fieldSchema, orgFieldSchema);\n\n    return fieldSchema;\n  });\n\n  // calculate preset bins for quantitative and temporal data\n  for (const fieldSchema of fieldSchemas) {\n    if (fieldSchema.vlType === TYPE.QUANTITATIVE) {\n      for (const maxbins of opt.enum.binProps.maxbins) {\n        fieldSchema.binStats[maxbins] = binSummary(maxbins, fieldSchema.stats);\n      }\n    } else if (fieldSchema.vlType === TYPE.TEMPORAL) {\n      for (const unit of opt.enum.timeUnit) {\n        if (unit !== undefined) {\n          if (typeof unit === 'object') {\n            if ('unit' in unit) {\n              // is TimeUnitParams\n              fieldSchema.timeStats[unit.unit] = timeSummary(unit.unit, fieldSchema.stats);\n            } else {\n              throw new Error('Unrecognized TimeUnit type when calculating fieldSchema.stats');\n            }\n          } else {\n            fieldSchema.timeStats[unit] = timeSummary(unit, fieldSchema.stats);\n          }\n        }\n      }\n    }\n  }\n\n  const derivedTableSchema: TableSchema<FieldSchema> = {\n    ...tableSchema,\n    fields: fieldSchemas,\n  };\n\n  return new Schema(derivedTableSchema);\n}\n\n// order the field schema when we construct a new Schema\n// this orders the fields in the UI\nconst order = {\n  nominal: 0,\n  key: 1,\n  ordinal: 2,\n  temporal: 3,\n  quantitative: 4,\n};\n\nexport class Schema {\n  private _tableSchema: TableSchema<FieldSchema>;\n  private _fieldSchemaIndex: {[field: string]: FieldSchema};\n\n  constructor(tableSchema: TableSchema<FieldSchema>) {\n    this._tableSchema = tableSchema;\n\n    tableSchema.fields.sort(function (a: FieldSchema, b: FieldSchema) {\n      // first order by vlType: nominal < temporal < quantitative < ordinal\n      if (order[a.vlType] < order[b.vlType]) {\n        return -1;\n      } else if (order[a.vlType] > order[b.vlType]) {\n        return 1;\n      } else {\n        // then order by field (alphabetically)\n        return a.name.localeCompare(b.name);\n      }\n    });\n\n    // Add index for sorting\n    tableSchema.fields.forEach((fieldSchema, index) => (fieldSchema.index = index));\n\n    this._fieldSchemaIndex = tableSchema.fields.reduce((m, fieldSchema: FieldSchema) => {\n      m[fieldSchema.name] = fieldSchema;\n      return m;\n    }, {});\n  }\n\n  /** @return a list of the field names (for enumerating). */\n  public fieldNames() {\n    return this._tableSchema.fields.map((fieldSchema) => fieldSchema.name);\n  }\n\n  /** @return a list of FieldSchemas */\n  public get fieldSchemas() {\n    return this._tableSchema.fields;\n  }\n\n  public fieldSchema(fieldName: string) {\n    return this._fieldSchemaIndex[fieldName];\n  }\n\n  public tableSchema() {\n    // the fieldschemas are re-arranged\n    // but this is not allowed in table schema.\n    // so we will re-order based on original index.\n    const tableSchema = duplicate(this._tableSchema);\n    tableSchema.fields.sort((a, b) => a.originalIndex - b.originalIndex);\n    return tableSchema;\n  }\n\n  /**\n   * @return primitive type of the field if exist, otherwise return null\n   */\n  public primitiveType(fieldName: string) {\n    return this._fieldSchemaIndex[fieldName] ? this._fieldSchemaIndex[fieldName].type : null;\n  }\n\n  /**\n   * @return vlType of measturement of the field if exist, otherwise return null\n   */\n  public vlType(fieldName: string) {\n    return this._fieldSchemaIndex[fieldName] ? this._fieldSchemaIndex[fieldName].vlType : null;\n  }\n\n  /** @return cardinality of the field associated with encQ, null if it doesn't exist.\n   *  @param augmentTimeUnitDomain - TimeUnit field domains will not be augmented if explicitly set to false.\n   */\n  public cardinality(fieldQ: FieldQuery, augmentTimeUnitDomain = true, excludeInvalid = false) {\n    const fieldSchema = this._fieldSchemaIndex[fieldQ.field as string];\n    if (fieldQ.aggregate || (isAutoCountQuery(fieldQ) && fieldQ.autoCount)) {\n      return 1;\n    } else if (fieldQ.bin) {\n      // encQ.bin will either be a boolean or a BinQuery\n      let bin: BinQuery;\n      if (typeof fieldQ.bin === 'boolean') {\n        // autoMaxBins defaults to 10 if channel is Wildcard\n        bin = {\n          maxbins: autoMaxBins(fieldQ.channel as Channel),\n        };\n      } else if (fieldQ.bin === '?') {\n        bin = {\n          enum: [true, false],\n        };\n      } else {\n        bin = fieldQ.bin;\n      }\n      const maxbins: any = bin.maxbins;\n      if (!fieldSchema.binStats[maxbins]) {\n        // need to calculate\n        fieldSchema.binStats[maxbins] = binSummary(maxbins, fieldSchema.stats);\n      }\n      // don't need to worry about excludeInvalid here because invalid values don't affect linearly binned field's cardinality\n      return fieldSchema.binStats[maxbins].distinct;\n    } else if (fieldQ.timeUnit) {\n      if (augmentTimeUnitDomain) {\n        switch (fieldQ.timeUnit) {\n          // TODO: this should not always be the case once Vega-Lite supports turning off domain augmenting (VL issue #1385)\n          case vegaTime.SECONDS:\n            return 60;\n          case vegaTime.MINUTES:\n            return 60;\n          case vegaTime.HOURS:\n            return 24;\n          case vegaTime.DAY:\n            return 7;\n          case vegaTime.DATE:\n            return 31;\n          case vegaTime.MONTH:\n            return 12;\n          case vegaTime.QUARTER:\n            return 4;\n          case vegaTime.MILLISECONDS:\n            return 1000;\n        }\n      }\n      const unit = fieldQ.timeUnit as string;\n      let timeStats = fieldSchema.timeStats;\n      // if the cardinality for the timeUnit is not cached, calculate it\n      if (!timeStats || !timeStats[unit]) {\n        timeStats = {\n          ...timeStats,\n          [unit]: timeSummary(fieldQ.timeUnit as TimeUnit, fieldSchema.stats),\n        };\n      }\n\n      if (excludeInvalid) {\n        return timeStats[unit].distinct - invalidCount(timeStats[unit].unique, ['Invalid Date', null]);\n      } else {\n        return timeStats[unit].distinct;\n      }\n    } else {\n      if (fieldSchema) {\n        if (excludeInvalid) {\n          return fieldSchema.stats.distinct - invalidCount(fieldSchema.stats.unique, [NaN, null]);\n        } else {\n          return fieldSchema.stats.distinct;\n        }\n      } else {\n        return null;\n      }\n    }\n  }\n\n  /**\n   * Given an EncodingQuery with a timeUnit, returns true if the date field\n   * has multiple distinct values for all parts of the timeUnit. Returns undefined\n   * if the timeUnit is undefined.\n   * i.e.\n   * ('yearmonth', [Jan 1 2000, Feb 2 2000] returns false)\n   * ('yearmonth', [Jan 1 2000, Feb 2 2001] returns true)\n   */\n  public timeUnitHasVariation(fieldQ: FieldQuery): boolean {\n    if (!fieldQ.timeUnit) {\n      return;\n    }\n\n    // if there is no variation in `date`, there should not be variation in `day`\n    if (fieldQ.timeUnit === vegaTime.DAY) {\n      const dateEncQ: EncodingQuery = extend({}, fieldQ, {timeUnit: vegaTime.DATE});\n      if (this.cardinality(dateEncQ, false, true) <= 1) {\n        return false;\n      }\n    }\n\n    const fullTimeUnit = fieldQ.timeUnit;\n    for (const timeUnitPart of TIMEUNIT_PARTS) {\n      if (containsTimeUnit(fullTimeUnit as TimeUnit, timeUnitPart)) {\n        // Create a clone of encQ, but with singleTimeUnit\n        const singleUnitEncQ = extend({}, fieldQ, {timeUnit: timeUnitPart});\n        if (this.cardinality(singleUnitEncQ, false, true) <= 1) {\n          return false;\n        }\n      }\n    }\n    return true;\n  }\n\n  public domain(fieldQueryParts: {field: string}): any[] {\n    // TODO: differentiate for field with bin / timeUnit\n    const fieldSchema = this._fieldSchemaIndex[fieldQueryParts.field as string];\n    let domain: any[] = keys(fieldSchema.stats.unique);\n    if (fieldSchema.vlType === TYPE.QUANTITATIVE) {\n      // return [min, max], coerced into number types\n      return [+fieldSchema.stats.min, +fieldSchema.stats.max];\n    } else if (fieldSchema.type === PrimitiveType.DATETIME) {\n      // return [min, max] dates\n      return [fieldSchema.stats.min, fieldSchema.stats.max];\n    } else if (fieldSchema.type === PrimitiveType.INTEGER || fieldSchema.type === PrimitiveType.NUMBER) {\n      // coerce non-quantitative numerical data into number type\n      domain = domain.map((x) => +x);\n      return domain.sort(cmp);\n    } else if (fieldSchema.vlType === TYPE.ORDINAL && fieldSchema.ordinalDomain) {\n      return fieldSchema.ordinalDomain;\n    }\n\n    return domain\n      .map((x) => {\n        // Convert 'null' to null as it is encoded similarly in datalib.\n        // This is wrong when it is a string 'null' but that rarely happens.\n        return x === 'null' ? null : x;\n      })\n      .sort(cmp);\n  }\n\n  /**\n   * @return a Summary corresponding to the field of the given EncodingQuery\n   */\n  public stats(fieldQ: FieldQuery) {\n    // TODO: differentiate for field with bin / timeUnit vs without\n    const fieldSchema = this._fieldSchemaIndex[fieldQ.field as string];\n    return fieldSchema ? fieldSchema.stats : null;\n  }\n}\n\n/**\n * @return a summary of the binning scheme determined from the given max number of bins\n */\nfunction binSummary(maxbins: number, summary: DLFieldProfile): DLFieldProfile {\n  const bin = dlBin({\n    min: summary.min,\n    max: summary.max,\n    maxbins: maxbins,\n  });\n\n  // start with summary, pre-binning\n  const result = extend({}, summary);\n  result.unique = binUnique(bin, summary.unique);\n  result.distinct = (bin.stop - bin.start) / bin.step;\n  result.min = bin.start;\n  result.max = bin.stop;\n\n  return result;\n}\n\nconst SET_DATE_METHOD: Record<LocalSingleTimeUnit, any> = {\n  year: 'setFullYear',\n  month: 'setMonth',\n  date: 'setDate',\n  hours: 'setHours',\n  minutes: 'setMinutes',\n  seconds: 'setSeconds',\n  milliseconds: 'setMilliseconds',\n  // the units below have their own special cases\n  dayofyear: null,\n  week: null,\n  quarter: null,\n  day: null,\n};\n\nfunction dateMethods(singleUnit: SingleTimeUnit, isUtc: boolean) {\n  const rawSetDateMethod = SET_DATE_METHOD[singleUnit];\n  const setDateMethod = isUtc ? `setUTC${rawSetDateMethod.substr(3)}` : rawSetDateMethod;\n  const getDateMethod = `get${isUtc ? 'UTC' : ''}${rawSetDateMethod.substr(3)}`;\n  return {setDateMethod, getDateMethod};\n}\n\nfunction convert(unit: TimeUnit, date: Date): Date {\n  const isUTC = isUTCTimeUnit(unit);\n  const result: Date = isUTC\n    ? // start with uniform date\n      new Date(Date.UTC(1972, 0, 1, 0, 0, 0, 0)) // 1972 is the first leap year after 1970, the start of unix time\n    : new Date(1972, 0, 1, 0, 0, 0, 0);\n  for (const timeUnitPart of TIMEUNIT_PARTS) {\n    if (containsTimeUnit(unit, timeUnitPart)) {\n      switch (timeUnitPart) {\n        case vegaTime.DAY:\n          throw new Error(\"Cannot convert to TimeUnits containing 'day'\");\n        case vegaTime.DAYOFYEAR:\n          throw new Error(\"Cannot convert to TimeUnits containing 'dayofyear'\");\n        case vegaTime.WEEK:\n          throw new Error(\"Cannot convert to TimeUnits containing 'week'\");\n        case vegaTime.QUARTER: {\n          const {getDateMethod, setDateMethod} = dateMethods('month', isUTC);\n          // indicate quarter by setting month to be the first of the quarter i.e. may (4) -> april (3)\n          result[setDateMethod](Math.floor(date[getDateMethod]() / 3) * 3);\n          break;\n        }\n        default: {\n          const {getDateMethod, setDateMethod} = dateMethods(timeUnitPart, isUTC);\n          result[setDateMethod](date[getDateMethod]());\n        }\n      }\n    }\n  }\n  return result;\n}\n\n/** @return a modified version of the passed summary with unique and distinct set according to the timeunit.\n *  Maps 'null' (string) keys to the null value and invalid dates to 'Invalid Date' in the unique dictionary.\n */\nfunction timeSummary(timeunit: TimeUnit, summary: DLFieldProfile): DLFieldProfile {\n  const result = extend({}, summary);\n\n  const unique: {[value: string]: number} = {};\n  keys(summary.unique).forEach(function (dateString) {\n    // don't convert null value because the Date constructor will actually convert it to a date\n    const date: Date = dateString === 'null' ? null : new Date(dateString);\n    // at this point, `date` is either the null value, a valid Date object, or \"Invalid Date\" which is a Date\n    let key: string;\n    if (date === null) {\n      key = null;\n    } else if (isNaN(date.getTime())) {\n      key = 'Invalid Date';\n    } else {\n      key = (timeunit === vegaTime.DAY ? date.getDay() : convert(timeunit, date)).toString();\n    }\n    unique[key] = (unique[key] || 0) + summary.unique[dateString];\n  });\n\n  result.unique = unique;\n  result.distinct = keys(unique).length;\n\n  return result;\n}\n\n/**\n * @return a new unique object based off of the old unique count and a binning scheme\n */\nfunction binUnique(bin: any, oldUnique: any) {\n  const newUnique = {};\n  for (const value in oldUnique) {\n    let bucket: number;\n    if (value === null) {\n      bucket = null;\n    } else if (isNaN(Number(value))) {\n      bucket = NaN;\n    } else {\n      bucket = bin.value(Number(value)) as number;\n    }\n    newUnique[bucket] = (newUnique[bucket] || 0) + oldUnique[value];\n  }\n  return newUnique;\n}\n\n/** @return the number of items in list that occur as keys of unique */\nfunction invalidCount(unique: {}, list: any[]) {\n  return list.reduce(function (prev, cur) {\n    return unique[cur] ? prev + 1 : prev;\n  }, 0);\n}\n\nexport enum PrimitiveType {\n  STRING = 'string' as any,\n  NUMBER = 'number' as any,\n  INTEGER = 'integer' as any,\n  BOOLEAN = 'boolean' as any,\n  DATETIME = 'datetime' as any,\n}\n","import {QueryConfig} from '../config';\nimport {isEncodingNestedProp, Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {isWildcard, Wildcard} from '../wildcard';\nimport {Schema} from '../schema';\nimport {every} from '../util';\n\nimport {EncodingQueryBase} from '../query/encoding';\n\n/**\n * Abstract interface for a constraint.\n */\nexport interface AbstractConstraint {\n  name: string;\n  description: string;\n  properties: Property[];\n\n  /**\n   * Whether this constraint requires all specified properties types to be specific\n   * in order to call satisfy function.\n   */\n  allowWildcardForProperties: boolean;\n\n  /**\n   * Whether this constraint is strict (not optional).\n   */\n  strict: boolean;\n}\n\n/**\n * Abstract model for a constraint.\n */\nexport class AbstractConstraintModel {\n  protected constraint: AbstractConstraint;\n\n  constructor(constraint: AbstractConstraint) {\n    this.constraint = constraint;\n  }\n\n  public name(): string {\n    return this.constraint.name;\n  }\n\n  public description(): string {\n    return this.constraint.description;\n  }\n\n  public properties(): Property[] {\n    return this.constraint.properties;\n  }\n\n  public strict(): boolean {\n    return this.constraint.strict;\n  }\n}\n\n/**\n * Collection of constraints for a single encoding mapping.\n */\n\n/** A method for satisfying whether the provided encoding query satisfy the constraint. */\nexport interface EncodingConstraintChecker<E extends EncodingQueryBase> {\n  (encQ: E, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig): boolean;\n}\n\nexport class EncodingConstraintModel<E extends EncodingQueryBase> extends AbstractConstraintModel {\n  constructor(constraint: EncodingConstraint<E>) {\n    super(constraint);\n  }\n\n  public hasAllRequiredPropertiesSpecific(encQ: E): boolean {\n    return every(this.constraint.properties, (prop: Property) => {\n      if (isEncodingNestedProp(prop)) {\n        const parent = prop.parent;\n        const child = prop.child;\n\n        if (!encQ[parent]) {\n          return true;\n        }\n\n        return !isWildcard(encQ[parent][child]);\n      }\n\n      if (!encQ[prop]) {\n        return true;\n      }\n\n      return !isWildcard(encQ[prop]);\n    });\n  }\n\n  public satisfy(encQ: E, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig): boolean {\n    // TODO: Re-order logic to optimize the \"allowWildcardForProperties\" check\n    if (!this.constraint.allowWildcardForProperties) {\n      // TODO: extract as a method and do unit test\n\n      if (!this.hasAllRequiredPropertiesSpecific(encQ)) {\n        return true;\n      }\n    }\n    return (this.constraint as EncodingConstraint<E>).satisfy(encQ, schema, encWildcardIndex, opt);\n  }\n}\n\n/** Constraint for a single encoding mapping */\nexport interface EncodingConstraint<E extends EncodingQueryBase> extends AbstractConstraint {\n  /** Method for checking if the encoding query satisfies this constraint. */\n  satisfy: EncodingConstraintChecker<E>;\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {ExtendedChannel} from 'vega-lite/build/src/channel';\nimport {channelCompatibility, TypedFieldDef} from 'vega-lite/build/src/channeldef';\nimport {\n  channelScalePropertyIncompatability,\n  hasDiscreteDomain,\n  Scale,\n  ScaleType,\n  scaleTypeSupportProperty,\n} from 'vega-lite/build/src/scale';\nimport {normalizeTimeUnit, isLocalSingleTimeUnit, isUTCTimeUnit} from 'vega-lite/build/src/timeunit';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from '../config';\nimport {getEncodingNestedProp, Property, SCALE_PROPS} from '../property';\nimport {PropIndex} from '../propindex';\nimport {AutoCountQuery, FieldQuery, isFieldQuery, ScaleQuery, scaleType, toFieldDef} from '../query/encoding';\nimport {ExpandedType, isDiscrete} from '../query/expandedtype';\nimport {PrimitiveType, Schema} from '../schema';\nimport {contains} from '../util';\nimport {isWildcard, Wildcard} from '../wildcard';\nimport {EncodingConstraint, EncodingConstraintModel} from './base';\n\nexport const FIELD_CONSTRAINTS: EncodingConstraintModel<FieldQuery>[] = [\n  {\n    name: 'aggregateOpSupportedByType',\n    description: 'Aggregate function should be supported by data type.',\n    properties: [Property.TYPE, Property.AGGREGATE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.aggregate) {\n        return !isDiscrete(fieldQ.type);\n      }\n      // TODO: some aggregate function are actually supported by ordinal\n      return true; // no aggregate is okay with any type.\n    },\n  },\n  {\n    name: 'asteriskFieldWithCountOnly',\n    description: 'Field=\"*\" should be disallowed except aggregate=\"count\"',\n    properties: [Property.FIELD, Property.AGGREGATE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      return (fieldQ.field === '*') === (fieldQ.aggregate === 'count');\n    },\n  },\n  {\n    name: 'minCardinalityForBin',\n    description: 'binned quantitative field should not have too low cardinality',\n    properties: [Property.BIN, Property.FIELD, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.bin && fieldQ.type === TYPE.QUANTITATIVE) {\n        // We remove bin so schema can infer the raw unbinned cardinality.\n        const fieldQwithoutBin: FieldQuery = {\n          channel: fieldQ.channel,\n          field: fieldQ.field,\n          type: fieldQ.type,\n        };\n        return schema.cardinality(fieldQwithoutBin) >= opt.minCardinalityForBin;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'binAppliedForQuantitative',\n    description: 'bin should be applied to quantitative field only.',\n    properties: [Property.TYPE, Property.BIN],\n    allowWildcardForProperties: false,\n    strict: true, // FIXME VL2.0 actually support ordinal type for bin\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.bin) {\n        // If binned, the type must be quantitative\n        return fieldQ.type === TYPE.QUANTITATIVE;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'channelFieldCompatible',\n    description: `encoding channel's range type be compatible with channel type.`,\n    properties: [Property.CHANNEL, Property.TYPE, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      const fieldDef: TypedFieldDef<string> = {\n        field: 'f', // actual field doesn't really matter here\n        ...toFieldDef(fieldQ, {schema, props: ['bin', 'timeUnit', 'type']}),\n      };\n\n      const {compatible} = channelCompatibility(fieldDef, fieldQ.channel as ExtendedChannel);\n\n      if (compatible) {\n        return true;\n      } else {\n        // In VL, facet's field def must be discrete (O/N), but in CompassQL we can relax this a bit.\n        const isFacet = fieldQ.channel === 'row' || fieldQ.channel === 'column' || fieldQ.channel === 'facet';\n\n        const unit = fieldDef.timeUnit && normalizeTimeUnit(fieldDef.timeUnit)?.unit;\n        if (isFacet && unit && (isLocalSingleTimeUnit(unit) || isUTCTimeUnit(unit))) {\n          return true;\n        }\n        return false;\n      }\n    },\n  },\n  {\n    name: 'hasFn',\n    description: 'A field with as hasFn flag should have one of aggregate, timeUnit, or bin.',\n    properties: [Property.AGGREGATE, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.hasFn) {\n        return !!fieldQ.aggregate || !!fieldQ.bin || !!fieldQ.timeUnit;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitScaleZeroWithBinnedField',\n    description: 'Do not use scale zero with binned field',\n    properties: [Property.SCALE, getEncodingNestedProp('scale', 'zero'), Property.BIN],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.bin && fieldQ.scale) {\n        if ((fieldQ.scale as ScaleQuery).zero === true) {\n          return false;\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'onlyOneTypeOfFunction',\n    description: 'Only of of aggregate, autoCount, timeUnit, or bin should be applied at the same time.',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT, Property.TIMEUNIT, Property.BIN],\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery | AutoCountQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (isFieldQuery(fieldQ)) {\n        const numFn =\n          (!isWildcard(fieldQ.aggregate) && !!fieldQ.aggregate ? 1 : 0) +\n          (!isWildcard(fieldQ.bin) && !!fieldQ.bin ? 1 : 0) +\n          (!isWildcard(fieldQ.timeUnit) && !!fieldQ.timeUnit ? 1 : 0);\n        return numFn <= 1;\n      }\n      // For autoCount there is always only one type of function\n      return true;\n    },\n  },\n  {\n    name: 'timeUnitAppliedForTemporal',\n    description: 'Time unit should be applied to temporal field only.',\n    properties: [Property.TYPE, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.timeUnit && fieldQ.type !== TYPE.TEMPORAL) {\n        return false;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'timeUnitShouldHaveVariation',\n    description: 'A particular time unit should be applied only if they produce unique values.',\n    properties: [Property.TIMEUNIT, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.timeUnit && fieldQ.type === TYPE.TEMPORAL) {\n        if (!encWildcardIndex.has('timeUnit') && !opt.constraintManuallySpecifiedValue) {\n          // Do not have to check this as this is manually specified by users.\n          return true;\n        }\n        return schema.timeUnitHasVariation(fieldQ);\n      }\n      return true;\n    },\n  },\n  {\n    name: 'scalePropertiesSupportedByScaleType',\n    description: 'Scale properties must be supported by correct scale type',\n    properties: [].concat(SCALE_PROPS, [Property.SCALE, Property.TYPE]),\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.scale) {\n        const scale: ScaleQuery = fieldQ.scale as ScaleQuery;\n\n        //  If fieldQ.type is an Wildcard and scale.type is undefined, it is equivalent\n        //  to scale type is Wildcard. If scale type is an Wildcard, we do not yet know\n        //  what the scale type is, and thus can ignore the constraint.\n\n        const sType = scaleType(fieldQ);\n\n        if (sType === undefined || sType === null) {\n          // If still ambiguous, doesn't check the constraint\n          return true;\n        }\n\n        for (const scaleProp in scale) {\n          if (scaleProp === 'type' || scaleProp === 'name' || scaleProp === 'enum') {\n            // ignore type and properties of wildcards\n            continue;\n          }\n          const sProp = scaleProp as keyof Scale;\n          if (sType === 'point') {\n            // HACK: our current implementation of scaleType() can return point\n            // when the scaleType is a band since we didn't pass all parameter to Vega-Lite's scale type method.\n            if (!scaleTypeSupportProperty('point', sProp) && !scaleTypeSupportProperty('band', sProp)) {\n              return false;\n            }\n          } else if (!scaleTypeSupportProperty(sType, sProp)) {\n            return false;\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'scalePropertiesSupportedByChannel',\n    description: 'Not all scale properties are supported by all encoding channels',\n    properties: [].concat(SCALE_PROPS, [Property.SCALE, Property.CHANNEL]),\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ) {\n        const channel: ExtendedChannel = fieldQ.channel as ExtendedChannel;\n        const scale: ScaleQuery = fieldQ.scale as ScaleQuery;\n        if (channel && !isWildcard(channel) && scale) {\n          if (channel === 'row' || channel === 'column' || channel === 'facet') {\n            // row / column do not have scale\n            return false;\n          }\n          for (const scaleProp in scale) {\n            if (!scale.hasOwnProperty(scaleProp)) continue;\n            if (scaleProp === 'type' || scaleProp === 'name' || scaleProp === 'enum') {\n              // ignore type and properties of wildcards\n              continue;\n            }\n            const isSupported = channelScalePropertyIncompatability(channel, scaleProp as keyof Scale) === undefined;\n            if (!isSupported) {\n              return false;\n            }\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'typeMatchesPrimitiveType',\n    description: \"Data type should be supported by field's primitive type.\",\n    properties: [Property.FIELD, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.field === '*') {\n        return true;\n      }\n\n      const primitiveType = schema.primitiveType(fieldQ.field as string);\n      const type = fieldQ.type;\n\n      if (!encWildcardIndex.has('field') && !encWildcardIndex.has('type') && !opt.constraintManuallySpecifiedValue) {\n        // Do not have to check this as this is manually specified by users.\n        return true;\n      }\n\n      switch (primitiveType) {\n        case PrimitiveType.BOOLEAN:\n        case PrimitiveType.STRING:\n          return type !== TYPE.QUANTITATIVE && type !== TYPE.TEMPORAL;\n        case PrimitiveType.NUMBER:\n        case PrimitiveType.INTEGER:\n          return type !== TYPE.TEMPORAL;\n        case PrimitiveType.DATETIME:\n          // TODO: add NOMINAL, ORDINAL support after we support this in Vega-Lite\n          return type === TYPE.TEMPORAL;\n        case null:\n          // field does not exist in the schema\n          return false;\n      }\n      throw new Error('Not implemented');\n    },\n  },\n  {\n    name: 'typeMatchesSchemaType',\n    description: \"Enumerated data type of a field should match the field's type in the schema.\",\n    properties: [Property.FIELD, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, encWildcardIndex: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (!encWildcardIndex.has('field') && !encWildcardIndex.has('type') && !opt.constraintManuallySpecifiedValue) {\n        // Do not have to check this as this is manually specified by users.\n        return true;\n      }\n\n      if (fieldQ.field === '*') {\n        return fieldQ.type === TYPE.QUANTITATIVE;\n      }\n\n      return schema.vlType(fieldQ.field as string) === fieldQ.type;\n    },\n  },\n  {\n    name: 'maxCardinalityForCategoricalColor',\n    description: 'Categorical channel should not have too high cardinality',\n    properties: [Property.CHANNEL, Property.FIELD],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      // TODO: missing case where ordinal / temporal use categorical color\n      // (once we do so, need to add Property.BIN, Property.TIMEUNIT)\n      if (fieldQ.channel === CHANNEL.COLOR && (fieldQ.type === TYPE.NOMINAL || fieldQ.type === ExpandedType.KEY)) {\n        return schema.cardinality(fieldQ) <= opt.maxCardinalityForCategoricalColor;\n      }\n      return true; // other channel is irrelevant to this constraint\n    },\n  },\n  {\n    name: 'maxCardinalityForFacet',\n    description: 'Row/column channel should not have too high cardinality',\n    properties: [Property.CHANNEL, Property.FIELD, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.channel === CHANNEL.ROW || fieldQ.channel === CHANNEL.COLUMN) {\n        return schema.cardinality(fieldQ) <= opt.maxCardinalityForFacet;\n      }\n      return true; // other channel is irrelevant to this constraint\n    },\n  },\n  {\n    name: 'maxCardinalityForShape',\n    description: 'Shape channel should not have too high cardinality',\n    properties: [Property.CHANNEL, Property.FIELD, Property.BIN, Property.TIMEUNIT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (fieldQ: FieldQuery, schema: Schema, _: PropIndex<Wildcard<any>>, opt: QueryConfig) => {\n      if (fieldQ.channel === CHANNEL.SHAPE) {\n        return schema.cardinality(fieldQ) <= opt.maxCardinalityForShape;\n      }\n      return true; // other channel is irrelevant to this constraint\n    },\n  },\n  {\n    name: 'dataTypeAndFunctionMatchScaleType',\n    description: 'Scale type must match data type',\n    properties: [\n      Property.TYPE,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TIMEUNIT,\n      Property.BIN,\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.scale) {\n        const type = fieldQ.type;\n        const sType = scaleType(fieldQ);\n\n        if (isDiscrete(type)) {\n          return sType === undefined || hasDiscreteDomain(sType);\n        } else if (type === TYPE.TEMPORAL) {\n          if (!fieldQ.timeUnit) {\n            return contains([ScaleType.TIME, ScaleType.UTC, undefined], sType);\n          } else {\n            return contains([ScaleType.TIME, ScaleType.UTC, undefined], sType) || hasDiscreteDomain(sType);\n          }\n        } else if (type === TYPE.QUANTITATIVE) {\n          if (fieldQ.bin) {\n            return contains([ScaleType.LINEAR, undefined], sType);\n          } else {\n            return contains(\n              [\n                ScaleType.LOG,\n                ScaleType.POW,\n                ScaleType.SQRT,\n                ScaleType.QUANTILE,\n                ScaleType.QUANTIZE,\n                ScaleType.LINEAR,\n                undefined,\n              ],\n              sType\n            );\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'stackIsOnlyUsedWithXY',\n    description: 'stack should only be allowed for x and y channels',\n    properties: [Property.STACK, Property.CHANNEL],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (fieldQ: FieldQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      if (fieldQ.stack) {\n        return fieldQ.channel === CHANNEL.X || fieldQ.channel === CHANNEL.Y;\n      }\n      return true;\n    },\n  },\n].map((ec: EncodingConstraint<FieldQuery>) => new EncodingConstraintModel<FieldQuery>(ec));\n\nexport const FIELD_CONSTRAINT_INDEX: {\n  [name: string]: EncodingConstraintModel<FieldQuery | AutoCountQuery>;\n} = FIELD_CONSTRAINTS.reduce((m, ec: EncodingConstraintModel<FieldQuery | AutoCountQuery>) => {\n  m[ec.name()] = ec;\n  return m;\n}, {});\n\nexport const FIELD_CONSTRAINTS_BY_PROPERTY = FIELD_CONSTRAINTS.reduce((index, c) => {\n  for (const prop of c.properties()) {\n    // Initialize array and use it\n    index.set(prop, index.get(prop) || []);\n    index.get(prop).push(c);\n  }\n  return index;\n}, new PropIndex<EncodingConstraintModel<FieldQuery>[]>());\n","import {QueryConfig} from '../config';\nimport {Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {Wildcard} from '../wildcard';\nimport {Schema} from '../schema';\nimport {contains} from '../util';\n\nimport {ValueQuery} from '../query/encoding';\nimport {EncodingConstraintModel, EncodingConstraint} from './base';\n\nexport const VALUE_CONSTRAINTS: EncodingConstraintModel<ValueQuery>[] = [\n  {\n    name: 'doesNotSupportConstantValue',\n    description: 'row, column, x, y, order, and detail should not work with constant values.',\n    properties: [Property.TYPE, Property.AGGREGATE],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (valueQ: ValueQuery, _: Schema, __: PropIndex<Wildcard<any>>, ___: QueryConfig) => {\n      return !contains(['row', 'column', 'x', 'y', 'detail', 'order'], valueQ.channel);\n    },\n  },\n].map((ec: EncodingConstraint<ValueQuery>) => new EncodingConstraintModel<ValueQuery>(ec));\n\nexport const VALUE_CONSTRAINT_INDEX: {[name: string]: EncodingConstraintModel<ValueQuery>} = VALUE_CONSTRAINTS.reduce(\n  (m, ec: EncodingConstraintModel<ValueQuery>) => {\n    m[ec.name()] = ec;\n    return m;\n  },\n  {}\n);\n\nexport const VALUE_CONSTRAINTS_BY_PROPERTY = VALUE_CONSTRAINTS.reduce((index, c) => {\n  for (const prop of c.properties()) {\n    index.set(prop, index.get(prop) || []);\n    index.get(prop).push(c);\n  }\n\n  return index;\n}, new PropIndex<EncodingConstraintModel<ValueQuery>[]>());\n","import {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {Property} from '../property';\nimport {Wildcard} from '../wildcard';\nimport {Schema} from '../schema';\n\nimport {isValueQuery} from '../query/encoding';\nimport {FIELD_CONSTRAINTS_BY_PROPERTY} from './field';\nimport {VALUE_CONSTRAINTS_BY_PROPERTY} from './value';\n\n/**\n * Check all encoding constraints for a particular property and index tuple\n */\nexport function checkEncoding(\n  prop: Property,\n  wildcard: Wildcard<any>,\n  index: number,\n  specM: SpecQueryModel,\n  schema: Schema,\n  opt: QueryConfig\n): string {\n  // Check encoding constraint\n  const encodingConstraints = FIELD_CONSTRAINTS_BY_PROPERTY.get(prop) || [];\n  const encQ = specM.getEncodingQueryByIndex(index);\n\n  for (const c of encodingConstraints) {\n    // Check if the constraint is enabled\n    if (c.strict() || !!opt[c.name()]) {\n      // For strict constraint, or enabled non-strict, check the constraints\n\n      const satisfy = c.satisfy(encQ, schema, specM.wildcardIndex.encodings[index], opt);\n      if (!satisfy) {\n        const violatedConstraint = `(enc) ${c.name()}`;\n        /* istanbul ignore if */\n        if (opt.verbose) {\n          console.log(`${violatedConstraint} failed with ${specM.toShorthand()} for ${wildcard.name}`);\n        }\n        return violatedConstraint;\n      }\n    }\n  }\n\n  const valueContraints = VALUE_CONSTRAINTS_BY_PROPERTY.get(prop) || [];\n\n  for (const c of valueContraints) {\n    // Check if the constraint is enabled\n    if ((c.strict() || !!opt[c.name()]) && isValueQuery(encQ)) {\n      // For strict constraint, or enabled non-strict, check the constraints\n      const satisfy = c.satisfy(encQ, schema, specM.wildcardIndex.encodings[index], opt);\n      if (!satisfy) {\n        const violatedConstraint = `(enc) ${c.name()}`;\n        /* istanbul ignore if */\n        if (opt.verbose) {\n          console.log(`${violatedConstraint} failed with ${specM.toShorthand()} for ${wildcard.name}`);\n        }\n        return violatedConstraint;\n      }\n    }\n  }\n  return null;\n}\n","import {SUM_OPS} from 'vega-lite/build/src/aggregate';\nimport * as CHANNEL from 'vega-lite/build/src/channel';\nimport {NONPOSITION_CHANNELS, supportMark} from 'vega-lite/build/src/channel';\nimport * as MARK from 'vega-lite/build/src/mark';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {ScaleType} from 'vega-lite/build/src/scale';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {getEncodingNestedProp, isEncodingNestedProp, isEncodingProperty, Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {\n  EncodingQuery,\n  FieldQuery,\n  isAutoCountQuery,\n  isDimension,\n  isDisabledAutoCountQuery,\n  isEnabledAutoCountQuery,\n  isFieldQuery,\n  isMeasure,\n  isValueQuery,\n  ScaleQuery,\n  scaleType,\n} from '../query/encoding';\nimport {ExpandedType} from '../query/expandedtype';\nimport {Schema} from '../schema';\nimport {contains, every, some} from '../util';\nimport {isWildcard, Wildcard} from '../wildcard';\nimport {AbstractConstraint, AbstractConstraintModel} from './base';\n\nconst NONPOSITION_CHANNELS_INDEX = NONPOSITION_CHANNELS.reduce((m, channel) => {\n  m[channel] = true;\n  return m;\n}, {});\n\nexport interface SpecConstraintChecker {\n  (specM: SpecQueryModel, schema: Schema, opt: QueryConfig): boolean;\n}\n\nexport class SpecConstraintModel extends AbstractConstraintModel {\n  constructor(specConstraint: SpecConstraint) {\n    super(specConstraint);\n  }\n\n  public hasAllRequiredPropertiesSpecific(specM: SpecQueryModel): boolean {\n    return every(this.constraint.properties, (prop) => {\n      if (prop === Property.MARK) {\n        return !isWildcard(specM.getMark());\n      }\n\n      // TODO: transform\n\n      if (isEncodingNestedProp(prop)) {\n        const parent = prop.parent;\n        const child = prop.child;\n\n        return every(specM.getEncodings(), (encQ) => {\n          if (!encQ[parent]) {\n            return true;\n          }\n\n          return !isWildcard(encQ[parent][child]);\n        });\n      }\n\n      if (!isEncodingProperty(prop)) {\n        throw new Error('UNIMPLEMENTED');\n      }\n\n      return every(specM.getEncodings(), (encQ) => {\n        if (!encQ[prop]) {\n          return true;\n        }\n        return !isWildcard(encQ[prop]);\n      });\n    });\n  }\n\n  public satisfy(specM: SpecQueryModel, schema: Schema, opt: QueryConfig) {\n    // TODO: Re-order logic to optimize the \"allowWildcardForProperties\" check\n    if (!this.constraint.allowWildcardForProperties) {\n      if (!this.hasAllRequiredPropertiesSpecific(specM)) {\n        return true;\n      }\n    }\n\n    return (this.constraint as SpecConstraint).satisfy(specM, schema, opt);\n  }\n}\n\nexport interface SpecConstraint extends AbstractConstraint {\n  /** Method for checking if the spec query satisfies this constraint. */\n  satisfy: SpecConstraintChecker;\n}\n\nexport const SPEC_CONSTRAINTS: SpecConstraintModel[] = [\n  {\n    name: 'noRepeatedChannel',\n    description: 'Each encoding channel should only be used once.',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: true,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const usedChannel = {};\n\n      // channel for all encodings should be valid\n      return every(specM.getEncodings(), (encQ) => {\n        if (!isWildcard(encQ.channel)) {\n          // If channel is specified, it should no be used already\n          if (usedChannel[encQ.channel]) {\n            return false;\n          }\n          usedChannel[encQ.channel] = true;\n          return true;\n        }\n        return true; // unspecified channel is valid\n      });\n    },\n  },\n  {\n    name: 'alwaysIncludeZeroInScaleWithBarMark',\n    description: 'Do not recommend bar mark if scale does not start at zero',\n    properties: [\n      Property.MARK,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'zero'),\n      Property.CHANNEL,\n      Property.TYPE,\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n      const encodings = specM.getEncodings();\n\n      if (mark === MARK.BAR) {\n        for (const encQ of encodings) {\n          if (\n            isFieldQuery(encQ) &&\n            (encQ.channel === CHANNEL.X || encQ.channel === CHANNEL.Y) &&\n            encQ.type === TYPE.QUANTITATIVE &&\n            encQ.scale &&\n            (encQ.scale as ScaleQuery).zero === false\n          ) {\n            // TODO: zero shouldn't be manually specified\n            return false;\n          }\n        }\n      }\n\n      return true;\n    },\n  },\n  {\n    name: 'autoAddCount',\n    description:\n      'Automatically adding count only for plots with only ordinal, binned quantitative, or temporal with timeunit fields.',\n    properties: [Property.BIN, Property.TIMEUNIT, Property.TYPE, Property.AUTOCOUNT],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const hasAutoCount = some(specM.getEncodings(), (encQ: EncodingQuery) => isEnabledAutoCountQuery(encQ));\n\n      if (hasAutoCount) {\n        // Auto count should only be applied if all fields are nominal, ordinal, temporal with timeUnit, binned quantitative, or autoCount\n        return every(specM.getEncodings(), (encQ: EncodingQuery) => {\n          if (isValueQuery(encQ)) {\n            return true;\n          }\n\n          if (isAutoCountQuery(encQ)) {\n            return true;\n          }\n\n          switch (encQ.type) {\n            case TYPE.QUANTITATIVE:\n              return !!encQ.bin;\n            case TYPE.TEMPORAL:\n              return !!encQ.timeUnit;\n            case TYPE.ORDINAL:\n            case ExpandedType.KEY:\n            case TYPE.NOMINAL:\n              return true;\n          }\n          /* istanbul ignore next */\n          throw new Error('Unsupported Type');\n        });\n      } else {\n        const autoCountEncIndex = specM.wildcardIndex.encodingIndicesByProperty.get('autoCount') || [];\n        const neverHaveAutoCount = every(autoCountEncIndex, (index: number) => {\n          const encQ = specM.getEncodingQueryByIndex(index);\n          return isAutoCountQuery(encQ) && !isWildcard(encQ.autoCount);\n        });\n        if (neverHaveAutoCount) {\n          // If the query surely does not have autoCount\n          // then one of the field should be\n          // (1) unbinned quantitative\n          // (2) temporal without time unit\n          // (3) nominal or ordinal field\n          // or at least have potential to be (still ambiguous).\n          return some(specM.getEncodings(), (encQ: EncodingQuery) => {\n            if ((isFieldQuery(encQ) || isAutoCountQuery(encQ)) && encQ.type === TYPE.QUANTITATIVE) {\n              if (isDisabledAutoCountQuery(encQ)) {\n                return false;\n              } else {\n                return isFieldQuery(encQ) && (!encQ.bin || isWildcard(encQ.bin));\n              }\n            } else if (isFieldQuery(encQ) && encQ.type === TYPE.TEMPORAL) {\n              return !encQ.timeUnit || isWildcard(encQ.timeUnit);\n            }\n            return false; // nominal or ordinal\n          });\n        }\n      }\n\n      return true; // no auto count, no constraint\n    },\n  },\n  {\n    name: 'channelPermittedByMarkType',\n    description: 'Each encoding channel should be supported by the mark type',\n    properties: [Property.CHANNEL, Property.MARK],\n    allowWildcardForProperties: true, // only require mark\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n\n      // if mark is unspecified, no need to check\n      if (isWildcard(mark)) return true;\n\n      // TODO: can optimize this to detect only what's the changed property if needed.\n      return every(specM.getEncodings(), (encQ) => {\n        // channel unspecified, no need to check\n        if (isWildcard(encQ.channel)) return true;\n\n        if (encQ.channel === 'row' || encQ.channel === 'column' || encQ.channel === 'facet') return true;\n\n        return !!supportMark(encQ.channel, mark as Mark);\n      });\n    },\n  },\n  {\n    name: 'hasAllRequiredChannelsForMark',\n    description: 'All required channels for the specified mark should be specified',\n    properties: [Property.CHANNEL, Property.MARK],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n\n      switch (mark) {\n        case MARK.AREA:\n        case MARK.LINE:\n          return specM.channelUsed(CHANNEL.X) && specM.channelUsed(CHANNEL.Y);\n        case MARK.TEXT:\n          return specM.channelUsed(CHANNEL.TEXT);\n        case MARK.BAR:\n        case MARK.CIRCLE:\n        case MARK.SQUARE:\n        case MARK.TICK:\n        case MARK.RULE:\n        case MARK.RECT:\n          return specM.channelUsed(CHANNEL.X) || specM.channelUsed(CHANNEL.Y);\n        case MARK.POINT:\n          // This allows generating a point plot if channel was not a wildcard.\n          return (\n            !specM.wildcardIndex.hasProperty(Property.CHANNEL) ||\n            specM.channelUsed(CHANNEL.X) ||\n            specM.channelUsed(CHANNEL.Y)\n          );\n      }\n      /* istanbul ignore next */\n      throw new Error(`hasAllRequiredChannelsForMark not implemented for mark${JSON.stringify(mark)}`);\n    },\n  },\n  {\n    name: 'omitAggregate',\n    description: 'Omit aggregate plots.',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (specM.isAggregate()) {\n        return false;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitAggregatePlotWithDimensionOnlyOnFacet',\n    description: 'Omit aggregate plots with dimensions only on facets as that leads to inefficient use of space.',\n    properties: [Property.CHANNEL, Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (specM.isAggregate()) {\n        let hasNonFacetDim = false;\n        let hasDim = false;\n        let hasEnumeratedFacetDim = false;\n        specM.specQuery.encodings.forEach((encQ, index) => {\n          if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) return; // skip unused field\n\n          // FieldQuery & !encQ.aggregate\n          if (isFieldQuery(encQ) && !encQ.aggregate) {\n            // isDimension\n            hasDim = true;\n            if (contains([CHANNEL.ROW, CHANNEL.COLUMN], encQ.channel)) {\n              if (specM.wildcardIndex.hasEncodingProperty(index, Property.CHANNEL)) {\n                hasEnumeratedFacetDim = true;\n              }\n            } else {\n              hasNonFacetDim = true;\n            }\n          }\n        });\n        if (hasDim && !hasNonFacetDim) {\n          if (hasEnumeratedFacetDim || opt.constraintManuallySpecifiedValue) {\n            return false;\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitAggregatePlotWithoutDimension',\n    description: 'Aggregate plots without dimension should be omitted',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT, Property.BIN, Property.TIMEUNIT, Property.TYPE],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (specM.isAggregate()) {\n        // TODO relax\n        return some(specM.getEncodings(), (encQ: EncodingQuery) => {\n          if (isDimension(encQ) || (isFieldQuery(encQ) && encQ.type === 'temporal')) {\n            return true;\n          }\n          return false;\n        });\n      }\n      return true;\n    },\n  },\n  {\n    // TODO: we can be smarter and check if bar has occlusion based on profiling statistics\n    name: 'omitBarLineAreaWithOcclusion',\n    description: \"Don't use bar, line or area to visualize raw plot as they often lead to occlusion.\",\n    properties: [Property.MARK, Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (contains([MARK.BAR, MARK.LINE, MARK.AREA], specM.getMark())) {\n        return specM.isAggregate();\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitBarTickWithSize',\n    description: 'Do not map field to size channel with bar and tick mark',\n    properties: [Property.CHANNEL, Property.MARK],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      const mark = specM.getMark();\n      if (contains([MARK.TICK, MARK.BAR], mark)) {\n        if (specM.channelEncodingField(CHANNEL.SIZE)) {\n          if (opt.constraintManuallySpecifiedValue) {\n            // If size is used and we constraintManuallySpecifiedValue,\n            // then the spec violates this constraint.\n            return false;\n          } else {\n            // Otherwise have to search for the size channel and check if it is enumerated\n            const encodings = specM.specQuery.encodings;\n            for (let i = 0; i < encodings.length; i++) {\n              const encQ = encodings[i];\n              if (encQ.channel === CHANNEL.SIZE) {\n                if (specM.wildcardIndex.hasEncodingProperty(i, Property.CHANNEL)) {\n                  // If enumerated, then this is bad\n                  return false;\n                } else {\n                  // If it's manually specified, no need to continue searching, just return.\n                  return true;\n                }\n              }\n            }\n          }\n        }\n      }\n      return true; // skip\n    },\n  },\n  {\n    name: 'omitBarAreaForLogScale',\n    description: \"Do not use bar and area mark for x and y's log scale\",\n    properties: [\n      Property.MARK,\n      Property.CHANNEL,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TYPE,\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n      const encodings = specM.getEncodings();\n\n      // TODO: mark or scale type should be enumerated\n      if (mark === MARK.AREA || mark === MARK.BAR) {\n        for (const encQ of encodings) {\n          if (isFieldQuery(encQ) && (encQ.channel === CHANNEL.X || encQ.channel === CHANNEL.Y) && encQ.scale) {\n            const sType = scaleType(encQ);\n\n            if (sType === ScaleType.LOG) {\n              return false;\n            }\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitMultipleNonPositionalChannels',\n    description:\n      'Unless manually specified, do not use multiple non-positional encoding channel to avoid over-encoding.',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      // have to use specM.specQuery.encodings insetad of specM.getEncodings()\n      // since specM.getEncodings() remove encQ with autoCount===false from the array\n      // and thus might shift the index\n      const encodings = specM.specQuery.encodings;\n      let nonPositionChannelCount = 0;\n      let hasEnumeratedNonPositionChannel = false;\n\n      for (let i = 0; i < encodings.length; i++) {\n        const encQ = encodings[i];\n        if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) {\n          continue; // ignore skipped encoding\n        }\n\n        const channel = encQ.channel;\n        if (!isWildcard(channel)) {\n          if (NONPOSITION_CHANNELS_INDEX[`${channel}`]) {\n            nonPositionChannelCount += 1;\n            if (specM.wildcardIndex.hasEncodingProperty(i, Property.CHANNEL)) {\n              hasEnumeratedNonPositionChannel = true;\n            }\n            if (\n              nonPositionChannelCount > 1 &&\n              (hasEnumeratedNonPositionChannel || opt.constraintManuallySpecifiedValue)\n            ) {\n              return false;\n            }\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitNonPositionalOrFacetOverPositionalChannels',\n    description: 'Do not use non-positional channels unless all positional channels are used',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      const encodings = specM.specQuery.encodings;\n      let hasNonPositionalChannelOrFacet = false;\n      let hasEnumeratedNonPositionOrFacetChannel = false;\n      let hasX = false;\n      let hasY = false;\n      for (let i = 0; i < encodings.length; i++) {\n        const encQ = encodings[i];\n        if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) {\n          continue; // ignore skipped encoding\n        }\n\n        const channel = encQ.channel;\n        if (channel === CHANNEL.X) {\n          hasX = true;\n        } else if (channel === CHANNEL.Y) {\n          hasY = true;\n        } else if (!isWildcard(channel)) {\n          // All non positional channel / Facet\n          hasNonPositionalChannelOrFacet = true;\n          if (specM.wildcardIndex.hasEncodingProperty(i, Property.CHANNEL)) {\n            hasEnumeratedNonPositionOrFacetChannel = true;\n          }\n        }\n      }\n\n      if (\n        hasEnumeratedNonPositionOrFacetChannel ||\n        (opt.constraintManuallySpecifiedValue && hasNonPositionalChannelOrFacet)\n      ) {\n        return hasX && hasY;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitRaw',\n    description: 'Omit raw plots.',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (!specM.isAggregate()) {\n        return false;\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitRawContinuousFieldForAggregatePlot',\n    description:\n      'Aggregate plot should not use raw continuous field as group by values. ' +\n      '(Quantitative should be binned. Temporal should have time unit.)',\n    properties: [Property.AGGREGATE, Property.AUTOCOUNT, Property.TIMEUNIT, Property.BIN, Property.TYPE],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (specM.isAggregate()) {\n        const encodings = specM.specQuery.encodings;\n        for (let i = 0; i < encodings.length; i++) {\n          const encQ = encodings[i];\n          if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) continue; // skip unused encoding\n\n          // TODO: aggregate for ordinal and temporal\n\n          if (isFieldQuery(encQ) && encQ.type === TYPE.TEMPORAL) {\n            // Temporal fields should have timeUnit or is still a wildcard\n            if (\n              !encQ.timeUnit &&\n              (specM.wildcardIndex.hasEncodingProperty(i, Property.TIMEUNIT) || opt.constraintManuallySpecifiedValue)\n            ) {\n              return false;\n            }\n          }\n          if (encQ.type === TYPE.QUANTITATIVE) {\n            if (isFieldQuery(encQ) && !encQ.bin && !encQ.aggregate) {\n              // If Raw Q\n              if (\n                specM.wildcardIndex.hasEncodingProperty(i, Property.BIN) ||\n                specM.wildcardIndex.hasEncodingProperty(i, Property.AGGREGATE) ||\n                specM.wildcardIndex.hasEncodingProperty(i, Property.AUTOCOUNT)\n              ) {\n                // and it's raw from enumeration\n                return false;\n              }\n              if (opt.constraintManuallySpecifiedValue) {\n                // or if we constraintManuallySpecifiedValue\n                return false;\n              }\n            }\n          }\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitRawDetail',\n    description: 'Do not use detail channel with raw plot.',\n    properties: [Property.CHANNEL, Property.AGGREGATE, Property.AUTOCOUNT],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (specM.isAggregate()) {\n        return true;\n      }\n      return every(specM.specQuery.encodings, (encQ, index) => {\n        if (isValueQuery(encQ) || isDisabledAutoCountQuery(encQ)) return true; // ignore autoCount field\n\n        if (encQ.channel === CHANNEL.DETAIL) {\n          // Detail channel for raw plot is not good, except when its enumerated\n          // or when it's manually specified but we constraintManuallySpecifiedValue.\n          if (\n            specM.wildcardIndex.hasEncodingProperty(index, Property.CHANNEL) ||\n            opt.constraintManuallySpecifiedValue\n          ) {\n            return false;\n          }\n        }\n        return true;\n      });\n    },\n  },\n  {\n    name: 'omitRepeatedField',\n    description: 'Each field should be mapped to only one channel',\n    properties: [Property.FIELD],\n    allowWildcardForProperties: true,\n    strict: false, // over-encoding is sometimes good, but let's turn it off by default\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      const fieldUsed = {};\n      const fieldEnumerated = {};\n\n      const encodings = specM.specQuery.encodings;\n      for (let i = 0; i < encodings.length; i++) {\n        const encQ = encodings[i];\n\n        if (isValueQuery(encQ) || isAutoCountQuery(encQ)) continue;\n\n        let field;\n        if (encQ.field && !isWildcard(encQ.field)) {\n          field = encQ.field as string;\n        }\n        if (isAutoCountQuery(encQ) && !isWildcard(encQ.autoCount)) {\n          field = 'count_*';\n        }\n\n        if (field) {\n          if (specM.wildcardIndex.hasEncodingProperty(i, Property.FIELD)) {\n            fieldEnumerated[field] = true;\n          }\n          // When the field is specified previously,\n          // if it is enumerated (either previously or in this encQ)\n          // or if the opt.constraintManuallySpecifiedValue is true,\n          // then it violates the constraint.\n\n          if (fieldUsed[field]) {\n            if (fieldEnumerated[field] || opt.constraintManuallySpecifiedValue) {\n              return false;\n            }\n          }\n\n          fieldUsed[field] = true;\n        }\n      }\n      return true;\n    },\n  },\n  // TODO: omitShapeWithBin\n  {\n    name: 'omitVerticalDotPlot',\n    description: 'Do not output vertical dot plot.',\n    properties: [Property.CHANNEL],\n    allowWildcardForProperties: true,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const encodings = specM.getEncodings();\n      if (encodings.length === 1 && encodings[0].channel === CHANNEL.Y) {\n        return false;\n      }\n      return true;\n    },\n  },\n  // EXPENSIVE CONSTRAINTS -- check them later!\n  {\n    name: 'hasAppropriateGraphicTypeForMark',\n    description: 'Has appropriate graphic type for mark',\n    properties: [\n      Property.CHANNEL,\n      Property.MARK,\n      Property.TYPE,\n      Property.TIMEUNIT,\n      Property.BIN,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT,\n    ],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const mark = specM.getMark();\n\n      switch (mark) {\n        case MARK.AREA:\n        case MARK.LINE:\n          if (specM.isAggregate()) {\n            // TODO: refactor based on profiling statistics\n            const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n            const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n            const xIsMeasure = isMeasure(xEncQ);\n            const yIsMeasure = isMeasure(yEncQ);\n\n            // for aggregate line / area, we need at least one group-by axis and one measure axis.\n            return (\n              xEncQ &&\n              yEncQ &&\n              xIsMeasure !== yIsMeasure &&\n              // and the dimension axis should not be nominal\n              // TODO: make this clause optional\n\n              !(isFieldQuery(xEncQ) && !xIsMeasure && contains(['nominal', 'key'], xEncQ.type)) &&\n              !(isFieldQuery(yEncQ) && !yIsMeasure && contains(['nominal', 'key'], yEncQ.type))\n            );\n            // TODO: allow connected scatterplot\n          }\n          return true;\n        case MARK.TEXT:\n          // FIXME correctly when we add text\n          return true;\n        case MARK.BAR:\n        case MARK.TICK:\n          // Bar and tick should not use size.\n          if (specM.channelEncodingField(CHANNEL.SIZE)) {\n            return false;\n          } else {\n            // Tick and Bar should have one and only one measure\n            const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n            const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n            const xIsMeasure = isMeasure(xEncQ);\n            const yIsMeasure = isMeasure(yEncQ);\n            if (xIsMeasure !== yIsMeasure) {\n              return true;\n            }\n            return false;\n          }\n        case MARK.RECT:\n          // Until CompassQL supports layering, it only makes sense for\n          // rect to encode DxD or 1xD (otherwise just use bar).\n          // Furthermore, color should only be used in a 'heatmap' fashion\n          // (with a measure field).\n          const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n          const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n          const xIsDimension = isDimension(xEncQ);\n          const yIsDimension = isDimension(yEncQ);\n\n          const colorEncQ = specM.getEncodingQueryByChannel(CHANNEL.COLOR);\n          const colorIsQuantitative = isMeasure(colorEncQ);\n          const colorIsOrdinal = isFieldQuery(colorEncQ) ? colorEncQ.type === TYPE.ORDINAL : false;\n\n          const correctChannels =\n            (xIsDimension && yIsDimension) ||\n            (xIsDimension && !specM.channelUsed(CHANNEL.Y)) ||\n            (yIsDimension && !specM.channelUsed(CHANNEL.X));\n\n          const correctColor = !colorEncQ || (colorEncQ && (colorIsQuantitative || colorIsOrdinal));\n\n          return correctChannels && correctColor;\n        case MARK.CIRCLE:\n        case MARK.POINT:\n        case MARK.SQUARE:\n        case MARK.RULE:\n          return true;\n      }\n      /* istanbul ignore next */\n      throw new Error(`hasAllRequiredChannelsForMark not implemented for mark${mark}`);\n    },\n  },\n  {\n    name: 'omitInvalidStackSpec',\n    description: 'If stack is specified, must follow Vega-Lite stack rules',\n    properties: [\n      Property.STACK,\n      Property.FIELD,\n      Property.CHANNEL,\n      Property.MARK,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TYPE,\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      if (!specM.wildcardIndex.hasProperty(Property.STACK)) {\n        return true;\n      }\n\n      const stackProps = specM.getVlStack();\n      if (stackProps === null && specM.getStackOffset() !== null) {\n        return false;\n      }\n\n      if (stackProps.fieldChannel !== specM.getStackChannel()) {\n        return false;\n      }\n\n      return true;\n    },\n  },\n  {\n    name: 'omitNonSumStack',\n    description: 'Stack specifications that use non-summative aggregates should be omitted (even implicit ones)',\n    properties: [\n      Property.CHANNEL,\n      Property.MARK,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT,\n      Property.SCALE,\n      getEncodingNestedProp('scale', 'type'),\n      Property.TYPE,\n    ],\n    allowWildcardForProperties: false,\n    strict: true,\n    satisfy: (specM: SpecQueryModel, _: Schema, __: QueryConfig) => {\n      const specStack = specM.getVlStack();\n      if (specStack != null) {\n        const stackParentEncQ = specM.getEncodingQueryByChannel(specStack.fieldChannel) as FieldQuery;\n        if (!contains(SUM_OPS, stackParentEncQ.aggregate)) {\n          return false;\n        }\n      }\n      return true;\n    },\n  },\n  {\n    name: 'omitTableWithOcclusionIfAutoAddCount',\n    description:\n      'Plots without aggregation or autocount where x and y are both discrete should be omitted if autoAddCount is enabled as they often lead to occlusion',\n    properties: [\n      Property.CHANNEL,\n      Property.TYPE,\n      Property.TIMEUNIT,\n      Property.BIN,\n      Property.AGGREGATE,\n      Property.AUTOCOUNT,\n    ],\n    allowWildcardForProperties: false,\n    strict: false,\n    satisfy: (specM: SpecQueryModel, _: Schema, opt: QueryConfig) => {\n      if (opt.autoAddCount) {\n        const xEncQ = specM.getEncodingQueryByChannel('x');\n        const yEncQ = specM.getEncodingQueryByChannel('y');\n\n        if ((!isFieldQuery(xEncQ) || isDimension(xEncQ)) && (!isFieldQuery(yEncQ) || isDimension(yEncQ))) {\n          if (!specM.isAggregate()) {\n            return false;\n          } else {\n            return every(specM.getEncodings(), (encQ) => {\n              const channel = encQ.channel;\n\n              if (\n                channel !== CHANNEL.X &&\n                channel !== CHANNEL.Y &&\n                channel !== CHANNEL.ROW &&\n                channel !== CHANNEL.COLUMN\n              ) {\n                // Non-position fields should not be unaggreated fields\n                if (isFieldQuery(encQ) && !encQ.aggregate) {\n                  return false;\n                }\n              }\n              return true;\n            });\n          }\n        }\n      }\n      return true;\n    },\n  },\n].map((sc) => new SpecConstraintModel(sc));\n\n// For testing\nexport const SPEC_CONSTRAINT_INDEX: {[name: string]: SpecConstraintModel} = SPEC_CONSTRAINTS.reduce(\n  (m: any, c: SpecConstraintModel) => {\n    m[c.name()] = c;\n    return m;\n  },\n  {}\n);\n\nconst SPEC_CONSTRAINTS_BY_PROPERTY = SPEC_CONSTRAINTS.reduce((index, c) => {\n  for (const prop of c.properties()) {\n    // Initialize array and use it\n    index.set(prop, index.get(prop) || []);\n    index.get(prop).push(c);\n  }\n  return index;\n}, new PropIndex<SpecConstraintModel[]>());\n\n/**\n * Check all encoding constraints for a particular property and index tuple\n */\nexport function checkSpec(\n  prop: Property,\n  wildcard: Wildcard<any>,\n  specM: SpecQueryModel,\n  schema: Schema,\n  opt: QueryConfig\n): string {\n  // Check encoding constraint\n  const specConstraints = SPEC_CONSTRAINTS_BY_PROPERTY.get(prop) || [];\n\n  for (const c of specConstraints) {\n    // Check if the constraint is enabled\n    if (c.strict() || !!opt[c.name()]) {\n      // For strict constraint, or enabled non-strict, check the constraints\n\n      const satisfy = c.satisfy(specM, schema, opt);\n      if (!satisfy) {\n        const violatedConstraint = `(spec) ${c.name()}`;\n        /* istanbul ignore if */\n        if (opt.verbose) {\n          console.log(`${violatedConstraint} failed with ${specM.toShorthand()} for ${wildcard.name}`);\n        }\n        return violatedConstraint;\n      }\n    }\n  }\n  return null;\n}\n","import {Mark} from 'vega-lite/build/src/mark';\n\nimport {QueryConfig} from './config';\nimport {checkEncoding} from './constraint/encoding';\nimport {checkSpec} from './constraint/spec';\nimport {WildcardIndex} from './wildcardindex';\nimport {SpecQueryModel} from './model';\nimport {Property, ENCODING_TOPLEVEL_PROPS, ENCODING_NESTED_PROPS} from './property';\nimport {PropIndex} from './propindex';\nimport {Wildcard} from './wildcard';\nimport {Schema} from './schema';\nimport {isValueQuery, isDisabledAutoCountQuery} from './query/encoding';\n\nconst ENUMERATOR_INDEX = new PropIndex<EnumeratorFactory>();\n\nexport interface Enumerator {\n  (answerSets: SpecQueryModel[], specM: SpecQueryModel): SpecQueryModel[];\n}\n\nexport function getEnumerator(prop: Property) {\n  return ENUMERATOR_INDEX.get(prop);\n}\n\nexport interface EnumeratorFactory {\n  (wildcardIndex: WildcardIndex, schema: Schema, opt: QueryConfig): Enumerator;\n}\n\nENUMERATOR_INDEX.set('mark', (wildcardIndex: WildcardIndex, schema: Schema, opt: QueryConfig): Enumerator => {\n  return (answerSet, specM: SpecQueryModel) => {\n    const markWildcard = specM.getMark() as Wildcard<Mark>;\n\n    // enumerate the value\n    markWildcard.enum.forEach((mark) => {\n      specM.setMark(mark);\n      // Check spec constraint\n      const violatedSpecConstraint = checkSpec('mark', wildcardIndex.mark, specM, schema, opt);\n      if (!violatedSpecConstraint) {\n        // emit\n        answerSet.push(specM.duplicate());\n      }\n    });\n\n    // Reset to avoid side effect\n    specM.resetMark();\n\n    return answerSet;\n  };\n});\n\nENCODING_TOPLEVEL_PROPS.forEach((prop) => {\n  ENUMERATOR_INDEX.set(prop, EncodingPropertyGeneratorFactory(prop));\n});\n\nENCODING_NESTED_PROPS.forEach((nestedProp) => {\n  ENUMERATOR_INDEX.set(nestedProp, EncodingPropertyGeneratorFactory(nestedProp));\n});\n\n/**\n * @param prop property type.\n * @return an answer set reducer factory for the given prop.\n */\nexport function EncodingPropertyGeneratorFactory(prop: Property): EnumeratorFactory {\n  /**\n   * @return as reducer that takes a specQueryModel as input and output an answer set array.\n   */\n  return (wildcardIndex: WildcardIndex, schema: Schema, opt: QueryConfig): Enumerator => {\n    return (answerSet: SpecQueryModel[], specM: SpecQueryModel) => {\n      // index of encoding mappings that require enumeration\n      const indices = wildcardIndex.encodingIndicesByProperty.get(prop);\n\n      function enumerate(jobIndex: number) {\n        if (jobIndex === indices.length) {\n          // emit and terminate\n          answerSet.push(specM.duplicate());\n          return;\n        }\n        const index = indices[jobIndex];\n        const wildcard: Wildcard<any> = wildcardIndex.encodings[index].get(prop);\n        const encQ = specM.getEncodingQueryByIndex(index);\n        const propWildcard = specM.getEncodingProperty(index, prop);\n\n        if (\n          isValueQuery(encQ) ||\n          // TODO: encQ.exclude\n          // If this encoding query is an excluded autoCount, there is no point enumerating other properties\n          // for this encoding query because they will be excluded anyway.\n          // Thus, we can just move on to the next encoding to enumerate.\n          isDisabledAutoCountQuery(encQ) ||\n          // nested encoding property might have its parent set to false\n          // therefore, we no longer have to enumerate them\n          !propWildcard\n        ) {\n          // TODO: encQ.excluded\n          enumerate(jobIndex + 1);\n        } else {\n          wildcard.enum.forEach((propVal) => {\n            if (propVal === null) {\n              // our duplicate() method use JSON.stringify, parse and thus can accidentally\n              // convert undefined in an array into null\n              propVal = undefined;\n            }\n            specM.setEncodingProperty(index, prop, propVal, wildcard);\n\n            // Check encoding constraint\n            const violatedEncodingConstraint = checkEncoding(prop, wildcard, index, specM, schema, opt);\n            if (violatedEncodingConstraint) {\n              return; // do not keep searching\n            }\n            // Check spec constraint\n            const violatedSpecConstraint = checkSpec(prop, wildcard, specM, schema, opt);\n            if (violatedSpecConstraint) {\n              return; // do not keep searching\n            }\n            // If qualify all of the constraints, keep enumerating\n            enumerate(jobIndex + 1);\n          });\n\n          // Reset to avoid side effect\n          specM.resetEncodingProperty(index, prop, wildcard);\n        }\n      }\n\n      // start enumerating from 0\n      enumerate(0);\n\n      return answerSet;\n    };\n  };\n}\n","import {isArray, isObject} from 'datalib/src/util';\n\nimport {getReplacerIndex} from './shorthand';\nimport {Property} from '../property';\nimport {PropIndex} from '../propindex';\nimport {Dict, keys} from '../util';\n\nexport interface ExtendedGroupBy {\n  property: string;\n  replace?: Dict<string>;\n}\n\nexport const REPLACE_BLANK_FIELDS: Dict<string> = {'*': ''};\nexport const REPLACE_XY_CHANNELS: Dict<string> = {x: 'xy', y: 'xy'};\nexport const REPLACE_FACET_CHANNELS: Dict<string> = {row: 'facet', column: 'facet'};\nexport const REPLACE_MARK_STYLE_CHANNELS: Dict<string> = {\n  color: 'style',\n  opacity: 'style',\n  shape: 'style',\n  size: 'style',\n};\n\nexport function isExtendedGroupBy(g: string | ExtendedGroupBy): g is ExtendedGroupBy {\n  return isObject(g) && !!g['property'];\n}\n\nexport type GroupBy = string | Array<string | ExtendedGroupBy>;\n\nexport interface Nest {\n  groupBy: GroupBy;\n  orderGroupBy?: string | string[];\n}\n\nexport function parseGroupBy(\n  groupBy: Array<string | ExtendedGroupBy>,\n  include?: PropIndex<boolean>,\n  replaceIndex?: PropIndex<Dict<string>>\n) {\n  include = include || new PropIndex<boolean>();\n  replaceIndex = replaceIndex || new PropIndex<Dict<string>>();\n\n  groupBy.forEach((grpBy: string | ExtendedGroupBy) => {\n    if (isExtendedGroupBy(grpBy)) {\n      include.setByKey(grpBy.property, true);\n      replaceIndex.setByKey(grpBy.property, grpBy.replace);\n    } else {\n      include.setByKey(grpBy, true);\n    }\n  });\n\n  return {\n    include: include,\n    replaceIndex: replaceIndex,\n    replacer: getReplacerIndex(replaceIndex),\n  };\n}\n\nexport function toString(groupBy: GroupBy): string {\n  if (isArray(groupBy)) {\n    return groupBy\n      .map((g: string | ExtendedGroupBy) => {\n        if (isExtendedGroupBy(g)) {\n          if (g.replace) {\n            const replaceIndex = keys(g.replace).reduce((index, valFrom) => {\n              const valTo = g.replace[valFrom];\n              (index[valTo] = index[valTo] || []).push(valFrom);\n              return index;\n            }, {});\n\n            return (\n              `${g.property}[` +\n              keys(replaceIndex)\n                .map((valTo) => {\n                  const valsFrom = replaceIndex[valTo].sort();\n                  return `${valsFrom.join(',')}=>${valTo}`;\n                })\n                .join(';') +\n              ']'\n            );\n          }\n          return g.property;\n        }\n        return g;\n      })\n      .join(',');\n  } else {\n    return groupBy;\n  }\n}\n\nexport const GROUP_BY_FIELD_TRANSFORM = [\n  Property.FIELD,\n  Property.TYPE,\n  Property.AGGREGATE,\n  Property.BIN,\n  Property.TIMEUNIT,\n  Property.STACK,\n];\n\nexport const GROUP_BY_ENCODING = (GROUP_BY_FIELD_TRANSFORM as Array<string | ExtendedGroupBy>).concat([\n  {\n    property: Property.CHANNEL,\n    replace: {\n      x: 'xy',\n      y: 'xy',\n      color: 'style',\n      size: 'style',\n      shape: 'style',\n      opacity: 'style',\n      row: 'facet',\n      column: 'facet',\n    },\n  },\n]);\n","import {isArray} from 'datalib/src/util';\nimport {SpecQueryModel, SpecQueryModelGroup} from './model';\nimport {Property} from './property';\nimport {PropIndex} from './propindex';\nimport {GROUP_BY_ENCODING, GROUP_BY_FIELD_TRANSFORM, Nest, parseGroupBy} from './query/groupby';\nimport {Replacer, spec as specShorthand} from './query/shorthand';\nimport {SpecQuery} from './query/spec';\nimport {Dict} from './util';\n\n/**\n * Registry for all possible grouping key functions.\n */\nconst groupRegistry: Dict<(specM: SpecQuery) => string> = {};\n\n/**\n * Add a grouping function to the registry.\n */\nexport function registerKeyFn(name: string, keyFn: (specM: SpecQuery) => string) {\n  groupRegistry[name] = keyFn;\n}\n\nexport const FIELD = 'field';\nexport const FIELD_TRANSFORM = 'fieldTransform';\nexport const ENCODING = 'encoding';\nexport const SPEC = 'spec';\n\n/**\n * Group the input spec query model by a key function registered in the group registry\n * @return\n */\nexport function nest(specModels: SpecQueryModel[], queryNest: Nest[]): SpecQueryModelGroup {\n  if (queryNest) {\n    const rootGroup: SpecQueryModelGroup = {\n      name: '',\n      path: '',\n      items: [],\n    };\n    const groupIndex: Dict<SpecQueryModelGroup> = {};\n\n    // global `includes` and `replaces` will get augmented by each level's groupBy.\n    // Upper level's `groupBy` will get cascaded to lower-level groupBy.\n    // `replace` can be overriden in a lower-level to support different grouping.\n    const includes: Array<PropIndex<boolean>> = [];\n    const replaces: Array<PropIndex<Dict<string>>> = [];\n    const replacers: Array<PropIndex<Replacer>> = [];\n\n    for (let l = 0; l < queryNest.length; l++) {\n      includes.push(l > 0 ? includes[l - 1].duplicate() : new PropIndex<boolean>());\n      replaces.push(l > 0 ? replaces[l - 1].duplicate() : new PropIndex<Dict<string>>());\n\n      const groupBy = queryNest[l].groupBy;\n      if (isArray(groupBy)) {\n        // If group is array, it's an array of extended group by that need to be parsed\n        const parsedGroupBy = parseGroupBy(groupBy, includes[l], replaces[l]);\n        replacers.push(parsedGroupBy.replacer);\n      }\n    }\n\n    // With includes and replacers, now we can construct the nesting tree\n\n    specModels.forEach((specM) => {\n      let path = '';\n      let group: SpecQueryModelGroup = rootGroup;\n      for (let l = 0; l < queryNest.length; l++) {\n        const groupBy = (group.groupBy = queryNest[l].groupBy);\n        group.orderGroupBy = queryNest[l].orderGroupBy;\n\n        const key = isArray(groupBy)\n          ? specShorthand(specM.specQuery, includes[l], replacers[l])\n          : groupRegistry[groupBy](specM.specQuery);\n\n        path += `/${key}`;\n        if (!groupIndex[path]) {\n          // this item already exists on the path\n          groupIndex[path] = {\n            name: key,\n            path: path,\n            items: [],\n          };\n\n          group.items.push(groupIndex[path]);\n        }\n        group = groupIndex[path];\n      }\n      group.items.push(specM);\n    });\n    return rootGroup;\n  } else {\n    // no nesting, just return a flat group\n    return {\n      name: '',\n      path: '',\n      items: specModels,\n    };\n  }\n}\n\n// TODO: move this to groupBy, rename properly, and export\nconst GROUP_BY_FIELD = [Property.FIELD];\nconst PARSED_GROUP_BY_FIELD = parseGroupBy(GROUP_BY_FIELD);\n\nexport function getGroupByKey(specM: SpecQuery, groupBy: string) {\n  return groupRegistry[groupBy](specM);\n}\n\nregisterKeyFn(FIELD, (specQ: SpecQuery) => {\n  return specShorthand(specQ, PARSED_GROUP_BY_FIELD.include, PARSED_GROUP_BY_FIELD.replacer);\n});\n\nexport const PARSED_GROUP_BY_FIELD_TRANSFORM = parseGroupBy(GROUP_BY_FIELD_TRANSFORM);\n\nregisterKeyFn(FIELD_TRANSFORM, (specQ: SpecQuery) => {\n  return specShorthand(specQ, PARSED_GROUP_BY_FIELD_TRANSFORM.include, PARSED_GROUP_BY_FIELD_TRANSFORM.replacer);\n});\n\nexport const PARSED_GROUP_BY_ENCODING = parseGroupBy(GROUP_BY_ENCODING);\n\nregisterKeyFn(ENCODING, (specQ: SpecQuery) => {\n  return specShorthand(specQ, PARSED_GROUP_BY_ENCODING.include, PARSED_GROUP_BY_ENCODING.replacer);\n});\n\nregisterKeyFn(SPEC, (specQ: SpecQuery) => JSON.stringify(specQ));\n","import {Mark} from 'vega-lite/build/src/mark';\n\nimport {Wildcard} from './wildcard';\nimport {Property, isEncodingProperty} from './property';\nimport {PropIndex} from './propindex';\n\nexport interface EncodingsWildcardIndex {\n  [index: number]: PropIndex<Wildcard<any>>;\n}\n\nexport class WildcardIndex {\n  private _mark: Wildcard<Mark>;\n  // TODO: transform\n\n  /**\n   * Dictionary mapping encoding index to an encoding wildcard index.\n   */\n\n  private _encodings: EncodingsWildcardIndex;\n  private _encodingIndicesByProperty: PropIndex<number[]>;\n\n  constructor() {\n    this._mark = undefined;\n    this._encodings = {};\n    this._encodingIndicesByProperty = new PropIndex<number[]>();\n  }\n\n  public setEncodingProperty(index: number, prop: Property, wildcard: Wildcard<any>) {\n    const encodingsIndex = this._encodings;\n\n    // Init encoding index and set prop\n    const encIndex = (encodingsIndex[index] = encodingsIndex[index] || new PropIndex<Wildcard<any>>());\n    encIndex.set(prop, wildcard);\n\n    // Initialize indicesByProperty[prop] and add index\n    const indicesByProp = this._encodingIndicesByProperty;\n    indicesByProp.set(prop, indicesByProp.get(prop) || []);\n    indicesByProp.get(prop).push(index);\n\n    return this;\n  }\n\n  public hasEncodingProperty(index: number, prop: Property) {\n    return !!this._encodings[index] && this._encodings[index].has(prop);\n  }\n\n  public hasProperty(prop: Property) {\n    if (isEncodingProperty(prop)) {\n      return this.encodingIndicesByProperty.has(prop);\n    } else if (prop === 'mark') {\n      return !!this.mark;\n    }\n    /* istanbul ignore next */\n    throw new Error(`Unimplemented for property ${prop}`);\n  }\n\n  public isEmpty() {\n    return !this.mark && this.encodingIndicesByProperty.size() === 0;\n  }\n\n  public setMark(mark: Wildcard<Mark>) {\n    this._mark = mark;\n    return this;\n  }\n\n  public get mark() {\n    return this._mark;\n  }\n\n  public get encodings() {\n    return this._encodings;\n  }\n\n  public get encodingIndicesByProperty() {\n    return this._encodingIndicesByProperty;\n  }\n}\n","import {isString} from 'datalib/src/util';\nimport {ExtendedChannel} from 'vega-lite/build/src/channel';\nimport {Data} from 'vega-lite/build/src/data';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {FacetedUnitSpec, TopLevel} from 'vega-lite/build/src/spec';\nimport {StackOffset, StackProperties} from 'vega-lite/build/src/stack';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from './config';\nimport {getGroupByKey} from './nest';\nimport {\n  ENCODING_NESTED_PROPS,\n  ENCODING_TOPLEVEL_PROPS,\n  isEncodingNestedParent,\n  isEncodingNestedProp,\n  Property,\n} from './property';\nimport {\n  AutoCountQuery,\n  EncodingQuery,\n  isAutoCountQuery,\n  isDisabledAutoCountQuery,\n  isFieldQuery,\n  toEncoding,\n} from './query/encoding';\nimport {ExtendedGroupBy, parseGroupBy} from './query/groupby';\nimport {spec as specShorthand} from './query/shorthand';\nimport {getStackChannel, getStackOffset, getVlStack, isAggregate, SpecQuery} from './query/spec';\nimport {RankingScore} from './ranking/ranking';\nimport {ResultTree} from './result';\nimport {Schema} from './schema';\nimport {Dict, duplicate, extend} from './util';\nimport {getDefaultEnumValues, getDefaultName, initWildcard, isWildcard, SHORT_WILDCARD, Wildcard} from './wildcard';\nimport {WildcardIndex} from './wildcardindex';\n\n/**\n * Internal class for specQuery that provides helper for the enumeration process.\n */\nexport class SpecQueryModel {\n  private _spec: SpecQuery;\n\n  /** channel => EncodingQuery */\n  private _channelFieldCount: Dict<number>;\n  private _wildcardIndex: WildcardIndex;\n  private _assignedWildcardIndex: Dict<any>;\n  private _schema: Schema;\n  private _opt: QueryConfig;\n\n  private _rankingScore: Dict<RankingScore> = {};\n\n  /**\n   * Build a WildcardIndex by detecting wildcards\n   * in the input specQuery and replacing short wildcards (\"?\")\n   * with full ones (objects with `name` and `enum` values).\n   *\n   * @return a SpecQueryModel that wraps the specQuery and the WildcardIndex.\n   */\n  public static build(specQ: SpecQuery, schema: Schema, opt: QueryConfig): SpecQueryModel {\n    const wildcardIndex: WildcardIndex = new WildcardIndex();\n    // mark\n    if (isWildcard(specQ.mark)) {\n      const name = getDefaultName(Property.MARK);\n      specQ.mark = initWildcard(specQ.mark, name, opt.enum.mark);\n      wildcardIndex.setMark(specQ.mark);\n    }\n\n    // TODO: transform\n\n    // encodings\n    specQ.encodings.forEach((encQ, index) => {\n      if (isAutoCountQuery(encQ)) {\n        // This is only for testing purpose\n        console.warn('A field with autoCount should not be included as autoCount meant to be an internal object.');\n\n        encQ.type = TYPE.QUANTITATIVE; // autoCount is always quantitative\n      }\n\n      if (isFieldQuery(encQ) && encQ.type === undefined) {\n        // type is optional -- we automatically augment wildcard if not specified\n        encQ.type = SHORT_WILDCARD;\n      }\n\n      // For each property of the encodingQuery, enumerate\n      ENCODING_TOPLEVEL_PROPS.forEach((prop) => {\n        if (isWildcard(encQ[prop])) {\n          // Assign default wildcard name and enum values.\n          const defaultWildcardName = getDefaultName(prop) + index;\n          const defaultEnumValues = getDefaultEnumValues(prop, schema, opt);\n          const wildcard = (encQ[prop] = initWildcard(encQ[prop], defaultWildcardName, defaultEnumValues));\n\n          // Add index of the encoding mapping to the property's wildcard index.\n          wildcardIndex.setEncodingProperty(index, prop, wildcard);\n        }\n      });\n\n      // For each nested property of the encoding query  (e.g., encQ.bin.maxbins)\n      ENCODING_NESTED_PROPS.forEach((prop) => {\n        const propObj = encQ[prop.parent]; // the property object e.g., encQ.bin\n        if (propObj) {\n          const child = prop.child;\n          if (isWildcard(propObj[child])) {\n            // Assign default wildcard name and enum values.\n            const defaultWildcardName = getDefaultName(prop) + index;\n            const defaultEnumValues = getDefaultEnumValues(prop, schema, opt);\n            const wildcard = (propObj[child] = initWildcard(propObj[child], defaultWildcardName, defaultEnumValues));\n\n            // Add index of the encoding mapping to the property's wildcard index.\n            wildcardIndex.setEncodingProperty(index, prop, wildcard);\n          }\n        }\n      });\n    });\n\n    // AUTO COUNT\n    // Add Auto Count Field\n    if (opt.autoAddCount) {\n      const channel: Wildcard<ExtendedChannel> = {\n        name: getDefaultName(Property.CHANNEL) + specQ.encodings.length,\n        enum: getDefaultEnumValues(Property.CHANNEL, schema, opt),\n      };\n      const autoCount: Wildcard<boolean> = {\n        name: getDefaultName(Property.AUTOCOUNT) + specQ.encodings.length,\n        enum: [false, true],\n      };\n      const countEncQ: AutoCountQuery = {\n        channel,\n        autoCount,\n        type: TYPE.QUANTITATIVE,\n      };\n      specQ.encodings.push(countEncQ);\n\n      const index = specQ.encodings.length - 1;\n\n      // Add index of the encoding mapping to the property's wildcard index.\n      wildcardIndex.setEncodingProperty(index, Property.CHANNEL, channel);\n      wildcardIndex.setEncodingProperty(index, Property.AUTOCOUNT, autoCount);\n    }\n\n    return new SpecQueryModel(specQ, wildcardIndex, schema, opt, {});\n  }\n\n  constructor(\n    spec: SpecQuery,\n    wildcardIndex: WildcardIndex,\n    schema: Schema,\n    opt: QueryConfig,\n    wildcardAssignment: Dict<any>\n  ) {\n    this._spec = spec;\n    this._channelFieldCount = spec.encodings.reduce((m, encQ) => {\n      if (!isWildcard(encQ.channel) && (!isAutoCountQuery(encQ) || encQ.autoCount !== false)) {\n        m[`${encQ.channel}`] = 1;\n      }\n      return m;\n    }, {} as Dict<number>);\n\n    this._wildcardIndex = wildcardIndex;\n    this._assignedWildcardIndex = wildcardAssignment;\n    this._opt = opt;\n    this._schema = schema;\n  }\n\n  public get wildcardIndex() {\n    return this._wildcardIndex;\n  }\n\n  public get schema() {\n    return this._schema;\n  }\n\n  public get specQuery() {\n    return this._spec;\n  }\n\n  public duplicate(): SpecQueryModel {\n    return new SpecQueryModel(\n      duplicate(this._spec),\n      this._wildcardIndex,\n      this._schema,\n      this._opt,\n      duplicate(this._assignedWildcardIndex)\n    );\n  }\n\n  public setMark(mark: Mark) {\n    const name = this._wildcardIndex.mark.name;\n    this._assignedWildcardIndex[name] = this._spec.mark = mark;\n  }\n\n  public resetMark() {\n    const wildcard = (this._spec.mark = this._wildcardIndex.mark);\n    delete this._assignedWildcardIndex[wildcard.name];\n  }\n\n  public getMark() {\n    return this._spec.mark;\n  }\n\n  public getEncodingProperty(index: number, prop: Property) {\n    const encQ = this._spec.encodings[index];\n    if (isEncodingNestedProp(prop)) {\n      // nested encoding property\n      return encQ[prop.parent][prop.child];\n    }\n    return encQ[prop]; // encoding property (non-nested)\n  }\n\n  public setEncodingProperty(index: number, prop: Property, value: any, wildcard: Wildcard<any>) {\n    const encQ = this._spec.encodings[index];\n\n    if (prop === Property.CHANNEL && encQ.channel && !isWildcard(encQ.channel)) {\n      // If there is an old channel\n      this._channelFieldCount[encQ.channel as ExtendedChannel]--;\n    }\n\n    if (isEncodingNestedProp(prop)) {\n      // nested encoding property\n      encQ[prop.parent][prop.child] = value;\n    } else if (isEncodingNestedParent(prop) && value === true) {\n      encQ[prop] = extend(\n        {},\n        encQ[prop], // copy all existing properties\n        {enum: undefined, name: undefined} // except name and values to it no longer an wildcard\n      );\n    } else {\n      // encoding property (non-nested)\n      encQ[prop] = value;\n    }\n\n    this._assignedWildcardIndex[wildcard.name] = value;\n\n    if (prop === Property.CHANNEL) {\n      // If there is a new channel, make sure it exists and add it to the count.\n      this._channelFieldCount[value] = (this._channelFieldCount[value] || 0) + 1;\n    }\n  }\n\n  public resetEncodingProperty(index: number, prop: Property, wildcard: Wildcard<any>) {\n    const encQ = this._spec.encodings[index];\n    if (prop === Property.CHANNEL) {\n      this._channelFieldCount[encQ.channel as ExtendedChannel]--;\n    }\n\n    // reset it to wildcard\n    if (isEncodingNestedProp(prop)) {\n      // nested encoding property\n      encQ[prop.parent][prop.child] = wildcard;\n    } else {\n      // encoding property (non-nested)\n      encQ[prop] = wildcard;\n    }\n\n    // add remove value that is reset from the assignment map\n    delete this._assignedWildcardIndex[wildcard.name];\n  }\n\n  public channelUsed(channel: ExtendedChannel) {\n    // do not include encoding that has autoCount = false because it is not a part of the output spec.\n    return this._channelFieldCount[channel] > 0;\n  }\n\n  public channelEncodingField(channel: ExtendedChannel) {\n    const encodingQuery = this.getEncodingQueryByChannel(channel);\n    return isFieldQuery(encodingQuery);\n  }\n\n  public getEncodings(): EncodingQuery[] {\n    // do not include encoding that has autoCount = false because it is not a part of the output spec.\n    return this._spec.encodings.filter((encQ) => !isDisabledAutoCountQuery(encQ));\n  }\n\n  public getEncodingQueryByChannel(channel: ExtendedChannel) {\n    for (const specEncoding of this._spec.encodings) {\n      if (specEncoding.channel === channel) {\n        return specEncoding;\n      }\n    }\n    return undefined;\n  }\n\n  public getEncodingQueryByIndex(i: number) {\n    return this._spec.encodings[i];\n  }\n\n  public isAggregate() {\n    return isAggregate(this._spec);\n  }\n\n  /**\n   * @return The Vega-Lite `StackProperties` object that describes the stack\n   * configuration of `this`. Returns `null` if this is not stackable.\n   */\n  public getVlStack(): StackProperties {\n    return getVlStack(this._spec);\n  }\n\n  /**\n   * @return The `StackOffset` specified in `this`, `undefined` if none\n   * is specified.\n   */\n  public getStackOffset(): StackOffset {\n    return getStackOffset(this._spec);\n  }\n\n  /**\n   * @return The `ExtendedChannel` in which `stack` is specified in `this`, or\n   * `null` if none is specified.\n   */\n  public getStackChannel(): ExtendedChannel {\n    return getStackChannel(this._spec);\n  }\n\n  public toShorthand(groupBy?: string | (string | ExtendedGroupBy)[]): string {\n    if (groupBy) {\n      if (isString(groupBy)) {\n        return getGroupByKey(this.specQuery, groupBy);\n      }\n      const parsedGroupBy = parseGroupBy(groupBy);\n      return specShorthand(this._spec, parsedGroupBy.include, parsedGroupBy.replacer);\n    }\n    return specShorthand(this._spec);\n  }\n\n  /**\n   * Convert a query to a Vega-Lite spec if it is completed.\n   * @return a Vega-Lite spec if completed, null otherwise.\n   */\n  public toSpec(data?: Data): TopLevel<FacetedUnitSpec> {\n    if (isWildcard(this._spec.mark)) return null;\n\n    const spec: any = {};\n    data = data || this._spec.data;\n    if (data) {\n      spec.data = data;\n    }\n\n    if (this._spec.transform) {\n      spec.transform = this._spec.transform;\n    }\n\n    spec.mark = this._spec.mark as Mark;\n    spec.encoding = toEncoding(this.specQuery.encodings, {schema: this._schema, wildcardMode: 'null'});\n\n    if (this._spec.width) {\n      spec.width = this._spec.width;\n    }\n    if (this._spec.height) {\n      spec.height = this._spec.height;\n    }\n    if (this._spec.background) {\n      spec.background = this._spec.background;\n    }\n    if (this._spec.padding) {\n      spec.padding = this._spec.padding;\n    }\n    if (this._spec.title) {\n      spec.title = this._spec.title;\n    }\n\n    if (spec.encoding === null) {\n      return null;\n    }\n    if (this._spec.config || this._opt.defaultSpecConfig)\n      spec.config = extend({}, this._opt.defaultSpecConfig, this._spec.config);\n\n    return spec;\n  }\n\n  public getRankingScore(rankingName: string) {\n    return this._rankingScore[rankingName];\n  }\n\n  public setRankingScore(rankingName: string, score: RankingScore) {\n    this._rankingScore[rankingName] = score;\n  }\n}\nexport type SpecQueryModelGroup = ResultTree<SpecQueryModel>;\n","import {Query} from './query';\nimport {Nest} from './groupby';\nimport {duplicate} from '../util';\n\n/**\n * Normalize the non-nested version of the query\n * (basically when you have a `groupBy`)\n * to a standardize nested.\n */\nexport function normalize(q: Query): Query {\n  if (q.groupBy) {\n    const nest: Nest = {\n      groupBy: q.groupBy,\n    };\n\n    if (q.orderBy) {\n      nest.orderGroupBy = q.orderBy;\n    }\n\n    const normalizedQ: Query = {\n      spec: duplicate(q.spec), // We will cause side effect to q.spec in SpecQueryModel.build\n      nest: [nest],\n    };\n\n    if (q.chooseBy) {\n      normalizedQ.chooseBy = q.chooseBy;\n    }\n\n    if (q.config) {\n      normalizedQ.config = q.config;\n    }\n\n    return normalizedQ;\n  }\n  return duplicate(q); // We will cause side effect to q.spec in SpecQueryModel.build\n}\n","import {GroupBy} from './query/groupby';\n\n/**\n * An ordered tree structure for storing query results.\n */\nexport interface ResultTree<T> {\n  name: string;\n  path: string;\n  items: (ResultTree<T> | T)[];\n  groupBy?: GroupBy;\n  orderGroupBy?: string | string[];\n}\n\nexport function isResultTree<T>(item: ResultTree<T> | T): item is ResultTree<T> {\n  return (<ResultTree<T>>item).items !== undefined;\n}\n\nexport function getTopResultTreeItem<T>(specQuery: ResultTree<T>): T {\n  let topItem = specQuery.items[0];\n  while (topItem && isResultTree(topItem)) {\n    topItem = topItem.items[0];\n  }\n  return <T>topItem;\n}\n\nexport function mapLeaves<T, U>(group: ResultTree<T>, f: (item: T) => U): ResultTree<U> {\n  return {\n    ...group,\n    items: group.items.map((item) => (isResultTree(item) ? mapLeaves(item, f) : f(item))),\n  };\n}\n","import {hasDiscreteDomain} from 'vega-lite/build/src/scale';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {FieldQuery, scaleType} from '../../query/encoding';\nimport {ExpandedType} from '../../query/expandedtype';\n\n/**\n * Finer grained data types that takes binning and timeUnit into account.\n */\nexport enum ExtendedType {\n  Q = TYPE.QUANTITATIVE as any,\n  BIN_Q = `bin_${TYPE.QUANTITATIVE}` as any,\n  T = TYPE.TEMPORAL as any,\n\n  /**\n   * Time Unit Temporal Field with time scale.\n   */\n  TIMEUNIT_T = 'timeUnit_time' as any,\n  /**\n   * Time Unit Temporal Field with ordinal scale.\n   */\n  TIMEUNIT_O = `timeUnit_${TYPE.ORDINAL}` as any,\n  O = TYPE.ORDINAL as any,\n  N = TYPE.NOMINAL as any,\n  K = ExpandedType.KEY as any,\n  NONE = '-' as any,\n}\n\nexport const Q = ExtendedType.Q;\nexport const BIN_Q = ExtendedType.BIN_Q;\nexport const T = ExtendedType.T;\nexport const TIMEUNIT_T = ExtendedType.TIMEUNIT_T;\nexport const TIMEUNIT_O = ExtendedType.TIMEUNIT_O;\nexport const O = ExtendedType.O;\nexport const N = ExtendedType.N;\nexport const K = ExtendedType.K;\nexport const NONE = ExtendedType.NONE;\n\nexport function getExtendedType(fieldQ: FieldQuery): ExtendedType {\n  if (fieldQ.bin) {\n    return ExtendedType.BIN_Q;\n  } else if (fieldQ.timeUnit) {\n    const sType = scaleType(fieldQ);\n    return hasDiscreteDomain(sType) ? ExtendedType.TIMEUNIT_O : ExtendedType.TIMEUNIT_T;\n  }\n  return fieldQ.type as ExtendedType;\n}\n","import {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {FeatureScore} from '../ranking';\nimport {Dict} from '../../util';\n\nexport abstract class Scorer {\n  public readonly type: string;\n  public readonly scoreIndex: Dict<number>;\n  constructor(type: string) {\n    this.type = type;\n    this.scoreIndex = this.initScore();\n  }\n\n  protected abstract initScore(): Dict<number>;\n\n  protected getFeatureScore(feature: string): FeatureScore {\n    const type = this.type;\n    const score = this.scoreIndex[feature];\n    if (score !== undefined) {\n      return {type, feature, score};\n    }\n    return undefined;\n  }\n\n  public abstract getScore(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): FeatureScore[];\n}\n","import {QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {fieldDef as fieldDefShorthand} from '../../query/shorthand';\nimport {EncodingQuery, isFieldQuery, isAutoCountQuery} from '../../query/encoding';\nimport {Dict, extend, forEach, keys, contains} from '../../util';\n\nimport {Schema} from '../../schema';\nimport {FeatureScore} from '../ranking';\nimport {BIN_Q, TIMEUNIT_T, TIMEUNIT_O, Q, N, O, T, ExtendedType, getExtendedType, K} from './type';\n\nimport {Scorer} from './base';\nimport {Channel} from 'vega-lite/build/src/channel';\n\nexport const TERRIBLE = -10;\n\n/**\n * Effectiveness score for relationship between\n * Field Type (with Bin and TimeUnit) and Channel Score (Cleveland / Mackinlay based)\n */\nexport class TypeChannelScorer extends Scorer {\n  constructor() {\n    super('TypeChannel');\n  }\n  protected initScore() {\n    const SCORE = {} as Dict<number>;\n\n    // Continuous Quantitative / Temporal Fields\n    const CONTINUOUS_TYPE_CHANNEL_SCORE = {\n      x: 0,\n      y: 0,\n      size: -0.575,\n      color: -0.725, // Middle between -0.7 and -0.75\n      text: -2,\n      opacity: -3,\n\n      shape: TERRIBLE,\n      row: TERRIBLE,\n      column: TERRIBLE,\n      detail: 2 * TERRIBLE,\n    };\n\n    [Q, T, TIMEUNIT_T].forEach((type) => {\n      keys(CONTINUOUS_TYPE_CHANNEL_SCORE).forEach((channel: Channel) => {\n        SCORE[this.featurize(type, channel)] = CONTINUOUS_TYPE_CHANNEL_SCORE[channel];\n      });\n    });\n\n    // Discretized Quantitative / Temporal Fields / Ordinal\n\n    const ORDERED_TYPE_CHANNEL_SCORE = extend({}, CONTINUOUS_TYPE_CHANNEL_SCORE, {\n      row: -0.75,\n      column: -0.75,\n\n      shape: -3.1,\n      text: -3.2,\n      detail: -4,\n    });\n\n    [BIN_Q, TIMEUNIT_O, O].forEach((type) => {\n      keys(ORDERED_TYPE_CHANNEL_SCORE).forEach((channel: Channel) => {\n        SCORE[this.featurize(type, channel)] = ORDERED_TYPE_CHANNEL_SCORE[channel];\n      });\n    });\n\n    const NOMINAL_TYPE_CHANNEL_SCORE = {\n      x: 0,\n      y: 0,\n      color: -0.6, // TODO: make it adjustable based on preference (shape is better for black and white)\n      shape: -0.65,\n      row: -0.7,\n      column: -0.7,\n      text: -0.8,\n\n      detail: -2,\n      size: -3,\n      opacity: -3.1,\n    };\n\n    keys(NOMINAL_TYPE_CHANNEL_SCORE).forEach((channel: Channel) => {\n      SCORE[this.featurize(N, channel)] = NOMINAL_TYPE_CHANNEL_SCORE[channel];\n      SCORE[this.featurize(K, channel)] =\n        // Putting key on position or detail isn't terrible\n        contains(['x', 'y', 'detail'], channel) ? -1 : NOMINAL_TYPE_CHANNEL_SCORE[channel] - 2;\n    });\n\n    return SCORE;\n  }\n\n  public featurize(type: ExtendedType, channel: Channel) {\n    return `${type}_${channel}`;\n  }\n\n  public getScore(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): FeatureScore[] {\n    const encodingQueryByField = specM.getEncodings().reduce((m, encQ) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const fieldKey = fieldDefShorthand(encQ);\n        (m[fieldKey] = m[fieldKey] || []).push(encQ);\n      }\n      return m;\n    }, {});\n\n    const features: FeatureScore[] = [];\n\n    forEach(encodingQueryByField, (encQs: EncodingQuery[]) => {\n      const bestFieldFeature = encQs.reduce((best: FeatureScore, encQ) => {\n        if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n          const type = getExtendedType(encQ);\n          const feature = this.featurize(type, encQ.channel as Channel);\n          const featureScore = this.getFeatureScore(feature);\n\n          if (best === null || featureScore.score > best.score) {\n            return featureScore;\n          }\n        }\n        return best;\n      }, null);\n\n      features.push(bestFieldFeature);\n\n      // TODO: add plus for over-encoding of one field\n    });\n    return features;\n  }\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport * as MARK from 'vega-lite/build/src/mark';\nimport {Mark} from 'vega-lite/build/src/mark';\nimport {QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {Dict, forEach} from '../../util';\nimport {FeatureScore} from '../ranking';\nimport {Scorer} from './base';\nimport {BIN_Q, ExtendedType, getExtendedType, K, N, NONE, O, Q, T, TIMEUNIT_O, TIMEUNIT_T} from './type';\n\nexport class MarkScorer extends Scorer {\n  constructor() {\n    super('Mark');\n  }\n\n  protected initScore() {\n    return init();\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    let mark = specM.getMark() as Mark;\n    if (mark === MARK.CIRCLE || mark === MARK.SQUARE) {\n      mark = MARK.POINT;\n    }\n    const xEncQ = specM.getEncodingQueryByChannel(CHANNEL.X);\n    const xType = xEncQ ? getExtendedType(xEncQ) : NONE;\n\n    const yEncQ = specM.getEncodingQueryByChannel(CHANNEL.Y);\n    const yType = yEncQ ? getExtendedType(yEncQ) : NONE;\n\n    const isOccluded = !specM.isAggregate(); // FIXME\n\n    const feature = `${xType}_${yType}_${isOccluded}_${mark}`;\n    const featureScore = this.getFeatureScore(feature);\n\n    if (featureScore) {\n      return [featureScore];\n    }\n    console.error('feature score missing for', feature);\n    return [];\n  }\n}\n\nexport function featurize(xType: ExtendedType, yType: ExtendedType, hasOcclusion: boolean, mark: Mark) {\n  return `${xType}_${yType}_${hasOcclusion}_${mark}`;\n}\n\nfunction init() {\n  const MEASURES = [Q, T];\n  const DISCRETE = [BIN_Q, TIMEUNIT_O, O, N, K];\n  const DISCRETE_OR_NONE = DISCRETE.concat([NONE]);\n\n  const SCORE = {} as Dict<number>;\n  // QxQ\n  MEASURES.forEach((xType) => {\n    MEASURES.forEach((yType) => {\n      // has occlusion\n      const occludedQQMark = {\n        point: 0,\n        text: -0.2,\n        tick: -0.5,\n        rect: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n      forEach(occludedQQMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n\n      // no occlusion\n      // TODO: possible to use connected scatter plot\n      const noOccludedQQMark = {\n        point: 0,\n        text: -0.2,\n        tick: -0.5,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n      forEach(noOccludedQQMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n    });\n  });\n\n  // DxQ, QxD\n  MEASURES.forEach((xType) => {\n    // HAS OCCLUSION\n    DISCRETE_OR_NONE.forEach((yType) => {\n      const occludedDimensionMeasureMark = {\n        tick: 0,\n        point: -0.2,\n        text: -0.5,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n      forEach(occludedDimensionMeasureMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n        // also do the inverse\n        const feature2 = featurize(yType, xType, true, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    [TIMEUNIT_T].forEach((yType) => {\n      const occludedDimensionMeasureMark = {\n        // For Time Dimension with time scale, tick is not good\n        point: 0,\n        text: -0.5,\n        tick: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n      forEach(occludedDimensionMeasureMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n        // also do the inverse\n        const feature2 = featurize(yType, xType, true, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    // NO OCCLUSION\n    [NONE, N, O, K].forEach((yType) => {\n      const noOccludedQxN = {\n        bar: 0,\n        point: -0.2,\n        tick: -0.25,\n        text: -0.3,\n        // Line / Area can mislead trend for N\n        line: -2, // FIXME line vs area?\n        area: -2,\n        // Non-sense to use rule here\n        rule: -2.5,\n      };\n      forEach(noOccludedQxN, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n\n        // also do the inverse\n        const feature2 = featurize(yType, xType, false, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    [BIN_Q].forEach((yType) => {\n      const noOccludedQxBinQ = {\n        bar: 0,\n        point: -0.2,\n        tick: -0.25,\n        text: -0.3,\n        // Line / Area isn't the best fit for bin\n        line: -0.5, // FIXME line vs area?\n        area: -0.5,\n        // Non-sense to use rule here\n        rule: -2.5,\n      };\n      forEach(noOccludedQxBinQ, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n\n        // also do the inverse\n        const feature2 = featurize(yType, xType, false, mark);\n        SCORE[feature2] = score;\n      });\n    });\n\n    [TIMEUNIT_T, TIMEUNIT_O].forEach((yType) => {\n      // For aggregate / surely no occlusion plot, Temporal with time or ordinal\n      // are not that different.\n      const noOccludedQxBinQ = {\n        line: 0,\n        area: -0.1,\n        bar: -0.2,\n        point: -0.3,\n        tick: -0.35,\n        text: -0.4,\n        // Non-sense to use rule here\n        rule: -2.5,\n      };\n      forEach(noOccludedQxBinQ, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n\n        // also do the inverse\n        const feature2 = featurize(yType, xType, false, mark);\n        SCORE[feature2] = score;\n      });\n    });\n  });\n\n  [TIMEUNIT_T].forEach((xType) => {\n    [TIMEUNIT_T].forEach((yType) => {\n      // has occlusion\n      const ttMark = {\n        point: 0,\n        rect: -0.1, // assuming rect will be small\n        text: -0.5,\n        tick: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n      // No difference between has occlusion and no occlusion\n      // as most of the time, it will be the occluded case.\n      forEach(ttMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n      forEach(ttMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n    });\n\n    DISCRETE_OR_NONE.forEach((yType) => {\n      // has occlusion\n      const tdMark = {\n        tick: 0,\n        point: -0.2,\n        text: -0.5,\n        rect: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n      // No difference between has occlusion and no occlusion\n      // as most of the time, it will be the occluded case.\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(yType, xType, true, mark);\n        SCORE[feature] = score;\n      });\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n      forEach(tdMark, (score, mark: Mark) => {\n        const feature = featurize(yType, xType, false, mark);\n        SCORE[feature] = score;\n      });\n    });\n  });\n\n  // DxD\n  // Note: We use for loop here because using forEach sometimes leads to a mysterious bug\n  for (const xType of DISCRETE_OR_NONE) {\n    for (const yType of DISCRETE_OR_NONE) {\n      // has occlusion\n      const ddMark = {\n        point: 0,\n        rect: 0,\n        text: -0.1,\n        tick: -1,\n        bar: -2,\n        line: -2,\n        area: -2,\n        rule: -2.5,\n      };\n\n      forEach(ddMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, true, mark);\n        SCORE[feature] = score;\n      });\n\n      // same for no occlusion.\n      forEach(ddMark, (score, mark: Mark) => {\n        const feature = featurize(xType, yType, false, mark);\n        SCORE[feature] = score;\n      });\n    }\n  }\n\n  return SCORE;\n}\n","import {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {RankingScore, FeatureScore} from '../ranking';\nimport {AxisScorer} from './axis';\nimport {DimensionScorer} from './dimension';\nimport {FacetScorer} from './facet';\nimport {SizeChannelScorer} from './sizechannel';\nimport {TypeChannelScorer} from './typechannel';\nimport {MarkScorer} from './mark';\n\nconst SCORERS = [\n  new AxisScorer(),\n  new DimensionScorer(),\n  new FacetScorer(),\n  new MarkScorer(),\n  new SizeChannelScorer(),\n  new TypeChannelScorer(),\n];\n\n// TODO: x/y, row/column preference\n// TODO: stacking\n// TODO: Channel, Cardinality\n// TODO: Penalize over encoding\nexport function effectiveness(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): RankingScore {\n  const features = SCORERS.reduce((f, scorer) => {\n    const scores = scorer.getScore(specM, schema, opt);\n    return f.concat(scores);\n  }, [] as FeatureScore[]);\n\n  return {\n    score: features.reduce((s, f) => {\n      return s + f.score;\n    }, 0),\n    features: features,\n  };\n}\n","/**\n * Field Type (with Bin and TimeUnit) and Channel Score (Cleveland / Mackinlay based)\n */\n\nimport * as CHANNEL from 'vega-lite/build/src/channel';\nimport {Channel} from 'vega-lite/build/src/channel';\nimport {DEFAULT_QUERY_CONFIG, QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {EncodingQuery, isAutoCountQuery, isFieldQuery} from '../../query/encoding';\nimport {Schema} from '../../schema';\nimport {Dict} from '../../util';\nimport {FeatureScore} from '../ranking';\nimport {Scorer} from './base';\nimport {BIN_Q, ExtendedType, getExtendedType, N, O, T, TIMEUNIT_O, TIMEUNIT_T} from './type';\n\n/**\n * Effectiveness Score for preferred axis.\n */\nexport class AxisScorer extends Scorer {\n  constructor() {\n    super('Axis');\n  }\n  protected initScore(opt: QueryConfig = {}) {\n    opt = {...DEFAULT_QUERY_CONFIG, ...opt};\n    const score: Dict<number> = {};\n\n    const preferredAxes = [\n      {\n        feature: BIN_Q,\n        opt: 'preferredBinAxis',\n      },\n      {\n        feature: T,\n        opt: 'preferredTemporalAxis',\n      },\n      {\n        feature: TIMEUNIT_T,\n        opt: 'preferredTemporalAxis',\n      },\n      {\n        feature: TIMEUNIT_O,\n        opt: 'preferredTemporalAxis',\n      },\n      {\n        feature: O,\n        opt: 'preferredOrdinalAxis',\n      },\n      {\n        feature: N,\n        opt: 'preferredNominalAxis',\n      },\n    ];\n\n    preferredAxes.forEach((pAxis) => {\n      if (opt[pAxis.opt] === CHANNEL.X) {\n        // penalize the other axis\n        score[`${pAxis.feature}_${CHANNEL.Y}`] = -0.01;\n      } else if (opt[pAxis.opt] === CHANNEL.Y) {\n        // penalize the other axis\n        score[`${pAxis.feature}_${CHANNEL.X}`] = -0.01;\n      }\n    });\n\n    return score;\n  }\n\n  public featurize(type: ExtendedType, channel: Channel) {\n    return `${type}_${channel}`;\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    return specM.getEncodings().reduce((features, encQ: EncodingQuery) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const type = getExtendedType(encQ);\n        const feature = this.featurize(type, encQ.channel as Channel);\n        const featureScore = this.getFeatureScore(feature);\n\n        if (featureScore) {\n          features.push(featureScore);\n        }\n      }\n      return features;\n    }, []);\n  }\n}\n","import {Dict} from '../../util';\nimport {Scorer} from './base';\nimport {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {FeatureScore} from '../ranking';\nimport {EncodingQuery, isFieldQuery, isAutoCountQuery} from '../../query/encoding';\n\n/**\n * Penalize if facet channels are the only dimensions\n */\nexport class DimensionScorer extends Scorer {\n  constructor() {\n    super('Dimension');\n  }\n\n  protected initScore() {\n    return {\n      row: -2,\n      column: -2,\n      color: 0,\n      opacity: 0,\n      size: 0,\n      shape: 0,\n    } as Dict<number>;\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    if (specM.isAggregate()) {\n      specM.getEncodings().reduce(\n        (maxFScore, encQ: EncodingQuery) => {\n          if (isAutoCountQuery(encQ) || (isFieldQuery(encQ) && !encQ.aggregate)) {\n            // isDimension\n            const featureScore = this.getFeatureScore(`${encQ.channel}`);\n            if (featureScore && featureScore.score > maxFScore.score) {\n              return featureScore;\n            }\n          }\n          return maxFScore;\n        },\n        {type: 'Dimension', feature: 'No Dimension', score: -5}\n      );\n    }\n    return [];\n  }\n}\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {DEFAULT_QUERY_CONFIG, QueryConfig} from '../../config';\nimport {SpecQueryModel} from '../../model';\nimport {EncodingQuery, isAutoCountQuery, isFieldQuery} from '../../query/encoding';\nimport {Schema} from '../../schema';\nimport {Dict} from '../../util';\nimport {FeatureScore} from '../ranking';\nimport {Scorer} from './base';\n\n/**\n * Effective Score for preferred facet\n */\nexport class FacetScorer extends Scorer {\n  constructor() {\n    super('Facet');\n  }\n  protected initScore(opt?: QueryConfig) {\n    opt = {...DEFAULT_QUERY_CONFIG, ...opt};\n    const score: Dict<number> = {};\n\n    if (opt.preferredFacet === CHANNEL.ROW) {\n      // penalize the other axis\n      score[CHANNEL.COLUMN] = -0.01;\n    } else if (opt.preferredFacet === CHANNEL.COLUMN) {\n      // penalize the other axis\n      score[CHANNEL.ROW] = -0.01;\n    }\n\n    return score;\n  }\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    return specM.getEncodings().reduce((features, encQ: EncodingQuery) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const featureScore = this.getFeatureScore(encQ.channel as string);\n        if (featureScore) {\n          features.push(featureScore);\n        }\n      }\n      return features;\n    }, []);\n  }\n}\n","import {Dict} from '../../util';\nimport {Scorer} from './base';\nimport {SpecQueryModel} from '../../model';\nimport {Schema} from '../../schema';\nimport {QueryConfig} from '../../config';\nimport {FeatureScore} from '../ranking';\nimport {isFieldQuery, isAutoCountQuery} from '../../query/encoding';\n\n/**\n * Effectivenss score that penalize size for bar and tick\n */\nexport class SizeChannelScorer extends Scorer {\n  constructor() {\n    super('SizeChannel');\n  }\n\n  protected initScore() {\n    return {\n      bar_size: -2,\n      tick_size: -2,\n    } as Dict<number>;\n  }\n\n  public getScore(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore[] {\n    const mark = specM.getMark();\n    return specM.getEncodings().reduce((featureScores, encQ) => {\n      if (isFieldQuery(encQ) || isAutoCountQuery(encQ)) {\n        const feature = `${mark}_${encQ.channel}`;\n        const featureScore = this.getFeatureScore(feature);\n        if (featureScore) {\n          featureScores.push(featureScore);\n        }\n      }\n      return featureScores;\n    }, []);\n  }\n}\n","import * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {EncodingQuery, isDimension, isEnabledAutoCountQuery, isFieldQuery} from '../query/encoding';\nimport {Schema} from '../schema';\nimport {some} from '../util';\nimport {FeatureScore, RankingScore} from './ranking';\n\nexport const name = 'aggregationQuality';\n\nexport function score(specM: SpecQueryModel, schema: Schema, opt: QueryConfig): RankingScore {\n  const feature = aggregationQualityFeature(specM, schema, opt);\n  return {\n    score: feature.score,\n    features: [feature],\n  };\n}\n\nfunction aggregationQualityFeature(specM: SpecQueryModel, _: Schema, __: QueryConfig): FeatureScore {\n  const encodings = specM.getEncodings();\n  if (specM.isAggregate()) {\n    const isRawContinuous = (encQ: EncodingQuery) => {\n      return (\n        isFieldQuery(encQ) &&\n        ((encQ.type === TYPE.QUANTITATIVE && !encQ.bin && !encQ.aggregate) ||\n          (encQ.type === TYPE.TEMPORAL && !encQ.timeUnit))\n      );\n    };\n\n    if (some(encodings, isRawContinuous)) {\n      // These are plots that pollute continuous fields as dimension.\n      // They are often intermediate visualizations rather than what users actually want.\n      return {\n        type: name,\n        score: 0.1,\n        feature: 'Aggregate with raw continuous',\n      };\n    }\n\n    if (some(encodings, (encQ) => isFieldQuery(encQ) && isDimension(encQ))) {\n      const hasCount = some(encodings, (encQ: EncodingQuery) => {\n        return (isFieldQuery(encQ) && encQ.aggregate === 'count') || isEnabledAutoCountQuery(encQ);\n      });\n      const hasBin = some(encodings, (encQ: EncodingQuery) => {\n        return isFieldQuery(encQ) && !!encQ.bin;\n      });\n\n      if (hasCount) {\n        // If there is count, we might add additional count field, making it a little less simple\n        // then when we just apply aggregate to Q field\n        return {\n          type: name,\n          score: 0.8,\n          feature: 'Aggregate with count',\n        };\n      } else if (hasBin) {\n        // This is not as good as binning all the Q and show heatmap\n        return {\n          type: name,\n          score: 0.7,\n          feature: 'Aggregate with bin but without count',\n        };\n      } else {\n        return {\n          type: name,\n          score: 0.9,\n          feature: 'Aggregate without count and without bin',\n        };\n      }\n    }\n    // no dimension -- often not very useful\n    return {\n      type: name,\n      score: 0.3,\n      feature: 'Aggregate without dimension',\n    };\n  } else {\n    if (some(encodings, (encQ) => isFieldQuery(encQ) && !isDimension(encQ))) {\n      // raw plots with measure -- simplest of all!\n      return {\n        type: name,\n        score: 1,\n        feature: 'Raw with measure',\n      };\n    }\n    // raw plots with no measure -- often a lot of occlusion\n    return {\n      type: name,\n      score: 0.2,\n      feature: 'Raw without measure',\n    };\n  }\n}\n","import {QueryConfig} from '../config';\nimport {SpecQueryModel} from '../model';\nimport {Schema} from '../schema';\nimport {isFieldQuery} from '../query/encoding';\n\nimport {RankingScore, FeatureScore} from './ranking';\n\nexport const name = 'fieldOrder';\n\n/**\n * Return ranking score based on indices of encoded fields in the schema.\n * If there are multiple fields, prioritize field on the lower indices of encodings.\n *\n * For example, to compare two specs with two encodings each,\n * first we compare the field on the 0-th index\n * and only compare the field on the 1-th index only if the fields on the 0-th index are the same.\n */\nexport function score(specM: SpecQueryModel, schema: Schema, _: QueryConfig): RankingScore {\n  const fieldWildcardIndices = specM.wildcardIndex.encodingIndicesByProperty.get('field');\n  if (!fieldWildcardIndices) {\n    return {\n      score: 0,\n      features: [],\n    };\n  }\n\n  const encodings = specM.specQuery.encodings;\n  const numFields = schema.fieldSchemas.length;\n\n  const features: FeatureScore[] = [];\n  let totalScore = 0;\n  let base = 1;\n\n  for (let i = fieldWildcardIndices.length - 1; i >= 0; i--) {\n    const index = fieldWildcardIndices[i];\n    const encoding = encodings[index];\n\n    // Skip ValueQuery as we only care about order of fields.\n    let field;\n\n    if (isFieldQuery(encoding)) {\n      field = encoding.field as string;\n    } else {\n      // ignore ValueQuery / AutoCountQuery\n      continue;\n    }\n\n    const fieldWildcard = specM.wildcardIndex.encodings[index].get('field');\n    const fieldIndex = schema.fieldSchema(field).index;\n    // reverse order field with lower index should get higher score and come first\n    const score = -fieldIndex * base;\n    totalScore += score;\n\n    features.push({\n      score: score,\n      type: 'fieldOrder',\n      feature: `field ${fieldWildcard.name} is ${field} (#${fieldIndex} in the schema)`,\n    });\n\n    base *= numFields;\n  }\n\n  return {\n    score: totalScore,\n    features: features,\n  };\n}\n","import {QueryConfig} from '../config';\nimport {SpecQueryModel, SpecQueryModelGroup} from '../model';\nimport {getTopResultTreeItem} from '../result';\nimport {Query} from '../query/query';\nimport {Dict} from '../util';\nimport {Schema} from '../schema';\nimport {effectiveness} from './effectiveness';\n\nexport * from './effectiveness';\nimport * as aggregation from './aggregation';\nimport * as fieldOrder from './fieldorder';\n\nexport {aggregation, fieldOrder};\n\nexport interface RankingScore {\n  score: number;\n  features: FeatureScore[];\n}\n\nexport interface FeatureScore {\n  score: number;\n  type: string;\n  feature: string;\n}\n\nexport interface FeatureInitializer {\n  (): Dict<number>;\n}\n\nexport interface Featurizer {\n  (specM: SpecQueryModel, schema: Schema, opt: QueryConfig): FeatureScore[];\n}\n\nexport interface FeatureFactory {\n  type: string;\n  init: FeatureInitializer;\n  getScore: Featurizer;\n}\n\nexport interface RankingFunction {\n  (specM: SpecQueryModel, schema: Schema, opt: QueryConfig): RankingScore;\n}\n\n/**\n * Registry for all encoding ranking functions\n */\nconst rankingRegistry: Dict<RankingFunction> = {};\n\n/**\n * Add an ordering function to the registry.\n */\nexport function register(name: string, keyFn: RankingFunction) {\n  rankingRegistry[name] = keyFn;\n}\n\nexport function get(name: string) {\n  return rankingRegistry[name];\n}\n\nexport function rank(group: SpecQueryModelGroup, query: Query, schema: Schema, level: number): SpecQueryModelGroup {\n  if (!query.nest || level === query.nest.length) {\n    if (query.orderBy || query.chooseBy) {\n      group.items.sort(comparatorFactory(query.orderBy || query.chooseBy, schema, query.config));\n      if (query.chooseBy) {\n        if (group.items.length > 0) {\n          // for chooseBy -- only keep the top-item\n          group.items.splice(1);\n        }\n      }\n    }\n  } else {\n    // sort lower-level nodes first because our ranking takes top-item in the subgroup\n    group.items.forEach((subgroup) => {\n      rank(subgroup as SpecQueryModelGroup, query, schema, level + 1);\n    });\n    if (query.nest[level].orderGroupBy) {\n      group.items.sort(groupComparatorFactory(query.nest[level].orderGroupBy, schema, query.config));\n    }\n  }\n  return group;\n}\n\nexport function comparatorFactory(name: string | string[], schema: Schema, opt: QueryConfig) {\n  return (m1: SpecQueryModel, m2: SpecQueryModel) => {\n    if (name instanceof Array) {\n      return getScoreDifference(name, m1, m2, schema, opt);\n    } else {\n      return getScoreDifference([name], m1, m2, schema, opt);\n    }\n  };\n}\n\nexport function groupComparatorFactory(\n  name: string | string[],\n  schema: Schema,\n  opt: QueryConfig\n): (g1: SpecQueryModelGroup, g2: SpecQueryModelGroup) => number {\n  return (g1: SpecQueryModelGroup, g2: SpecQueryModelGroup): number => {\n    const m1 = getTopResultTreeItem(g1);\n    const m2 = getTopResultTreeItem(g2);\n    if (name instanceof Array) {\n      return getScoreDifference(name, m1, m2, schema, opt);\n    } else {\n      return getScoreDifference([name], m1, m2, schema, opt);\n    }\n  };\n}\n\nfunction getScoreDifference(\n  name: string[],\n  m1: SpecQueryModel,\n  m2: SpecQueryModel,\n  schema: Schema,\n  opt: QueryConfig\n): number {\n  for (const rankingName of name) {\n    const scoreDifference = getScore(m2, rankingName, schema, opt).score - getScore(m1, rankingName, schema, opt).score;\n    if (scoreDifference !== 0) {\n      return scoreDifference;\n    }\n  }\n  return 0;\n}\n\nexport function getScore(model: SpecQueryModel, rankingName: string, schema: Schema, opt: QueryConfig) {\n  if (model.getRankingScore(rankingName) !== undefined) {\n    return model.getRankingScore(rankingName);\n  }\n  const fn = get(rankingName);\n  const score = fn(model, schema, opt);\n  model.setRankingScore(rankingName, score);\n  return score;\n}\n\nexport const EFFECTIVENESS = 'effectiveness';\nregister(EFFECTIVENESS, effectiveness);\n\nregister(aggregation.name, aggregation.score);\nregister(fieldOrder.name, fieldOrder.score);\n","import * as CHANNEL from 'vega-lite/build/src/channel';\nimport {hasDiscreteDomain} from 'vega-lite/build/src/scale';\nimport * as TYPE from 'vega-lite/build/src/type';\nimport {QueryConfig} from './config';\nimport {SpecQueryModel} from './model';\nimport {AxisQuery, EncodingQuery, isFieldQuery, ScaleQuery, scaleType} from './query/encoding';\nimport {ExpandedType} from './query/expandedtype';\nimport {Schema} from './schema';\nimport {Dict} from './util';\n\nexport function stylize(answerSet: SpecQueryModel[], schema: Schema, opt: QueryConfig): SpecQueryModel[] {\n  const encQIndex: Dict<EncodingQuery> = {};\n  answerSet = answerSet.map(function (specM) {\n    if (opt.smallRangeStepForHighCardinalityOrFacet) {\n      specM = smallRangeStepForHighCardinalityOrFacet(specM, schema, encQIndex, opt);\n    }\n\n    if (opt.nominalColorScaleForHighCardinality) {\n      specM = nominalColorScaleForHighCardinality(specM, schema, encQIndex, opt);\n    }\n\n    if (opt.xAxisOnTopForHighYCardinalityWithoutColumn) {\n      specM = xAxisOnTopForHighYCardinalityWithoutColumn(specM, schema, encQIndex, opt);\n    }\n    return specM;\n  });\n\n  return answerSet;\n}\n\nexport function smallRangeStepForHighCardinalityOrFacet(\n  specM: SpecQueryModel,\n  schema: Schema,\n  encQIndex: Dict<EncodingQuery>,\n  opt: QueryConfig\n): SpecQueryModel {\n  [CHANNEL.ROW, CHANNEL.Y, CHANNEL.COLUMN, CHANNEL.X].forEach((channel) => {\n    encQIndex[channel] = specM.getEncodingQueryByChannel(channel);\n  });\n\n  const yEncQ = encQIndex[CHANNEL.Y];\n  if (yEncQ !== undefined && isFieldQuery(yEncQ)) {\n    if (\n      encQIndex[CHANNEL.ROW] ||\n      schema.cardinality(yEncQ) > opt.smallRangeStepForHighCardinalityOrFacet.maxCardinality\n    ) {\n      // We check for undefined rather than\n      // yEncQ.scale = yEncQ.scale || {} to cover the case where\n      // yEncQ.scale has been set to false/null.\n      // This prevents us from incorrectly overriding scale and\n      // assigning a rangeStep when scale is set to false.\n      if (yEncQ.scale === undefined) {\n        yEncQ.scale = {};\n      }\n\n      // We do not want to assign a rangeStep if scale is set to false\n      // and we only apply this if the scale is (or can be) an ordinal scale.\n      const yScaleType = scaleType(yEncQ);\n      if (yEncQ.scale && (yScaleType === undefined || hasDiscreteDomain(yScaleType))) {\n        if (!specM.specQuery.height) {\n          specM.specQuery.height = {step: 12};\n        }\n      }\n    }\n  }\n\n  const xEncQ = encQIndex[CHANNEL.X];\n  if (isFieldQuery(xEncQ)) {\n    if (\n      encQIndex[CHANNEL.COLUMN] ||\n      schema.cardinality(xEncQ) > opt.smallRangeStepForHighCardinalityOrFacet.maxCardinality\n    ) {\n      // Just like y, we don't want to do this if scale is null/false\n      if (xEncQ.scale === undefined) {\n        xEncQ.scale = {};\n      }\n\n      // We do not want to assign a rangeStep if scale is set to false\n      // and we only apply this if the scale is (or can be) an ordinal scale.\n      const xScaleType = scaleType(xEncQ);\n      if (xEncQ.scale && (xScaleType === undefined || hasDiscreteDomain(xScaleType))) {\n        if (!specM.specQuery.width) {\n          specM.specQuery.width = {step: 12};\n        }\n      }\n    }\n  }\n\n  return specM;\n}\n\nexport function nominalColorScaleForHighCardinality(\n  specM: SpecQueryModel,\n  schema: Schema,\n  encQIndex: Dict<EncodingQuery>,\n  opt: QueryConfig\n): SpecQueryModel {\n  encQIndex[CHANNEL.COLOR] = specM.getEncodingQueryByChannel(CHANNEL.COLOR);\n\n  const colorEncQ = encQIndex[CHANNEL.COLOR];\n  if (\n    isFieldQuery(colorEncQ) &&\n    colorEncQ !== undefined &&\n    (colorEncQ.type === TYPE.NOMINAL || colorEncQ.type === ExpandedType.KEY) &&\n    schema.cardinality(colorEncQ) > opt.nominalColorScaleForHighCardinality.maxCardinality\n  ) {\n    if (colorEncQ.scale === undefined) {\n      colorEncQ.scale = {};\n    }\n\n    if (colorEncQ.scale) {\n      if (!(colorEncQ.scale as ScaleQuery).range) {\n        (colorEncQ.scale as ScaleQuery).scheme = opt.nominalColorScaleForHighCardinality.palette;\n      }\n    }\n  }\n\n  return specM;\n}\n\nexport function xAxisOnTopForHighYCardinalityWithoutColumn(\n  specM: SpecQueryModel,\n  schema: Schema,\n  encQIndex: Dict<EncodingQuery>,\n  opt: QueryConfig\n): SpecQueryModel {\n  [CHANNEL.COLUMN, CHANNEL.X, CHANNEL.Y].forEach((channel) => {\n    encQIndex[channel] = specM.getEncodingQueryByChannel(channel);\n  });\n\n  if (encQIndex[CHANNEL.COLUMN] === undefined) {\n    const xEncQ = encQIndex[CHANNEL.X];\n    const yEncQ = encQIndex[CHANNEL.Y];\n    if (\n      isFieldQuery(xEncQ) &&\n      isFieldQuery(yEncQ) &&\n      yEncQ !== undefined &&\n      yEncQ.field &&\n      hasDiscreteDomain(scaleType(yEncQ))\n    ) {\n      if (xEncQ !== undefined) {\n        if (schema.cardinality(yEncQ) > opt.xAxisOnTopForHighYCardinalityWithoutColumn.maxCardinality) {\n          if (xEncQ.axis === undefined) {\n            xEncQ.axis = {};\n          }\n\n          if (xEncQ.axis && !(xEncQ.axis as AxisQuery).orient) {\n            (xEncQ.axis as AxisQuery).orient = 'top';\n          }\n        }\n      }\n    }\n  }\n\n  return specM;\n}\n","import {QueryConfig, DEFAULT_QUERY_CONFIG} from './config';\nimport {getEnumerator} from './enumerator';\nimport {SpecQueryModel} from './model';\nimport {fromKey} from './property';\nimport {SpecQuery} from './query/spec';\nimport {Schema} from './schema';\nimport {stylize} from './stylize';\n\nexport function generate(specQ: SpecQuery, schema: Schema, opt: QueryConfig = DEFAULT_QUERY_CONFIG) {\n  // 1. Build a SpecQueryModel, which also contains wildcardIndex\n  const specM = SpecQueryModel.build(specQ, schema, opt);\n  const wildcardIndex = specM.wildcardIndex;\n\n  // 2. Enumerate each of the properties based on propPrecedence.\n\n  let answerSet = [specM]; // Initialize Answer Set with only the input spec query.\n  opt.propertyPrecedence.forEach((propKey) => {\n    const prop = fromKey(propKey);\n    // If the original specQuery contains wildcard for this prop\n    if (wildcardIndex.hasProperty(prop)) {\n      // update answerset\n      const enumerator = getEnumerator(prop);\n      const reducer = enumerator(wildcardIndex, schema, opt);\n      answerSet = answerSet.reduce(reducer, []);\n    }\n  });\n\n  if (opt.stylize) {\n    if (\n      opt.nominalColorScaleForHighCardinality !== null ||\n      opt.smallRangeStepForHighCardinalityOrFacet !== null ||\n      opt.xAxisOnTopForHighYCardinalityWithoutColumn !== null\n    ) {\n      return stylize(answerSet, schema, opt);\n    }\n  }\n\n  return answerSet;\n}\n","import {DEFAULT_QUERY_CONFIG, QueryConfig} from './config';\nimport {generate} from './generate';\nimport {SpecQueryModelGroup} from './model';\nimport {nest} from './nest';\nimport {normalize} from './query/normalize';\nimport {Query} from './query/query';\nimport {rank} from './ranking/ranking';\nimport {Schema} from './schema';\n\nexport function recommend(q: Query, schema: Schema, config?: QueryConfig): {query: Query; result: SpecQueryModelGroup} {\n  // 1. Normalize non-nested `groupBy` to always have `groupBy` inside `nest`\n  //    and merge config with the following precedence\n  //    query.config > config > DEFAULT_QUERY_CONFIG\n  q = {\n    ...normalize(q),\n    config: {\n      ...DEFAULT_QUERY_CONFIG,\n      ...config,\n      ...q.config,\n    },\n  };\n  // 2. Generate\n  const answerSet = generate(q.spec, schema, q.config);\n  const nestedAnswerSet = nest(answerSet, q.nest);\n  const result = rank(nestedAnswerSet, q, schema, 0);\n\n  return {\n    query: q,\n    result: result,\n  };\n}\n"]}